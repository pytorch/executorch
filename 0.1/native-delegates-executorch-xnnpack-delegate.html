


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>ExecuTorch XNNPACK delegate &mdash; ExecuTorch  documentation</title>
  

  
  
    <link rel="shortcut icon" href="_static/ExecuTorch-Logo-cropped.svg"/>
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="_static/progress-bar.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Introduction to the ExecuTorch SDK" href="sdk-overview.html" />
    <link rel="prev" title="Kernel Library Selective Build" href="kernel-library-selective-build.html" />


  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
    <!-- End Google Tag Manager -->
  


  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pytorch.org/executorch/versions.html'> &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="intro-overview.html">ExecuTorch Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="concepts.html">ExecuTorch Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro-how-it-works.html">How ExecuTorch Works</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="getting-started-architecture.html">High-level Architecture and Components of ExecuTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting-started-setup.html">Setting Up ExecuTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime-build-and-cross-compilation.html">Building with CMake</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tutorials/export-to-executorch-tutorial.html">Exporting to ExecuTorch Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="running-a-model-cpp-tutorial.html">Running an ExecuTorch Model in C++ Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/sdk-integration-tutorial.html">Using the ExecuTorch SDK to Profile a Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo-apps-ios.html">Building an ExecuTorch iOS Demo App</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo-apps-android.html">Building an ExecuTorch Android Demo App</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples-end-to-end-to-lower-model-to-delegate.html">Lowering a Model as a Delegate</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial-xnnpack-delegate-lowering.html">Building and Running ExecuTorch with XNNPACK Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="executorch-arm-delegate-tutorial.html">Building and Running ExecuTorch with ARM Ethos-U Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="build-run-coreml.html">Building and Running ExecuTorch with Core ML Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="build-run-mps.html">Building and Running ExecuTorch with MPS Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="build-run-qualcomm-ai-engine-direct-backend.html">Building and Running ExecuTorch with Qualcomm AI Engine Direct Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="build-run-xtensa.html">Building and Running ExecuTorch on Xtensa HiFi4 DSP</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Exporting to ExecuTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="export-overview.html">Exporting to ExecuTorch</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="export-to-executorch-api-reference.html">Export to ExecuTorch API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="executorch-runtime-api-reference.html">ExecuTorch Runtime API Reference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">IR Specification</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="ir-exir.html">Export IR Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="ir-ops-set-definition.html">Definition of the Core ATen Operator Set</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Compiler Entry Points</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="compiler-delegate-and-partitioner.html">Backend and Delegate</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiler-backend-dialect.html">Backend Dialect</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiler-custom-compiler-passes.html">Custom Compiler Passes and Partitioners</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiler-memory-planning.html">Memory Planning</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Runtime</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="runtime-overview.html">ExecuTorch Runtime Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime-backend-delegate-implementation-and-linking.html">Backend Delegate Implementation and Linking</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime-platform-abstraction-layer.html">Runtime Platform Abstraction Layer (PAL)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quantization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="quantization-overview.html">Quantization Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Kernel Library</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="kernel-library-overview.html">Overview of ExecuTorchâ€™s Kernel Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="kernel-library-custom-aten-kernel.html">Kernel Registration</a></li>
<li class="toctree-l1"><a class="reference internal" href="kernel-library-selective-build.html">Kernel Library Selective Build</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Native Delegates</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">ExecuTorch XNNPACK delegate</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">SDK</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="sdk-overview.html">Introduction to the ExecuTorch SDK</a></li>
<li class="toctree-l1"><a class="reference internal" href="sdk-bundled-io.html">Bundled Program â€“ a Tool for ExecuTorch Model Validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="sdk-etrecord.html">Prerequisite | ETRecord - ExecuTorch Record</a></li>
<li class="toctree-l1"><a class="reference internal" href="sdk-etdump.html">Prerequisite | ETDump - ExecuTorch Dump</a></li>
<li class="toctree-l1"><a class="reference internal" href="sdk-profiling.html">Profiling Models in ExecuTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="sdk-inspector.html">Inspector APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="sdk-delegate-integration.html">SDK Delegate Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="sdk-tutorial.html">SDK usage tutorial</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>ExecuTorch XNNPACK delegate</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="_sources/native-delegates-executorch-xnnpack-delegate.md.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        


          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="executorch-xnnpack-delegate">
<h1>ExecuTorch XNNPACK delegate<a class="headerlink" href="#executorch-xnnpack-delegate" title="Permalink to this headline">Â¶</a></h1>
<p>This is a high-level overview of the ExecuTorch XNNPACK backend delegate. This high performance delegate is aimed to reduce CPU inference latency for ExecuTorch models. We will provide a brief introduction to the XNNPACK library and explore the delegateâ€™s overall architecture and intended use cases.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>XNNPACK delegate is currently under active development, and may change in the future</p>
</div>
<div class="section" id="what-is-xnnpack">
<h2>What is XNNPACK?<a class="headerlink" href="#what-is-xnnpack" title="Permalink to this headline">Â¶</a></h2>
<p>XNNPACK is a library of highly-optimized neural network operators for ARM, x86, and WebAssembly architectures in Android, iOS, Windows, Linux, and macOS environments. It is an open source project, you can find more information about it on <a class="reference external" href="https://github.com/google/XNNPACK">github</a>.</p>
</div>
<div class="section" id="what-are-executorch-delegates">
<h2>What are ExecuTorch delegates?<a class="headerlink" href="#what-are-executorch-delegates" title="Permalink to this headline">Â¶</a></h2>
<p>A delegate is an entry point for backends to process and execute parts of the ExecuTorch program. Delegated portions of ExecuTorch models hand off execution to backends. The XNNPACK backend delegate is one of many available in ExecuTorch. It leverages the XNNPACK third-party library to accelerate ExecuTorch programs efficiently across a variety of CPUs. More detailed information on the delegates and developing your own delegates is available <a class="reference internal" href="compiler-delegate-and-partitioner.html"><span class="doc std std-doc">here</span></a>. It is recommended that you get familiar with that content before continuing on to the Architecture section.</p>
</div>
<div class="section" id="architecture">
<h2>Architecture<a class="headerlink" href="#architecture" title="Permalink to this headline">Â¶</a></h2>
<p><img alt="High Level XNNPACK delegate Architecture" src="_images/xnnpack-delegate-architecture.png" /></p>
<div class="section" id="ahead-of-time">
<h3>Ahead-of-time<a class="headerlink" href="#ahead-of-time" title="Permalink to this headline">Â¶</a></h3>
<p>In the ExecuTorch export flow, lowering to the XNNPACK delegate happens at the <code class="docutils literal notranslate"><span class="pre">to_backend()</span></code> stage. In this stage, the model is partitioned by the <code class="docutils literal notranslate"><span class="pre">XnnpackPartitioner</span></code>. Partitioned sections of the graph are converted to a XNNPACK specific graph represenationed and then serialized via flatbuffer. The serialized flatbuffer is then ready to be deserialized and executed by the XNNPACK backend at runtime.</p>
<p><img alt="ExecuTorch XNNPACK delegate Export Flow" src="_images/xnnpack-et-flow-diagram.png" /></p>
<div class="section" id="partitioner">
<h4>Partitioner<a class="headerlink" href="#partitioner" title="Permalink to this headline">Â¶</a></h4>
<p>The partitioner is implemented by backend delegates to mark nodes suitable for lowering. The <code class="docutils literal notranslate"><span class="pre">XnnpackPartitioner</span></code> lowers using node targets and module metadata. Some more references for partitioners can be found <a class="reference internal" href="compiler-delegate-and-partitioner.html"><span class="doc std std-doc">here</span></a></p>
<div class="section" id="module-based-partitioning">
<h5>Module-based partitioning<a class="headerlink" href="#module-based-partitioning" title="Permalink to this headline">Â¶</a></h5>
<p><code class="docutils literal notranslate"><span class="pre">source_fn</span></code> is embedded in the nodeâ€™s metadata and gives information on where these nodes come from. For example, modules like <code class="docutils literal notranslate"><span class="pre">torch.nn.Linear</span></code> when captured and exported <code class="docutils literal notranslate"><span class="pre">to_edge</span></code> generate groups of nodes for their computation. The group of nodes associated with computing the linear module then has a <code class="docutils literal notranslate"><span class="pre">source_fn</span></code> of <code class="docutils literal notranslate"><span class="pre">torch.nn.Linear.</span> <span class="pre">Partitioning</span> <span class="pre">based</span> <span class="pre">on</span> </code>source_fn` allows us to identify groups of nodes which are lowerable via XNNPACK.</p>
<p>For example after capturing <code class="docutils literal notranslate"><span class="pre">torch.nn.Linear</span></code> you would find the following key in the metadata for the addmm node associated with linear:</p>
<div class="highlight-none notranslate highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">linear_node</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s2">&quot;source_fn&quot;</span><span class="p">])</span>
<span class="go">&#39;source_fn&#39;: (&#39;fn&#39;, &lt;class &#39;torch.nn.modules.linear.Linear&#39;&gt;)</span>
</pre></div>
</div>
</div>
<div class="section" id="op-based-partitioning">
<h5>Op-based partitioning<a class="headerlink" href="#op-based-partitioning" title="Permalink to this headline">Â¶</a></h5>
<p>The <code class="docutils literal notranslate"><span class="pre">XnnpackPartitioner</span></code> also partitions using op targets. It traverses the graph and identifies individual nodes which are lowerable to XNNPACK. A drawback to module-based partitioning is that operators which come from <a class="reference external" href="https://github.com/pytorch/pytorch/blob/main/torch/_decomp/decompositions.py">decompositions</a> may be skipped. For example, an operator like <code class="docutils literal notranslate"><span class="pre">torch.nn.Hardsigmoid</span></code> is decomposed into add, muls, divs, and clamps. While hardsigmoid is not lowerable, we can lower the decomposed ops. Relying on <code class="docutils literal notranslate"><span class="pre">source_fn</span></code> metadata would skip these lowerables because they belong to a non-lowerable module, so in order to improve model performance, we greedily lower operators based on the op targets as well as the <code class="docutils literal notranslate"><span class="pre">source_fn</span></code>.</p>
</div>
<div class="section" id="passes">
<h5>Passes<a class="headerlink" href="#passes" title="Permalink to this headline">Â¶</a></h5>
<p>Before any serialization, we apply passes on the subgraphs to prepare the graph. These passes are essentially graph transformations that help improve the performance of the delegate. We give an overview of the most significant passes and their function below. For a description of all passes see <a class="reference external" href="https://github.com/pytorch/executorch/tree/main/backends/xnnpack/passes">here</a>:</p>
<ul class="simple">
<li><p>Channels Last Reshape</p>
<ul>
<li><p>ExecuTorch tensors tend to be contiguous before passing them into delegates, while XNNPACK only accepts channels-last memory layout. This pass minimizes the number of permutation operators inserted to pass in channels-last memory format.</p></li>
</ul>
</li>
<li><p>Conv1d to Conv2d</p>
<ul>
<li><p>Allows us to delegate Conv1d nodes by transforming them to Conv2d</p></li>
</ul>
</li>
<li><p>Conv and BN Fusion</p>
<ul>
<li><p>Fuses batch norm operations with the previous convolution node</p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="serialiazation">
<h4>Serialiazation<a class="headerlink" href="#serialiazation" title="Permalink to this headline">Â¶</a></h4>
<p>After partitioning the lowerable subgraphs from the model, The XNNPACK delegate pre-processes these subgraphs and serializes them via flatbuffer for the XNNPACK backend.</p>
<div class="section" id="serialization-schema">
<h5>Serialization Schema<a class="headerlink" href="#serialization-schema" title="Permalink to this headline">Â¶</a></h5>
<p>The XNNPACK delegate uses flatbuffer for serialization. In order to improve runtime performance, the XNNPACK delegateâ€™s flatbuffer <a class="reference external" href="https://github.com/pytorch/executorch/blob/main/backends/xnnpack/serialization/schema.fbs">schema</a> mirrors the XNNPACK Libraryâ€™s graph level API calls. The serialized data are arguments to XNNPACKâ€™s APIs, so that at runtime, the XNNPACK execution graph can efficiently be created with successive calls to XNNPACKâ€™s APIs.</p>
</div>
</div>
</div>
<div class="section" id="runtime">
<h3>Runtime<a class="headerlink" href="#runtime" title="Permalink to this headline">Â¶</a></h3>
<p>The XNNPACK backendâ€™s runtime interfaces with the ExecuTorch runtime through the custom <code class="docutils literal notranslate"><span class="pre">init</span></code> and <code class="docutils literal notranslate"><span class="pre">execute</span></code> function. Each delegated subgraph is contained in an individually serialized XNNPACK blob. When the model is initialized, ExecuTorch calls <code class="docutils literal notranslate"><span class="pre">init</span></code> on all XNNPACK Blobs to load the subgraph from serialized flatbuffer. After, when the model is executed, each subgraph is executed via the backend through the custom <code class="docutils literal notranslate"><span class="pre">execute</span></code> function. To read more about how delegate runtimes interface with ExecuTorch, refer to this <a class="reference internal" href="compiler-delegate-and-partitioner.html"><span class="doc std std-doc">resource</span></a>.</p>
<div class="section" id="xnnpack-library">
<h4>XNNPACK Library<a class="headerlink" href="#xnnpack-library" title="Permalink to this headline">Â¶</a></h4>
<p>The XNNPACK Library currently used by the delegate is on the following <a class="reference external" href="https://github.com/google/XNNPACK/tree/51a987591a6fc9f0fc0707077f53d763ac132cbf">version</a>. XNNPACK delegate supports CPUâ€™s on multiple platforms; more information on the supported hardware architectures can be found on the XNNPACK Libraryâ€™s <a class="reference external" href="https://github.com/google/XNNPACK">README</a>.</p>
</div>
<div class="section" id="init">
<h4>Init<a class="headerlink" href="#init" title="Permalink to this headline">Â¶</a></h4>
<p>When calling XNNPACK delegateâ€™s <code class="docutils literal notranslate"><span class="pre">init</span></code>, we deserialize the preprocessed blobs via flatbuffer. We define the nodes (operators) and edges (intermediate tensors) to build the XNNPACK execution graph using the information we serialized ahead-of-time. As we mentioned earlier, the majority of processing has been done ahead-of-time, so that at runtime we can just call the XNNPACK APIs with the serialized arguments in succession. As we define static data into the execution graph, XNNPACK performs weight packing at runtime to prepare static data like weights and biases for efficient execution. After creating the execution graph, we create the runtime object and pass it on to <code class="docutils literal notranslate"><span class="pre">execute</span></code>.</p>
<p>Since weight packing creates an extra copy of the weights inside XNNPACK, We free the original copy of the weights inside the preprocessed XNNPACK Blob, this allows us to remove some of the memory overhead.</p>
</div>
<div class="section" id="execute">
<h4>Execute<a class="headerlink" href="#execute" title="Permalink to this headline">Â¶</a></h4>
<p>When executing the XNNPACK subgraphs, we prepare the tensor inputs and outputs and feed them to the XNNPACK runtime graph. After executing the runtime graph, the output pointers are filled with the computed tensors.</p>
</div>
<div class="section" id="profiling">
<h4>Profiling<a class="headerlink" href="#profiling" title="Permalink to this headline">Â¶</a></h4>
<p>We have enabled basic profiling for XNNPACK delegate that can be enabled with the following compiler flag <code class="docutils literal notranslate"><span class="pre">-DENABLE_XNNPACK_PROFILING</span></code>. After running the model it will produce basic per-op and total timings. We provide an example of the profiling below. The timings listed are the average across runs, and the units are in microseconds.</p>
<div class="highlight-none notranslate highlight-default"><div class="highlight"><pre><span></span><span class="n">Fully</span> <span class="n">Connected</span> <span class="p">(</span><span class="n">NC</span><span class="p">,</span> <span class="n">F32</span><span class="p">)</span> <span class="n">GEMM</span><span class="p">:</span> <span class="mf">109.510002</span>
<span class="n">Total</span> <span class="n">Time</span><span class="p">:</span> <span class="mf">109.510002</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Profiling is a work in progress, and is planned to be integrated with <a class="reference internal" href="sdk-delegate-integration.html"><span class="doc std std-doc">SDK Tools</span></a> and Tensorboard.</p>
</div>
</div>
</div>
</div>
<div class="section" id="quantization">
<h2>Quantization<a class="headerlink" href="#quantization" title="Permalink to this headline">Â¶</a></h2>
<p>The XNNPACK delegate can also be used as a backend to execute symmetrically quantized models. For quantized model delegation, we quantize models using the <code class="docutils literal notranslate"><span class="pre">XNNPACKQuantizer</span></code>. <code class="docutils literal notranslate"><span class="pre">Quantizers</span></code> are backend specific, which means the <code class="docutils literal notranslate"><span class="pre">XNNPACKQuantizer</span></code> is configured to quantize models to leverage the quantized operators offered by the XNNPACK Library. We will not go over the details of how to implement your custom quantizer, you can follow the docs <a class="reference external" href="https://pytorch.org/tutorials/prototype/pt2e_quantizer.html">here</a> to do so. However, we will provide a brief overview of how to quantize the model to leverage quantized execution of the XNNPACK delegate.</p>
<div class="section" id="configuring-the-xnnpackquantizer">
<h3>Configuring the XNNPACKQuantizer<a class="headerlink" href="#configuring-the-xnnpackquantizer" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-none notranslate highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.ao.quantization.quantizer.xnnpack_quantizer</span> <span class="kn">import</span> <span class="p">(</span>
  <span class="n">XNNPACKQuantizer</span><span class="p">,</span>
  <span class="n">get_symmetric_quantization_config</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">quantizer</span> <span class="o">=</span> <span class="n">XNNPACKQuantizer</span><span class="p">()</span>
<span class="n">quantizer</span><span class="o">.</span><span class="n">set_global</span><span class="p">(</span><span class="n">get_symmetric_quantization_config</span><span class="p">())</span>
</pre></div>
</div>
<p>Here we initialize the <code class="docutils literal notranslate"><span class="pre">XNNPACKQuantizer</span></code> and set the quantization config to be symmetrically quantized. Symmetric quantization is when weights are symmetrically quantized with <code class="docutils literal notranslate"><span class="pre">qmin</span> <span class="pre">=</span> <span class="pre">-127</span></code> and <code class="docutils literal notranslate"><span class="pre">qmax</span> <span class="pre">=</span> <span class="pre">127</span></code>, which forces the quantization zeropoints to be zero. <code class="docutils literal notranslate"><span class="pre">get_symmetric_quantization_config()</span></code> can be configured with the following arguments:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">is_per_channel</span></code></p>
<ul>
<li><p>Weights are quantized across channels</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">is_qat</span></code></p>
<ul>
<li><p>Quantize aware training</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">is_dynamic</span></code></p>
<ul>
<li><p>Dynamic quantization</p></li>
</ul>
</li>
</ul>
<p>We can then configure the <code class="docutils literal notranslate"><span class="pre">XNNPACKQuantizer</span></code> as we wish. We set the following configs below as an example:</p>
<div class="highlight-none notranslate highlight-python"><div class="highlight"><pre><span></span><span class="n">quantizer</span><span class="o">.</span><span class="n">set_global</span><span class="p">(</span><span class="n">quantization_config</span><span class="p">)</span>
    <span class="o">.</span><span class="n">set_object_type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">,</span> <span class="n">quantization_config</span><span class="p">)</span> <span class="c1"># can configure by module type</span>
    <span class="o">.</span><span class="n">set_object_type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">linear</span><span class="p">,</span> <span class="n">quantization_config</span><span class="p">)</span> <span class="c1"># or torch functional op typea</span>
    <span class="o">.</span><span class="n">set_module_name</span><span class="p">(</span><span class="s2">&quot;foo.bar&quot;</span><span class="p">,</span> <span class="n">quantization_config</span><span class="p">)</span>  <span class="c1"># or by module fully qualified name</span>
</pre></div>
</div>
</div>
<div class="section" id="quantizing-your-model-with-the-xnnpackquantizer">
<h3>Quantizing your model with the XNNPACKQuantizer<a class="headerlink" href="#quantizing-your-model-with-the-xnnpackquantizer" title="Permalink to this headline">Â¶</a></h3>
<p>After configuring our quantizer, we are now ready to quantize our model</p>
<div class="highlight-none notranslate highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch._export</span> <span class="kn">import</span> <span class="n">capture_pre_autograd_graph</span>

<span class="n">exported_model</span> <span class="o">=</span> <span class="n">capture_pre_autograd_graph</span><span class="p">(</span><span class="n">model_to_quantize</span><span class="p">,</span> <span class="n">example_inputs</span><span class="p">)</span>
<span class="n">prepared_model</span> <span class="o">=</span> <span class="n">prepare_pt2e</span><span class="p">(</span><span class="n">exported_model</span><span class="p">,</span> <span class="n">quantizer</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">prepared_model</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
<p>Prepare performs some Conv2d-BN fusion, and inserts quantization observers in the appropriate places. For Post-Training Quantization, we generally calibrate our model after this step. We run sample examples through the <code class="docutils literal notranslate"><span class="pre">prepared_model</span></code> to observe the statistics of the Tensors to calculate the quantization parameters.</p>
<p>Finally, we convert our model here:</p>
<div class="highlight-none notranslate highlight-python"><div class="highlight"><pre><span></span><span class="n">quantized_model</span> <span class="o">=</span> <span class="n">convert_pt2e</span><span class="p">(</span><span class="n">prepared_model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">quantized_model</span><span class="p">)</span>
</pre></div>
</div>
<p>You will now see the Q/DQ representation of the model, which means <code class="docutils literal notranslate"><span class="pre">torch.ops.quantized_decomposed.dequantize_per_tensor</span></code> are inserted at quantized operator inputs and <code class="docutils literal notranslate"><span class="pre">torch.ops.quantized_decomposed.quantize_per_tensor</span></code> are inserted at operator outputs. Example:</p>
<div class="highlight-none notranslate highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_qdq_quantized_linear</span><span class="p">(</span>
    <span class="n">x_i8</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">x_zero_point</span><span class="p">,</span> <span class="n">x_quant_min</span><span class="p">,</span> <span class="n">x_quant_max</span><span class="p">,</span>
    <span class="n">weight_i8</span><span class="p">,</span> <span class="n">weight_scale</span><span class="p">,</span> <span class="n">weight_zero_point</span><span class="p">,</span> <span class="n">weight_quant_min</span><span class="p">,</span> <span class="n">weight_quant_max</span><span class="p">,</span>
    <span class="n">bias_fp32</span><span class="p">,</span>
    <span class="n">out_scale</span><span class="p">,</span> <span class="n">out_zero_point</span><span class="p">,</span> <span class="n">out_quant_min</span><span class="p">,</span> <span class="n">out_quant_max</span>
<span class="p">):</span>
    <span class="n">x_fp32</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">quantized_decomposed</span><span class="o">.</span><span class="n">dequantize_per_tensor</span><span class="p">(</span>
        <span class="n">x_i8</span><span class="p">,</span> <span class="n">x_scale</span><span class="p">,</span> <span class="n">x_zero_point</span><span class="p">,</span> <span class="n">x_quant_min</span><span class="p">,</span> <span class="n">x_quant_max</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
    <span class="n">weight_fp32</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">quantized_decomposed</span><span class="o">.</span><span class="n">dequantize_per_tensor</span><span class="p">(</span>
        <span class="n">weight_i8</span><span class="p">,</span> <span class="n">weight_scale</span><span class="p">,</span> <span class="n">weight_zero_point</span><span class="p">,</span> <span class="n">weight_quant_min</span><span class="p">,</span> <span class="n">weight_quant_max</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
    <span class="n">out_fp32</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">default</span><span class="p">(</span><span class="n">x_fp32</span><span class="p">,</span> <span class="n">weight_fp32</span><span class="p">,</span> <span class="n">bias_fp32</span><span class="p">)</span>
    <span class="n">out_i8</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">quantized_decomposed</span><span class="o">.</span><span class="n">quantize_per_tensor</span><span class="p">(</span>
        <span class="n">out_fp32</span><span class="p">,</span> <span class="n">out_scale</span><span class="p">,</span> <span class="n">out_zero_point</span><span class="p">,</span> <span class="n">out_quant_min</span><span class="p">,</span> <span class="n">out_quant_max</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out_i8</span>
</pre></div>
</div>
<p>You can read more indepth explanations on PyTorch 2 quantization <a class="reference external" href="https://pytorch.org/tutorials/prototype/pt2e_quant_ptq.html">here</a>.</p>
</div>
</div>
<div class="section" id="see-also">
<h2>See Also<a class="headerlink" href="#see-also" title="Permalink to this headline">Â¶</a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="demo-apps-android.html"><span class="doc std std-doc">Integrating XNNPACK Delegate Android App</span></a></p></li>
<li><p><a class="reference internal" href="tutorial-xnnpack-delegate-lowering.html"><span class="doc std std-doc">Complete the Lowering to XNNPACK Tutorial</span></a></p></li>
</ul>
</div>
</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="sdk-overview.html" class="btn btn-neutral float-right" title="Introduction to the ExecuTorch SDK" accesskey="n" rel="next">Next <img src="_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="kernel-library-selective-build.html" class="btn btn-neutral" title="Kernel Library Selective Build" accesskey="p" rel="prev"><img src="_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2023, ExecuTorch.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>


        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">ExecuTorch XNNPACK delegate</a><ul>
<li><a class="reference internal" href="#what-is-xnnpack">What is XNNPACK?</a></li>
<li><a class="reference internal" href="#what-are-executorch-delegates">What are ExecuTorch delegates?</a></li>
<li><a class="reference internal" href="#architecture">Architecture</a><ul>
<li><a class="reference internal" href="#ahead-of-time">Ahead-of-time</a><ul>
<li><a class="reference internal" href="#partitioner">Partitioner</a><ul>
<li><a class="reference internal" href="#module-based-partitioning">Module-based partitioning</a></li>
<li><a class="reference internal" href="#op-based-partitioning">Op-based partitioning</a></li>
<li><a class="reference internal" href="#passes">Passes</a></li>
</ul>
</li>
<li><a class="reference internal" href="#serialiazation">Serialiazation</a><ul>
<li><a class="reference internal" href="#serialization-schema">Serialization Schema</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#runtime">Runtime</a><ul>
<li><a class="reference internal" href="#xnnpack-library">XNNPACK Library</a></li>
<li><a class="reference internal" href="#init">Init</a></li>
<li><a class="reference internal" href="#execute">Execute</a></li>
<li><a class="reference internal" href="#profiling">Profiling</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#quantization">Quantization</a><ul>
<li><a class="reference internal" href="#configuring-the-xnnpackquantizer">Configuring the XNNPACKQuantizer</a></li>
<li><a class="reference internal" href="#quantizing-your-model-with-the-xnnpackquantizer">Quantizing your model with the XNNPACKQuantizer</a></li>
</ul>
</li>
<li><a class="reference internal" href="#see-also">See Also</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
         <script src="_static/jquery.js"></script>
         <script src="_static/underscore.js"></script>
         <script src="_static/doctools.js"></script>
         <script src="_static/clipboard.min.js"></script>
         <script src="_static/copybutton.js"></script>
         <script src="_static/design-tabs.js"></script>
         <script src="_static/js/progress-bar.js"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(false);
      });
  </script>
 
<script script type="text/javascript">
  var collapsedSections = ['Introduction', 'Getting Started', 'Exporting to ExecuTorch', 'API Reference', 'IR Specification', 'Compiler Entry Points', 'Runtime', 'Quantization', 'Kernel Library', 'Native Delegates', 'SDK', 'Tutorials']
</script>

 
<script type="text/javascript">
  $(document).ready(function () {
    // Patch links on interactive tutorial pages to point
    // to the correct ExecuTorch URLs.
    var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
    if (downloadNote.length >= 1) {
      var tutorialUrl = $("#tutorial-type").text().substring($("#tutorial-type").text().indexOf("tutorials/") + 9); // 9 is the length of "tutorials/"
      var githubLink = "https://github.com/pytorch/executorch/blob/main/docs/source/tutorials_source" + tutorialUrl + ".py",
        notebookLink = $(".reference.download")[1].href,
        notebookDownloadPath = notebookLink.split('_downloads')[1],
        colabLink = "https://colab.research.google.com/github/pytorch/executorch/blob/gh-pages/main/_downloads" + notebookDownloadPath;

      $(".pytorch-call-to-action-links a[data-response='Run in Google Colab']").attr("href", colabLink);
      $(".pytorch-call-to-action-links a[data-response='View on Github']").attr("href", githubLink);
    }

    // Patch the "GitHub" link at the top of the page
    // to point to the ExecuTorch repo.
    var overwrite = function (_) {
      if ($(this).length > 0) {
        $(this)[0].href = "https://github.com/pytorch/executorch"
      }
    }
    // PC
    $(".main-menu a:contains('GitHub')").each(overwrite);
    // Overwrite link to Tutorials and Get Started top navigation. If these sections are moved
    // this overrides need to be updated.
    $(".main-menu a:contains('Tutorials')").attr("href", "https://pytorch.org/executorch/stable/index.html#tutorials-and-examples");
    $(".main-menu a:contains('Get Started')").attr("href", "https://pytorch.org/executorch/stable/getting-started-setup.html");
    // Mobile
    $(".mobile-menu a:contains('Github')").each(overwrite);
    // Overwrite link to Tutorials and Get Started top navigation. If these sections are moved
    // this overrides need to be updated.
    $(".mobile-menu a:contains('Tutorials')").attr("href", "https://pytorch.org/executorch/stable/index.html#tutorials-and-examples");
    $(".mobile-menu a:contains('Get Started')").attr("href", "https://pytorch.org/executorch/stable/getting-started-setup.html");

  });
</script>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>Â© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>
            
          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>
            
           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>