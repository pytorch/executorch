{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Using the ExecuTorch Developer Tools for Numerical Debugging\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The [ExecuTorch Developer Tools](../devtools-overview.html)_ is a set of tools designed to\nprovide users with the ability to profile, debug, and visualize ExecuTorch\nmodels.\n\nThis tutorial will show a full end-to-end flow of how to utilize the Developer Tools to debug a model\nby detecting numerical discrepancies between the original PyTorch model and the ExecuTorch model.\n\nThe tutorial will show you how to:\n1. Check if the lowered ExecuTorch model is numerically correct.\n2. Gain a deeper understanding of where the numerical discrepancy comes from using the Inspector API.\n\nThis is particularly useful when working with delegated models (e.g., XNNPACK) where numerical\nprecision may differ. Specifically, it will:\n\n1. Generate the artifacts consumed by the Developer Tools ([ETRecord](../etrecord.html)_, [ETDump](../etdump.html)_).\n2. Run the model and compare final outputs between eager model and runtime.\n3. If discrepancies exist, use the Inspector's [calculate_numeric_gap](../model-inspector.html#calculate-numeric-gap)_ method to identify operator-level issues.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Currently operator-level debugging support is limited to ET-visible operators,\n   and treat every delegate call as a single operator.\n   We are working on expanding this support to dive into delegate operators.</p></div>\n\nWe provide two example debugging pipelines on xnnpack-delegated Vision Transformer (VIT) model:\n\n- **Python Pipeline**: Export, run, and debug entirely in Python using the ExecuTorch Runtime API.\n- **CMake Pipeline**: Export in Python, run with CMake example runner, then analyze in Python.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n\nTo run this tutorial, you'll first need to\n[Set up your ExecuTorch environment](../getting-started-setup.html)_.\n\nFor the Python pipeline, you'll need the ExecuTorch Python runtime bindings.\nFor the CMake pipeline, follow [these instructions](../runtime-build-and-cross-compilation.html#configure-the-cmake-build)_ to set up CMake.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pipeline 1: Python Runtime\n\nThis pipeline allows you to export, run, and debug your model entirely in Python,\nmaking it ideal for rapid iteration during development.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Export Model and Generate ETRecord\n\nFirst, we export the model and generate an ``ETRecord``. The ETRecord contains\nmodel graphs and metadata for linking runtime results to the eager model.\nWe use ``to_edge_transform_and_lower`` with ``generate_etrecord=True`` to\nautomatically capture the ETRecord during the lowering process.\n\n```python\nimport os\nimport tempfile\n\nimport torch\nfrom executorch.backends.xnnpack.partition.xnnpack_partitioner import XnnpackPartitioner\nfrom executorch.backends.xnnpack.utils.configs import get_xnnpack_edge_compile_config\nfrom executorch.exir import ExecutorchProgramManager, to_edge_transform_and_lower\nfrom torch.export import export, ExportedProgram\nfrom torchvision import models  # type: ignore[import-untyped]\n\n# Create Vision Transformer model\nvit = models.vision_transformer.vit_b_16(weights=\"IMAGENET1K_V1\")\nmodel = vit.eval()\nmodel_inputs = (torch.randn(1, 3, 224, 224),)\n\ntemp_dir = tempfile.mkdtemp()\n\n# Export and lower model to XNNPACK delegate\naten_model: ExportedProgram = export(model, model_inputs, strict=True)\nedge_program_manager = to_edge_transform_and_lower(\n    aten_model,\n    partitioner=[XnnpackPartitioner()],\n    compile_config=get_xnnpack_edge_compile_config(),\n    generate_etrecord=True,\n)\n\net_program_manager: ExecutorchProgramManager = edge_program_manager.to_executorch()\n\n# Save the .pte file\npte_path = os.path.join(temp_dir, \"model.pte\")\net_program_manager.save(pte_path)\n\n# Get and save ETRecord with representative inputs\netrecord = et_program_manager.get_etrecord()\netrecord.update_representative_inputs(model_inputs)\netrecord_path = os.path.join(temp_dir, \"etrecord.bin\")\netrecord.save(etrecord_path)\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>The ``update_representative_inputs`` method is crucial for debugging.\n   It stores the inputs that will be used to compute reference outputs\n   from the exported program, which are then compared against the runtime outputs.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Run Model and Generate ETDump with Debug Buffer\n\nNext, we run the model using the ExecuTorch Python Runtime API with debug\noutput enabled. The debug buffer captures intermediate outputs from the\nruntime execution.\n\n```python\nfrom executorch.runtime import Method, Program, Runtime, Verification\n\n# Load and run the model with debug output enabled\net_runtime: Runtime = Runtime.get()\nprogram: Program = et_runtime.load_program(\n    pte_path,\n    verification=Verification.Minimal,\n    enable_etdump=True,\n    debug_buffer_size=1024 * 1024 * 1024,  # 1GB buffer\n)\n\nforward: Method = program.load_method(\"forward\")\nruntime_outputs = forward.execute(*model_inputs)\n\n# Save ETDump and debug buffer\netdump_path = os.path.join(temp_dir, \"etdump.etdp\")\ndebug_buffer_path = os.path.join(temp_dir, \"debug_buffer.bin\")\nprogram.write_etdump_result_to_file(etdump_path, debug_buffer_path)\n```\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>The debug buffer size should be large enough to hold all intermediate\n   outputs.\n   If the buffer is too small, some intermediate outputs may be truncated or error might be rasied.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Compare Final Outputs (Best Practice)\n\n**Best Practice**: Before diving into operator-level debugging, first compare\nthe final outputs between the eager model and the runtime model. This helps\nyou quickly determine if there are any numerical issues worth investigating.\n\n```python\n# Get eager model output\nwith torch.no_grad():\n    eager_output = model(*model_inputs)\n\n# Compare with runtime output\nif isinstance(runtime_outputs, (list, tuple)):\n    runtime_output = runtime_outputs[0]\nelse:\n    runtime_output = runtime_outputs\n\n# Calculate MSE between eager and runtime outputs\nmse = torch.mean((eager_output - runtime_output) ** 2).item()\nprint(f\"Final output MSE: {mse}\")\n\n# Check if outputs are close enough\nif torch.allclose(eager_output, runtime_output, rtol=1e-3, atol=1e-5):\n    print(\"Outputs match within tolerance!\")\nelse:\n    print(\"Outputs differ - proceeding with operator-level analysis...\")\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Operator-Level Debugging with calculate_numeric_gap\n\nIf the final outputs show discrepancies, use the Inspector's ``calculate_numeric_gap``\nmethod to identify which operators are contributing to the numerical differences.\n\n```python\nimport pandas as pd\nfrom executorch.devtools import Inspector\n\ninspector = Inspector(\n    etdump_path=etdump_path,\n    etrecord=etrecord_path,\n    debug_buffer_path=debug_buffer_path,\n)\n\npd.set_option(\"display.width\", 100000)\npd.set_option(\"display.max_columns\", None)\n\n# Calculate numerical gap using Mean Squared Error\ndf: pd.DataFrame = inspector.calculate_numeric_gap(\"MSE\")\nprint(df)\n```\nThe returned DataFrame contains columns for each operator including:\n\n- ``aot_ops``: The operators in the eager model graph\n- ``aot_intermediate_output``: Intermediate outputs from eager model\n- ``runtime_ops``: The operators executed at runtime (may show DELEGATE_CALL for delegated ops)\n- ``runtime_intermediate_output``: Intermediate outputs from runtime\n- ``gap``: The numerical gap (MSE) between eager and runtime outputs\n\nExample output:\n\n```text\n|    | aot_ops                                                         | aot_intermediate_output                            | runtime_ops                                        | runtime_intermediate_output                        | gap                        |\n|----|----------------------------------------------------------------|----------------------------------------------------|----------------------------------------------------|----------------------------------------------------| ---------------------------|\n| 0  | [conv2d]                                                        | [[[tensor([-0.0130,  0.0075, -0.0334, -0.0122,...  | [DELEGATE_CALL]                                    | [[[tensor([-0.0130,  0.0075, -0.0334, -0.0122,...  | [3.2530690555343034e-15]   |\n| 1  | [permute, cat, add, dropout]                                    | [[[tensor(-0.0024), tensor(0.0054), tensor(0.0...  | [DELEGATE_CALL]                                    | [[[tensor(-0.0024), tensor(0.0054), tensor(0.0...  | [3.2488685838924244e-15]   |\n...\n| 4  | [transpose, linear, unflatten, unsqueeze, tran...]              | [[[tensor(0.0045), tensor(-0.0084), tensor(0.0...  | [DELEGATE_CALL, DELEGATE_CALL, DELEGATE_CALL, ...] | [[tensor(0.0045), tensor(-0.0084), tensor(0.00...  | [0.00010033142876115867]   |\n...\n| 59 | [transpose_66, linear_44, unflatten_11, unsque...]              | [[[tensor(-0.3346), tensor(0.1540), tensor(-0....  | [DELEGATE_CALL, DELEGATE_CALL, DELEGATE_CALL, ...] | [[tensor(-0.3346), tensor(0.1540), tensor(-0.0...  | [0.02629170972698486]      |\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Analyze and Identify Problematic Operators\n\nOnce you have the numerical gaps, identify operators with significant\ndiscrepancies for further investigation.\n\n```python\n# Find operators with the largest discrepancies\ndf_sorted = df.sort_values(by=\"gap\", ascending=False, key=lambda x: x.apply(lambda y: y[0] if isinstance(y, list) else y))\n\nprint(\"Top 5 operators with largest numerical discrepancies:\")\nprint(df_sorted.head(5))\n\n# Filter for operators with gap above a threshold\nthreshold = 1e-4\nproblematic_ops = df[df[\"gap\"].apply(lambda x: x[0] > threshold if isinstance(x, list) else x > threshold)]\nprint(f\"\\nOperators with MSE > {threshold}:\")\nprint(problematic_ops)\n```\nExample output showing problematic operators in a ViT model:\n\n```text\nTop 5 operators with largest numerical discrepancies:\n                                              aot_ops                            aot_intermediate_output                                        runtime_ops                        runtime_intermediate_output                     gap\n59  [transpose_66, linear_44, unflatten_11, unsque...  [[[tensor(-0.3346), tensor(0.1540), tensor(-0....  [DELEGATE_CALL, DELEGATE_CALL, DELEGATE_CALL, ...  [[tensor(-0.3346), tensor(0.1540), tensor(-0.0...   [0.02629170972698486]\n24  [transpose_24, linear_16, unflatten_4, unsquee...  [[[tensor(0.0344), tensor(-0.0583), tensor(-0....  [DELEGATE_CALL, DELEGATE_CALL, DELEGATE_CALL, ...  [[tensor(0.0344), tensor(-0.0583), tensor(-0.0...  [0.010045093258604096]\n29  [transpose_30, linear_20, unflatten_5, unsquee...  [[[tensor(0.0457), tensor(0.0266), tensor(-0.0...  [DELEGATE_CALL, DELEGATE_CALL, DELEGATE_CALL, ...  [[tensor(0.0457), tensor(0.0266), tensor(-0.05...  [0.008497326594593926]\n34  [transpose_36, linear_24, unflatten_6, unsquee...  [[[tensor(-0.1336), tensor(-0.0154), tensor(-0...  [DELEGATE_CALL, DELEGATE_CALL, DELEGATE_CALL, ...  [[tensor(-0.1336), tensor(-0.0154), tensor(-0....  [0.007672668965640913]\n19  [transpose_18, linear_12, unflatten_3, unsquee...  [[[tensor(-0.0801), tensor(0.0458), tensor(-0....  [DELEGATE_CALL, DELEGATE_CALL, DELEGATE_CALL, ...  [[tensor(-0.0801), tensor(0.0458), tensor(-0.0...  [0.007446783635888463]\n\nOperators with MSE > 0.0001:\n                                              aot_ops                            aot_intermediate_output                                        runtime_ops                        runtime_intermediate_output                       gap\n4   [transpose, linear, unflatten, unsqueeze, tran...  [[[tensor(0.0045), tensor(-0.0084), tensor(0.0...  [DELEGATE_CALL, DELEGATE_CALL, DELEGATE_CALL, ...  [[tensor(0.0045), tensor(-0.0084), tensor(0.00...  [0.00010033142876115867]\n9   [transpose_6, linear_4, unflatten_1, unsqueeze...  [[[tensor(0.0113), tensor(-0.0737), tensor(-0....  [DELEGATE_CALL, DELEGATE_CALL, DELEGATE_CALL, ...  [[tensor(0.0113), tensor(-0.0737), tensor(-0.0...   [0.0005611182577030275]\n14  [transpose_12, linear_8, unflatten_2, unsqueez...  [[[tensor(-0.0476), tensor(-0.0941), tensor(-0...  [DELEGATE_CALL, DELEGATE_CALL, DELEGATE_CALL, ...  [[tensor(-0.0476), tensor(-0.0941), tensor(-0....    [0.004658652508649068]\n...\n```\nIn this example, we can see that the attention layers (transpose + linear + unflatten patterns)\nshow the largest numerical discrepancies, which is expected behavior for delegated operators\nusing different precision.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pipeline 2: CMake Runtime\n\nThis pipeline is useful when you want to test your model with the native\nC++ runtime or on platforms where Python bindings are not available.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Export Model and Generate ETRecord\n\nFirst, we export the model and generate an ``ETRecord``, same as step 1 of pipeline 1:\n\n```python\nimport os\nimport tempfile\n\nimport torch\nfrom executorch.backends.xnnpack.partition.xnnpack_partitioner import XnnpackPartitioner\nfrom executorch.backends.xnnpack.utils.configs import get_xnnpack_edge_compile_config\nfrom executorch.exir import ExecutorchProgramManager, to_edge_transform_and_lower\nfrom torch.export import export, ExportedProgram\nfrom torchvision import models  # type: ignore[import-untyped]\n\n# Create Vision Transformer model\nvit = models.vision_transformer.vit_b_16(weights=\"IMAGENET1K_V1\")\nmodel = vit.eval()\nmodel_inputs = (torch.randn(1, 3, 224, 224),)\n\ntemp_dir = tempfile.mkdtemp()\n\n# Export and lower model to XNNPACK delegate\naten_model: ExportedProgram = export(model, model_inputs, strict=True)\nedge_program_manager = to_edge_transform_and_lower(\n    aten_model,\n    partitioner=[XnnpackPartitioner()],\n    compile_config=get_xnnpack_edge_compile_config(),\n    generate_etrecord=True,\n)\n\net_program_manager: ExecutorchProgramManager = edge_program_manager.to_executorch()\n\n# Save the .pte file\npte_path = os.path.join(temp_dir, \"model.pte\")\net_program_manager.save(pte_path)\n\n# Get and save ETRecord with representative inputs\netrecord = et_program_manager.get_etrecord()\netrecord.update_representative_inputs(model_inputs)\netrecord_path = os.path.join(temp_dir, \"etrecord.bin\")\netrecord.save(etrecord_path)\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Create BundledProgram\n\nFor the CMake pipeline, we create a ``BundledProgram`` that packages the model\nwith sample inputs and expected outputs for testing. We reuse the\n``et_program_manager`` from Step 1.\n\n```python\nfrom executorch.devtools import BundledProgram\nfrom executorch.devtools.bundled_program.config import MethodTestCase, MethodTestSuite\nfrom executorch.devtools.bundled_program.serialize import (\n    serialize_from_bundled_program_to_flatbuffer,\n)\n\n# Define the method name and test inputs\n# IMPORTANT: Use the same inputs as etrecord.update_representative_inputs()\nm_name = \"forward\"\ntest_inputs = [model_inputs]\n\n# Create test cases by running the eager model to get expected outputs\nmethod_test_suites = [\n    MethodTestSuite(\n        method_name=m_name,\n        test_cases=[\n            MethodTestCase(inputs=inp, expected_outputs=model(*inp)) for inp in test_inputs\n        ],\n    )\n]\n\n# Generate BundledProgram using the existing et_program_manager\nbundled_program = BundledProgram(et_program_manager, method_test_suites)\n\n# Serialize BundledProgram to flatbuffer\nserialized_bundled_program = serialize_from_bundled_program_to_flatbuffer(\n    bundled_program\n)\nbundled_program_path = os.path.join(temp_dir, \"bundled_program.bpte\")\nwith open(bundled_program_path, \"wb\") as f:\n    f.write(serialized_bundled_program)\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Run with Devtool Example Runner\n\nThis step we will verify the final result and generate etdump for next\nstep usage by using devtool example runner.\n\nFirst, build the example runner with XNNPACK backend support:\n\n```bash\ncd /path/to/executorch\n./examples/devtools/build_example_runner.sh --xnnpack\n```\nwhere ``--xnnpack`` is a build flag that enables XNNPACK backend support.\nThen run the example runner with output verification and debug output enabled:\n\n```bash\ncmake-out/examples/devtools/example_runner \\\n    --bundled_program_path=/path/to/bundled_program.bpte \\\n    --output_verification \\\n    --dump_intermediate_outputs \\\n    --debug_buffer_size=1073741824\n```\nThe key flags are:\n\n- ``--output_verification``: Compare runtime outputs against the expected\n  outputs stored in the BundledProgram (uses rtol=1e-3, atol=1e-5)\n- ``--dump_intermediate_outputs``: Capture intermediate outputs for\n  operator-level debugging\n- ``--debug_buffer_size=<bytes>``: Size of debug buffer (1GB in this example)\n\nExample output on success:\n\n```text\nI 00:00:00.123456 executorch:example_runner.cpp:135] Model file bundled_program.bpte is loaded.\nI 00:00:00.123456 executorch:example_runner.cpp:145] Running method forward\nI 00:00:00.234567 executorch:example_runner.cpp:250] Model executed successfully.\nI 00:00:00.234567 executorch:example_runner.cpp:287] Model verified successfully.\n```\nIf verification fails (outputs don't match within tolerance), you'll see an error:\n\n```text\nE 00:00:00.234567 executorch:example_runner.cpp:287] Bundle verification failed with status 0x10\n```\nThis will also generate:\n\n- ``etdump.etdp``: The ETDump file containing execution trace (default path, configurable via ``--etdump_path``)\n- ``debug_output.bin``: The debug buffer containing intermediate outputs (default path, configurable via ``--debug_output_path``)\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Analyze Results in Python\n\nAfter running the model with the CMake runner, load the generated artifacts\nback into Python for analysis using the Inspector.\n\n```python\nfrom executorch.devtools import Inspector\n\netrecord_path = \"/path/to/etrecord.bin\"\netdump_path = \"/path/to/etdump.etdp\"\ndebug_buffer_path = \"/path/to/debug_output.bin\"\n\ninspector = Inspector(\n    etdump_path=etdump_path,\n    etrecord=etrecord_path,\n    debug_buffer_path=debug_buffer_path,\n)\n```\nThen use the same analysis techniques as in Pipeline 1:\n\n```python\nimport pandas as pd\n\n# Calculate numerical gaps\ndf = inspector.calculate_numeric_gap(\"MSE\")\n\n# Find problematic operators\ndf_sorted = df.sort_values(by=\"gap\", ascending=False,\n    key=lambda x: x.apply(lambda y: y[0] if isinstance(y, list) else y))\nprint(\"Top operators with largest gaps:\")\nprint(df_sorted.head(5))\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Best Practices for Debugging\n\n1. **Start with final outputs**: Always compare the final model output first\n   before diving into operator-level analysis. This saves time if outputs match.\n\n2. **Use appropriate thresholds**: Small numerical differences (< 1e-6) are\n   typically acceptable. Focus on operators with gaps > 1e-4.\n\n3. **Focus on delegated operators**: Numerical discrepancies are most common\n   in delegated operators (shown as ``DELEGATE_CALL``) due to different\n   precision handling in delegate backends.\n\n4. **Check accumulation patterns**: In transformer models, attention layers\n   often show larger gaps due to accumulated numerical differences across\n   many operations.\n\n5. **Use stack traces**: With ETRecord, you can trace operators back to the\n   original PyTorch source code for easier debugging using\n   ``event.stack_traces`` and ``event.module_hierarchy``.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n\nIn this tutorial, we learned how to use the ExecuTorch Developer Tools\nto debug numerical discrepancies in models. The key workflow is:\n\n1. Export the model with ETRecord generation enabled\n2. Run the model with debug buffer enabled (Python or CMake)\n3. **First** compare final outputs between eager and runtime models\n4. **If issues found**, use ``calculate_numeric_gap`` for operator-level analysis\n5. Identify and investigate operators with significant gaps\n\n### Links Mentioned\n\n- [ExecuTorch Developer Tools Overview](../devtools-overview.html)_\n- [ETRecord](../etrecord.html)_\n- [ETDump](../etdump.html)_\n- [Inspector](../model-inspector.html)_\n- [Model Debugging Guide](../model-debugging.html)_\n- [Profiling Tutorial](devtools-integration-tutorial.html)_\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}