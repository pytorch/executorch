name: nightly

on:
  schedule:
    - cron: 0 2 * * *
  push:
    tags:
      - ciflow/nightly/*
  pull_request:
    paths:
      - .github/workflows/nightly.yml
      - .ci/scripts/test_qnn_static_llm.sh
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}--${{ github.event.pull_request.number || github.sha }}-${{ github.event_name == 'workflow_dispatch' }}
  cancel-in-progress: true

jobs:
  update-pytorch-commit-hash:
    runs-on: ubuntu-latest
    environment: ${{ (github.event_name == 'schedule') && 'update-commit-hash' || '' }}
    steps:
      - name: update-pytorch-commit-hash
        uses: pytorch/test-infra/.github/actions/update-commit-hash@main
        if: ${{ github.event_name == 'schedule' }}
        with:
          repo-name: pytorch
          branch: main
          pin-folder: .ci/docker/ci_commit_pins
          test-infra-ref: main
          updatebot-token: ${{ secrets.UPDATEBOT_TOKEN }}
          pytorchbot-token: ${{ secrets.GH_PYTORCHBOT_TOKEN }}

  link-check:
    needs: update-pytorch-commit-hash
    uses: ./.github/workflows/_link_check.yml
    with:
      ref: ${{ github.sha }}
    
  test-static-hf-llm-qnn-linux:
    name: test-static-hf-llm-qnn-linux
    uses: pytorch/test-infra/.github/workflows/linux_job_v2.yml@main
    permissions:
      id-token: write
      contents: read
    strategy:
      matrix:
        task: [smollm2_135m, stories_110m]
      fail-fast: false
    with:
      runner: linux.24xlarge
      docker-image: ci-image:executorch-ubuntu-22.04-qnn-sdk
      submodules: 'recursive'
      ref: ${{ github.event_name == 'pull_request' && github.event.pull_request.head.sha || github.sha }}
      timeout: 900
      upload-artifact: qnn-llama-pte-${{ matrix.task }}
      script: |
        # The generic Linux job chooses to use base env, not the one setup by the image
        CONDA_ENV=$(conda env list --json | jq -r ".envs | .[-1]")
        conda activate "${CONDA_ENV}"

        BUILD_TOOL="cmake"

        PYTHON_EXECUTABLE=python bash .ci/scripts/setup-qnn-deps.sh
        PYTHON_EXECUTABLE=python bash .ci/scripts/build-qnn-sdk.sh

        # Setup executorch
        PYTHON_EXECUTABLE=python bash .ci/scripts/setup-linux.sh --build-tool "${BUILD_TOOL}"

        # Setup install_requirements for llama
        PYTHON_EXECUTABLE=python bash examples/models/llama/install_requirements.sh

        PYTHON_EXECUTABLE=python bash .ci/scripts/test_qnn_static_llm.sh ${{ matrix.task }}
