# Test ExecuTorch CUDA Build Compatibility
# This workflow tests whether ExecuTorch can be successfully built with CUDA support
# across different CUDA versions (12.6, 12.8, 12.9) using the command:
# CMAKE_ARGS="-DEXECUTORCH_BUILD_CUDA=ON" ./install_executorch.sh
#
# Note: ExecuTorch automatically detects the system CUDA version using nvcc and
# installs the appropriate PyTorch wheel. No manual CUDA/PyTorch installation needed.

name: Test CUDA Builds

on:
  pull_request:
  push:
    branches:
      - main
      - release/*

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.sha }}-${{ github.event_name == 'workflow_dispatch' }}-${{ github.event_name == 'schedule' }}
  cancel-in-progress: false

jobs:
  test-cuda-builds:
    strategy:
      fail-fast: false
      matrix:
        cuda-version: ["12.6", "12.8", "13.0"]

    name: test-executorch-cuda-build-${{ matrix.cuda-version }}
    uses: pytorch/test-infra/.github/workflows/linux_job_v2.yml@main
    permissions:
      id-token: write
      contents: read
    with:
      timeout: 90
      runner: linux.g5.4xlarge.nvidia.gpu
      gpu-arch-type: cuda
      gpu-arch-version: ${{ matrix.cuda-version }}
      use-custom-docker-registry: false
      submodules: recursive
      ref: ${{ github.event_name == 'pull_request' && github.event.pull_request.head.sha || github.sha }}
      script: |
        set -eux

        # Test ExecuTorch CUDA build - ExecuTorch will automatically detect CUDA version
        # and install the appropriate PyTorch wheel when CMAKE_ARGS="-DEXECUTORCH_BUILD_CUDA=ON"
        source .ci/scripts/test-cuda-build.sh "${{ matrix.cuda-version }}"

  # This job will fail if any of the CUDA versions fail
  check-all-cuda-builds:
    needs: test-cuda-builds
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Check if all CUDA builds succeeded
        run: |
          if [[ "${{ needs.test-cuda-builds.result }}" != "success" ]]; then
            echo "ERROR: One or more ExecuTorch CUDA builds failed!"
            echo "CUDA build results: ${{ needs.test-cuda-builds.result }}"
            exit 1
          else
            echo "SUCCESS: All ExecuTorch CUDA builds (12.6, 12.8, 12.9) completed successfully!"
          fi

  test-models-cuda:
    name: test-models-cuda
    uses: pytorch/test-infra/.github/workflows/linux_job_v2.yml@main
    permissions:
      id-token: write
      contents: read
    strategy:
      fail-fast: false
      matrix:
        model: [linear, add, add_mul, resnet18]
    with:
      timeout: 90
      runner: linux.g5.4xlarge.nvidia.gpu
      gpu-arch-type: cuda
      gpu-arch-version: 12.6
      use-custom-docker-registry: false
      submodules: recursive
      ref: ${{ github.event_name == 'pull_request' && github.event.pull_request.head.sha || github.sha }}
      script: |
        set -eux

        PYTHON_EXECUTABLE=python CMAKE_ARGS="-DEXECUTORCH_BUILD_CUDA=ON" ./install_executorch.sh
        export LD_LIBRARY_PATH=/opt/conda/lib:$LD_LIBRARY_PATH
        PYTHON_EXECUTABLE=python source .ci/scripts/test_model.sh "${{ matrix.model }}" cmake cuda
