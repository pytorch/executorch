name: S3 File Upload

# This workflow downloads a file from a given URL and uploads it to an S3 bucket.
#
# Usage (Manual Trigger):
#   1. Go to Actions tab -> S3 File Upload workflow
#   2. Click "Run workflow"
#   3. Provide:
#      - file_url: URL to download the file from (required)
#      - bucket_name: Name of the target S3 bucket (required)
#      - target_path: Optional path prefix (e.g., "folder/" or "folder/file.txt")
#      - acl: S3 ACL (default: private)
#
# Usage (Repository Dispatch):
#   curl -X POST \
#     -H "Accept: application/vnd.github.v3+json" \
#     -H "Authorization: token $GITHUB_TOKEN" \
#     https://api.github.com/repos/pytorch/executorch/dispatches \
#     -d '{"event_type":"s3-file-upload",
#          "client_payload":{
#            "file_url":"https://example.org/path-to-resource",
#            "bucket_name":"example-bucket",
#            "target_path":"folder/",
#            "acl":"private"
#          }}'
#
# AWS Prerequisites:
#   - AWS_ROLE_ARN secret must be configured with appropriate IAM role
#   - IAM role must have permissions to write to the target S3 bucket
#
# Security Features:
#   - Download timeout: 10 minutes max
#   - Max file size: 2GB
#   - Filename sanitization to prevent path traversal
#   - Default private ACL for uploaded files

on:
  workflow_dispatch:
    inputs:
      file_url:
        description: 'URL to download the file from'
        required: true
        type: string
      bucket_name:
        description: 'Name of the target S3 bucket'
        required: true
        type: string
      target_path:
        description: 'Optional path prefix inside the bucket'
        required: false
        type: string
        default: ''
      acl:
        description: 'S3 ACL for the uploaded file'
        required: false
        type: choice
        options:
          - 'private'
          - 'public-read'
          - 'bucket-owner-full-control'
        default: 'private'
  repository_dispatch:
    types: [s3-file-upload]

jobs:
  upload-file-to-s3:
    name: upload-file-to-s3
    runs-on: ubuntu-22.04
    timeout-minutes: 30
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download file from URL
        shell: bash
        run: |
          set -eux

          FILE_URL="${{ github.event.inputs.file_url || github.event.client_payload.file_url }}"

          if [ -z "$FILE_URL" ]; then
            echo "Error: file_url is required"
            exit 1
          fi

          echo "Downloading file from: $FILE_URL"

          # Extract and sanitize filename from URL
          FILENAME=$(basename "$FILE_URL" | sed 's/[^a-zA-Z0-9._-]/_/g')

          # Validate filename
          if [ -z "$FILENAME" ] || [ "$FILENAME" = "." ] || [ "$FILENAME" = ".." ]; then
            echo "Error: Invalid filename extracted from URL"
            exit 1
          fi

          # Download with security measures: timeout, max size, user-agent
          curl -L -o "$FILENAME" "$FILE_URL" \
            --max-time 600 \
            --max-filesize 2147483648 \
            --user-agent "GitHub-Actions-S3-Upload/1.0"

          # Verify file was downloaded
          if [ ! -f "$FILENAME" ]; then
            echo "Error: Failed to download file"
            exit 1
          fi

          FILE_SIZE=$(stat -c%s "$FILENAME" 2>/dev/null || \
            stat -f%z "$FILENAME" 2>/dev/null || echo "unknown")
          echo "Downloaded file: $FILENAME (size: $FILE_SIZE bytes)"

          # Save filename for next step
          echo "DOWNLOADED_FILENAME=$FILENAME" >> $GITHUB_ENV

      - name: Install AWS CLI
        shell: bash
        run: |
          set -eux

          # Check if aws cli is already installed
          if command -v aws &> /dev/null; then
            echo "AWS CLI is already installed"
            aws --version
          else
            echo "Installing AWS CLI"
            pip install awscli==1.32.18
            aws --version
          fi

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: us-east-1

      - name: Upload file to S3
        shell: bash
        run: |
          set -eux

          BUCKET_NAME="${{ github.event.inputs.bucket_name || github.event.client_payload.bucket_name }}"
          TARGET_PATH="${{ github.event.inputs.target_path || github.event.client_payload.target_path }}"
          FILENAME="${DOWNLOADED_FILENAME}"
          ACL="${{ github.event.inputs.acl || github.event.client_payload.acl || 'private' }}"

          if [ -z "$BUCKET_NAME" ]; then
            echo "Error: bucket_name is required"
            exit 1
          fi

          # Construct S3 path
          # If TARGET_PATH is empty, use just the filename
          # If TARGET_PATH ends with /, treat it as a directory prefix
          # Otherwise, use TARGET_PATH as the complete object key
          if [ -z "$TARGET_PATH" ]; then
            S3_PATH="s3://${BUCKET_NAME}/${FILENAME}"
            PUBLIC_URL_PATH="${FILENAME}"
          elif [[ "$TARGET_PATH" == */ ]]; then
            S3_PATH="s3://${BUCKET_NAME}/${TARGET_PATH}${FILENAME}"
            PUBLIC_URL_PATH="${TARGET_PATH}${FILENAME}"
          else
            S3_PATH="s3://${BUCKET_NAME}/${TARGET_PATH}"
            PUBLIC_URL_PATH="${TARGET_PATH}"
          fi

          echo "Uploading $FILENAME to $S3_PATH with ACL: $ACL"

          # Upload file to S3
          aws s3 cp "$FILENAME" "$S3_PATH" --acl "$ACL"

          echo "File uploaded successfully to $S3_PATH"

          # Generate and display the public URL (only meaningful for public-read)
          PUBLIC_URL="https://${BUCKET_NAME}.s3.amazonaws.com/${PUBLIC_URL_PATH}"
          echo "S3 URL: $PUBLIC_URL"
