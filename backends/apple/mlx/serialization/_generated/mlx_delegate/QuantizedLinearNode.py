# automatically generated by the FlatBuffers compiler, do not modify

# namespace: mlx_delegate

import flatbuffers
from flatbuffers.compat import import_numpy
np = import_numpy()

class QuantizedLinearNode(object):
    __slots__ = ['_tab']

    @classmethod
    def GetRootAs(cls, buf, offset=0):
        n = flatbuffers.encode.Get(flatbuffers.packer.uoffset, buf, offset)
        x = QuantizedLinearNode()
        x.Init(buf, n + offset)
        return x

    @classmethod
    def GetRootAsQuantizedLinearNode(cls, buf, offset=0):
        """This method is deprecated. Please switch to GetRootAs."""
        return cls.GetRootAs(buf, offset)
    # QuantizedLinearNode
    def Init(self, buf, pos):
        self._tab = flatbuffers.table.Table(buf, pos)

    # QuantizedLinearNode
    def X(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))
        if o != 0:
            x = o + self._tab.Pos
            from mlx_delegate.Tid import Tid
            obj = Tid()
            obj.Init(self._tab.Bytes, x)
            return obj
        return None

    # QuantizedLinearNode
    def W(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))
        if o != 0:
            x = o + self._tab.Pos
            from mlx_delegate.Tid import Tid
            obj = Tid()
            obj.Init(self._tab.Bytes, x)
            return obj
        return None

    # QuantizedLinearNode
    def Scales(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(8))
        if o != 0:
            x = o + self._tab.Pos
            from mlx_delegate.Tid import Tid
            obj = Tid()
            obj.Init(self._tab.Bytes, x)
            return obj
        return None

    # QuantizedLinearNode
    def Out(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(10))
        if o != 0:
            x = o + self._tab.Pos
            from mlx_delegate.Tid import Tid
            obj = Tid()
            obj.Init(self._tab.Bytes, x)
            return obj
        return None

    # QuantizedLinearNode
    def Biases(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(12))
        if o != 0:
            x = o + self._tab.Pos
            from mlx_delegate.Tid import Tid
            obj = Tid()
            obj.Init(self._tab.Bytes, x)
            return obj
        return None

    # QuantizedLinearNode
    def Bias(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(14))
        if o != 0:
            x = o + self._tab.Pos
            from mlx_delegate.Tid import Tid
            obj = Tid()
            obj.Init(self._tab.Bytes, x)
            return obj
        return None

    # QuantizedLinearNode
    def GroupSize(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(16))
        if o != 0:
            return self._tab.Get(flatbuffers.number_types.Int32Flags, o + self._tab.Pos)
        return 0

    # QuantizedLinearNode
    def Bits(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(18))
        if o != 0:
            return self._tab.Get(flatbuffers.number_types.Int32Flags, o + self._tab.Pos)
        return 0

    # QuantizedLinearNode
    def Mode(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(20))
        if o != 0:
            return self._tab.String(o + self._tab.Pos)
        return None

    # QuantizedLinearNode
    def OutDtype(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(22))
        if o != 0:
            return self._tab.Get(flatbuffers.number_types.Int8Flags, o + self._tab.Pos)
        return 0

def QuantizedLinearNodeStart(builder):
    builder.StartObject(10)

def Start(builder):
    QuantizedLinearNodeStart(builder)

def QuantizedLinearNodeAddX(builder, x):
    builder.PrependStructSlot(0, flatbuffers.number_types.UOffsetTFlags.py_type(x), 0)

def AddX(builder, x):
    QuantizedLinearNodeAddX(builder, x)

def QuantizedLinearNodeAddW(builder, w):
    builder.PrependStructSlot(1, flatbuffers.number_types.UOffsetTFlags.py_type(w), 0)

def AddW(builder, w):
    QuantizedLinearNodeAddW(builder, w)

def QuantizedLinearNodeAddScales(builder, scales):
    builder.PrependStructSlot(2, flatbuffers.number_types.UOffsetTFlags.py_type(scales), 0)

def AddScales(builder, scales):
    QuantizedLinearNodeAddScales(builder, scales)

def QuantizedLinearNodeAddOut(builder, out):
    builder.PrependStructSlot(3, flatbuffers.number_types.UOffsetTFlags.py_type(out), 0)

def AddOut(builder, out):
    QuantizedLinearNodeAddOut(builder, out)

def QuantizedLinearNodeAddBiases(builder, biases):
    builder.PrependStructSlot(4, flatbuffers.number_types.UOffsetTFlags.py_type(biases), 0)

def AddBiases(builder, biases):
    QuantizedLinearNodeAddBiases(builder, biases)

def QuantizedLinearNodeAddBias(builder, bias):
    builder.PrependStructSlot(5, flatbuffers.number_types.UOffsetTFlags.py_type(bias), 0)

def AddBias(builder, bias):
    QuantizedLinearNodeAddBias(builder, bias)

def QuantizedLinearNodeAddGroupSize(builder, groupSize):
    builder.PrependInt32Slot(6, groupSize, 0)

def AddGroupSize(builder, groupSize):
    QuantizedLinearNodeAddGroupSize(builder, groupSize)

def QuantizedLinearNodeAddBits(builder, bits):
    builder.PrependInt32Slot(7, bits, 0)

def AddBits(builder, bits):
    QuantizedLinearNodeAddBits(builder, bits)

def QuantizedLinearNodeAddMode(builder, mode):
    builder.PrependUOffsetTRelativeSlot(8, flatbuffers.number_types.UOffsetTFlags.py_type(mode), 0)

def AddMode(builder, mode):
    QuantizedLinearNodeAddMode(builder, mode)

def QuantizedLinearNodeAddOutDtype(builder, outDtype):
    builder.PrependInt8Slot(9, outDtype, 0)

def AddOutDtype(builder, outDtype):
    QuantizedLinearNodeAddOutDtype(builder, outDtype)

def QuantizedLinearNodeEnd(builder):
    return builder.EndObject()

def End(builder):
    return QuantizedLinearNodeEnd(builder)
