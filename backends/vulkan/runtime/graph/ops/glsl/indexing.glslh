/*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 * All rights reserved.
 *
 * This source code is licensed under the BSD-style license found in the
 * LICENSE file in the root directory of this source tree.
 */

#ifndef INDEXING_GLSLH
#define INDEXING_GLSLH

#define DIMLIMIT 8
#define DIMLIMIT_DIV4 2

#define mul_4(x) ((x) << 2)
#define div_4(x) ((x) >> 2)

#define mod_4(x) ((x) & 3)

//
// BufferMetadata
//

struct BufferMetadata {
  uvec4 sizes[DIMLIMIT_DIV4];
  uvec4 dim_order[DIMLIMIT_DIV4];
  uvec4 strides[DIMLIMIT_DIV4];
  uvec2 ndim_numel;
};

uint ndim(const BufferMetadata meta) {
  return meta.ndim_numel[0];
}

int int_ndim(const BufferMetadata meta) {
  return int(meta.ndim_numel[0]);
}

uint numel(const BufferMetadata meta) {
  return meta.ndim_numel[1];
}

uint dim_order_at(const BufferMetadata meta, const int dim) {
  return meta.dim_order[div_4(dim)][mod_4(dim)];
}

uint dim_order_at(const BufferMetadata meta, const uint dim) {
  return meta.dim_order[div_4(dim)][mod_4(dim)];
}

uint stride_at(const BufferMetadata meta, const int dim) {
  return meta.strides[div_4(dim)][mod_4(dim)];
}

uint stride_at(const BufferMetadata meta, const uint dim) {
  return meta.strides[div_4(dim)][mod_4(dim)];
}

uint size_at(const BufferMetadata meta, const int dim) {
  return meta.sizes[div_4(dim)][mod_4(dim)];
}

uint size_at(const BufferMetadata meta, const uint dim) {
  return meta.sizes[div_4(dim)][mod_4(dim)];
}

bool are_equal(const BufferMetadata meta1, const BufferMetadata meta2) {
  // sizes and strides must be the same to be considered equal
  if (meta1.sizes[0] != meta2.sizes[0]) {
    return false;
  }
  if (meta1.sizes[1] != meta2.sizes[1]) {
    return false;
  }
  if (meta1.strides[0] != meta2.strides[0]) {
    return false;
  }
  if (meta1.strides[1] != meta2.strides[1]) {
    return false;
  }
  return true;
}

//
// TensorIndex
//

struct TensorIndex {
  uvec4 data[DIMLIMIT_DIV4];
};

void initialize(out TensorIndex tidx) {
  tidx.data[0] = uvec4(0);
  tidx.data[1] = uvec4(0);
}

uint idx_at(const TensorIndex tidx, const int dim) {
  return tidx.data[div_4(dim)][mod_4(dim)];
}

void permute(inout TensorIndex tidx, const ivec4 permute_order[DIMLIMIT_DIV4]) {
  TensorIndex new_tidx = tidx;
  for (int d = 0; d < DIMLIMIT; ++d) {
    int src_dim = permute_order[div_4(d)][mod_4(d)];
    new_tidx.data[div_4(d)][mod_4(d)] = idx_at(tidx, src_dim);
  }
  tidx = new_tidx;
}

//
// Index Conversions
//

void contiguous_idx_to_tensor_idx(
    const BufferMetadata meta,
    uint contiguous_idx,
    out TensorIndex tidx) {
  initialize(tidx);
  int dim = int_ndim(meta);
  int i = 0;

  uint contiguous_strides[DIMLIMIT];
  contiguous_strides[0] = 1;
  for (int d = 1; d < DIMLIMIT; ++d) {
    contiguous_strides[d] = size_at(meta, d - 1) * contiguous_strides[d - 1];
  }

  for (int d = max(dim - 1, 0); d >= 0; d--) {
    uint dim_stride = contiguous_strides[d];

    tidx.data[div_4(d)][mod_4(d)] = contiguous_idx / dim_stride;
    contiguous_idx = contiguous_idx % dim_stride;
  }
}

uint tensor_idx_to_contiguous_idx(
    const BufferMetadata meta,
    const TensorIndex tidx) {
  uint contiguous_strides[DIMLIMIT];
  contiguous_strides[0] = 1;
  for (int d = 1; d < DIMLIMIT; ++d) {
    contiguous_strides[d] = size_at(meta, d - 1) * contiguous_strides[d - 1];
  }

  uint contig_idx = 0;
  for (int d = 0; d < ndim(meta); ++d) {
    contig_idx += contiguous_strides[d] * idx_at(tidx, d);
  }
  return contig_idx;
}

void linear_idx_to_tensor_idx(
    const BufferMetadata meta,
    uint linear_idx,
    out TensorIndex tidx) {
  initialize(tidx);
  int dim = int_ndim(meta);
  int i = 0;
  for (int d = max(dim - 1, 0); d >= 0; d--) {
    uint dim_idx = dim_order_at(meta, d);
    uint dim_stride = stride_at(meta, dim_idx);

    tidx.data[div_4(dim_idx)][mod_4(dim_idx)] = linear_idx / dim_stride;
    linear_idx = linear_idx % dim_stride;
  }
}

uint tensor_idx_to_linear_idx(
    const BufferMetadata meta,
    const TensorIndex tidx) {
  uint lin_idx = 0;
  for (int d = 0; d < ndim(meta); ++d) {
    lin_idx += stride_at(meta, d) * idx_at(tidx, d);
  }
  return lin_idx;
}

void clamp_tensor_idx(const BufferMetadata meta, inout TensorIndex tidx) {
  tidx.data[0] = min(tidx.data[0], meta.sizes[0] - 1);
  tidx.data[1] = min(tidx.data[1], meta.sizes[1] - 1);
}

//
// Debug utilities
//

#ifdef DEBUG_MODE

void printTensorIndex(const TensorIndex tidx) {
    debugPrintfEXT(
        "TensorIndex: tidx=[%u %u %u %u %u %u %u %u]\\n",
        tidx.data[0][0], tidx.data[0][1], tidx.data[0][2], tidx.data[0][3],
        tidx.data[1][0], tidx.data[1][1], tidx.data[1][2], tidx.data[1][3]
    );
}

void printBufferMetadata(const BufferMetadata meta) {
    debugPrintfEXT(
        "BufferMetadata: ndim=%u numel=%u\\n  sizes=[%u %u %u %u %u %u %u %u]\\n  dim_order=[%u %u %u %u %u %u %u %u]\\n  strides=[%u %u %u %u %u %u %u %u]\\n",
        meta.ndim_numel[0], meta.ndim_numel[1],
        meta.sizes[0][0], meta.sizes[0][1], meta.sizes[0][2], meta.sizes[0][3],
        meta.sizes[1][1], meta.sizes[1][1], meta.sizes[1][2], meta.sizes[1][3],
        meta.dim_order[0][0], meta.dim_order[0][1],
        meta.dim_order[0][2], meta.dim_order[0][3],
        meta.dim_order[1][0], meta.dim_order[1][1],
        meta.dim_order[1][2], meta.dim_order[1][3],
        meta.strides[0][0], meta.strides[0][1],
        meta.strides[0][2], meta.strides[0][3],
        meta.strides[1][1], meta.strides[1][1],
        meta.strides[1][2], meta.strides[1][3]
    );
}

#endif

#endif // INDEXING_GLSLH
