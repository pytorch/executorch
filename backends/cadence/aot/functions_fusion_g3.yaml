# Copyright (c) Meta Platforms, Inc. and affiliates.
#
# This yaml file contains operators that are also defined by the ATen library.
# For lean mode:
#   - Codegen'd target `executorch_generated_lib` will be reading all the information
#     from this file, including operator schema and kernel metadata.
#   - Selective build target `codegen:executorch_defined_ops` now is selecting all the
#     operators in this file, by dumping all the op names into `selected_operators.yaml`.
#
# See the README.md file in executorch/kernels/portable for a description of the syntax used
# by this file.


# aten ops
- op: _to_copy.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::to_copy_out

- op: _softmax.out
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::_softmax_out

- op: add.out
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::add_out

- op: add.Scalar_out
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::add_scalar_out

- op: bmm.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::bmm_out

- op: cat.out
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::cat_out

- op: clamp.out
  cpp_no_default_args: ['min']
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::clamp_out

- op: clamp.Tensor_out
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::clamp_Tensor_out

- op: clone.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::clone_out

- op: div.out
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::div_out

- op: div.out_mode
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::div_out_mode

- op: embedding.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::embedding_out

- op: full.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::full_out

- op: lt.Scalar_out
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::lt_Scalar_out

- op: lt.Tensor_out
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::lt_Tensor_out

- op: mul.out
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::mul_out
- op: mul.Scalar_out
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::mul_scalar_out

- op: permute_copy.out
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::permute_copy_out

- op: rsqrt.out
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::rsqrt_out

- op: sigmoid.out
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::sigmoid_out

- op: slice_copy.Tensor_out
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::slice_copy_Tensor_out

- op: split_with_sizes_copy.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::split_with_sizes_copy_out

- op: sqrt.out
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::sqrt_out

- op: sub.out
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::sub_out

- op: sub.Scalar_out
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::sub_scalar_out

- op: tanh.out
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::tanh_out

- op: transpose_copy.int_out
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::transpose_copy_int_out

- op: view_copy.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::view_copy_out

- op: where.self_out
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::where_self_out

- op: native_layer_norm.out
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::native_layer_norm_out

- op: mean.out
  kernels:
    - arg_meta: null
      kernel_name:  impl::G3::mean_out

- op: exp.out
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::exp_out

- op: hardtanh.out
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::hardtanh_out

# custom ops
- func: cadence::quantize_per_tensor.out(Tensor input, float scale, int zero_point, int quant_min, int quant_max, ScalarType dtype, *, Tensor(a!) out) -> Tensor(a!)
  variants: function
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::native::quantize_per_tensor_out

- func: cadence::dequantize_per_tensor.out(Tensor input, float scale, int zero_point, int quant_min, int quant_max, ScalarType dtype, *, Tensor(a!) out) -> Tensor(a!)
  variants: function
  kernels:
    - arg_meta: null
      kernel_name: impl::G3::native::dequantize_per_tensor_out
