/*
 * Copyright (c) 2018 by Cadence Design Systems, Inc.  ALL RIGHTS RESERVED.
 * These coded instructions, statements, and computer programs are the
 * copyrighted works and confidential proprietary information of
 * Cadence Design Systems Inc.  They may be adapted and modified by bona fide
 * purchasers for internal use, but neither the original nor any adapted
 * or modified version may be disclosed or distributed to third parties
 * in any manner, medium, or form, in whole or in part, without the prior
 * written consent of Cadence Design Systems Inc.  This software and its
 * derivatives are to be executed solely on products incorporating a Cadence
 * Design Systems processor.
 */

#if ((XCHAL_VISION_TYPE >= 6))

#define VQ_TRUE   1
#define VQ_FALSE  0

#undef MAKE_NAME_VQ
#undef MAKE_ARGUMENTS
#undef MAKE_PARAMS

#if DILATED_VQ_CONV == VQ_TRUE

#define MAKE_NAME_VQ(a, b)             a ## VQ ## b
#define MAKE_ARGUMENTS(a, b, c, d, e)  (const xai_pTile3D a, const xai_pTile4D b, const xai_pArray c, const xai_pArray outputScaleArray, xai_pTile3D d, const xai_cnn_conv_params * e)
#define MAKE_PARAMS(a, b, c, d, e)     (a, b, c, outputScaleArray, d, e)

#elif DILATED_VQ_CONV == VQ_FALSE

#define MAKE_NAME_VQ(a, b)             a ## b
#define MAKE_ARGUMENTS(a, b, c, d, e)  (const xai_pTile3D a, const xai_pTile4D b, const xai_pArray c, xai_pTile3D d, const xai_cnn_conv_params * e)
#define MAKE_PARAMS(a, b, c, d, e)     (a, b, c, d, e)
#endif

#define MAKE_NAME_IMPL(name, MORPH_FNAME_SPECIFIER_IDT, suffix)  name ## _ ## MORPH_FNAME_SPECIFIER_IDT ## suffix

#if INPUT_DATA_TYPE == UNSIGNED8BIT

#define MAKE_NAME(name, suffix)  MAKE_NAME_IMPL(name, U8, suffix)
#define MORPH_IDT_CHECK              XAI_CHECK_TILE3D_U8
#define MORPH_IDT_SCALAR             uint8_t
#define MORPH_IDT_2Nx8               xb_vec2Nx8U
#define MORPH_OP_PRIME_2Nx8          IVP_LA2NX8U_PP
#define MORPH_OP_ALIGN_LOAD_2Nx8     IVP_LV2NX8U_XP
#define MORPH_OP_LOAD_2Nx8           IVP_LA2NX8U_XP
#define MORPH_OP_L2_2Nx8             IVP_L2U2NX8U_XP
#define MORPH_OP_LOAD_2Nx8_IP        IVP_LA2NX8U_IP
#define MORPH_OP_LOAD_2Nx8_VARIABLE  IVP_LAV2NX8U_XP
#define MORPH_OP_MULA                IVP_MULUSA2N8XR16
#define MORPH_OP_MUL4TA              IVP_MULUS4TA2N8XR8
#define MORPH_OP_MULQA               IVP_MULUSQA2N8XR8
#define MORPH_OP_MULPA               IVP_MULUSPA2N8XR16
#define MORPH_OP_GATHER              IVP_GATHERANX8U
#define MORPH_OP_GATHER_2Nx8_LOW     IVP_GATHERD2NX8U_L
#define MORPH_OP_GATHER_2Nx8_HIGH    IVP_GATHERD2NX8U_H
#define MORPH_OP_DSELI               IVP_DSEL2NX8UI
#define MORPH_OP_SEL                 IVP_SEL2NX8U

#elif INPUT_DATA_TYPE == SIGNED8BIT

#undef MAKE_NAME
#undef MORPH_IDT_CHECK
#undef MORPH_IDT_SCALAR
#undef MORPH_IDT_2Nx8
#undef MORPH_OP_PRIME_2Nx8
#undef MORPH_OP_ALIGN_LOAD_2Nx8
#undef MORPH_OP_LOAD_2Nx8_IP
#undef MORPH_OP_LOAD_2Nx8_VARIABLE
#undef MORPH_OP_LOAD_2Nx8
#undef MORPH_OP_L2_2Nx8
#undef MORPH_OP_MULA
#undef MORPH_OP_MUL4TA
#undef MORPH_OP_MULQA
#undef MORPH_OP_MULPA
#undef MORPH_OP_GATHER
#undef MORPH_OP_GATHER_2Nx8_LOW
#undef MORPH_OP_GATHER_2Nx8_HIGH
#undef MORPH_OP_DSELI
#undef MORPH_OP_SEL

#define MAKE_NAME(name, suffix)  MAKE_NAME_IMPL(name, S8, suffix)
#define MORPH_IDT_CHECK              XAI_CHECK_TILE3D_S8
#define MORPH_IDT_SCALAR             int8_t
#define MORPH_IDT_2Nx8               xb_vec2Nx8
#define MORPH_OP_PRIME_2Nx8          IVP_LA2NX8_PP
#define MORPH_OP_ALIGN_LOAD_2Nx8     IVP_LV2NX8_XP
#define MORPH_OP_LOAD_2Nx8           IVP_LA2NX8_XP
#define MORPH_OP_L2_2Nx8             IVP_L2U2NX8_XP
#define MORPH_OP_LOAD_2Nx8_IP        IVP_LA2NX8_IP
#define MORPH_OP_LOAD_2Nx8_VARIABLE  IVP_LAV2NX8_XP
#define MORPH_OP_MULA                IVP_MULA2N8XR16
#define MORPH_OP_MUL4TA              IVP_MUL4TA2N8XR8
#define MORPH_OP_MULQA               IVP_MULQA2N8XR8
#define MORPH_OP_MULPA               IVP_MULPA2N8XR16
#define MORPH_OP_GATHER              IVP_GATHERANX8S
#define MORPH_OP_GATHER_2Nx8_LOW     IVP_GATHERD2NX8_L
#define MORPH_OP_GATHER_2Nx8_HIGH    IVP_GATHERD2NX8_H
#define MORPH_OP_DSELI               IVP_DSEL2NX8I
#define MORPH_OP_SEL                 IVP_SEL2NX8
#endif

/******************************************************************************************
*   xaiConvolved(VQ)3D_S_1x1j1d1I8S8IX_MOW_WHD
*  ***************************************************************************************/

/******************************************************************************/
/* Description : P6 optimized generic implementation for 1x1 3D convolution.  */
/*               Based on MORPH pre-processor specifiers, code implementation */
/*               is generated during preprocessing stage. This method can be  */
/*               used to generate 1x1 3D MOW_WHD dilated convolution function */
/*               and 1x1 3D VQ MOW_WHD dilated convolution function for U8    */
/*               bit and S8 bit input data with input stride equal to 1       */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                */
/*               Output scale array, CNN convolution params structure         */
/* Outputs     : XI Error Code                                                */
/* InOuts      : Output Tile                                                  */
/* Assumptions : CoeffData is S8                                              */
/*               biasArray is signed 32b, value not exceeding signed 24b      */
/*               Output scale array is U16                                    */
/*               OutData is S8 / U8 / S16                                     */
/*               Kernel Size is 1x1xDxN                                       */
/*               Input and Output are in WHD format                           */
/*               Coeff is in WHDN format                                      */
/******************************************************************************/
/*********************************************************************************
   convolved3D_S_1x1j1d1_S8S8IX_MOW_WHD_NOEDGE
   convolved3D_S_1x1j1d1_U8S8IX_MOW_WHD_NOEDGE
   convolvedVQ3D_S_1x1j1d1_S8S8IX_MOW_WHD_NOEDGE
   convolvedVQ3D_S_1x1j1d1_U8S8IX_MOW_WHD_NOEDGE
 * MOW no edge variant                                                            *
 * If DataPitch1 = width for input and output tile                              *
 **********************************************************************************/

static _XAI_INLINE_ void MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_1x1j1d1), S8IX_MOW_WHD_NOEDGE) \
  MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Getting parameters from the tile structures */
  const int32_t outW          = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH          = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh       = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh      = XAI_TILE3D_GET_DIM3(outTile);
  const int32_t inDataPitch2  = XAI_TILE3D_GET_DIM2_PITCH(inTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);
  const int32_t coeffPitch3   = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  uint8_t enableReLu          = XAI_CNN_CONV_GET_FLAG_RELU(param);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  const int32_t vectorizationWidth = 2 * XCHAL_IVPN_SIMD_WIDTH;

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  int32_t inCh, outCh, xy;
  MORPH_IDT_2Nx8 *restrict pdvecIn1;
  MORPH_IDT_2Nx8 *restrict pdvecIn2;
  MORPH_IDT_2Nx8 *restrict pdvecIn3;
  MORPH_IDT_2Nx8 *restrict pdvecIn4;
  xb_vec2Nx8 * restrict pdvecOut;
  xb_vec2Nx8 * restrict pdvecCoeff1;
  xb_vec2Nx8 * restrict pdvecCoeff2;
  xb_vec2Nx8 * restrict pdvecCoeff3;
  xb_vec2Nx8 * restrict pdvecCoeff4;

  /* There are no edges input and output width. Output width and
   * height loops are combined. Input data is loaded continuously
   * from the input WH plane and output is stored continuously in
   * output WH plane.
   * The overall design approach is split into 2 sections, one
   * with aligned input data and the other with unaligned input data.
   */
  if (XAI_TILE3D_IS_ALIGNED_2NX8(inTile))
  {
    for (xy = 0; xy < outW * outH; xy += vectorizationWidth) /* Loop across Output width */
    {
      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[xy * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[xy];

      /* initialize coeff and Bias data pointer */
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 4) /* Loop across Output depth */
      {
        /* In order to handle odd depths*/
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
        int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);
        int32_t enable4thCh = XT_SALT(outCh, numOutCh - 3);

        /* Load the bias values corresponding to four output channels */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
        xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4 * enable4thCh);
        xb_vecN_2x32v hvecBias4; IVP_LSRN_2X32_XP(hvecBias4, pBias, 4);

        xb_vec2Nx24 dacc1, dacc2, dacc3, dacc4;
        dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
        dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
        IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);
        dacc4 = IVP_CVT24UNX32L(hvecBias4, hvecBias4);
        IVP_CVT24UNX32H(dacc4, hvecBias4, hvecBias4);

        /* Coefficient and input pointers */
        int8_t *pCoeff = &pCoeffData[outCh * coeffPitch3];
        pdvecCoeff1 = (xb_vec2Nx8 *) pCoeff;
        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        pdvecCoeff3 = (xb_vec2Nx8 *) (pCoeff + 2 * coeffPitch3 * enable3rdCh);
        pdvecCoeff4 = (xb_vec2Nx8 *) (pCoeff + 3 * coeffPitch3 * enable4thCh);
        pdvecIn1    = (MORPH_IDT_2Nx8 *) (pInput);
        pdvecIn2    = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch2);
        pdvecIn3    = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2);
        pdvecIn4    = (MORPH_IDT_2Nx8 *) (pInput + 3 * inDataPitch2);

        /* Priming Loads for Coefficients */
        valign vaCoeff1 = IVP_LA2NX8_PP(pdvecCoeff1);
        valign vaCoeff2 = IVP_LA2NX8_PP(pdvecCoeff2);
        valign vaCoeff3 = IVP_LA2NX8_PP(pdvecCoeff3);
        valign vaCoeff4 = IVP_LA2NX8_PP(pdvecCoeff4);

        for (inCh = 0; inCh < numInCh - 3; inCh += 4)  /* Loop across input depth */
        {
          /* input vectors are read from 4 input depths at at time
           * Scalar 32 bit coeff are extracted from the coeff vectors */
          MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3, dvecData4;

          /* Read vector input data from 1st depth */
          MORPH_OP_ALIGN_LOAD_2Nx8(dvecData1, pdvecIn1, 4 * inDataPitch2);

          /* Read vector input data from 2nd depth */
          MORPH_OP_ALIGN_LOAD_2Nx8(dvecData2, pdvecIn2, 4 * inDataPitch2);

          /* Read vector input data from 3rd depth */
          MORPH_OP_ALIGN_LOAD_2Nx8(dvecData3, pdvecIn3, 4 * inDataPitch2);

          /* Read vector input data from 4th depth */
          MORPH_OP_ALIGN_LOAD_2Nx8(dvecData4, pdvecIn4, 4 * inDataPitch2);

          xb_vec2Nx8 dvecCoeff1, dvecCoeff2, dvecCoeff3, dvecCoeff4;
          IVP_LAV2NX8_XP(dvecCoeff1, vaCoeff1, pdvecCoeff1, 4);
          IVP_LAV2NX8_XP(dvecCoeff2, vaCoeff2, pdvecCoeff2, 4);
          IVP_LAV2NX8_XP(dvecCoeff3, vaCoeff3, pdvecCoeff3, 4);
          IVP_LAV2NX8_XP(dvecCoeff4, vaCoeff4, pdvecCoeff4, 4);

          int32_t coeff1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16 \
                                            (IVP_MOVNX16_FROM2NX8(dvecCoeff1)), 0);
          int32_t coeff2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16 \
                                            (IVP_MOVNX16_FROM2NX8(dvecCoeff2)), 0);
          int32_t coeff3 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16 \
                                            (IVP_MOVNX16_FROM2NX8(dvecCoeff3)), 0);
          int32_t coeff4 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16 \
                                            (IVP_MOVNX16_FROM2NX8(dvecCoeff4)), 0);

          MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, coeff1);
          MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, coeff2);
          MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, coeff3);
          MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1, coeff4);
        } /* end of for (inCh = 0; inCh < numInCh - 3; inCh += 4)*/

        /* Corner case handling if number of inCh is not a multiple of 4 */
        if (inCh < numInCh)
        {
          int32_t remInCh = numInCh - inCh;

          /* input vectors are read from 4 input depths at at time
           * Scalar 32 bit coeff are extracted from the coeff vectors */
          MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3;

          /* Read vector input data from 1st depth */
          MORPH_OP_ALIGN_LOAD_2Nx8(dvecData1, pdvecIn1, inDataPitch2 * XT_SALT(1, remInCh));

          /* Read vector input data from 2nd depth */
          MORPH_OP_ALIGN_LOAD_2Nx8(dvecData2, pdvecIn1, inDataPitch2 * XT_SALT(2, remInCh));

          /* Read vector input data from 3rd depth */
          MORPH_OP_ALIGN_LOAD_2Nx8(dvecData3, pdvecIn1, 0);

          xb_vec2Nx8 dvecCoeff1, dvecCoeff2, dvecCoeff3, dvecCoeff4;
          IVP_LAV2NX8_XP(dvecCoeff1, vaCoeff1, pdvecCoeff1, remInCh);
          IVP_LAV2NX8_XP(dvecCoeff2, vaCoeff2, pdvecCoeff2, remInCh);
          IVP_LAV2NX8_XP(dvecCoeff3, vaCoeff3, pdvecCoeff3, remInCh);
          IVP_LAV2NX8_XP(dvecCoeff4, vaCoeff4, pdvecCoeff4, remInCh);

          int32_t coeff1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16 \
                                            (IVP_MOVNX16_FROM2NX8(dvecCoeff1)), 0);
          int32_t coeff2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16 \
                                            (IVP_MOVNX16_FROM2NX8(dvecCoeff2)), 0);
          int32_t coeff3 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16 \
                                            (IVP_MOVNX16_FROM2NX8(dvecCoeff3)), 0);
          int32_t coeff4 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16 \
                                            (IVP_MOVNX16_FROM2NX8(dvecCoeff4)), 0);

          MORPH_OP_MULQA(dacc1, 0, dvecData3, dvecData2, dvecData1, coeff1);
          MORPH_OP_MULQA(dacc2, 0, dvecData3, dvecData2, dvecData1, coeff2);
          MORPH_OP_MULQA(dacc3, 0, dvecData3, dvecData2, dvecData1, coeff3);
          MORPH_OP_MULQA(dacc4, 0, dvecData3, dvecData2, dvecData1, coeff4);
        } /* end of corner case handling*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      pOutScaleData[outCh + 2 * enable3rdCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      pOutScaleData[outCh + 3 * enable4thCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* variable store count */
        int32_t varLen = outW * outH - xy;

        /* store output to 1st output depth */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData; vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* store output to 2nd output depth */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* store output to 3rd output depth */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable3rdCh);
        IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable3rdCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* store output to 4th output depth */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch2 * enable4thCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable4thCh);
        IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable4thCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 4 * outDataPitch2 * bytesPerPixel;
      } /* end of for (outCh = 0; outCh < numOutCh; outCh += 4)*/
    }   /* end of for (xy = 0; xy < outW*outH; xy += vectorizationWidth)*/
  }
  else
  {
#ifdef __XCC__
    XT_MEMW();   /* Adding Memory Wait as Gather and Normal Load/Stores are not synchronized */
#endif

    /* generate the sequence 0,1,2,3,0 + coeffPitch3, 1 + coeffPitch3,
     * 2 + coeffPitch3, 3 + coeffPitch3, 0 + 2 * coeffPitch3, 1 + 2 * coeffPitch3,
     * 2 + 2 * coeffPitch3, 3 + 2 * coeffPitch3, .....
     *
     * for e.g, if coeffPitch3 is 32:
     * 0,1,2,3,32,33,34,35,64,65,66,67,96,96,98,99,..
     *
     * This sequence is used to gather coeff from 4 diff output channels, 4 each from
     * every channel corresponding to 4 i/p channels, as innermost loop(inCh) is unrolled by
     * 4 to make use of quad multipler.
     */
    xb_vecNx16U vecIdx1 = IVP_SEQNX16();
    vecIdx1 = IVP_PACKVRNRNX48(IVP_MULNX16(vecIdx1, coeffPitch3), 0);
    vecIdx1 = IVP_SELNX16I(IVP_ADDNX16(vecIdx1, 1), vecIdx1, IVP_SELI_16B_INTERLEAVE_1_LO);
    vecIdx1 = IVP_SELNX16I(IVP_ADDNX16(vecIdx1, 2), vecIdx1, IVP_SELI_32B_INTERLEAVE_1_LO);
    xb_gsr gs0;

    for (xy = 0; xy < outW * outH; xy += vectorizationWidth) /* Loop across Output width * Outputheight */
    {
      xb_vecNx16U vecIdx2;
      /* variable store count */
      int32_t varLen = outW * outH - xy;
      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[xy * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[xy];

      /* initialize  Bias data pointer */
      int32_t *pBias = &pBiasData[0];
      int8_t *pCoeff = &pCoeffData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 4) /* Loop across Output depth */
      {
        /* In order to handle odd depths*/
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
        int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);
        int32_t enable4thCh = XT_SALT(outCh, numOutCh - 3);

        /* load and replicate bias data for each output channel */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
        xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4 * enable4thCh);
        xb_vecN_2x32v hvecBias4; IVP_LSRN_2X32_XP(hvecBias4, pBias, 4);

        xb_vec2Nx24 dacc1, dacc2, dacc3, dacc4;
        dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
        dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
        IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);
        dacc4 = IVP_CVT24UNX32L(hvecBias4, hvecBias4);
        IVP_CVT24UNX32H(dacc4, hvecBias4, hvecBias4);

        /* boolean mask to gather coeffs, if all the four o/p channels
         * are present 16 coeff are loaded.
         */
        vboolN mask = IVP_LTNX16(IVP_SEQNX16(), (xb_vecNx16) XT_MIN(((numOutCh - outCh) * 4), 16));
        /* Assign valid address for predicated false lines */
        vecIdx2  = IVP_MOVNX16UT(vecIdx1, 0, mask);
        pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
        pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2);

        for (inCh = 0; inCh < numInCh - 3; inCh += 4)        /* Loop across input depth */
        {
          /* input vectors are read from 4 input depths at at time
           * Scalar 32 bit coeff are extracted from the coeff vectors */

          MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3, dvecData4;

          /* Read vector input data from 1st depth */
          valign vaInData; vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecData1, vaInData, pdvecIn1, inDataPitch2);

          /* Read vector input data from 2nd depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecData2, vaInData, pdvecIn1, 3 * inDataPitch2);

          /* Read vector input data from 3rd depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
          MORPH_OP_LOAD_2Nx8(dvecData3, vaInData, pdvecIn2, inDataPitch2);

          /* Read vector input data from 4th depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
          MORPH_OP_LOAD_2Nx8(dvecData4, vaInData, pdvecIn2, 3 * inDataPitch2);

          /* gather the coeffs */
          gs0 = IVP_GATHERANX8S(pCoeff + inCh, vecIdx2);
          xb_vec2Nx8 dvecCoeffData = IVP_GATHERD2NX8_L(gs0);

          /* extract scalar coeff from coeff vectors */
          int32_t coeff1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 0); /* 1st o/p depth coeff */
          int32_t coeff2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 1); /* 2nd o/p depth coeff */
          int32_t coeff3 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 2); /* 3rd o/p depth coeff */
          int32_t coeff4 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 3); /* 4th o/p depth coeff */

          MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, coeff1);
          MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, coeff2);
          MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, coeff3);
          MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1, coeff4);
        } /* end of for (inCh = 0; inCh < numInCh; inCh += 4)*/
        if (inCh < numInCh)
        {
          MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3;

          pdvecIn2 = (MORPH_IDT_2Nx8 *) (((int8_t *) pdvecIn1) + 2 * inDataPitch2 * XT_SALT(inCh, numInCh - 2));
          /* Read vector input data from 1st depth */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecData1, vaInData, pdvecIn1, inDataPitch2 * XT_SALT(inCh, numInCh - 1));

          /* Read vector input data from 2nd depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          IVP_LAV2NX8_XP(dvecData2, vaInData, pdvecIn1, varLen * XT_SALT(inCh, numInCh - 1));

          /* Read vector input data from 3rd depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
          IVP_LAV2NX8_XP(dvecData3, vaInData, pdvecIn2, varLen * XT_SALT(inCh, numInCh - 2));

          /* Boolean mask for gather to handle cases where inCh<4 */
          vboolN mask1 = IVP_LTNX16(IVP_ANDNX16(IVP_SEQNX16(), 3), (numInCh - inCh));
          /* Assign valid address for predicated false lines */
          vecIdx2 = IVP_MOVNX16UT(vecIdx2, 0, mask1);
          /* Gather coeffs */
          gs0 = IVP_GATHERANX8S(pCoeff + inCh, vecIdx2);
          xb_vec2Nx8 dvecCoeffData = IVP_GATHERD2NX8_L(gs0);

          /* extract scalar coeff from coeff vectors */
          int32_t coeff1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 0); /* 1st o/p depth coeff */
          int32_t coeff2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 1); /* 2nd o/p depth coeff */
          int32_t coeff3 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 2); /* 3rd o/p depth coeff */
          int32_t coeff4 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 3); /* 4th o/p depth coeff */

          MORPH_OP_MULQA(dacc1, 0, dvecData3, dvecData2, dvecData1, coeff1);
          MORPH_OP_MULQA(dacc2, 0, dvecData3, dvecData2, dvecData1, coeff2);
          MORPH_OP_MULQA(dacc3, 0, dvecData3, dvecData2, dvecData1, coeff3);
          MORPH_OP_MULQA(dacc4, 0, dvecData3, dvecData2, dvecData1, coeff4);
        } /* end of if (inCh < numInCh)*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      pOutScaleData[outCh + 2 * enable3rdCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      pOutScaleData[outCh + 3 * enable4thCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* store output to 1st output depth */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData; vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* store output to 2nd output depth */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* store output to 3rd output depth */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable3rdCh);
        IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable3rdCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* store output to 4th output depth */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch2 * enable4thCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable4thCh);
        IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable4thCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 4 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 4 * coeffPitch3;
      } /* end of for (outCh = 0; outCh < numOutCh; outCh += 4)*/
    }   /* end of for (xy = 0; xy < outW*outH; xy += vectorizationWidth)*/
  }
}

/******************************************************************************************
* MOW fold 16 Stride 1 varaint                                                            *
* If inDataPitch1 is lesser than or equal to                                              *
* 16 this function is called.                                                             *
******************************************************************************************/

static _XAI_INLINE_ void MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_1x1j1d1), S8IX_MOW_WHD_FOLD16) \
  MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Getting parameters from the tile structures */
  const int32_t outW          = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH          = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh       = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh      = XAI_TILE3D_GET_DIM3(outTile);
  const int32_t inDataPitch1  = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2  = XAI_TILE3D_GET_DIM2_PITCH(inTile);
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);
  const int32_t coeffPitch3   = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  uint8_t enableReLu          = XAI_CNN_CONV_GET_FLAG_RELU(param);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  int32_t inCh, outCh, y;
  MORPH_IDT_2Nx8 *restrict pdvecIn1;
  MORPH_IDT_2Nx8 *restrict pdvecIn2;

  xb_vec2Nx8 * restrict pdvecOut;

  xb_vecN_2x32v * restrict phvecCoeff1;


  /* there are 2 implementations, one for
   * input channels less than or equal to 64, and other for input channels
   * greater than 64.
   * Adding one more loop to support more than 64 input channels is causing
   * significant overhead and degrades the the performance.
   */

  if ((numInCh <= 2 * XCHAL_IVPN_SIMD_WIDTH))
  {
    for (y = 0; y < outH; y += 4) /* Loop across Output height */
    {
      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y];

      /* initialize coeff and Bias data pointer */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 4) /* Loop across Output depth */
      {
        /* In order to handle odd depths*/
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
        int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);
        int32_t enable4thCh = XT_SALT(outCh, numOutCh - 3);

        /* Load the bias values corresponding to two output channels */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
        xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4 * enable4thCh);
        xb_vecN_2x32v hvecBias4; IVP_LSRN_2X32_XP(hvecBias4, pBias, 4);

        xb_vec2Nx24 dacc1, dacc2, dacc3, dacc4;
        dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
        dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
        IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);
        dacc4 = IVP_CVT24UNX32L(hvecBias4, hvecBias4);
        IVP_CVT24UNX32H(dacc4, hvecBias4, hvecBias4);


        /* variables for coeff loads */
        xb_vecN_2x32v hvecCoeffData1, hvecCoeffData2, hvecCoeffData3, hvecCoeffData4;

        /* read coeff vectors , for 4 consecutive output depths */
        /* coeff vector for 1st output channel */
        phvecCoeff1 = (xb_vecN_2x32v *) (pCoeff);
        valign vaCoeffData; vaCoeffData = IVP_LAN_2X32_PP(phvecCoeff1);
        IVP_LAVN_2X32_XP(hvecCoeffData1, vaCoeffData, phvecCoeff1, coeffPitch3);

        /* coeff vector for 2nd output channel */
        vaCoeffData = IVP_LAN_2X32_PP(phvecCoeff1);
        IVP_LAVN_2X32_XP(hvecCoeffData2, vaCoeffData, phvecCoeff1, coeffPitch3 * enable2ndCh);

        /* coeff vector for 3rd output channel */
        vaCoeffData = IVP_LAN_2X32_PP(phvecCoeff1);
        IVP_LAVN_2X32_XP(hvecCoeffData3, vaCoeffData, phvecCoeff1, coeffPitch3 * enable3rdCh);

        /* coeff vector for 4th output channel */
        vaCoeffData = IVP_LAN_2X32_PP(phvecCoeff1);
        IVP_LAVN_2X32_XP(hvecCoeffData4, vaCoeffData, phvecCoeff1, coeffPitch3 * enable4thCh);

        pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
        pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2);

        for (inCh = 0; inCh < numInCh - 3; inCh += 4) /* Loop across input depth */
        {
          /* input vectors are read from 4 input depths at at time
           * Scalar 32 bit coeff are extracted from the coeff vectors */

          MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3, dvecData4;

          /* Read vector input data from 1st depth */
          valign vaInData; vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecData1, vaInData, pdvecIn1, inDataPitch2);

          /* Read vector input data from 2nd depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecData2, vaInData, pdvecIn1, 3 * inDataPitch2);

          /* Read vector input data from 3rd depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
          MORPH_OP_LOAD_2Nx8(dvecData3, vaInData, pdvecIn2, inDataPitch2);

          /* Read vector input data from 4th depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
          MORPH_OP_LOAD_2Nx8(dvecData4, vaInData, pdvecIn2, 3 * inDataPitch2);

          /* extract scalar coeff from coeff vectors */
          int32_t coeff1 = IVP_EXTRVRN_2X32(hvecCoeffData1, inCh); /* 1st o/p depth coeff */
          int32_t coeff2 = IVP_EXTRVRN_2X32(hvecCoeffData2, inCh); /* 2nd o/p depth coeff */
          int32_t coeff3 = IVP_EXTRVRN_2X32(hvecCoeffData3, inCh); /* 3rd o/p depth coeff */
          int32_t coeff4 = IVP_EXTRVRN_2X32(hvecCoeffData4, inCh); /* 4th o/p depth coeff */

          MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, coeff1);
          MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, coeff2);
          MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, coeff3);
          MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1, coeff4);
        } /* end of for (inCh = 0; inCh < numInCh; inCh += 4)*/
          /* Corner case handling if number of inCh is not a multiple of 4 */
        if (inCh < numInCh)
        {
          MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3;

          /* Read vector input data from 1st depth */
          valign vaInData; vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecData1, vaInData, pdvecIn1, inDataPitch2 * XT_SALT(inCh, numInCh - 1));

          /* Read vector input data from 2nd depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecData2, vaInData, pdvecIn1, inDataPitch2 * XT_SALT(inCh, numInCh - 2));

          /* Read vector input data from 3rd depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecData3, vaInData, pdvecIn1, inDataPitch2);


          /* extract scalar coeff from coeff vectors */
          int32_t coeff1 = IVP_EXTRVRN_2X32(hvecCoeffData1, inCh); /* 1st o/p depth coeff */
          int32_t coeff2 = IVP_EXTRVRN_2X32(hvecCoeffData2, inCh); /* 2nd o/p depth coeff */
          int32_t coeff3 = IVP_EXTRVRN_2X32(hvecCoeffData3, inCh); /* 3rd o/p depth coeff */
          int32_t coeff4 = IVP_EXTRVRN_2X32(hvecCoeffData4, inCh); /* 4th o/p depth coeff */

          MORPH_OP_MULQA(dacc1, 0, dvecData3, dvecData2, dvecData1, coeff1);
          MORPH_OP_MULQA(dacc2, 0, dvecData3, dvecData2, dvecData1, coeff2);
          MORPH_OP_MULQA(dacc3, 0, dvecData3, dvecData2, dvecData1, coeff3);
          MORPH_OP_MULQA(dacc4, 0, dvecData3, dvecData2, dvecData1, coeff4);
        }

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      pOutScaleData[outCh + 2 * enable3rdCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      pOutScaleData[outCh + 3 * enable4thCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* In order to handle odd depths*/
        int32_t enable2ndRow = XT_SALT(y, outH - 1);
        int32_t enable3rdRow = XT_SALT(y, outH - 2);
        int32_t enable4thRow = XT_SALT(y, outH - 3);

        /* Storing the first output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2ndRow * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)), \
                       vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first output depth, 3rd row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch1 * enable3rdRow * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), 2 * inDataPitch1 * bytesPerPixel)), \
                       vaOutData, pdvecOut, bytesPerPixel * enable3rdRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first output depth, 4th row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch1 * enable4thRow * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), 3 * inDataPitch1 * bytesPerPixel)), \
                       vaOutData, pdvecOut, bytesPerPixel * enable4thRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)),
                       vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * \
                       enable2ndRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, 3rd row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                              2 * outDataPitch1 * enable3rdRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), 2 * inDataPitch1 * bytesPerPixel)),
                       vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * \
                       enable3rdRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, 4th row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                              3 * outDataPitch1 * enable4thRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), 3 * inDataPitch1 * bytesPerPixel)),
                       vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * \
                       enable4thRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 3rd output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * enable3rdCh * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 3rd output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (2 * outDataPitch2 * enable3rdCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut3H, dvecOut3L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)),
                       vaOutData, pdvecOut, bytesPerPixel * enable3rdCh * \
                       enable2ndRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 3rd output depth, 3rd row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (2 * outDataPitch2 * enable3rdCh + \
                                              2 * outDataPitch1 * enable3rdRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut3H, dvecOut3L, IVP_ADD2NX8(IVP_SEQ2NX8(), 2 * inDataPitch1 * bytesPerPixel)),
                       vaOutData, pdvecOut, bytesPerPixel * enable3rdCh * \
                       enable3rdRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 3rd output depth, 4th row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (2 * outDataPitch2 * enable3rdCh + \
                                              3 * outDataPitch1 * enable4thRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut3H, dvecOut3L, IVP_ADD2NX8(IVP_SEQ2NX8(), 3 * inDataPitch1 * bytesPerPixel)),
                       vaOutData, pdvecOut, bytesPerPixel * enable3rdCh * \
                       enable4thRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 4th output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch2 * enable4thCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * enable4thCh * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 4th output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (3 * outDataPitch2 * enable4thCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut4H, dvecOut4L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)),
                       vaOutData, pdvecOut, bytesPerPixel * enable4thCh * \
                       enable2ndRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 4th output depth, 3rd row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (3 * outDataPitch2 * enable4thCh + \
                                              2 * outDataPitch1 * enable3rdRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut4H, dvecOut4L, IVP_ADD2NX8(IVP_SEQ2NX8(), 2 * inDataPitch1 * bytesPerPixel)),
                       vaOutData, pdvecOut, bytesPerPixel * enable4thCh * \
                       enable3rdRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 4th output depth, 4th row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (3 * outDataPitch2 * enable4thCh + \
                                              3 * outDataPitch1 * enable4thRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut4H, dvecOut4L, IVP_ADD2NX8(IVP_SEQ2NX8(), 3 * inDataPitch1 * bytesPerPixel)),
                       vaOutData, pdvecOut, bytesPerPixel * enable4thCh * \
                       enable4thRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 4 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 4 * coeffPitch3;
      } /* end of for (outCh = 0; outCh < numOutCh; outCh += 4)*/
    }   /* end of for (y = 0; y < outH; y++)*/
  }     /* end of if ((numInCh <= 2*XCHAL_IVPN_SIMD_WIDTH))*/
  else
  {
#ifdef __XCC__
    XT_MEMW(); /* Adding Memory Wait as Gather and Normal Load/Stores are not synchronized */
#endif

    /* generate the sequence 0,1,2,3,0 + coeffPitch3, 1 + coeffPitch3,
     * 2 + coeffPitch3, 3 + coeffPitch3, 0 + 2 * coeffPitch3, 1 + 2 * coeffPitch3,
     * 2 + 2 * coeffPitch3, 3 + 2 * coeffPitch3, .....
     *
     * for e.g, if coeffPitch3 is 32:
     * 0,1,2,3,32,33,34,35,64,65,66,67,96,96,98,99,..
     *
     * This sequence is used to gather coeff from 4 diff output channels, 4 each from
     * every channel corresponding to 4 i/p channels, as innermost loop(inCh) is unrolled by
     * 4 to make use of quad multipler.
     */
    xb_vecNx16U vecIdx1 = IVP_SEQNX16();
    vecIdx1 = IVP_PACKVRNRNX48(IVP_MULNX16(vecIdx1, coeffPitch3), 0);
    vecIdx1 = IVP_SELNX16I(IVP_ADDNX16(vecIdx1, 1), vecIdx1, IVP_SELI_16B_INTERLEAVE_1_LO);
    vecIdx1 = IVP_SELNX16I(IVP_ADDNX16(vecIdx1, 2), vecIdx1, IVP_SELI_32B_INTERLEAVE_1_LO);
    xb_gsr gs0;

    xb_vecNx16U vecIdx2;
    for (y = 0; y < outH; y += 4)        /* Loop across Output height */
    {
      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y];

      /* initialize  Bias data pointer */

      int32_t *pBias = &pBiasData[0];
      int8_t *pCoeff = &pCoeffData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 4)  /* Loop across Output depth */
      {
        /* In order to handle odd depths*/
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
        int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);
        int32_t enable4thCh = XT_SALT(outCh, numOutCh - 3);

        /* Load the bias values corresponding to two output channels */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
        xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4 * enable4thCh);
        xb_vecN_2x32v hvecBias4; IVP_LSRN_2X32_XP(hvecBias4, pBias, 4);

        xb_vec2Nx24 dacc1, dacc2, dacc3, dacc4;
        dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
        dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
        IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);
        dacc4 = IVP_CVT24UNX32L(hvecBias4, hvecBias4);
        IVP_CVT24UNX32H(dacc4, hvecBias4, hvecBias4);

        /* boolean mask to gather coeffs, if all the four o/p channels
         * are present 16 coeff are loaded.
         */
        vboolN mask = IVP_LTNX16(IVP_SEQNX16(), (xb_vecNx16) XT_MIN(((numOutCh - outCh) * 4), 16));
        /* Assign valid address for predicated false lines */
        vecIdx2  = IVP_MOVNX16UT(vecIdx1, 0, mask);
        pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
        pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2);

        for (inCh = 0; inCh < numInCh - 3; inCh += 4) /* Loop across input depth */
        {
          /* input vectors are read from 4 input depths at at time
           * Scalar 32 bit coeff are extracted from the coeff vectors */

          MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3, dvecData4;

          /* Read vector input data from 1st depth */
          valign vaInData; vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecData1, vaInData, pdvecIn1, inDataPitch2);

          /* Read vector input data from 2nd depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecData2, vaInData, pdvecIn1, 3 * inDataPitch2);

          /* Read vector input data from 3rd depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
          MORPH_OP_LOAD_2Nx8(dvecData3, vaInData, pdvecIn2, inDataPitch2);

          /* Read vector input data from 4th depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
          MORPH_OP_LOAD_2Nx8(dvecData4, vaInData, pdvecIn2, 3 * inDataPitch2);

          /* gather the coeffs */
          gs0 = IVP_GATHERANX8S(pCoeff + inCh, vecIdx2);
          xb_vec2Nx8 dvecCoeffData = IVP_GATHERD2NX8_L(gs0);

          /* extract scalar coeff from coeff vectors */
          int32_t coeff1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 0); /* 1st o/p depth coeff */
          int32_t coeff2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 1); /* 2nd o/p depth coeff */
          int32_t coeff3 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 2); /* 3rd o/p depth coeff */
          int32_t coeff4 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 3); /* 4th o/p depth coeff */

          MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, coeff1);
          MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, coeff2);
          MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, coeff3);
          MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1, coeff4);
        }       /* end of for (inCh = 0; inCh < numInCh; inCh += 4)*/
        if (inCh < numInCh)
        {
          MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3;

          pdvecIn2 = (MORPH_IDT_2Nx8 *) (((int8_t *) pdvecIn1) + 2 * inDataPitch2 * XT_SALT(inCh, numInCh - 2));
          /* Read vector input data from 1st depth */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecData1, vaInData, pdvecIn1, inDataPitch2 * XT_SALT(inCh, numInCh - 1));

          /* Read vector input data from 2nd depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          IVP_LAV2NX8_XP(dvecData2, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * XT_SALT(inCh, numInCh - 1));

          /* Read vector input data from 3rd depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
          IVP_LAV2NX8_XP(dvecData3, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * XT_SALT(inCh, numInCh - 2));

          /* Boolean mask for gather to handle cases where inCh<4 */
          vboolN mask1 = IVP_LTNX16(IVP_ANDNX16(IVP_SEQNX16(), 3), (numInCh - inCh));
          /* Assign valid address for predicated false lines */
          vecIdx2 = IVP_MOVNX16UT(vecIdx2, 0, mask1);
          /* Gather coeffs */
          gs0 = IVP_GATHERANX8S(pCoeff + inCh, vecIdx2);
          xb_vec2Nx8 dvecCoeffData = IVP_GATHERD2NX8_L(gs0);

          /* extract scalar coeff from coeff vectors */
          int32_t coeff1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 0); /* 1st o/p depth coeff */
          int32_t coeff2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 1); /* 2nd o/p depth coeff */
          int32_t coeff3 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 2); /* 3rd o/p depth coeff */
          int32_t coeff4 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 3); /* 4th o/p depth coeff */

          MORPH_OP_MULQA(dacc1, 0, dvecData3, dvecData2, dvecData1, coeff1);
          MORPH_OP_MULQA(dacc2, 0, dvecData3, dvecData2, dvecData1, coeff2);
          MORPH_OP_MULQA(dacc3, 0, dvecData3, dvecData2, dvecData1, coeff3);
          MORPH_OP_MULQA(dacc4, 0, dvecData3, dvecData2, dvecData1, coeff4);
        } /* end of if (inCh < numInCh)*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      pOutScaleData[outCh + 2 * enable3rdCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      pOutScaleData[outCh + 3 * enable4thCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* In order to handle odd depths*/
        int32_t enable2ndRow = XT_SALT(y, outH - 1);
        int32_t enable3rdRow = XT_SALT(y, outH - 2);
        int32_t enable4thRow = XT_SALT(y, outH - 3);

        /* Storing the first output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2ndRow * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)), \
                       vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first output depth, 3rd row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch1 * enable3rdRow * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), 2 * inDataPitch1 * bytesPerPixel)), \
                       vaOutData, pdvecOut, bytesPerPixel * enable3rdRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first output depth, 4th row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch1 * enable4thRow * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), 3 * inDataPitch1 * bytesPerPixel)), \
                       vaOutData, pdvecOut, bytesPerPixel * enable4thRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)),
                       vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * \
                       enable2ndRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, 3rd row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                              2 * outDataPitch1 * enable3rdRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), 2 * inDataPitch1 * bytesPerPixel)),
                       vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * \
                       enable3rdRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, 4th row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                              3 * outDataPitch1 * enable4thRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), 3 * inDataPitch1 * bytesPerPixel)),
                       vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * \
                       enable4thRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 3rd output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * enable3rdCh * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 3rd output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (2 * outDataPitch2 * enable3rdCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut3H, dvecOut3L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)),
                       vaOutData, pdvecOut, bytesPerPixel * enable3rdCh * \
                       enable2ndRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 3rd output depth, 3rd row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (2 * outDataPitch2 * enable3rdCh + \
                                              2 * outDataPitch1 * enable3rdRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut3H, dvecOut3L, IVP_ADD2NX8(IVP_SEQ2NX8(), 2 * inDataPitch1 * bytesPerPixel)),
                       vaOutData, pdvecOut, bytesPerPixel * enable3rdCh * \
                       enable3rdRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 3rd output depth, 4th row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (2 * outDataPitch2 * enable3rdCh + \
                                              3 * outDataPitch1 * enable4thRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut3H, dvecOut3L, IVP_ADD2NX8(IVP_SEQ2NX8(), 3 * inDataPitch1 * bytesPerPixel)),
                       vaOutData, pdvecOut, bytesPerPixel * enable3rdCh * \
                       enable4thRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 4th output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch2 * enable4thCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * enable4thCh * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 4th output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (3 * outDataPitch2 * enable4thCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut4H, dvecOut4L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)),
                       vaOutData, pdvecOut, bytesPerPixel * enable4thCh * \
                       enable2ndRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 4th output depth, 3rd row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (3 * outDataPitch2 * enable4thCh + \
                                              2 * outDataPitch1 * enable3rdRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut4H, dvecOut4L, IVP_ADD2NX8(IVP_SEQ2NX8(), 2 * inDataPitch1 * bytesPerPixel)),
                       vaOutData, pdvecOut, bytesPerPixel * enable4thCh * \
                       enable3rdRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 4th output depth, 4th row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (3 * outDataPitch2 * enable4thCh + \
                                              3 * outDataPitch1 * enable4thRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut4H, dvecOut4L, IVP_ADD2NX8(IVP_SEQ2NX8(), 3 * inDataPitch1 * bytesPerPixel)),
                       vaOutData, pdvecOut, bytesPerPixel * enable4thCh * \
                       enable4thRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 4 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 4 * coeffPitch3;
      } /* end of for (outCh = 0; outCh < numOutCh; outCh += 4)*/
    }   /* end of for (y = 0; y < outH; y++)*/
  }     /* end of else part of if ((numInCh <= 2*XCHAL_IVPN_SIMD_WIDTH))*/
}


/******************************************************************************************
* MOW fold 32 Stride 1 varaint                                                            *
* If inDataPitch1 is lesser than or equal to                                              *
* 16 this function is called.                                                             *
******************************************************************************************/

static _XAI_INLINE_ void MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_1x1j1d1), S8IX_MOW_WHD_FOLD32) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Getting parameters from the tile structures */
  const int32_t outW          = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH          = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh       = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh      = XAI_TILE3D_GET_DIM3(outTile);
  const int32_t inDataPitch1  = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2  = XAI_TILE3D_GET_DIM2_PITCH(inTile);
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);
  const int32_t coeffPitch3   = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  uint8_t enableReLu          = XAI_CNN_CONV_GET_FLAG_RELU(param);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  int32_t inCh, outCh, y;
  MORPH_IDT_2Nx8 *restrict pdvecIn1;
  MORPH_IDT_2Nx8 *restrict pdvecIn2;

  xb_vec2Nx8 * restrict pdvecOut;

  xb_vecN_2x32v * restrict phvecCoeff1;


  /* there are 2 implementations, one for
   * input channels less than or equal to 64, and other for input channels
   * greater than 64.
   * Adding one more loop to support more than 64 input channels is causing
   * significant overhead and degrades the the performance.
   */

  if ((numInCh <= 2 * XCHAL_IVPN_SIMD_WIDTH))
  {
    for (y = 0; y < outH; y += 2) /* Loop across Output height */
    {
      int32_t enable2ndRow = XT_SALT(y, outH - 1);

      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y];

      /* initialize coeff and Bias data pointer */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 4) /* Loop across Output depth */
      {
        /* In order to handle odd depths*/
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
        int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);
        int32_t enable4thCh = XT_SALT(outCh, numOutCh - 3);

        /* Load the bias values corresponding to two output channels */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
        xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4 * enable4thCh);
        xb_vecN_2x32v hvecBias4; IVP_LSRN_2X32_XP(hvecBias4, pBias, 4);


        xb_vec2Nx24 dacc1, dacc2, dacc3, dacc4;
        dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
        dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
        IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);
        dacc4 = IVP_CVT24UNX32L(hvecBias4, hvecBias4);
        IVP_CVT24UNX32H(dacc4, hvecBias4, hvecBias4);


        /* variables for coeff loads */
        xb_vecN_2x32v hvecCoeffData1, hvecCoeffData2, hvecCoeffData3, hvecCoeffData4;

        /* read coeff vectors , for 4 consecutive output depths */
        /* coeff vector for 1st output channel */
        phvecCoeff1 = (xb_vecN_2x32v *) (pCoeff);
        valign vaCoeffData; vaCoeffData = IVP_LAN_2X32_PP(phvecCoeff1);
        IVP_LAVN_2X32_XP(hvecCoeffData1, vaCoeffData, phvecCoeff1, coeffPitch3);

        /* coeff vector for 2nd output channel */
        vaCoeffData = IVP_LAN_2X32_PP(phvecCoeff1);
        IVP_LAVN_2X32_XP(hvecCoeffData2, vaCoeffData, phvecCoeff1, coeffPitch3 * enable2ndCh);

        /* coeff vector for 3rd output channel */
        vaCoeffData = IVP_LAN_2X32_PP(phvecCoeff1);
        IVP_LAVN_2X32_XP(hvecCoeffData3, vaCoeffData, phvecCoeff1, coeffPitch3 * enable3rdCh);

        /* coeff vector for 4th output channel */
        vaCoeffData = IVP_LAN_2X32_PP(phvecCoeff1);
        IVP_LAVN_2X32_XP(hvecCoeffData4, vaCoeffData, phvecCoeff1, coeffPitch3 * enable4thCh);

        pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
        pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2);

        for (inCh = 0; inCh < numInCh - 3; inCh += 4) /* Loop across input depth */
        {
          /* input vectors are read from 4 input depths at at time
           * Scalar 32 bit coeff are extracted from the coeff vectors */

          MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3, dvecData4;

          /* Read vector input data from 1st depth */
          valign vaInData; vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecData1, vaInData, pdvecIn1, inDataPitch2);

          /* Read vector input data from 2nd depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecData2, vaInData, pdvecIn1, 3 * inDataPitch2);

          /* Read vector input data from 3rd depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
          MORPH_OP_LOAD_2Nx8(dvecData3, vaInData, pdvecIn2, inDataPitch2);

          /* Read vector input data from 4th depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
          MORPH_OP_LOAD_2Nx8(dvecData4, vaInData, pdvecIn2, 3 * inDataPitch2);

          /* extract scalar coeff from coeff vectors */
          int32_t coeff1 = IVP_EXTRVRN_2X32(hvecCoeffData1, inCh); /* 1st o/p depth coeff */
          int32_t coeff2 = IVP_EXTRVRN_2X32(hvecCoeffData2, inCh); /* 2nd o/p depth coeff */
          int32_t coeff3 = IVP_EXTRVRN_2X32(hvecCoeffData3, inCh); /* 3rd o/p depth coeff */
          int32_t coeff4 = IVP_EXTRVRN_2X32(hvecCoeffData4, inCh); /* 4th o/p depth coeff */

          MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, coeff1);
          MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, coeff2);
          MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, coeff3);
          MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1, coeff4);
        } /* end of for (inCh = 0; inCh < numInCh; inCh += 4)*/
          /* Corner case handling if number of inCh is not a multiple of 4 */
        if (inCh < numInCh)
        {
          MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3;

          /* Read vector input data from 1st depth */
          valign vaInData; vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecData1, vaInData, pdvecIn1, inDataPitch2 * XT_SALT(inCh, numInCh - 1));

          /* Read vector input data from 2nd depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecData2, vaInData, pdvecIn1, inDataPitch2 * XT_SALT(inCh, numInCh - 2));

          /* Read vector input data from 3rd depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecData3, vaInData, pdvecIn1, 0);


          /* extract scalar coeff from coeff vectors */
          int32_t coeff1 = IVP_EXTRVRN_2X32(hvecCoeffData1, inCh); /* 1st o/p depth coeff */
          int32_t coeff2 = IVP_EXTRVRN_2X32(hvecCoeffData2, inCh); /* 2nd o/p depth coeff */
          int32_t coeff3 = IVP_EXTRVRN_2X32(hvecCoeffData3, inCh); /* 3rd o/p depth coeff */
          int32_t coeff4 = IVP_EXTRVRN_2X32(hvecCoeffData4, inCh); /* 4th o/p depth coeff */

          MORPH_OP_MULQA(dacc1, 0, dvecData3, dvecData2, dvecData1, coeff1);
          MORPH_OP_MULQA(dacc2, 0, dvecData3, dvecData2, dvecData1, coeff2);
          MORPH_OP_MULQA(dacc3, 0, dvecData3, dvecData2, dvecData1, coeff3);
          MORPH_OP_MULQA(dacc4, 0, dvecData3, dvecData2, dvecData1, coeff4);
        }


        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      pOutScaleData[outCh + 2 * enable3rdCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      pOutScaleData[outCh + 3 * enable4thCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* Storing the first output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2ndRow * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)), \
                       vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);


        /* Storing the second output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)),
                       vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * \
                       enable2ndRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 3rd output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * enable3rdCh * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 3rd output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (2 * outDataPitch2 * enable3rdCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut3H, dvecOut3L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)),
                       vaOutData, pdvecOut, bytesPerPixel * enable3rdCh * \
                       enable2ndRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 4th output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch2 * enable4thCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * enable4thCh * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 4th output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (3 * outDataPitch2 * enable4thCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut4H, dvecOut4L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)),
                       vaOutData, pdvecOut, bytesPerPixel * enable4thCh * \
                       enable2ndRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 4 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 4 * coeffPitch3;
      } /* end of for (outCh = 0; outCh < numOutCh; outCh += 4)*/
    }   /* end of for (y = 0; y < outH; y++)*/
  }     /* end of if ((numInCh <= 2*XCHAL_IVPN_SIMD_WIDTH))*/
  else
  {
#ifdef __XCC__
    XT_MEMW(); /* Adding Memory Wait as Gather and Normal Load/Stores are not synchronized */
#endif

    /* generate the sequence 0,1,2,3,0 + coeffPitch3, 1 + coeffPitch3,
     * 2 + coeffPitch3, 3 + coeffPitch3, 0 + 2 * coeffPitch3, 1 + 2 * coeffPitch3,
     * 2 + 2 * coeffPitch3, 3 + 2 * coeffPitch3, .....
     *
     * for e.g, if coeffPitch3 is 32:
     * 0,1,2,3,32,33,34,35,64,65,66,67,96,96,98,99,..
     *
     * This sequence is used to gather coeff from 4 diff output channels, 4 each from
     * every channel corresponding to 4 i/p channels, as innermost loop(inCh) is unrolled by
     * 4 to make use of quad multipler.
     */
    xb_vecNx16U vecIdx1 = IVP_SEQNX16();
    vecIdx1 = IVP_PACKVRNRNX48(IVP_MULNX16(vecIdx1, coeffPitch3), 0);
    vecIdx1 = IVP_SELNX16I(IVP_ADDNX16(vecIdx1, 1), vecIdx1, IVP_SELI_16B_INTERLEAVE_1_LO);
    vecIdx1 = IVP_SELNX16I(IVP_ADDNX16(vecIdx1, 2), vecIdx1, IVP_SELI_32B_INTERLEAVE_1_LO);
    xb_gsr gs0;

    for (y = 0; y < outH; y += 2)        /* Loop across Output height */
    {
      xb_vecNx16U vecIdx2;
      /* In order to handle odd rows*/
      int32_t enable2ndRow = XT_SALT(y, outH - 1);
      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y];

      /* initialize  Bias data pointer */

      int32_t *pBias = &pBiasData[0];
      int8_t *pCoeff = &pCoeffData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 4)  /* Loop across Output depth */
      {
        /* In order to handle odd depths*/
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
        int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);
        int32_t enable4thCh = XT_SALT(outCh, numOutCh - 3);

        /* load and replicate bias data for each output channel */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
        xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4 * enable4thCh);
        xb_vecN_2x32v hvecBias4; IVP_LSRN_2X32_XP(hvecBias4, pBias, 4);

        xb_vec2Nx24 dacc1, dacc2, dacc3, dacc4;
        dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
        dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
        IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);
        dacc4 = IVP_CVT24UNX32L(hvecBias4, hvecBias4);
        IVP_CVT24UNX32H(dacc4, hvecBias4, hvecBias4);

        /* boolean mask to gather coeffs, if all the four o/p channels
         * are present 16 coeff are loaded.
         */
        vboolN mask = IVP_LTNX16(IVP_SEQNX16(), (xb_vecNx16) XT_MIN(((numOutCh - outCh) * 4), 16));
        /* Assign valid address for predicated false lines */
        vecIdx2 = IVP_MOVNX16UT(vecIdx1, 0, mask);

        pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
        pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2);

#ifdef IS_VISION_130
        for (inCh = 0; inCh < numInCh - 3; inCh += 4)        /* Loop across input depth */
        {
          /* input vectors are read from 4 input depths at at time
           * Scalar 32 bit coeff are extracted from the coeff vectors */

          MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3, dvecData4;

          /* Read vector input data from 1st depth */
          MORPH_OP_L2_2Nx8(dvecData1, pdvecIn1, inDataPitch2);

          /* Read vector input data from 2nd depth */
          MORPH_OP_L2_2Nx8(dvecData2, pdvecIn1, 3 * inDataPitch2);

          /* Read vector input data from 3rd depth */
          MORPH_OP_L2_2Nx8(dvecData3, pdvecIn2, inDataPitch2);

          /* Read vector input data from 4th depth */
          MORPH_OP_L2_2Nx8(dvecData4, pdvecIn2, 3 * inDataPitch2);

          /* gather the coeffs */
          gs0 = IVP_GATHERANX8S(pCoeff + inCh, vecIdx2);
          xb_vec2Nx8 dvecCoeffData = IVP_GATHERD2NX8_L(gs0);

          /* extract scalar coeff from coeff vectors */
          int32_t coeff1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 0); /* 1st o/p depth coeff */
          int32_t coeff2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 1); /* 2nd o/p depth coeff */
          int32_t coeff3 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 2); /* 3rd o/p depth coeff */
          int32_t coeff4 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 3); /* 4th o/p depth coeff */

          MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, coeff1);
          MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, coeff2);
          MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, coeff3);
          MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1, coeff4);
        }       /* end of for (inCh = 0; inCh < numInCh; inCh += 4)*/
        if (inCh < numInCh)
        {
          MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3;

          pdvecIn2 = (MORPH_IDT_2Nx8 *) (((int8_t *) pdvecIn1) + 2 * inDataPitch2 * XT_SALT(inCh, numInCh - 2));
          /* Read vector input data from 1st depth */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecData1, vaInData, pdvecIn1, inDataPitch2 * XT_SALT(inCh, numInCh - 1));

          /* Read vector input data from 2nd depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          IVP_LAV2NX8_XP(dvecData2, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * XT_SALT(inCh, numInCh - 1));

          /* Read vector input data from 3rd depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
          IVP_LAV2NX8_XP(dvecData3, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * XT_SALT(inCh, numInCh - 2));

          /* Boolean mask for gather to handle cases where inCh<4 */
          vboolN mask1 = IVP_LTNX16(IVP_ANDNX16(IVP_SEQNX16(), 3), (numInCh - inCh));
          /* Assign valid address for predicated false lines */
          vecIdx2 = IVP_MOVNX16UT(vecIdx2, 0, mask1);
          /* Gather coeffs */
          gs0 = IVP_GATHERANX8S(pCoeff + inCh, vecIdx2);
          xb_vec2Nx8 dvecCoeffData = IVP_GATHERD2NX8_L(gs0);

          /* extract scalar coeff from coeff vectors */
          int32_t coeff1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 0); /* 1st o/p depth coeff */
          int32_t coeff2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 1); /* 2nd o/p depth coeff */
          int32_t coeff3 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 2); /* 3rd o/p depth coeff */
          int32_t coeff4 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 3); /* 4th o/p depth coeff */

          MORPH_OP_MULQA(dacc1, 0, dvecData3, dvecData2, dvecData1, coeff1);
          MORPH_OP_MULQA(dacc2, 0, dvecData3, dvecData2, dvecData1, coeff2);
          MORPH_OP_MULQA(dacc3, 0, dvecData3, dvecData2, dvecData1, coeff3);
          MORPH_OP_MULQA(dacc4, 0, dvecData3, dvecData2, dvecData1, coeff4);
        } /* end of if (inCh < numInCh)*/
#else
        for (inCh = 0; inCh < numInCh - 3; inCh += 4)        /* Loop across input depth */
        {
          /* input vectors are read from 4 input depths at at time
           * Scalar 32 bit coeff are extracted from the coeff vectors */

          MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3, dvecData4;

          /* Read vector input data from 1st depth */
          valign vaInData; vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecData1, vaInData, pdvecIn1, inDataPitch2);

          /* Read vector input data from 2nd depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecData2, vaInData, pdvecIn1, 3 * inDataPitch2);

          /* Read vector input data from 3rd depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
          MORPH_OP_LOAD_2Nx8(dvecData3, vaInData, pdvecIn2, inDataPitch2);

          /* Read vector input data from 4th depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
          MORPH_OP_LOAD_2Nx8(dvecData4, vaInData, pdvecIn2, 3 * inDataPitch2);

          /* gather the coeffs */
          gs0 = IVP_GATHERANX8S(pCoeff + inCh, vecIdx2);
          xb_vec2Nx8 dvecCoeffData = IVP_GATHERD2NX8_L(gs0);

          /* extract scalar coeff from coeff vectors */
          int32_t coeff1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 0); /* 1st o/p depth coeff */
          int32_t coeff2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 1); /* 2nd o/p depth coeff */
          int32_t coeff3 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 2); /* 3rd o/p depth coeff */
          int32_t coeff4 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 3); /* 4th o/p depth coeff */

          MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, coeff1);
          MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, coeff2);
          MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, coeff3);
          MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1, coeff4);
        }       /* end of for (inCh = 0; inCh < numInCh; inCh += 4)*/
        if (inCh < numInCh)
        {
          MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3;

          pdvecIn2 = (MORPH_IDT_2Nx8 *) (((int8_t *) pdvecIn1) + 2 * inDataPitch2 * XT_SALT(inCh, numInCh - 2));
          /* Read vector input data from 1st depth */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecData1, vaInData, pdvecIn1, inDataPitch2 * XT_SALT(inCh, numInCh - 1));

          /* Read vector input data from 2nd depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          IVP_LAV2NX8_XP(dvecData2, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * XT_SALT(inCh, numInCh - 1));

          /* Read vector input data from 3rd depth */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
          IVP_LAV2NX8_XP(dvecData3, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * XT_SALT(inCh, numInCh - 2));

          /* Boolean mask for gather to handle cases where inCh<4 */
          vboolN mask1 = IVP_LTNX16(IVP_ANDNX16(IVP_SEQNX16(), 3), (numInCh - inCh));
          /* Assign valid address for predicated false lines */
          vecIdx2 = IVP_MOVNX16UT(vecIdx2, 0, mask1);
          /* Gather coeffs */
          gs0 = IVP_GATHERANX8S(pCoeff + inCh, vecIdx2);
          xb_vec2Nx8 dvecCoeffData = IVP_GATHERD2NX8_L(gs0);

          /* extract scalar coeff from coeff vectors */
          int32_t coeff1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 0); /* 1st o/p depth coeff */
          int32_t coeff2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 1); /* 2nd o/p depth coeff */
          int32_t coeff3 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 2); /* 3rd o/p depth coeff */
          int32_t coeff4 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                            IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 3); /* 4th o/p depth coeff */

          MORPH_OP_MULQA(dacc1, 0, dvecData3, dvecData2, dvecData1, coeff1);
          MORPH_OP_MULQA(dacc2, 0, dvecData3, dvecData2, dvecData1, coeff2);
          MORPH_OP_MULQA(dacc3, 0, dvecData3, dvecData2, dvecData1, coeff3);
          MORPH_OP_MULQA(dacc4, 0, dvecData3, dvecData2, dvecData1, coeff4);
        } /* end of if (inCh < numInCh)*/
#endif
        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      pOutScaleData[outCh + 2 * enable3rdCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      pOutScaleData[outCh + 3 * enable4thCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif

        /* Storing the first output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2ndRow * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)), \
                       vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);


        /* Storing the second output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)),
                       vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * \
                       enable2ndRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 3rd output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * enable3rdCh * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 3rd output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (2 * outDataPitch2 * enable3rdCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut3H, dvecOut3L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)),
                       vaOutData, pdvecOut, bytesPerPixel * enable3rdCh * \
                       enable2ndRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 4th output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch2 * enable4thCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * enable4thCh * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 4th output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (3 * outDataPitch2 * enable4thCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut4H, dvecOut4L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)),
                       vaOutData, pdvecOut, bytesPerPixel * enable4thCh * \
                       enable2ndRow * outW);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 4 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 4 * coeffPitch3;
      } /* end of for (outCh = 0; outCh < numOutCh; outCh += 4)*/
    }   /* end of for (y = 0; y < outH; y++)*/
  }     /* end of else part of if ((numInCh <= 2*XCHAL_IVPN_SIMD_WIDTH))*/
}

/****************** xaiConvolvedVQ3D_S_1x1j1d1_S8S8IX_MOW_WHD ******************/
/****************** xaiConvolvedVQ3D_S_1x1j1d1_U8S8IX_MOW_WHD ******************/
/****************** xaiConvolved3D_S_1x1j1d1_S8S8IX_MOW_WHD *****************/
/****************** xaiConvolved3D_S_1x1j1d1_U8S8IX_MOW_WHD *****************/

XAI_ERR_TYPE MAKE_NAME(MAKE_NAME_VQ(xaiConvolved, 3D_S_1x1j1d1), S8IX_MOW_WHD) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Error Checks */
  XAI_ERROR_CHECKS()
  {
    MORPH_IDT_CHECK(inTile);
    XAI_CHECK_CONV_OUTPUT_TILE3D(outTile);
    XAI_CHECK_TILE4D_S8(coeffTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(outTile);
    XAI_CHECK_TILE4D_IN_DRAM_BOUNDARY(coeffTile);
    XAI_CHECK_POINTER(param);
    XAI_CHECK_ARRAY_S32(biasArray);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(inTile, outTile);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(coeffTile, outTile);
    XAI_CHECK_KERNEL_SIZE(coeffTile, 1);
    XAI_CHECK_TILE3D_DATA_ORDER(inTile, XAI_WHD);
    XAI_CHECK_TILE3D_DATA_ORDER(outTile, XAI_WHD);
    XAI_CHECK_TILE4D_DATA_ORDER(coeffTile, XAI_WHDN);
    XAI_CHECK_STRIDE(param, 1);
    XAI_CHECK_ERROR((XAI_CNN_CONV_GET_STRIDEX(param) == XAI_CNN_CONV_GET_STRIDEY(param)),                                         \
                    XAI_ERR_BADARG, "Stride along width = %hhu and height = %hhu\nStride along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_DILATION(param, 1);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_DILATIONX(param) == XAI_CNN_CONV_GET_DILATIONY(param),                                             \
                    XAI_ERR_BADARG, "\nDilation along width = %hhu and height = %hhu\nDilation along width and height should be equal", \
                    XAI_CNN_CONV_GET_DILATIONX(param), XAI_CNN_CONV_GET_DILATIONY(param));
    XAI_CHECK_CONSISTENCY_MOW_WHD(inTile, coeffTile, biasArray, outTile, param);
    XAI_CHECK_COEFFTILE_CONTIGUOUS(coeffTile, param);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_ACCUM_SHIFT(param) < 24,                                     \
                    XAI_ERR_NORM, "\nThe accumulator shift = %hhu, value should be less than 24", \
                    XAI_CNN_CONV_GET_ACCUM_SHIFT(param));
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_OUTPUT_SHIFT(param) < 32,                               \
                    XAI_ERR_NORM, "\nThe output shift = %hhu, value should be less than 32", \
                    XAI_CNN_CONV_GET_OUTPUT_SHIFT(param));
    XAI_CHECK_CONV_RELU_LIMITS_IX(param, outTile);
#if DILATED_VQ_CONV == VQ_TRUE
    XAI_CHECK_ARRAY_U16(outputScaleArray);
    XAI_CHECK_ERROR(XAI_ARRAY_GET_WIDTH(outputScaleArray) >= XAI_TILE4D_GET_DIM4(coeffTile),                                                                                          \
                    XAI_ERR_DATASIZE, "\nWidth of Output Scale Array = %d, Number of Kernels = %d\nWidth of Output Scale Array should be greater than or equal to Number of Kernels", \
                    XAI_ARRAY_GET_WIDTH(outputScaleArray), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_ERROR((((uintptr_t) (XAI_ARRAY_GET_DATA_PTR(outputScaleArray)) & \
                      0x1) == 0), XAI_ERR_NORM, "The output scale array is not aligned to 2 byte boundary");
#endif
  }
#if DILATED_VQ_CONV == VQ_FALSE
  if (XAI_CNN_CONV_GET_OUTPUT_SCALE(param) == 0)
  {
    int32_t fillValue;
    int32_t reluFlag = XAI_CNN_CONV_GET_FLAG_RELU(param);
    fillValue = reluFlag ? (CLAMP(0, XAI_CNN_CONV_GET_RELU_MIN(param), XAI_CNN_CONV_GET_RELU_MAX(param))) : 0;
    return(xaiFillTile3D(outTile, fillValue, 0));
  }
#endif
  /* Getting parameters from the tile structures */
  const int32_t outW          = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH          = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh       = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh      = XAI_TILE3D_GET_DIM3(outTile);
  const int32_t inDataPitch1  = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2  = XAI_TILE3D_GET_DIM2_PITCH(inTile);
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);
  const int32_t coeffPitch3   = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);
  /* if pitch = width in input and output tile call the no edge variant*/
  int32_t enableFlatten = ((inDataPitch1 == XAI_TILE3D_GET_DIM1(inTile)) && \
                           (outDataPitch1 == outW) && (inDataPitch1 == outDataPitch1));

  XAI_ERROR_CHECKS_CONTINUE()
  {
    if ((XAI_TILE3D_IS_ALIGNED_2NX8(inTile) == 0) && (enableFlatten || (numInCh > 2 * XCHAL_IVPN_SIMD_WIDTH)))
    {
      XAI_CHECK_TILE4D_FITS_IN_SINGLE_DRAM(coeffTile);
      if (numOutCh > 1)
      {
        /* Max value of Gather Offset is (min(numOutCh-1,3)*coeffPitch3 + min(numInCh-1, 3)) */
        XAI_CHECK_ERROR(coeffPitch3 < ((USHRT_MAX - XT_MIN(numInCh - 1, 3)) / XT_MIN(numOutCh - 1, 3)),                              \
                        XAI_ERR_BADARG, "\ndim3Pitch value of coeffTile = %d, should be less than Gather Offset(16-bit limit) - %d", \
                        coeffPitch3, ((USHRT_MAX - XT_MIN(numInCh - 1, 3)) / XT_MIN(numOutCh - 1, 3)));
      }
    }
  }
  /* if pitch = width in input and output tile call the no edge variant*/
  if (enableFlatten)
  {
    MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_1x1j1d1), S8IX_MOW_WHD_NOEDGE) MAKE_PARAMS(inTile, coeffTile, biasArray, outTile, param);
    return(XAI_ERROR_STATUS());
  }
  /* check inDataPitch1, if it is less than or equal to 16,
   * call FOLD16 variant and if it's greater than
   * 16 but less than or equal to 32 call FOLD32 variant otherwise continue
   */
  if (inDataPitch1 <= 16)
  {
    MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_1x1j1d1), S8IX_MOW_WHD_FOLD16) MAKE_PARAMS(inTile, coeffTile, biasArray, outTile, param);
    return(XAI_ERROR_STATUS());
  }

  if (inDataPitch1 <= 32)
  {
    MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_1x1j1d1), S8IX_MOW_WHD_FOLD32) MAKE_PARAMS(inTile, coeffTile, biasArray, outTile, param);
    return(XAI_ERROR_STATUS());
  }

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  uint8_t enableReLu          = XAI_CNN_CONV_GET_FLAG_RELU(param);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  const int32_t vectorizationWidth = 2 * XCHAL_IVPN_SIMD_WIDTH;

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  int32_t inCh, outCh, x, y;
  MORPH_IDT_2Nx8 *restrict pdvecIn1;
  MORPH_IDT_2Nx8 *restrict pdvecIn2;
  MORPH_IDT_2Nx8 *restrict pdvecIn3;
  MORPH_IDT_2Nx8 *restrict pdvecIn4;
  xb_vec2Nx8 * restrict pdvecOut;
  xb_vec2Nx8 * restrict pdvecCoeff1;
  xb_vec2Nx8 * restrict pdvecCoeff2;
  xb_vec2Nx8 * restrict pdvecCoeff3;
  xb_vec2Nx8 * restrict pdvecCoeff4;
  xb_vecN_2x32v * restrict phvecCoeff1;

  /* The overall design approach is split into 2 sections, one
   * with aligned input data and the other with unaligned input data.
   * The implementation with aligned input data gives the best performance */

  /* In the unaligned input data case, there are 2 implementations, one for
   * input channels less than or equal to 64, and other for input channels
   * greater than 64.
   * Adding one more loop to support more than 64 input channels is causing
   * significant overhead and degrades the the performance.
   */

  if (XAI_TILE3D_IS_ALIGNED_2NX8(inTile))
  {
    for (x = 0; x < outW; x += vectorizationWidth)  /* Loop across Output width */
    {
      for (y = 0; y < outH; y++)  /* Loop across Output height */
      {
        /* initialize output data pointer */
        int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

        /* initialize input data pointer */
        MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y + x];

        /* initialize coeff and Bias data pointer */
        int32_t *pBias = &pBiasData[0];

        for (outCh = 0; outCh < numOutCh; outCh += 4) /* Loop across Output depth */
        {
          /* In order to handle odd depths*/
          int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
          int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);
          int32_t enable4thCh = XT_SALT(outCh, numOutCh - 3);

          /* Load the bias values corresponding to two output channels */
          xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
          xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
          xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4 * enable4thCh);
          xb_vecN_2x32v hvecBias4; IVP_LSRN_2X32_XP(hvecBias4, pBias, 4);

          xb_vec2Nx24 dacc1, dacc2, dacc3, dacc4;
          dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
          dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
          dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
          IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);
          dacc4 = IVP_CVT24UNX32L(hvecBias4, hvecBias4);
          IVP_CVT24UNX32H(dacc4, hvecBias4, hvecBias4);


          /* Coefficient and input pointers */
          int8_t *pCoeff = &pCoeffData[outCh * coeffPitch3];
          pdvecCoeff1 = (xb_vec2Nx8 *) pCoeff;
          pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
          pdvecCoeff3 = (xb_vec2Nx8 *) (pCoeff + 2 * coeffPitch3 * enable3rdCh);
          pdvecCoeff4 = (xb_vec2Nx8 *) (pCoeff + 3 * coeffPitch3 * enable4thCh);
          pdvecIn1    = (MORPH_IDT_2Nx8 *) (pInput);
          pdvecIn2    = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch2);
          pdvecIn3    = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2);
          pdvecIn4    = (MORPH_IDT_2Nx8 *) (pInput + 3 * inDataPitch2);

          /* Priming Loads for Coefficients */
          valign vaCoeff1 = IVP_LA2NX8_PP(pdvecCoeff1);
          valign vaCoeff2 = IVP_LA2NX8_PP(pdvecCoeff2);
          valign vaCoeff3 = IVP_LA2NX8_PP(pdvecCoeff3);
          valign vaCoeff4 = IVP_LA2NX8_PP(pdvecCoeff4);

          for (inCh = 0; inCh < numInCh - 3; inCh += 4)  /* Loop across input depth */
          {
            /* input vectors are read from 4 input depths at at time
             * Scalar 32 bit coeff are extracted from the coeff vectors */
            MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3, dvecData4;

            /* Read vector input data from 1st depth */
            MORPH_OP_ALIGN_LOAD_2Nx8(dvecData1, pdvecIn1, 4 * inDataPitch2);

            /* Read vector input data from 2nd depth */
            MORPH_OP_ALIGN_LOAD_2Nx8(dvecData2, pdvecIn2, 4 * inDataPitch2);

            /* Read vector input data from 3rd depth */
            MORPH_OP_ALIGN_LOAD_2Nx8(dvecData3, pdvecIn3, 4 * inDataPitch2);

            /* Read vector input data from 4th depth */
            MORPH_OP_ALIGN_LOAD_2Nx8(dvecData4, pdvecIn4, 4 * inDataPitch2);

            xb_vec2Nx8 dvecCoeff1, dvecCoeff2, dvecCoeff3, dvecCoeff4;
            IVP_LAV2NX8_XP(dvecCoeff1, vaCoeff1, pdvecCoeff1, 4);
            IVP_LAV2NX8_XP(dvecCoeff2, vaCoeff2, pdvecCoeff2, 4);
            IVP_LAV2NX8_XP(dvecCoeff3, vaCoeff3, pdvecCoeff3, 4);
            IVP_LAV2NX8_XP(dvecCoeff4, vaCoeff4, pdvecCoeff4, 4);

            int32_t coeff1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16 \
                                              (IVP_MOVNX16_FROM2NX8(dvecCoeff1)), 0);
            int32_t coeff2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16 \
                                              (IVP_MOVNX16_FROM2NX8(dvecCoeff2)), 0);
            int32_t coeff3 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16 \
                                              (IVP_MOVNX16_FROM2NX8(dvecCoeff3)), 0);
            int32_t coeff4 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16 \
                                              (IVP_MOVNX16_FROM2NX8(dvecCoeff4)), 0);

            MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, coeff1);
            MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, coeff2);
            MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, coeff3);
            MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1, coeff4);
          } /* end of for (inCh = 0; inCh < numInCh - 3; inCh += 4)*/

          /* Corner case handling if number of inCh is not a multiple of 4 */
          if (inCh < numInCh)
          {
            int32_t remInCh = numInCh - inCh;

            /* input vectors are read from 4 input depths at at time
             * Scalar 32 bit coeff are extracted from the coeff vectors */
            MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3;

            /* Read vector input data from 1st depth */
            MORPH_OP_ALIGN_LOAD_2Nx8(dvecData1, pdvecIn1, inDataPitch2 * XT_SALT(1, remInCh));

            /* Read vector input data from 2nd depth */
            MORPH_OP_ALIGN_LOAD_2Nx8(dvecData2, pdvecIn1, inDataPitch2 * XT_SALT(2, remInCh));

            /* Read vector input data from 3rd depth */
            MORPH_OP_ALIGN_LOAD_2Nx8(dvecData3, pdvecIn1, 0);

            xb_vec2Nx8 dvecCoeff1, dvecCoeff2, dvecCoeff3, dvecCoeff4;
            IVP_LAV2NX8_XP(dvecCoeff1, vaCoeff1, pdvecCoeff1, remInCh);
            IVP_LAV2NX8_XP(dvecCoeff2, vaCoeff2, pdvecCoeff2, remInCh);
            IVP_LAV2NX8_XP(dvecCoeff3, vaCoeff3, pdvecCoeff3, remInCh);
            IVP_LAV2NX8_XP(dvecCoeff4, vaCoeff4, pdvecCoeff4, remInCh);

            int32_t coeff1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16 \
                                              (IVP_MOVNX16_FROM2NX8(dvecCoeff1)), 0);
            int32_t coeff2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16 \
                                              (IVP_MOVNX16_FROM2NX8(dvecCoeff2)), 0);
            int32_t coeff3 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16 \
                                              (IVP_MOVNX16_FROM2NX8(dvecCoeff3)), 0);
            int32_t coeff4 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16 \
                                              (IVP_MOVNX16_FROM2NX8(dvecCoeff4)), 0);

            MORPH_OP_MULQA(dacc1, 0, dvecData3, dvecData2, dvecData1, coeff1);
            MORPH_OP_MULQA(dacc2, 0, dvecData3, dvecData2, dvecData1, coeff2);
            MORPH_OP_MULQA(dacc3, 0, dvecData3, dvecData2, dvecData1, coeff3);
            MORPH_OP_MULQA(dacc4, 0, dvecData3, dvecData2, dvecData1, coeff4);
          } /* end of corner case handling*/

          /* Pack, Output Scale, Output Shift and clamping */
          xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
          xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                        pOutScaleData[outCh + 2 * enable3rdCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                        pOutScaleData[outCh + 3 * enable4thCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
          /* variable store count */
          int32_t varLen = outW - x;

          /* store output to 1st output depth */
          pdvecOut = (xb_vec2Nx8 *) (pOutput);
          valign vaOutData; vaOutData = IVP_ZALIGN();
          IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
          IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* store output to 2nd output depth */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* store output to 3rd output depth */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable3rdCh);
          IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable3rdCh);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* store output to 4th output depth */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch2 * enable4thCh * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable4thCh);
          IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable4thCh);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          pOutput += 4 * outDataPitch2 * bytesPerPixel;
        } /* end of for (outCh = 0; outCh < numOutCh; outCh += 4)*/
      }   /* end of for (y = 0; y < outH; y++)*/
    }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  }
  else
  {
    if ((numInCh <= 2 * XCHAL_IVPN_SIMD_WIDTH))
    {
      for (x = 0; x < outW; x += vectorizationWidth) /* Loop across Output width */
      {
        for (y = 0; y < outH; y++) /* Loop across Output height */
        {
          /* initialize output data pointer */
          int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

          /* initialize input data pointer */
          MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y + x];

          /* initialize coeff and Bias data pointer */
          int8_t *pCoeff = &pCoeffData[0];
          int32_t *pBias = &pBiasData[0];

          for (outCh = 0; outCh < numOutCh; outCh += 4) /* Loop across Output depth */
          {
            /* In order to handle odd depths*/
            int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
            int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);
            int32_t enable4thCh = XT_SALT(outCh, numOutCh - 3);

            /* Load the bias values corresponding to two output channels */
            xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
            xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
            xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4 * enable4thCh);
            xb_vecN_2x32v hvecBias4; IVP_LSRN_2X32_XP(hvecBias4, pBias, 4);


            xb_vec2Nx24 dacc1, dacc2, dacc3, dacc4;
            dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
            IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
            dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
            IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
            dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
            IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);
            dacc4 = IVP_CVT24UNX32L(hvecBias4, hvecBias4);
            IVP_CVT24UNX32H(dacc4, hvecBias4, hvecBias4);


            /* variables for coeff loads */
            xb_vecN_2x32v hvecCoeffData1, hvecCoeffData2, hvecCoeffData3, hvecCoeffData4;

            /* read coeff vectors , for 4 consecutive output depths */
            /* coeff vector for 1st output channel */
            phvecCoeff1 = (xb_vecN_2x32v *) (pCoeff);
            valign vaCoeffData; vaCoeffData = IVP_LAN_2X32_PP(phvecCoeff1);
            IVP_LAVN_2X32_XP(hvecCoeffData1, vaCoeffData, phvecCoeff1, coeffPitch3);

            /* coeff vector for 2nd output channel */
            vaCoeffData = IVP_LAN_2X32_PP(phvecCoeff1);
            IVP_LAVN_2X32_XP(hvecCoeffData2, vaCoeffData, phvecCoeff1, coeffPitch3 * enable2ndCh);

            /* coeff vector for 3rd output channel */
            vaCoeffData = IVP_LAN_2X32_PP(phvecCoeff1);
            IVP_LAVN_2X32_XP(hvecCoeffData3, vaCoeffData, phvecCoeff1, coeffPitch3 * enable3rdCh);

            /* coeff vector for 4th output channel */
            vaCoeffData = IVP_LAN_2X32_PP(phvecCoeff1);
            IVP_LAVN_2X32_XP(hvecCoeffData4, vaCoeffData, phvecCoeff1, coeffPitch3 * enable4thCh);

            pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
            pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2);

            for (inCh = 0; inCh < numInCh - 3; inCh += 4) /* Loop across input depth */
            {
              /* input vectors are read from 4 input depths at at time
               * Scalar 32 bit coeff are extracted from the coeff vectors */

              MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3, dvecData4;

              /* Read vector input data from 1st depth */
              valign vaInData; vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
              MORPH_OP_LOAD_2Nx8(dvecData1, vaInData, pdvecIn1, inDataPitch2);

              /* Read vector input data from 2nd depth */
              vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
              MORPH_OP_LOAD_2Nx8(dvecData2, vaInData, pdvecIn1, 3 * inDataPitch2);

              /* Read vector input data from 3rd depth */
              vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
              MORPH_OP_LOAD_2Nx8(dvecData3, vaInData, pdvecIn2, inDataPitch2);

              /* Read vector input data from 4th depth */
              vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
              MORPH_OP_LOAD_2Nx8(dvecData4, vaInData, pdvecIn2, 3 * inDataPitch2);

              /* extract scalar coeff from coeff vectors */
              int32_t coeff1 = IVP_EXTRVRN_2X32(hvecCoeffData1, inCh); /* 1st o/p depth coeff */
              int32_t coeff2 = IVP_EXTRVRN_2X32(hvecCoeffData2, inCh); /* 2nd o/p depth coeff */
              int32_t coeff3 = IVP_EXTRVRN_2X32(hvecCoeffData3, inCh); /* 3rd o/p depth coeff */
              int32_t coeff4 = IVP_EXTRVRN_2X32(hvecCoeffData4, inCh); /* 4th o/p depth coeff */

              MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, coeff1);
              MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, coeff2);
              MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, coeff3);
              MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1, coeff4);
            } /* end of for (inCh = 0; inCh < numInCh - 3; inCh += 4)*/
              /* Corner case handling if number of inCh is not a multiple of 4 */
            if (inCh < numInCh)
            {
              MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3;

              /* Read vector input data from 1st depth */
              valign vaInData; vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
              MORPH_OP_LOAD_2Nx8(dvecData1, vaInData, pdvecIn1, inDataPitch2 * XT_SALT(inCh, numInCh - 1));

              /* Read vector input data from 2nd depth */
              vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
              MORPH_OP_LOAD_2Nx8(dvecData2, vaInData, pdvecIn1, inDataPitch2 * XT_SALT(inCh, numInCh - 2));

              /* Read vector input data from 3rd depth */
              vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
              MORPH_OP_LOAD_2Nx8(dvecData3, vaInData, pdvecIn1, inDataPitch2);


              /* extract scalar coeff from coeff vectors */
              int32_t coeff1 = IVP_EXTRVRN_2X32(hvecCoeffData1, inCh); /* 1st o/p depth coeff */
              int32_t coeff2 = IVP_EXTRVRN_2X32(hvecCoeffData2, inCh); /* 2nd o/p depth coeff */
              int32_t coeff3 = IVP_EXTRVRN_2X32(hvecCoeffData3, inCh); /* 3rd o/p depth coeff */
              int32_t coeff4 = IVP_EXTRVRN_2X32(hvecCoeffData4, inCh); /* 4th o/p depth coeff */

              MORPH_OP_MULQA(dacc1, 0, dvecData3, dvecData2, dvecData1, coeff1);
              MORPH_OP_MULQA(dacc2, 0, dvecData3, dvecData2, dvecData1, coeff2);
              MORPH_OP_MULQA(dacc3, 0, dvecData3, dvecData2, dvecData1, coeff3);
              MORPH_OP_MULQA(dacc4, 0, dvecData3, dvecData2, dvecData1, coeff4);
            }

            /* Pack, Output Scale, Output Shift and clamping */
            xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
            xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
            PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                          pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
            PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                          pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
            PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                          pOutScaleData[outCh + 2 * enable3rdCh], outShiftU, minLim, maxLim, typeFlag);
            PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                          pOutScaleData[outCh + 3 * enable4thCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
            PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                          outScale, outShiftU, minLim, maxLim, typeFlag);
            PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                          outScale, outShiftU, minLim, maxLim, typeFlag);
            PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                          outScale, outShiftU, minLim, maxLim, typeFlag);
            PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                          outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
            /* variable store count */
            int32_t varLen = outW - x;

            /* store output to 1st output depth */
            pdvecOut = (xb_vec2Nx8 *) (pOutput);
            valign vaOutData; vaOutData = IVP_ZALIGN();
            IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
            IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                           2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
            IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

            /* store output to 2nd output depth */
            pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
            IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
            IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                           2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
            IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

            /* store output to 3rd output depth */
            pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
            IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable3rdCh);
            IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                           2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable3rdCh);
            IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

            /* store output to 4th output depth */
            pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch2 * enable4thCh * bytesPerPixel);
            IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable4thCh);
            IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                           2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable4thCh);
            IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

            pOutput += 4 * outDataPitch2 * bytesPerPixel;
            pCoeff  += 4 * coeffPitch3;
          } /* end of for (outCh = 0; outCh < numOutCh; outCh += 4)*/
        }   /* end of for (y = 0; y < outH; y++)*/
      }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
    }       /* end of if ((numInCh <= 2*XCHAL_IVPN_SIMD_WIDTH))*/
    else
    {
#ifdef __XCC__
      XT_MEMW(); /* Adding Memory Wait as Gather and Normal Load/Stores are not synchronized */
#endif

      /* generate the sequence 0,1,2,3,0 + coeffPitch3, 1 + coeffPitch3,
       * 2 + coeffPitch3, 3 + coeffPitch3, 0 + 2 * coeffPitch3, 1 + 2 * coeffPitch3,
       * 2 + 2 * coeffPitch3, 3 + 2 * coeffPitch3, .....
       *
       * for e.g, if coeffPitch3 is 32:
       * 0,1,2,3,32,33,34,35,64,65,66,67,96,96,98,99,..
       *
       * This sequence is used to gather coeff from 4 diff output channels, 4 each from
       * every channel corresponding to 4 i/p channels, as innermost loop(inCh) is unrolled by
       * 4 to make use of quad multipler.
       */
      xb_vecNx16U vecIdx1 = IVP_SEQNX16();
      vecIdx1 = IVP_PACKVRNRNX48(IVP_MULNX16(vecIdx1, coeffPitch3), 0);
      vecIdx1 = IVP_SELNX16I(IVP_ADDNX16(vecIdx1, 1), vecIdx1, IVP_SELI_16B_INTERLEAVE_1_LO);
      vecIdx1 = IVP_SELNX16I(IVP_ADDNX16(vecIdx1, 2), vecIdx1, IVP_SELI_32B_INTERLEAVE_1_LO);
      xb_gsr gs0;

      for (x = 0; x < outW; x += vectorizationWidth)   /* Loop across Output width */
      {
        /* variable store count */
        int32_t varLen = outW - x;
        xb_vecNx16U vecIdx2;
        for (y = 0; y < outH; y++)        /* Loop across Output height */
        {
          /* initialize output data pointer */
          int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

          /* initialize input data pointer */
          MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y + x];

          /* initialize  Bias data pointer */

          int32_t *pBias = &pBiasData[0];
          int8_t *pCoeff = &pCoeffData[0];

          for (outCh = 0; outCh < numOutCh; outCh += 4)  /* Loop across Output depth */
          {
            /* In order to handle odd depths*/
            int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
            int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);
            int32_t enable4thCh = XT_SALT(outCh, numOutCh - 3);

            /* load and replicate bias data for each output channel */
            xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
            xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
            xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4 * enable4thCh);
            xb_vecN_2x32v hvecBias4; IVP_LSRN_2X32_XP(hvecBias4, pBias, 4);

            xb_vec2Nx24 dacc1, dacc2, dacc3, dacc4;
            dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
            IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
            dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
            IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
            dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
            IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);
            dacc4 = IVP_CVT24UNX32L(hvecBias4, hvecBias4);
            IVP_CVT24UNX32H(dacc4, hvecBias4, hvecBias4);

            /* boolean mask to gather coeffs, if all the four o/p channels
             * are present 16 coeff are loaded.
             */
            vboolN mask = IVP_LTNX16(IVP_SEQNX16(), (xb_vecNx16) XT_MIN(((numOutCh - outCh) * 4), 16));
            /* Assign valid address for predicated false lines */
            vecIdx2 = IVP_MOVNX16UT(vecIdx1, 0, mask);

            pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
            pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2);

            for (inCh = 0; inCh < numInCh - 3; inCh += 4)        /* Loop across input depth */
            {
              /* input vectors are read from 4 input depths at at time
               * Scalar 32 bit coeff are extracted from the coeff vectors */

              MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3, dvecData4;

              /* Read vector input data from 1st depth */
              valign vaInData; vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
              MORPH_OP_LOAD_2Nx8(dvecData1, vaInData, pdvecIn1, inDataPitch2);

              /* Read vector input data from 2nd depth */
              vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
              MORPH_OP_LOAD_2Nx8(dvecData2, vaInData, pdvecIn1, 3 * inDataPitch2);

              /* Read vector input data from 3rd depth */
              vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
              MORPH_OP_LOAD_2Nx8(dvecData3, vaInData, pdvecIn2, inDataPitch2);

              /* Read vector input data from 4th depth */
              vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
              MORPH_OP_LOAD_2Nx8(dvecData4, vaInData, pdvecIn2, 3 * inDataPitch2);

              /* gather the coeffs */
              gs0 = IVP_GATHERANX8S(pCoeff + inCh, vecIdx2);
              xb_vec2Nx8 dvecCoeffData = IVP_GATHERD2NX8_L(gs0);

              /* extract scalar coeff from coeff vectors */
              int32_t coeff1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                                IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 0); /* 1st o/p depth coeff */
              int32_t coeff2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                                IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 1); /* 2nd o/p depth coeff */
              int32_t coeff3 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                                IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 2); /* 3rd o/p depth coeff */
              int32_t coeff4 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                                IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 3); /* 4th o/p depth coeff */

              MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, coeff1);
              MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, coeff2);
              MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, coeff3);
              MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1, coeff4);
            }       /* end of for (inCh = 0; inCh < numInCh; inCh += 4)*/
            if (inCh < numInCh)
            {
              MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3;

              pdvecIn2 = (MORPH_IDT_2Nx8 *) (((int8_t *) pdvecIn1) + 2 * inDataPitch2 * XT_SALT(inCh, numInCh - 2));
              /* Read vector input data from 1st depth */
              valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
              MORPH_OP_LOAD_2Nx8(dvecData1, vaInData, pdvecIn1, inDataPitch2 * XT_SALT(inCh, numInCh - 1));

              /* Read vector input data from 2nd depth */
              vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
              IVP_LAV2NX8_XP(dvecData2, vaInData, pdvecIn1, varLen * XT_SALT(inCh, numInCh - 1));

              /* Read vector input data from 3rd depth */
              vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
              IVP_LAV2NX8_XP(dvecData3, vaInData, pdvecIn2, varLen * XT_SALT(inCh, numInCh - 2));

              /* Boolean mask for gather to handle cases where inCh<4 */
              vboolN mask1 = IVP_LTNX16(IVP_ANDNX16(IVP_SEQNX16(), 3), (numInCh - inCh));
              /* Assign valid address for predicated false lines */
              vecIdx2 = IVP_MOVNX16UT(vecIdx2, 0, mask1);
              /* Gather coeffs */
              gs0 = IVP_GATHERANX8S(pCoeff + inCh, vecIdx2);
              xb_vec2Nx8 dvecCoeffData = IVP_GATHERD2NX8_L(gs0);

              /* extract scalar coeff from coeff vectors */
              int32_t coeff1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                                IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 0); /* 1st o/p depth coeff */
              int32_t coeff2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                                IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 1); /* 2nd o/p depth coeff */
              int32_t coeff3 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                                IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 2); /* 3rd o/p depth coeff */
              int32_t coeff4 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                                IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 3); /* 4th o/p depth coeff */

              MORPH_OP_MULQA(dacc1, 0, dvecData3, dvecData2, dvecData1, coeff1);
              MORPH_OP_MULQA(dacc2, 0, dvecData3, dvecData2, dvecData1, coeff2);
              MORPH_OP_MULQA(dacc3, 0, dvecData3, dvecData2, dvecData1, coeff3);
              MORPH_OP_MULQA(dacc4, 0, dvecData3, dvecData2, dvecData1, coeff4);
            } /* end of if (inCh < numInCh)*/

            /* Pack, Output Scale, Output Shift and clamping */
            xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
            xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
            PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                          pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
            PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                          pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
            PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                          pOutScaleData[outCh + 2 * enable3rdCh], outShiftU, minLim, maxLim, typeFlag);
            PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                          pOutScaleData[outCh + 3 * enable4thCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
            PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                          outScale, outShiftU, minLim, maxLim, typeFlag);
            PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                          outScale, outShiftU, minLim, maxLim, typeFlag);
            PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                          outScale, outShiftU, minLim, maxLim, typeFlag);
            PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                          outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
            /* store output to 1st output depth */
            pdvecOut = (xb_vec2Nx8 *) (pOutput);
            valign vaOutData; vaOutData = IVP_ZALIGN();
            IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
            IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                           2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
            IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

            /* store output to 2nd output depth */
            pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
            IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
            IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                           2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
            IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

            /* store output to 3rd output depth */
            pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
            IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable3rdCh);
            IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                           2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable3rdCh);
            IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

            /* store output to 4th output depth */
            pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch2 * enable4thCh * bytesPerPixel);
            IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable4thCh);
            IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                           2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable4thCh);
            IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

            pOutput += 4 * outDataPitch2 * bytesPerPixel;
            pCoeff  += 4 * coeffPitch3;
          } /* end of for (outCh = 0; outCh < numOutCh; outCh += 4)*/
        }   /* end of for (y = 0; y < outH; y++)*/
      }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
    }       /* end of else part of if ((numInCh <= 2*XCHAL_IVPN_SIMD_WIDTH))*/
  }
  return(XAI_ERROR_STATUS());
}

/*****************************************************************************
*  xaiConvolved(VQ)3D_S_1x1j2d1I8S8IX_MOW_WHD
*  **************************************************************************/

/******************************************************************************/
/* Description : P6 optimized generic implementation for 1x1 3D convolution.  */
/*               Based on MORPH pre-processor specifiers, code implementation */
/*               is generated during preprocessing stage. This method can be  */
/*               used to generate 1x1 3D MOW_WHD dilated convolution function */
/*               and 1x1 3D VQ MOW_WHD dilated convolution function for U8    */
/*               bit and S8 bit input data with input stride equal to 2       */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                */
/*               Output scale array, CNN convolution params structure         */
/* Outputs     : XI Error Code                                                */
/* InOuts      : Output Tile                                                  */
/* Assumptions : CoeffData is S8                                              */
/*               biasArray is signed 32b, value not exceeding signed 24b      */
/*               Output scale array is U16                                    */
/*               OutData is S8 / U8 / S16                                     */
/*               Kernel Size is 1x1xDxN                                       */
/*               Input and Output are in WHD format                           */
/*               Coeff is in WHDN format                                      */
/******************************************************************************/

/****************** xaiConvolvedVQ3D_S_1x1j2d1_S8S8IX_MOW_WHD ******************/
/****************** xaiConvolvedVQ3D_S_1x1j2d1_U8S8IX_MOW_WHD ******************/
/******************* xaiConvolved3D_S_1x1j2d1_S8S8IX_MOW_WHD *******************/
/******************* xaiConvolved3D_S_1x1j2d1_U8S8IX_MOW_WHD *******************/

XAI_ERR_TYPE MAKE_NAME(MAKE_NAME_VQ(xaiConvolved, 3D_S_1x1j2d1), S8IX_MOW_WHD) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Error Checks */
  XAI_ERROR_CHECKS()
  {
    MORPH_IDT_CHECK(inTile);
    XAI_CHECK_CONV_OUTPUT_TILE3D(outTile);
    XAI_CHECK_TILE4D_S8(coeffTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(outTile);
    XAI_CHECK_TILE4D_IN_DRAM_BOUNDARY(coeffTile);
    XAI_CHECK_POINTER(param);
    XAI_CHECK_ARRAY_S32(biasArray);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(inTile, outTile);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(coeffTile, outTile);
    XAI_CHECK_KERNEL_SIZE(coeffTile, 1);
    XAI_CHECK_TILE3D_DATA_ORDER(inTile, XAI_WHD);
    XAI_CHECK_TILE3D_DATA_ORDER(outTile, XAI_WHD);
    XAI_CHECK_TILE4D_DATA_ORDER(coeffTile, XAI_WHDN);
    XAI_CHECK_STRIDE(param, 2);
    XAI_CHECK_ERROR((XAI_CNN_CONV_GET_STRIDEX(param) == XAI_CNN_CONV_GET_STRIDEY(param)),                                         \
                    XAI_ERR_BADARG, "Stride along width = %hhu and height = %hhu\nStride along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_DILATION(param, 1);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_DILATIONX(param) == XAI_CNN_CONV_GET_DILATIONY(param),                                             \
                    XAI_ERR_BADARG, "\nDilation along width = %hhu and height = %hhu\nDilation along width and height should be equal", \
                    XAI_CNN_CONV_GET_DILATIONX(param), XAI_CNN_CONV_GET_DILATIONY(param));
    XAI_CHECK_CONSISTENCY_MOW_WHD(inTile, coeffTile, biasArray, outTile, param);
    XAI_CHECK_COEFFTILE_CONTIGUOUS(coeffTile, param);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_ACCUM_SHIFT(param) < 24,                                     \
                    XAI_ERR_NORM, "\nThe accumulator shift = %hhu, value should be less than 24", \
                    XAI_CNN_CONV_GET_ACCUM_SHIFT(param));
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_OUTPUT_SHIFT(param) < 32,                               \
                    XAI_ERR_NORM, "\nThe output shift = %hhu, value should be less than 32", \
                    XAI_CNN_CONV_GET_OUTPUT_SHIFT(param));
    XAI_CHECK_CONV_RELU_LIMITS_IX(param, outTile);
#if DILATED_VQ_CONV == VQ_TRUE
    XAI_CHECK_ARRAY_U16(outputScaleArray);
    XAI_CHECK_ERROR(XAI_ARRAY_GET_WIDTH(outputScaleArray) >= XAI_TILE4D_GET_DIM4(coeffTile),                                                                                          \
                    XAI_ERR_DATASIZE, "\nWidth of Output Scale Array = %d, Number of Kernels = %d\nWidth of Output Scale Array should be greater than or equal to Number of Kernels", \
                    XAI_ARRAY_GET_WIDTH(outputScaleArray), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_ERROR((((uintptr_t) (XAI_ARRAY_GET_DATA_PTR(outputScaleArray)) & \
                      0x1) == 0), XAI_ERR_NORM, "The output scale array is not aligned to 2 byte boundary");
#endif
  }
#if DILATED_VQ_CONV == VQ_FALSE
  if (XAI_CNN_CONV_GET_OUTPUT_SCALE(param) == 0)
  {
    int32_t fillValue;
    int32_t reluFlag = XAI_CNN_CONV_GET_FLAG_RELU(param);
    fillValue = reluFlag ? (CLAMP(0, XAI_CNN_CONV_GET_RELU_MIN(param), XAI_CNN_CONV_GET_RELU_MAX(param))) : 0;
    return(xaiFillTile3D(outTile, fillValue, 0));
  }
#endif
  /* Getting parameters from the tile structures */
  const int32_t inW = XAI_TILE3D_GET_DIM1(inTile) + \
                      XAI_TILE3D_GET_DIM1_EDGE1(inTile) + XAI_TILE3D_GET_DIM1_EDGE2(inTile);
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  XAI_ERROR_CHECKS_CONTINUE()
  {
    if (numInCh > 64)
    {
      XAI_CHECK_TILE4D_FITS_IN_SINGLE_DRAM(coeffTile);
      if (numOutCh > 1)
      {
        /* Max value of Gather Offset is (min(numOutCh-1,3)*coeffPitch3 + min(numInCh-1, 3)) */
        XAI_CHECK_ERROR(XAI_TILE4D_GET_DIM3_PITCH(coeffTile) <                                                       \
                        ((USHRT_MAX - XT_MIN(numInCh - 1, 3)) / XT_MIN(numOutCh - 1, 3)), XAI_ERR_BADARG,            \
                        "\ndim3Pitch value of coeffTile = %d, should be less than Gather Offset(16-bit limit) - %d", \
                        XAI_TILE4D_GET_DIM3_PITCH(coeffTile), ((USHRT_MAX - XT_MIN(numInCh - 1, 3)) / XT_MIN(numOutCh - 1, 3)));
      }
    }
  }

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t stride        = XAI_CNN_CONV_GET_STRIDE(param);

  /* Pitches of Coefficient Data (WHDN) dim3 */
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  const int32_t vectorizationWidth = 2 * XCHAL_IVPN_SIMD_WIDTH;

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  /* variable declarations */
  int32_t inCh, outCh, x, y;
  MORPH_IDT_2Nx8 *restrict pdvecIn1;
  MORPH_IDT_2Nx8 *restrict pdvecIn2;
  xb_vec2Nx8 * restrict pdvecOut;
  xb_vecN_2x32v * restrict phvecCoeff;


  /* The overall design approach is split into 2 sections, one handles
   * optimal tile sizes for giving best performance, other handles rest
   * of the tile sizes */

  /* If sections check out for optimal input tile size for best performance.
   * if input tile depth is  lesser than or  equal to 64 use
   * this design approach, otherwise jump to else part. Adding one more loop
   * to support more than 64 input channels is causing significant overhead
   * damaging the performance */
  if ((numInCh <= 2 * XCHAL_IVPN_SIMD_WIDTH))
  {
    /* Loop structure Starts with loop across output channels */
    for (x = 0; x < outW; x += vectorizationWidth) /* loop across output width */
    {
      /* out of bound flag */
      int32_t flag = XT_SALT(2 * XCHAL_IVPN_SIMD_WIDTH, inW - stride * x);

      for (y = 0; y < outH; y++) /* Loop across Output height */
      {
        /* initialize output data pointer */
        int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

        /* initialize input data pointer */
        MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * stride * y + stride * x];

        /* initialize coeff and Bias data pointer */
        int8_t *pCoeff = &pCoeffData[0];
        int32_t *pBias = &pBiasData[0];

        for (outCh = 0; outCh < numOutCh; outCh += 4) /* Loop across Output depth */
        {
          /* In order to handle odd depths*/
          int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
          int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);
          int32_t enable4thCh = XT_SALT(outCh, numOutCh - 3);

          /* coeff and input data vector declaration */
          MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3, dvecData4;
          MORPH_IDT_2Nx8 dvecDataL, dvecDataU;
          xb_vecN_2x32v hvecCoeffData1, hvecCoeffData2, hvecCoeffData3, hvecCoeffData4;

          /* read coeff vectors , for 4 consecutive output depths */
          /* coeff vector for 1st output channel */
          phvecCoeff = (xb_vecN_2x32v *) (pCoeff);
          valign vaCoeffData; vaCoeffData = IVP_LAN_2X32_PP(phvecCoeff);
          IVP_LAVN_2X32_XP(hvecCoeffData1, vaCoeffData, phvecCoeff, coeffPitch3);

          /* coeff vector for 2nd output channel */
          vaCoeffData = IVP_LAN_2X32_PP(phvecCoeff);
          IVP_LAVN_2X32_XP(hvecCoeffData2, vaCoeffData, phvecCoeff, coeffPitch3 * enable2ndCh);

          /* coeff vector for 3rd output channel */
          vaCoeffData = IVP_LAN_2X32_PP(phvecCoeff);
          IVP_LAVN_2X32_XP(hvecCoeffData3, vaCoeffData, phvecCoeff, coeffPitch3 * enable3rdCh);

          /* coeff vector for 4th output channel */
          vaCoeffData = IVP_LAN_2X32_PP(phvecCoeff);
          IVP_LAVN_2X32_XP(hvecCoeffData4, vaCoeffData, phvecCoeff, coeffPitch3 * enable4thCh);

          /* load and replicate bias data for each output channel */
          xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
          xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
          xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4 * enable4thCh);
          xb_vecN_2x32v hvecBias4; IVP_LSRN_2X32_XP(hvecBias4, pBias, 4);

          /* Move data from N way 16 bit vecBias registers to
           * 2N way 24 bit accumulators*/
          xb_vec2Nx24 dacc1, dacc2, dacc3, dacc4;
          dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
          dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
          dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
          IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);
          dacc4 = IVP_CVT24UNX32L(hvecBias4, hvecBias4);
          IVP_CVT24UNX32H(dacc4, hvecBias4, hvecBias4);

          pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
          pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2);

          for (inCh = 0; inCh < numInCh - 3; inCh += 4) /* loop across input channels */
          {
            /* load data from 1st input channel */
            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8(dvecDataL, vaInData, pdvecIn1, vectorizationWidth * flag);
            MORPH_OP_LOAD_2Nx8(dvecDataU, vaInData, pdvecIn1, \
                               inDataPitch2 - vectorizationWidth * flag);
            dvecData1 = IVP_SEL2NX8I(dvecDataU, dvecDataL, IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0);

            /* load data from 2nd input channel */
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8(dvecDataL, vaInData, pdvecIn1, vectorizationWidth * flag);
            MORPH_OP_LOAD_2Nx8(dvecDataU, vaInData, pdvecIn1, \
                               3 * inDataPitch2 - vectorizationWidth * flag);
            dvecData2 = IVP_SEL2NX8I(dvecDataU, dvecDataL, IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0);


            /* load data from 3rd input channel */
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            MORPH_OP_LOAD_2Nx8(dvecDataL, vaInData, pdvecIn2, vectorizationWidth * flag);
            MORPH_OP_LOAD_2Nx8(dvecDataU, vaInData, pdvecIn2, \
                               inDataPitch2 - vectorizationWidth * flag);
            dvecData3 = IVP_SEL2NX8I(dvecDataU, dvecDataL, IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0);


            /* load data from 4th input channel */
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            MORPH_OP_LOAD_2Nx8(dvecDataL, vaInData, pdvecIn2, vectorizationWidth * flag);
            MORPH_OP_LOAD_2Nx8(dvecDataU, vaInData, pdvecIn2, \
                               3 * inDataPitch2 - vectorizationWidth * flag);
            dvecData4 = IVP_SEL2NX8I(dvecDataU, dvecDataL, IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0);


            /* extract scalar coeff from coeff vectors */
            int32_t coeff1 = IVP_EXTRVRN_2X32(hvecCoeffData1, inCh); /* 1st o/p depth coeff */
            int32_t coeff2 = IVP_EXTRVRN_2X32(hvecCoeffData2, inCh); /* 2nd o/p depth coeff */
            int32_t coeff3 = IVP_EXTRVRN_2X32(hvecCoeffData3, inCh); /* 3rd o/p depth coeff */
            int32_t coeff4 = IVP_EXTRVRN_2X32(hvecCoeffData4, inCh); /* 4th o/p depth coeff */

            MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, coeff1);
            MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, coeff2);
            MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, coeff3);
            MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1, coeff4);
          } /* for (inCh = 0; inCh < numInCh; inCh += 4)*/

          if (inCh < numInCh)
          {
            /* load data from 1st input channel */
            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8(dvecDataL, vaInData, pdvecIn1, vectorizationWidth * flag);
            MORPH_OP_LOAD_2Nx8(dvecDataU, vaInData, pdvecIn1, \
                               (inDataPitch2 - vectorizationWidth * flag) * XT_SALT(inCh, numInCh - 1));
            dvecData1 = IVP_SEL2NX8I(dvecDataU, dvecDataL, IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0);

            /* load data from 2nd input channel */
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8(dvecDataL, vaInData, pdvecIn1, vectorizationWidth * flag);
            MORPH_OP_LOAD_2Nx8(dvecDataU, vaInData, pdvecIn1, \
                               (inDataPitch2 - vectorizationWidth * flag) * XT_SALT(inCh, numInCh - 2));
            dvecData2 = IVP_SEL2NX8I(dvecDataU, dvecDataL, IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0);


            /* load data from 3rd input channel */
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8(dvecDataL, vaInData, pdvecIn1, vectorizationWidth * flag);
            MORPH_OP_LOAD_2Nx8(dvecDataU, vaInData, pdvecIn1, \
                               inDataPitch2 - vectorizationWidth * flag);
            dvecData3 = IVP_SEL2NX8I(dvecDataU, dvecDataL, IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0);


            /* extract scalar coeff from coeff vectors */
            int32_t coeff1 = IVP_EXTRVRN_2X32(hvecCoeffData1, inCh); /* 1st o/p depth coeff */
            int32_t coeff2 = IVP_EXTRVRN_2X32(hvecCoeffData2, inCh); /* 2nd o/p depth coeff */
            int32_t coeff3 = IVP_EXTRVRN_2X32(hvecCoeffData3, inCh); /* 3rd o/p depth coeff */
            int32_t coeff4 = IVP_EXTRVRN_2X32(hvecCoeffData4, inCh); /* 4th o/p depth coeff */

            MORPH_OP_MULQA(dacc1, 0, dvecData3, dvecData2, dvecData1, coeff1);
            MORPH_OP_MULQA(dacc2, 0, dvecData3, dvecData2, dvecData1, coeff2);
            MORPH_OP_MULQA(dacc3, 0, dvecData3, dvecData2, dvecData1, coeff3);
            MORPH_OP_MULQA(dacc4, 0, dvecData3, dvecData2, dvecData1, coeff4);
          }

          /* Pack, Output Scale, Output Shift and clamping */
          xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
          xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                        pOutScaleData[outCh + 2 * enable3rdCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                        pOutScaleData[outCh + 3 * enable4thCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
          /* variable store count */
          int32_t varLen = outW - x;

          /* store output to 1st output depth */
          pdvecOut = (xb_vec2Nx8 *) (pOutput);
          valign vaOutData; vaOutData = IVP_ZALIGN();
          IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
          IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* store output to 2nd output depth */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* store output to 3rd output depth */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable3rdCh);
          IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable3rdCh);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* store output to 4th output depth */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch2 * enable4thCh * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable4thCh);
          IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable4thCh);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          pOutput += 4 * outDataPitch2 * bytesPerPixel;
          pCoeff  += 4 * coeffPitch3;
        }   /* end of for (outCh = 0; outCh < numOutCh; outCh += 4)*/
      }     /* end of for (y = 0; y < outH ; y++)*/
    }       /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  }         /* end of if ((numInCh <= 2*XCHAL_IVPN_SIMD_WIDTH))*/
  else
  {
#ifdef __XCC__
    XT_MEMW(); /* Adding Memory Wait as Gather and Normal Load/Stores are not synchronized */
#endif

    /* generate the sequence 0,1,2,3,0 + coeffPitch3, 1 + coeffPitch3,
     * 2 + coeffPitch3, 3 + coeffPitch3, 0 + 2 * coeffPitch3, 1 + 2 * coeffPitch3,
     * 2 + 2 * coeffPitch3, 3 + 2 * coeffPitch3, .....
     *
     * for e.g, if coeffPitch3 is 32:
     * 0,1,2,3,32,33,34,35,64,65,66,67,96,96,98,99,..
     *
     * This sequene is used to gather coeff from 4 diff output channels, 4 each from
     * every channel corresponding to 4 i/p channels, as innermost loop(inCh) is unrolled by
     * 4 to make use of quad multipler.
     */
    xb_vecNx16U vecIdx1 = IVP_SEQNX16();
    vecIdx1 = IVP_PACKVRNRNX48(IVP_MULNX16(vecIdx1, coeffPitch3), 0);
    vecIdx1 = IVP_SELNX16I(IVP_ADDNX16(vecIdx1, 1), vecIdx1, IVP_SELI_16B_INTERLEAVE_1_LO);
    vecIdx1 = IVP_SELNX16I(IVP_ADDNX16(vecIdx1, 2), vecIdx1, IVP_SELI_32B_INTERLEAVE_1_LO);
    xb_gsr gs0;

    for (x = 0; x < outW; x += vectorizationWidth)     /* Loop across Output width */
    {
      /* out of bound flag */
      int32_t flag = XT_SALT(2 * XCHAL_IVPN_SIMD_WIDTH, inW - stride * x);
      xb_vecNx16U vecIdx2;
      /* variable store count */
      int32_t varLen = outW - x;

      for (y = 0; y < outH; y++)          /* Loop across Output height */
      {
        /* initialize output data pointer */
        int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

        /* initialize input data pointer */
        MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * stride * y + stride * x];

        /* initialize  Bias data pointer */

        int32_t *pBias = &pBiasData[0];
        int8_t *pCoeff = &pCoeffData[0];

        for (outCh = 0; outCh < numOutCh; outCh += 4)    /* Loop across Output depth */
        {
          /* In order to handle odd depths*/
          int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
          int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);
          int32_t enable4thCh = XT_SALT(outCh, numOutCh - 3);

          /* load and replicate bias data for each output channel */
          xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
          xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
          xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4 * enable4thCh);
          xb_vecN_2x32v hvecBias4; IVP_LSRN_2X32_XP(hvecBias4, pBias, 4);

          xb_vec2Nx24 dacc1, dacc2, dacc3, dacc4;
          dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
          dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
          dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
          IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);
          dacc4 = IVP_CVT24UNX32L(hvecBias4, hvecBias4);
          IVP_CVT24UNX32H(dacc4, hvecBias4, hvecBias4);

          /* boolean mask to gather coeffs, if all the four o/p channels
           * are present 16 coeff are loaded.
           */
          vboolN mask = IVP_LTNX16(IVP_SEQNX16(), (xb_vecNx16) XT_MIN(((numOutCh - outCh) * 4), 16));
          /* Assign valid address for predicated false lines */
          vecIdx2  = IVP_MOVNX16UT(vecIdx1, 0, mask);
          pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
          pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2);

          for (inCh = 0; inCh < numInCh - 3; inCh += 4)          /* Loop across input depth */
          {
            /* input vectors are read from 4 input depths at at time
             * Scalar 32 bit coeff are extracted from the coeff vectors */

            MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3, dvecData4;
            MORPH_IDT_2Nx8 dvecDataL, dvecDataU;

            /* load data from 1st input channel */
            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8(dvecDataL, vaInData, pdvecIn1, vectorizationWidth * flag);
            MORPH_OP_LOAD_2Nx8(dvecDataU, vaInData, pdvecIn1, \
                               inDataPitch2 - vectorizationWidth * flag);
            dvecData1 = IVP_SEL2NX8I(dvecDataU, dvecDataL, IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0);


            /* load data from 2nd input channel */
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8(dvecDataL, vaInData, pdvecIn1, vectorizationWidth * flag);
            MORPH_OP_LOAD_2Nx8(dvecDataU, vaInData, pdvecIn1, \
                               3 * inDataPitch2 - vectorizationWidth * flag);
            dvecData2 = IVP_SEL2NX8I(dvecDataU, dvecDataL, IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0);


            /* load data from 3rd input channel */
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            MORPH_OP_LOAD_2Nx8(dvecDataL, vaInData, pdvecIn2, vectorizationWidth * flag);
            MORPH_OP_LOAD_2Nx8(dvecDataU, vaInData, pdvecIn2, \
                               inDataPitch2 - vectorizationWidth * flag);
            dvecData3 = IVP_SEL2NX8I(dvecDataU, dvecDataL, IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0);


            /* load data from 4th input channel */
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            MORPH_OP_LOAD_2Nx8(dvecDataL, vaInData, pdvecIn2, vectorizationWidth * flag);
            MORPH_OP_LOAD_2Nx8(dvecDataU, vaInData, pdvecIn2, \
                               3 * inDataPitch2 - vectorizationWidth * flag);
            dvecData4 = IVP_SEL2NX8I(dvecDataU, dvecDataL, IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0);

            /* gather the coeffs */
            gs0 = IVP_GATHERANX8S(pCoeff + inCh, vecIdx2);
            xb_vec2Nx8 dvecCoeffData = IVP_GATHERD2NX8_L(gs0);

            /* extract scalar coeff from coeff vectors */
            int32_t coeff1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                              IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 0); /* 1st o/p depth coeff */
            int32_t coeff2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                              IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 1); /* 2nd o/p depth coeff */
            int32_t coeff3 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                              IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 2); /* 3rd o/p depth coeff */
            int32_t coeff4 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                              IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 3); /* 4th o/p depth coeff */

            MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, coeff1);
            MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, coeff2);
            MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, coeff3);
            MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1, coeff4);
          }        /* end of for (inCh = 0; inCh < numInCh; inCh += 4)*/
          if (inCh < numInCh)
          {
            MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3;
            MORPH_IDT_2Nx8 dvecDataL, dvecDataU;

            /* load data from 1st input channel */
            pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2);
            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8_VARIABLE(dvecDataL, vaInData, pdvecIn1, (inW - stride * x));
            MORPH_OP_LOAD_2Nx8_VARIABLE(dvecDataU, vaInData, pdvecIn1, \
                                        (inW - stride * x - vectorizationWidth));
            dvecData1 = IVP_SEL2NX8I(dvecDataU, dvecDataL, IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0);

            /* load data from 2nd input channel */
            pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + ((inCh + 1) * inDataPitch2 * XT_SALT(inCh, numInCh - 1)));
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8_VARIABLE(dvecDataL, vaInData, pdvecIn1, \
                                        (inW - stride * x) * XT_SALT(inCh, numInCh - 1));
            MORPH_OP_LOAD_2Nx8_VARIABLE(dvecDataU, vaInData, pdvecIn1, \
                                        (inW - stride * x - vectorizationWidth) * XT_SALT(inCh, numInCh - 1));
            dvecData2 = IVP_SEL2NX8I(dvecDataU, dvecDataL, IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0);



            /* load data from 3rd input channel */
            pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + ((inCh + 2) * inDataPitch2 * XT_SALT(inCh, numInCh - 2)));
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8_VARIABLE(dvecDataL, vaInData, pdvecIn1, \
                                        (inW - stride * x) * XT_SALT(inCh, numInCh - 2));
            MORPH_OP_LOAD_2Nx8_VARIABLE(dvecDataU, vaInData, pdvecIn1, \
                                        (inW - stride * x - vectorizationWidth) * XT_SALT(inCh, numInCh - 2));
            dvecData3 = IVP_SEL2NX8I(dvecDataU, dvecDataL, IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0);


            /* Boolean mask for gather to handle cases where inCh<4 */
            vboolN mask1 = IVP_LTNX16(IVP_ANDNX16(IVP_SEQNX16(), 3), (numInCh - inCh));
            /* Assign valid address for predicated false lines */
            vecIdx2 = IVP_MOVNX16UT(vecIdx2, 0, mask1);
            /* Gather coeffs */
            gs0 = IVP_GATHERANX8S(pCoeff + inCh, vecIdx2);
            xb_vec2Nx8 dvecCoeffData = IVP_GATHERD2NX8_L(gs0);

            /* extract scalar coeff from coeff vectors */
            int32_t coeff1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                              IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 0); /* 1st o/p depth coeff */
            int32_t coeff2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                              IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 1); /* 2nd o/p depth coeff */
            int32_t coeff3 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                              IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 2); /* 3rd o/p depth coeff */
            int32_t coeff4 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                              IVP_MOVNX16_FROM2NX8(dvecCoeffData)), 3); /* 4th o/p depth coeff */

            MORPH_OP_MULQA(dacc1, 0, dvecData3, dvecData2, dvecData1, coeff1);
            MORPH_OP_MULQA(dacc2, 0, dvecData3, dvecData2, dvecData1, coeff2);
            MORPH_OP_MULQA(dacc3, 0, dvecData3, dvecData2, dvecData1, coeff3);
            MORPH_OP_MULQA(dacc4, 0, dvecData3, dvecData2, dvecData1, coeff4);
          } /* end of if (inCh < numInCh)*/

          /* Pack, Output Scale, Output Shift and clamping */
          xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
          xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                        pOutScaleData[outCh + 2 * enable3rdCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                        pOutScaleData[outCh + 3 * enable4thCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
          /* store output to 1st output depth */
          pdvecOut = (xb_vec2Nx8 *) (pOutput);
          valign vaOutData; vaOutData = IVP_ZALIGN();
          IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
          IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* store output to 2nd output depth */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* store output to 3rd output depth */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable3rdCh);
          IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable3rdCh);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* store output to 4th output depth */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch2 * enable4thCh * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable4thCh);
          IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable4thCh);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          pOutput += 4 * outDataPitch2 * bytesPerPixel;
          pCoeff  += 4 * coeffPitch3;
        }   /* end of for (outCh = 0; outCh < numOutCh; outCh += 4)*/
      }     /* end of for (y = 0; y < outH; y++)*/
    }       /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  }         /* end of else part of if ((numInCh <= 2*XCHAL_IVPN_SIMD_WIDTH))*/
  return(XAI_ERROR_STATUS());
}

/******************************************************************************************
*  xaiConvolved(VQ)3D_S_1x1j4d1I8S8IX_MOW_WHD
*  ***************************************************************************************/

/******************************************************************************/
/* Description : P6 optimized generic implementation for 1x1 3D convolution.  */
/*               Based on MORPH pre-processor specifiers, code implementation */
/*               is generated during preprocessing stage. This method can be  */
/*               used to generate 1x1 3D MOW_WHD dilated convolution function */
/*               and 1x1 3D VQ MOW_WHD dilated convolution function for U8    */
/*               bit and S8 bit input data with input stride equal to 4       */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                */
/*               Output scale array, CNN convolution params structure         */
/* Outputs     : XI Error Code                                                */
/* InOuts      : Output Tile                                                  */
/* Assumptions : CoeffData is S8                                              */
/*               biasArray is signed 32b, value not exceeding signed 24b      */
/*               Output scale array is U16                                    */
/*               OutData is S8 / U8 / S16                                     */
/*               Kernel Size is 1x1xDxN                                       */
/*               Input and Output are in WHD format                           */
/*               Coeff is in WHDN format                                      */
/******************************************************************************/

/****************** xaiConvolvedVQ3D_S_1x1j4d1_S8S8IX_MOW_WHD ******************/
/****************** xaiConvolvedVQ3D_S_1x1j4d1_U8S8IX_MOW_WHD ******************/
/******************* xaiConvolved3D_S_1x1j4d1_S8S8IX_MOW_WHD *******************/
/******************* xaiConvolved3D_S_1x1j4d1_U8S8IX_MOW_WHD *******************/
//#if 0
XAI_ERR_TYPE MAKE_NAME(MAKE_NAME_VQ(xaiConvolved, 3D_S_1x1j4d1), S8IX_MOW_WHD) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Error Checks */
  XAI_ERROR_CHECKS()
  {
    MORPH_IDT_CHECK(inTile);
    XAI_CHECK_CONV_OUTPUT_TILE3D(outTile);
    XAI_CHECK_TILE4D_S8(coeffTile);
    XAI_CHECK_TILE3D_FITS_IN_SINGLE_DRAM(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(outTile);
    XAI_CHECK_TILE4D_IN_DRAM_BOUNDARY(coeffTile);
    XAI_CHECK_POINTER(param);
    XAI_CHECK_ARRAY_S32(biasArray);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(inTile, outTile);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(coeffTile, outTile);
    XAI_CHECK_KERNEL_SIZE(coeffTile, 1);
    XAI_CHECK_TILE3D_DATA_ORDER(inTile, XAI_WHD);
    XAI_CHECK_TILE3D_DATA_ORDER(outTile, XAI_WHD);
    XAI_CHECK_TILE4D_DATA_ORDER(coeffTile, XAI_WHDN);
    XAI_CHECK_STRIDE(param, 4);
    XAI_CHECK_ERROR((XAI_CNN_CONV_GET_STRIDEX(param) == XAI_CNN_CONV_GET_STRIDEY(param)),                                         \
                    XAI_ERR_BADARG, "Stride along width = %hhu and height = %hhu\nStride along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_DILATION(param, 1);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_DILATIONX(param) == XAI_CNN_CONV_GET_DILATIONY(param),                                             \
                    XAI_ERR_BADARG, "\nDilation along width = %hhu and height = %hhu\nDilation along width and height should be equal", \
                    XAI_CNN_CONV_GET_DILATIONX(param), XAI_CNN_CONV_GET_DILATIONY(param));
    XAI_CHECK_CONSISTENCY_MOW_WHD(inTile, coeffTile, biasArray, outTile, param);
    XAI_CHECK_ERROR(XAI_TILE3D_GET_DIM3(inTile) == XAI_TILE4D_GET_DIM3(coeffTile),                                               \
                    XAI_ERR_BADARG, "\ninTile depth = %d, coeffTile depth = %d\ninTile depth should be same as coeffTile depth", \
                    XAI_TILE3D_GET_DIM3(inTile), XAI_TILE4D_GET_DIM3(coeffTile));
    XAI_CHECK_ERROR(XAI_TILE3D_GET_DIM3(outTile) == XAI_TILE4D_GET_DIM4(coeffTile),                                                    \
                    XAI_ERR_BADARG, "\noutTile depth = %d, number of kernels = %d\noutTile depth should be same as number of kernels", \
                    XAI_TILE3D_GET_DIM3(outTile), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_COEFFTILE_CONTIGUOUS(coeffTile, param);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_ACCUM_SHIFT(param) < 24,                                     \
                    XAI_ERR_NORM, "\nThe accumulator shift = %hhu, value should be less than 24", \
                    XAI_CNN_CONV_GET_ACCUM_SHIFT(param));
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_OUTPUT_SHIFT(param) < 32,                               \
                    XAI_ERR_NORM, "\nThe output shift = %hhu, value should be less than 32", \
                    XAI_CNN_CONV_GET_OUTPUT_SHIFT(param));
    XAI_CHECK_CONV_RELU_LIMITS_IX(param, outTile);
#if DILATED_VQ_CONV == VQ_TRUE
    XAI_CHECK_ARRAY_U16(outputScaleArray);
    XAI_CHECK_ERROR(XAI_ARRAY_GET_WIDTH(outputScaleArray) >= XAI_TILE4D_GET_DIM4(coeffTile),                                                                                          \
                    XAI_ERR_DATASIZE, "\nWidth of Output Scale Array = %d, Number of Kernels = %d\nWidth of Output Scale Array should be greater than or equal to Number of Kernels", \
                    XAI_ARRAY_GET_WIDTH(outputScaleArray), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_ERROR((((uintptr_t) (XAI_ARRAY_GET_DATA_PTR(outputScaleArray)) & \
                      0x1) == 0), XAI_ERR_NORM, "The output scale array is not aligned to 2 byte boundary");
#endif
  }
#if DILATED_VQ_CONV == VQ_FALSE
  if (XAI_CNN_CONV_GET_OUTPUT_SCALE(param) == 0)
  {
    int32_t fillValue;
    int32_t reluFlag = XAI_CNN_CONV_GET_FLAG_RELU(param);
    fillValue = reluFlag ? (CLAMP(0, XAI_CNN_CONV_GET_RELU_MIN(param), XAI_CNN_CONV_GET_RELU_MAX(param))) : 0;
    return(xaiFillTile3D(outTile, fillValue, 0));
  }
#endif
  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t stride        = XAI_CNN_CONV_GET_STRIDE(param);

  /* Pitches of Coefficient Data (WHDN) dim3 */
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  xb_vec2Nx8* restrict pdvecOut;
  xb_vecNx8* restrict pvecCoeff1, * restrict pvecCoeff2, \
  * restrict pvecCoeff3, * restrict pvecCoeff4;

  /* Variable Declarations */
  int32_t inCh, outCh, x, y;
  const int32_t vectorizationWidth = XCHAL_IVPN_SIMD_WIDTH;
  int32_t varLen;

  /* declare gather registers and compute the sequence
   * 0,4,8,12, ....... 120, 124 required as offset for
   * gahering data
   */
  xb_gsr gs0, gs1;
  xb_vecNx16U vecIdx1 = IVP_SEQNX16() << 2;

#ifdef __XCC__
  XT_MEMW(); /* Adding Memory Wait as Gather and Normal Load/Stores are not synchronized */
#endif

  /* loop across output depth is unrolled by 4
   * , producing lanes from 4 output channels
   * in one iteration. Since vectorization width
   * is just half the width of the accumulator,
   * loop across output height is also unrolled by 2.
   * Unrolling across output height makes it possible
   * to utilize all the 64 MACs in the accumulator.
   *
   * Data loaded from the 2 input rows is concatenated
   * in such a manner that lower half of the output
   * vector gives the first output row and the upper
   * half of the */
  for (x = 0; x < outW; x += vectorizationWidth) /* Loop across Output width */
  {
    /* variable load and store count */
    varLen = XT_MIN(outW - x, vectorizationWidth);

    for (y = 0; y < outH; y += 2)    /* Loop across Output height */
    {
      /* In order to handle odd heights */
      int32_t enable2ndRow = XT_SALT(y, outH - 1);
      xb_vecNx16U vecIdx2;
      /* Initialize o/p data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize coeff and Bias data pointer */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 4)   /* Loop across Output depth */
      {
        /* In order to handle odd  depths*/
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
        int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);
        int32_t enable4thCh = XT_SALT(outCh, numOutCh - 3);

        /* Initialize i/p data pointer */
        MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y * stride + x * stride];

        /* load and replicate bias data */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
        xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4 * enable4thCh);
        xb_vecN_2x32v hvecBias4; IVP_LSRN_2X32_XP(hvecBias4, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc1, dacc2, dacc3, dacc4;
        dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
        dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
        IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);
        dacc4 = IVP_CVT24UNX32L(hvecBias4, hvecBias4);
        IVP_CVT24UNX32H(dacc4, hvecBias4, hvecBias4);

        /* priming of coeff load is done outside the innermost loop*/
        pvecCoeff1 = (xb_vecNx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LANX8S_PP(pvecCoeff1);

        pvecCoeff2 = (xb_vecNx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        valign vaCoeffData2; vaCoeffData2 = IVP_LANX8S_PP(pvecCoeff2);

        pvecCoeff3 = (xb_vecNx8 *) (pCoeff + 2 * coeffPitch3 * enable3rdCh);
        valign vaCoeffData3; vaCoeffData3 = IVP_LANX8S_PP(pvecCoeff3);

        pvecCoeff4 = (xb_vecNx8 *) (pCoeff + 3 * coeffPitch3 * enable4thCh);
        valign vaCoeffData4; vaCoeffData4 = IVP_LANX8S_PP(pvecCoeff4);

        /* mask for gathering input data based on varLen */
        vboolN mask1 = IVP_LTNX16(IVP_SEQNX16(), (xb_vecNx16) varLen);
        /* Assign valid address for predicated false lines */
        vecIdx2 = IVP_MOVNX16UT(vecIdx1, 0, mask1);

        /* loop acrosss input channels is unrolled by 2,
         * enabling us to use paired multipliers
         */

        /* 32 elements are gathered from the 1st input height
         * in the gs0 register and then 32 elements are gathered
         * from the next input height(as loop across output height
         * is unrolled by 2) in the gs1 register. So lower half of
         * the dvecData1 hold the data from 1st input height and
         * upper half holds the data from the 2nd input height
         *
         * Similarly dvecData2 holds data from the 2nd input channel,
         * lower half hold 1st input height and upper half holds 2nd
         * input height
         */

        for (inCh = 0; inCh < numInCh - 1; inCh += 2)   /* Loop across input channels */
        {
          /* variable declarations for input and coeff vectors */
          MORPH_IDT_2Nx8 dvecData1, dvecData2;

          /* loads data from 1st input channel */
          gs0       = MORPH_OP_GATHER(pInput, vecIdx2);
          gs1       = MORPH_OP_GATHER(pInput + stride * inDataPitch1 * enable2ndRow, vecIdx2);
          dvecData1 = MORPH_OP_GATHER_2Nx8_LOW(gs0);
          MORPH_OP_GATHER_2Nx8_HIGH(dvecData1, gs1);
          pInput += inDataPitch2;

          /* loads data from next input channel */
          gs0       = MORPH_OP_GATHER(pInput, vecIdx2);
          gs1       = MORPH_OP_GATHER(pInput + stride * inDataPitch1 * enable2ndRow, vecIdx2);
          dvecData2 = MORPH_OP_GATHER_2Nx8_LOW(gs0);
          MORPH_OP_GATHER_2Nx8_HIGH(dvecData2, gs1);
          pInput += inDataPitch2;

          /* load 2 coeff for all the 4 output channels, 8 to 16 bit
           * conversion is taken care of by the load instruction  */
          xb_vecNx16 vecCoeffData1, vecCoeffData2, vecCoeffData3, vecCoeffData4;
          IVP_LAVNX8S_XP(vecCoeffData1, vaCoeffData1, pvecCoeff1, 2);
          IVP_LAVNX8S_XP(vecCoeffData2, vaCoeffData2, pvecCoeff2, 2);
          IVP_LAVNX8S_XP(vecCoeffData3, vaCoeffData3, pvecCoeff3, 2);
          IVP_LAVNX8S_XP(vecCoeffData4, vaCoeffData4, pvecCoeff4, 2);

          /* multiply data from 1st input channel with 1st coeff
           * and data from 2nd input channel with 2nd coeff and
           * accumulate
           */
          MORPH_OP_MULPA(dacc1, dvecData2, dvecData1, \
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(vecCoeffData1), 0));
          MORPH_OP_MULPA(dacc2, dvecData2, dvecData1, \
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(vecCoeffData2), 0));
          MORPH_OP_MULPA(dacc3, dvecData2, dvecData1, \
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(vecCoeffData3), 0));
          MORPH_OP_MULPA(dacc4, dvecData2, dvecData1, \
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(vecCoeffData4), 0));
        }   /* end of for (inCh = 0; inCh < numInCh - 1; inCh += 2)*/

        /* handles left out odd input channel */
        if (inCh < numInCh)
        {
          MORPH_IDT_2Nx8 dvecData1;

          /* loads data from the left out input channel */
          gs0       = MORPH_OP_GATHER(pInput, vecIdx2);
          gs1       = MORPH_OP_GATHER(pInput + stride * inDataPitch1 * enable2ndRow, vecIdx2);
          dvecData1 = MORPH_OP_GATHER_2Nx8_LOW(gs0);
          MORPH_OP_GATHER_2Nx8_HIGH(dvecData1, gs1);

          xb_vecNx16 vecCoeffData1, vecCoeffData2, vecCoeffData3, vecCoeffData4;
          IVP_LAVNX8S_XP(vecCoeffData1, vaCoeffData1, pvecCoeff1, 1);
          IVP_LAVNX8S_XP(vecCoeffData2, vaCoeffData2, pvecCoeff2, 1);
          IVP_LAVNX8S_XP(vecCoeffData3, vaCoeffData3, pvecCoeff3, 1);
          IVP_LAVNX8S_XP(vecCoeffData4, vaCoeffData4, pvecCoeff4, 1);

          MORPH_OP_MULPA(dacc1, 0, dvecData1, \
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(vecCoeffData1), 0));
          MORPH_OP_MULPA(dacc2, 0, dvecData1, \
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(vecCoeffData2), 0));
          MORPH_OP_MULPA(dacc3, 0, dvecData1, \
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(vecCoeffData3), 0));
          MORPH_OP_MULPA(dacc4, 0, dvecData1, \
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(vecCoeffData4), 0));
        } /* end of if(inCh < numInCh)*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      pOutScaleData[outCh + 2 * enable3rdCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      pOutScaleData[outCh + 3 * enable4thCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* store the first half of the output vectors
         * dvecOut1, dvecOut2, dvecOut3, dvecOut4
         */

        /* Storing the first row outputs, first channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 3rd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable3rdCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 4th channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch2 * enable4thCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable4thCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* extract the upper half of the output vectors
         * dvecOut1, dvecOut2, dvecOut3, dvecOut4 and store
         * in the next output height
         */
        dvecOut1L = IVP_SEL2NX8I(0, dvecOut1L, IVP_SELI_8B_EXTRACT_HI_HALVES);
        dvecOut2L = IVP_SEL2NX8I(0, dvecOut2L, IVP_SELI_8B_EXTRACT_HI_HALVES);
        dvecOut3L = IVP_SEL2NX8I(0, dvecOut3L, IVP_SELI_8B_EXTRACT_HI_HALVES);
        dvecOut4L = IVP_SEL2NX8I(0, dvecOut4L, IVP_SELI_8B_EXTRACT_HI_HALVES);

        /* Storing the 2nd row outputs, 1st channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2ndRow * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, (-typeFlag + 1) * varLen * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * 2 * varLen * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, (-typeFlag + 1) * \
                       varLen * enable2ndCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable2ndCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 3rd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (2 * outDataPitch2 * enable3rdCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, (-typeFlag + 1) * \
                       varLen * enable3rdCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable3rdCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 4th channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (3 * outDataPitch2 * enable4thCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, (-typeFlag + 1) * \
                       varLen * enable4thCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable4thCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 4 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 4 * coeffPitch3;
      }   /* end of (outCh = 0; outCh < numOutCh; outCh += 4)*/
    }     /* end of for (y = 0; y < outH; y += 2)*/
  }       /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  return(XAI_ERROR_STATUS());
}

/******************************************************************************************
* MOW fold 16 Stride 1                                                                    *
* If inDataPitch1 is lesser than or equal to                                              *
* 16 this function is called.                                                             *
******************************************************************************************/

static _XAI_INLINE_ void MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_2x2j1d1), S8IX_MOW_WHD_FOLD16) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Pitches of Coefficient Data (WHDN) in dim1 and dim3 */
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  const uint8_t leftEdgeFlag = XAI_CNN_CONV_GET_FLAG_LEFTEDGE(param);
  const uint8_t topEdgeFlag  = XAI_CNN_CONV_GET_FLAG_TOPEDGE(param);
  int32_t leftEdge, topEdge;

  leftEdge = leftEdgeFlag ? (kSizeU / 2) : ((kSizeU / 2) - 1);
  topEdge  = topEdgeFlag ? (kSizeU / 2) : ((kSizeU / 2) - 1);

  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-(topEdge * inDataPitch1 + leftEdge)];


  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 *restrict pdvecIn1;
  MORPH_IDT_2Nx8 *restrict pdvecIn2;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1;
  xb_vec2Nx8* restrict pdvecCoeff2;

  /* Variable Declarations */
  int32_t inCh, outCh, y;

  /* loop across output channels and output height are unrolled twice
   * to produce four output vectors in 1 iteration
   */
  for (y = 0; y < outH - 3; y += 4)   /* Loop across output height */
  {
    /* initialize output data pointer */
    int8_t *pOutput = &pOutData[(y * outDataPitch1) * bytesPerPixel];

    /* initialize coeff and Bias data pointer */
    int8_t *pCoeff = &pCoeffData[0];
    int32_t *pBias = &pBiasData[0];

    for (outCh = 0; outCh < numOutCh; outCh += 2)    /* Loop across Output depth */
    {
      /* In order to handle odd output depths */
      int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

      /* Load the bias values corresponding to two output channels */
      xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
      xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

      /* wide vectors(accumulators) initialized with bias */
      xb_vec2Nx24 dacc1, dacc2;

      dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
      IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);

      dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
      IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);

      /* priming of coeff load is done outside the innermost loop*/
      pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
      valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

      pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
      valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y];

      pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
      pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch1);

      for (inCh = 0; inCh < numInCh - 1; inCh += 2)    /* Loop across input channels */
      {
        /* vectors for coeff and input loads */
        xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2;
        MORPH_IDT_2Nx8 dvecInData1, dvecInData2;
        MORPH_IDT_2Nx8 dvecInData1temp, dvecInData2temp;

        /* Process first input channel */
        /* load data from 4 input rows [Row0 | Row1 | Row2 | Row3] */
        valign vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        MORPH_OP_LOAD_2Nx8(dvecInData1, vaInData1, pdvecIn1, inDataPitch2);
        dvecInData1temp = IVP_SEL2NX8I(dvecInData1, dvecInData1, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* load data from next 4 input rows [Row1 | Row2 | Row3 | Row4] */
        valign vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        MORPH_OP_LOAD_2Nx8(dvecInData2, vaInData2, pdvecIn2, inDataPitch2);
        dvecInData2temp = IVP_SEL2NX8I(dvecInData2, dvecInData2, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* load all the 2x2 coefficients for 2 output depths*/
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, 8);
        IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, 8);

        /* Get co-efficients for first channel */
        int32_t qmulScalar1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0);
        int32_t qmulScalar2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0);

        /* Compute Row 1 of 1st output channel */
        MORPH_OP_MULQA(dacc1, dvecInData2temp, dvecInData2, dvecInData1temp, dvecInData1, qmulScalar1);

        /* Compute Row 1 of 2nd output channel */
        MORPH_OP_MULQA(dacc2, dvecInData2temp, dvecInData2, dvecInData1temp, dvecInData1, qmulScalar2);

        /* Process second input channel */
        /* load data from 4 input rows [Row0 | Row1 | Row2 | Row3] */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        MORPH_OP_LOAD_2Nx8(dvecInData1, vaInData1, pdvecIn1, inDataPitch2);
        dvecInData1temp = IVP_SEL2NX8I(dvecInData1, dvecInData1, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* load data from 4 input rows [Row1 | Row2 | Row3 | Row4] */
        vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        MORPH_OP_LOAD_2Nx8(dvecInData2, vaInData2, pdvecIn2, inDataPitch2);
        dvecInData2temp = IVP_SEL2NX8I(dvecInData2, dvecInData2, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* Get co-efficients for second channel */
        qmulScalar1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1);
        qmulScalar2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1);

        /* Compute Row 1 of 1st output channel */
        MORPH_OP_MULQA(dacc1, dvecInData2temp, dvecInData2, dvecInData1temp, dvecInData1, qmulScalar1);

        /* Compute Row 1 of 2nd output channel */
        MORPH_OP_MULQA(dacc2, dvecInData2temp, dvecInData2, dvecInData1temp, dvecInData1, qmulScalar2);
      }    /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

      if (inCh < numInCh)
      {
        /* vectors for coeff and input loads */
        xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2;
        MORPH_IDT_2Nx8 dvecInData1, dvecInData2;
        MORPH_IDT_2Nx8 dvecInData1temp, dvecInData2temp;

        /* load data from 2 input rows [Row0 | Row1 | Row2 | Row3] */
        valign vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        MORPH_OP_LOAD_2Nx8(dvecInData1, vaInData1, pdvecIn1, inDataPitch2);
        dvecInData1temp = IVP_SEL2NX8I(dvecInData1, dvecInData1, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* load data from 2 input rows [Row1 | Row2 | Row3 | Row4] */
        valign vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        MORPH_OP_LOAD_2Nx8(dvecInData2, vaInData2, pdvecIn2, inDataPitch2);
        dvecInData2temp = IVP_SEL2NX8I(dvecInData2, dvecInData2, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* load all the 2x2 coefficients for 2 output depths */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, 4);
        IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, 4);

        int32_t qmulScalar1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0);
        int32_t qmulScalar2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0);

        /* Compute Row 1 of 1st output channel */
        MORPH_OP_MULQA(dacc1, dvecInData2temp, dvecInData2, dvecInData1temp, dvecInData1, qmulScalar1);

        /* Compute Row 1 of 2nd output channel */
        MORPH_OP_MULQA(dacc2, dvecInData2temp, dvecInData2, dvecInData1temp, dvecInData1, qmulScalar2);
      }

      /* Pack, Output Scale, Output Shift and clamping */
      xb_vec2Nx8 dvecOut1L, dvecOut2L;
      xb_vec2Nx8 dvecOut1H, dvecOut2H;
#if DILATED_VQ_CONV == VQ_TRUE
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                    pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                    pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                    outScale, outShiftU, minLim, maxLim, typeFlag);
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                    outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
      /* Storing the first output depth, first row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput);
      valign vaOutData = IVP_ZALIGN();
      IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the first output depth, second row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the first output depth, third row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch1 * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), 2 * inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the first output depth, fourth row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch1 * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), 3 * inDataPitch1 * bytesPerPixel)),
                     vaOutData, pdvecOut, bytesPerPixel * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, first row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
      IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, second row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                            outDataPitch1) * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, third row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                            2 * outDataPitch1) * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), 2 * inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, fourth row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                            3 * outDataPitch1) * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), 3 * inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      pOutput += 2 * outDataPitch2 * bytesPerPixel;
      pCoeff  += 2 * coeffPitch3;
    }  /* end of for (outCh = 0; outCh < numOutCh; outCh += 2)*/
  }    /* end of for (y = 0; y < outH-3; y += 4)*/

  /* handle left out output rows */
  if (y < outH)
  {
    int32_t enable2ndRow = XT_SALT(y, outH - 1);
    int32_t enable3rdRow = XT_SALT(y, outH - 2);

    /* initialize output data pointer */
    int8_t *pOutput = &pOutData[(y * outDataPitch1) * bytesPerPixel];

    /* initialize coeff and Bias data pointer */
    int8_t *pCoeff = &pCoeffData[0];
    int32_t *pBias = &pBiasData[0];

    for (outCh = 0; outCh < numOutCh; outCh += 2)    /* Loop across Output depth */
    {
      /* In order to handle odd output depths and heights */
      int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

      /* Load the bias values corresponding to two output channels */
      xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
      xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

      /* wide vectors(accumulators) initialized with bias */
      xb_vec2Nx24 dacc1, dacc2;

      dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
      IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);

      dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
      IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);

      /* priming of coeff load is done outside the innermost loop*/
      pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
      valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

      pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
      valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y];

      for (inCh = 0; inCh < numInCh - 1; inCh += 2)    /* Loop across input channels */
      {
        /* vectors for coeff and input loads */
        xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2;
        MORPH_IDT_2Nx8 dvecInData1, dvecInData2;
        MORPH_IDT_2Nx8 dvecInData1temp, dvecInData2temp;

        pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
        pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch1);

        /* load data from first 4 input rows [Row0 | Row1 | Row2 | Row3] */
        valign vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        MORPH_OP_LOAD_2Nx8_VARIABLE(dvecInData1, vaInData1, pdvecIn1, (2 + enable2ndRow + enable3rdRow) * inDataPitch1);
        dvecInData1temp = IVP_SEL2NX8I(dvecInData1, dvecInData1, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* load data from next 4 input rows [Row1 | Row2 | Row3 | Row4]*/
        valign vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        MORPH_OP_LOAD_2Nx8_VARIABLE(dvecInData2, vaInData2, pdvecIn2, (1 + enable2ndRow + enable3rdRow) * inDataPitch1);
        dvecInData2temp = IVP_SEL2NX8I(dvecInData2, dvecInData2, IVP_SELI_8B_ROTATE_RIGHT_1);
        pInput         += inDataPitch2;

        /* load all the 2x2 coefficients for 2 output depths*/
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, 8);
        IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, 8 * enable2ndCh);

        int32_t qmulScalar1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0);
        int32_t qmulScalar2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0);

        /* Compute Row 1 of 1st output channel */
        MORPH_OP_MULQA(dacc1, dvecInData2temp, dvecInData2, dvecInData1temp, dvecInData1, qmulScalar1);

        /* Compute Row 1 of 2nd output channel */
        MORPH_OP_MULQA(dacc2, dvecInData2temp, dvecInData2, dvecInData1temp, dvecInData1, qmulScalar2);

        /* Process next input channel */
        /* load data from 2 input rows [Row0 | Row1 | Row2 | Row3] */
        pdvecIn1  = (MORPH_IDT_2Nx8 *) (pInput);
        pdvecIn2  = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch1);
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        MORPH_OP_LOAD_2Nx8_VARIABLE(dvecInData1, vaInData1, pdvecIn1, (2 + enable2ndRow + enable3rdRow) * inDataPitch1);
        dvecInData1temp = IVP_SEL2NX8I(dvecInData1, dvecInData1, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* load data from 2 input rows [Row4 | Row5 | Row6 | Row7] */
        vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        MORPH_OP_LOAD_2Nx8_VARIABLE(dvecInData2, vaInData2, pdvecIn2, (1 + enable2ndRow + enable3rdRow) * inDataPitch1);
        dvecInData2temp = IVP_SEL2NX8I(dvecInData2, dvecInData2, IVP_SELI_8B_ROTATE_RIGHT_1);
        pInput         += inDataPitch2;

        qmulScalar1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1);
        qmulScalar2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1);

        /* Compute Row 1 of 1st output channel */
        MORPH_OP_MULQA(dacc1, dvecInData2temp, dvecInData2, dvecInData1temp, dvecInData1, qmulScalar1);

        /* Compute Row 1 of 2nd output channel */
        MORPH_OP_MULQA(dacc2, dvecInData2temp, dvecInData2, dvecInData1temp, dvecInData1, qmulScalar2);
      }    /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

      if (inCh < numInCh)
      {
        /* vectors for coeff and input loads */
        xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2;
        MORPH_IDT_2Nx8 dvecInData1, dvecInData2;
        MORPH_IDT_2Nx8 dvecInData1temp, dvecInData2temp;

        pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
        pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch1);

        /* load data from 2 input rows [Row0 | Row1 | Row2 | Row3] */
        valign vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        MORPH_OP_LOAD_2Nx8_VARIABLE(dvecInData1, vaInData1, pdvecIn1, (2 + enable2ndRow + enable3rdRow) * inDataPitch1);
        dvecInData1temp = IVP_SEL2NX8I(dvecInData1, dvecInData1, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* load data from 2 input rows [Row4 | Row5 | Row6 | Row7] */
        valign vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        MORPH_OP_LOAD_2Nx8_VARIABLE(dvecInData2, vaInData2, pdvecIn2, (1 + enable2ndRow + enable3rdRow) * inDataPitch1);
        dvecInData2temp = IVP_SEL2NX8I(dvecInData2, dvecInData2, IVP_SELI_8B_ROTATE_RIGHT_1);
        pInput         += inDataPitch2;

        /* load all the 2x2 coefficients for 2 output depths*/
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, 4);
        IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, 4);

        int32_t qmulScalar1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0);
        int32_t qmulScalar2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0);

        /* Compute Row 1 of 1st output channel */
        MORPH_OP_MULQA(dacc1, dvecInData2temp, dvecInData2, dvecInData1temp, dvecInData1, qmulScalar1);

        /* Compute Row 1 of 2nd output channel */
        MORPH_OP_MULQA(dacc2, dvecInData2temp, dvecInData2, dvecInData1temp, dvecInData1, qmulScalar2);
      }

      /* Pack, Output Scale, Output Shift and clamping */
      xb_vec2Nx8 dvecOut1L, dvecOut2L;
      xb_vec2Nx8 dvecOut1H, dvecOut2H;
#if DILATED_VQ_CONV == VQ_TRUE
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                    pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                    pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                    outScale, outShiftU, minLim, maxLim, typeFlag);
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                    outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
      /* Storing the first output depth, first row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput);
      valign vaOutData = IVP_ZALIGN();
      IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the first output depth, second row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2ndRow * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the first output depth, 3rd row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch1 * enable3rdRow * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), 2 * inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * enable3rdRow * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, first row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
      IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, second row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                            outDataPitch1 * enable2ndRow) * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * enable2ndRow * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, 3rd row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                            2 * outDataPitch1 * enable3rdRow) * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), 2 * inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * enable3rdRow * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      pOutput += 2 * outDataPitch2 * bytesPerPixel;
      pCoeff  += 2 * coeffPitch3;
    } /* end of for (outCh = 0; outCh < numOutCh; outCh += 2)*/
  }   /* end of if(y < outH)*/
}

/******************************************************************************************
* MOW fold 32 Stride 1                                                                    *
* If inDataPitch1 is lesser than or equal to                                              *
* 32 this function is called.                                                             *
******************************************************************************************/

static _XAI_INLINE_ void MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_2x2j1d1), S8IX_MOW_WHD_FOLD32) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Pitches of Coefficient Data (WHDN) in dim1 and dim3 */
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  const uint8_t leftEdgeFlag = XAI_CNN_CONV_GET_FLAG_LEFTEDGE(param);
  const uint8_t topEdgeFlag  = XAI_CNN_CONV_GET_FLAG_TOPEDGE(param);
  int32_t leftEdge, topEdge;

  leftEdge = leftEdgeFlag ? (kSizeU / 2) : ((kSizeU / 2) - 1);
  topEdge  = topEdgeFlag ? (kSizeU / 2) : ((kSizeU / 2) - 1);

  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-(topEdge * inDataPitch1 + leftEdge)];


  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 *restrict pdvecIn1;
  MORPH_IDT_2Nx8 *restrict pdvecIn2;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1;
  xb_vec2Nx8* restrict pdvecCoeff2;

  /* Variable Declarations */
  int32_t inCh, outCh, y;

  /* loop across output channels and output height are unrolled twice
   * to produce four output vectors in 1 iteration
   */
  for (y = 0; y < outH; y += 2)   /* Loop across output height */
  {
    /* in order to hanlde odd output height */
    int32_t enable2Row = XT_SALT(y, outH - 1);

    /* initialize output data pointer */
    int8_t *pOutput = &pOutData[(y * outDataPitch1) * bytesPerPixel];

    /* initialize coeff and Bias data pointer */
    int8_t *pCoeff = &pCoeffData[0];
    int32_t *pBias = &pBiasData[0];

    for (outCh = 0; outCh < numOutCh; outCh += 2)    /* Loop across Output depth */
    {
      /* In order to handle odd output depths */
      int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

      /* Load the bias values corresponding to two output channels */
      xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
      xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

      /* wide vectors(accumulators) initialized with bias */
      xb_vec2Nx24 dacc1, dacc2;

      dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
      IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);

      dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
      IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);

      /* priming of coeff load is done outside the innermost loop*/
      pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
      valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

      pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
      valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y];

      /* load data from first 2 input rows */
      pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
      pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch1);


      for (inCh = 0; inCh < numInCh - 1; inCh += 2)    /* Loop across input channels */
      {
        /* vectors for coeff and input loads */
        xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2;
        MORPH_IDT_2Nx8 dvecInData1, dvecInData2;
        MORPH_IDT_2Nx8 dvecInData1temp, dvecInData2temp;

        /* load data from 2 input rows [Row0 | Row1] */
        valign vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        MORPH_OP_LOAD_2Nx8(dvecInData1, vaInData1, pdvecIn1, inDataPitch2);
        dvecInData1temp = IVP_SEL2NX8I(dvecInData1, dvecInData1, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* load data from 2 input rows [Row1 | Row2] */
        valign vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        MORPH_OP_LOAD_2Nx8(dvecInData2, vaInData2, pdvecIn2, inDataPitch2);
        dvecInData2temp = IVP_SEL2NX8I(dvecInData2, dvecInData2, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* load all the 2x2 coefficients for 2 output depths*/
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, 8);
        IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, 8);

        int32_t qmulScalar1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0);
        int32_t qmulScalar2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0);

        /* Compute Row 1 of 1st channel */
        MORPH_OP_MULQA(dacc1, dvecInData2temp, dvecInData2, dvecInData1temp, dvecInData1, qmulScalar1);

        /* Compute Row 2 of 1st channel */
        MORPH_OP_MULQA(dacc2, dvecInData2temp, dvecInData2, dvecInData1temp, dvecInData1, qmulScalar2);

        /* Process input channel2 */
        /* load data from 2 input rows [Row0 | Row1] */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        MORPH_OP_LOAD_2Nx8(dvecInData1, vaInData1, pdvecIn1, inDataPitch2);
        dvecInData1temp = IVP_SEL2NX8I(dvecInData1, dvecInData1, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* load data from 2 input rows [Row1 | Row2] */
        vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        MORPH_OP_LOAD_2Nx8(dvecInData2, vaInData2, pdvecIn2, inDataPitch2);
        dvecInData2temp = IVP_SEL2NX8I(dvecInData2, dvecInData2, IVP_SELI_8B_ROTATE_RIGHT_1);

        qmulScalar1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1);
        qmulScalar2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1);

        /* Compute Row 1 of 1st channel */
        MORPH_OP_MULQA(dacc1, dvecInData2temp, dvecInData2, dvecInData1temp, dvecInData1, qmulScalar1);

        /* Compute Row 2 of 1st channel */
        MORPH_OP_MULQA(dacc2, dvecInData2temp, dvecInData2, dvecInData1temp, dvecInData1, qmulScalar2);
      }    /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

      if (inCh < numInCh)
      {
        /* vectors for coeff and input loads */
        xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2;
        MORPH_IDT_2Nx8 dvecInData1, dvecInData2;
        MORPH_IDT_2Nx8 dvecInData1temp, dvecInData2temp;

        /* load data from 2 input rows [Row0 | Row1] */
        valign vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        MORPH_OP_LOAD_2Nx8(dvecInData1, vaInData1, pdvecIn1, inDataPitch2);
        dvecInData1temp = IVP_SEL2NX8I(dvecInData1, dvecInData1, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* load data from 2 input rows [Row1 | Row2] */
        valign vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        MORPH_OP_LOAD_2Nx8(dvecInData2, vaInData2, pdvecIn2, inDataPitch2);
        dvecInData2temp = IVP_SEL2NX8I(dvecInData2, dvecInData2, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* load all the 2x2 coefficients for 2 output depths*/
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, 8);
        IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, 8);

        int32_t qmulScalar1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0);
        int32_t qmulScalar2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0);

        /* Compute Row 1 of 1st channel */
        MORPH_OP_MULQA(dacc1, dvecInData2temp, dvecInData2, dvecInData1temp, dvecInData1, qmulScalar1);

        /* Compute Row 2 of 1st channel */
        MORPH_OP_MULQA(dacc2, dvecInData2temp, dvecInData2, dvecInData1temp, dvecInData1, qmulScalar2);
      }

      /* Pack, Output Scale, Output Shift and clamping */
      xb_vec2Nx8 dvecOut1L, dvecOut2L;
      xb_vec2Nx8 dvecOut1H, dvecOut2H;
#if DILATED_VQ_CONV == VQ_TRUE
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                    pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                    pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                    outScale, outShiftU, minLim, maxLim, typeFlag);
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                    outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
      /* Storing the first output depth, first row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput);
      valign vaOutData = IVP_ZALIGN();
      IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the first output depth, second row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2Row * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * enable2Row * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, first row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
      IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, second row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                            outDataPitch1 * enable2Row) * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)),
                     vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * \
                     enable2Row * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      pOutput += 2 * outDataPitch2 * bytesPerPixel;
      pCoeff  += 2 * coeffPitch3;
    }  /* end of for (outCh = 0; outCh < numOutCh; outCh += 2)*/
  }    /* end of for (y = 0; y < outH; y += 2)*/
}


/*****************************************************************************
*  xaiConvolved(VQ)3D_S_2x2j1d1I8S8IX_MOW_WHD
*  **************************************************************************/
/********************************************************************************/
/* Description : P6 optimized generic implementation for 2x2 3D convolution with*/
/*               dilation = 1. Based on MORPH pre-processor specifiers, code    */
/*               implementation is generated during preprocessing stage. This   */
/*               method can be used to generate 2x2 3D MOW_WHD convolution      */
/*               function and 2x2 3D VQ MOW_WHD convolution function for U8 bit */
/*               and S8 bit input data with input stride equal to 1             */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                  */
/*               Output scale array, CNN convolution params structure           */
/* Outputs     : XI Error Code                                                  */
/* InOuts      : Output Tile                                                    */
/* Assumptions : CoeffData is S8                                                */
/*               biasArray is signed 32b, value not exceeding signed 24b        */
/*               OutData is S8 / U8 / S16                                       */
/*               Kernel Size is 2x2xDxN                                         */
/*               Input and Output are in WHD format                             */
/*               Coeff is in WHDN format                                        */
/********************************************************************************/

/****************** xaiConvolvedVQ3D_S_2x2j1d1_S8S8IX_MOW_WHD ******************/
/****************** xaiConvolvedVQ3D_S_2x2j1d1_U8S8IX_MOW_WHD ******************/
/******************* xaiConvolved3D_S_2x2j1d1_S8S8IX_MOW_WHD *******************/
/******************* xaiConvolved3D_S_2x2j1d1_U8S8IX_MOW_WHD *******************/

XAI_ERR_TYPE MAKE_NAME(MAKE_NAME_VQ(xaiConvolved, 3D_S_2x2j1d1), S8IX_MOW_WHD) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Error Checks */
  XAI_ERROR_CHECKS()
  {
    MORPH_IDT_CHECK(inTile);
    XAI_CHECK_CONV_OUTPUT_TILE3D(outTile);
    XAI_CHECK_TILE4D_S8(coeffTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(outTile);
    XAI_CHECK_TILE4D_IN_DRAM_BOUNDARY(coeffTile);
    XAI_CHECK_POINTER(param);
    XAI_CHECK_ARRAY_S32(biasArray);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(inTile, outTile);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(coeffTile, outTile);
    XAI_CHECK_KERNEL_SIZE(coeffTile, 2);
    XAI_CHECK_TILE3D_DATA_ORDER(inTile, XAI_WHD);
    XAI_CHECK_TILE3D_DATA_ORDER(outTile, XAI_WHD);
    XAI_CHECK_TILE4D_DATA_ORDER(coeffTile, XAI_WHDN);
    XAI_CHECK_DILATION(param, 1);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_DILATIONX(param) == XAI_CNN_CONV_GET_DILATIONY(param),                                           \
                    XAI_ERR_BADARG, "Dilation along width = %hhu and height = %hhu\nDilation along width and height should be equal", \
                    XAI_CNN_CONV_GET_DILATIONX(param), XAI_CNN_CONV_GET_DILATIONY(param));
    XAI_CHECK_STRIDE(param, 1);
    XAI_CHECK_ERROR((XAI_CNN_CONV_GET_STRIDEX(param) == XAI_CNN_CONV_GET_STRIDEY(param)),                                           \
                    XAI_ERR_BADARG, "\nStride along width = %hhu and height = %hhu\nStride along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_EDGES_MOW_WHD(inTile, coeffTile, param);
    XAI_CHECK_CONSISTENCY_MOW_WHD(inTile, coeffTile, biasArray, outTile, param);
    XAI_CHECK_COEFFTILE_CONTIGUOUS(coeffTile, param);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_ACCUM_SHIFT(param) < 24,                                     \
                    XAI_ERR_NORM, "\nThe accumulator shift = %hhu, value should be less than 24", \
                    XAI_CNN_CONV_GET_ACCUM_SHIFT(param));
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_OUTPUT_SHIFT(param) < 32,                               \
                    XAI_ERR_NORM, "\nThe output shift = %hhu, value should be less than 32", \
                    XAI_CNN_CONV_GET_OUTPUT_SHIFT(param));
    XAI_CHECK_CONV_RELU_LIMITS_IX(param, outTile);
#if DILATED_VQ_CONV == VQ_TRUE
    XAI_CHECK_ARRAY_U16(outputScaleArray);
    XAI_CHECK_ERROR(XAI_ARRAY_GET_WIDTH(outputScaleArray) >= XAI_TILE4D_GET_DIM4(coeffTile),                                                                                          \
                    XAI_ERR_DATASIZE, "\nWidth of Output Scale Array = %d, Number of Kernels = %d\nWidth of Output Scale Array should be greater than or equal to Number of Kernels", \
                    XAI_ARRAY_GET_WIDTH(outputScaleArray), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_ERROR((((uintptr_t) (XAI_ARRAY_GET_DATA_PTR(outputScaleArray)) & \
                      0x1) == 0), XAI_ERR_NORM, "The output scale array is not aligned to 2 byte boundary");
#endif
  }
#if DILATED_VQ_CONV == VQ_FALSE
  if (XAI_CNN_CONV_GET_OUTPUT_SCALE(param) == 0)
  {
    int32_t fillValue;
    int32_t reluFlag = XAI_CNN_CONV_GET_FLAG_RELU(param);
    fillValue = reluFlag ? (CLAMP(0, XAI_CNN_CONV_GET_RELU_MIN(param), XAI_CNN_CONV_GET_RELU_MAX(param))) : 0;
    return(xaiFillTile3D(outTile, fillValue, 0));
  }
#endif

  /* check inDataPitch1, if it is less than or equal to 32,
   * call FOLD32 variant otherwise continue
   */

  if (XAI_TILE3D_GET_DIM1_PITCH(inTile) <= 16)
  {
    MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_2x2j1d1), S8IX_MOW_WHD_FOLD16) MAKE_PARAMS(inTile, coeffTile, biasArray, outTile, param);
    return(XAI_ERROR_STATUS());
  }

  if (XAI_TILE3D_GET_DIM1_PITCH(inTile) <= 32)
  {
    MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_2x2j1d1), S8IX_MOW_WHD_FOLD32) MAKE_PARAMS(inTile, coeffTile, biasArray, outTile, param);
    return(XAI_ERROR_STATUS());
  }

  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Pitches of Coefficient Data (WHDN) in dim1 and dim3 */
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  const uint8_t leftEdgeFlag = XAI_CNN_CONV_GET_FLAG_LEFTEDGE(param);
  const uint8_t topEdgeFlag  = XAI_CNN_CONV_GET_FLAG_TOPEDGE(param);
  int32_t leftEdge, topEdge;

  leftEdge = leftEdgeFlag ? (kSizeU / 2) : ((kSizeU / 2) - 1);
  topEdge  = topEdgeFlag ? (kSizeU / 2) : ((kSizeU / 2) - 1);

  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-(topEdge * inDataPitch1 + leftEdge)];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 *restrict pdvecIn1;
  MORPH_IDT_2Nx8 *restrict pdvecIn2;
  MORPH_IDT_2Nx8 *restrict pdvecIn3;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1;
  xb_vec2Nx8* restrict pdvecCoeff2;

  /* Variable Declarations */
  int32_t inCh, outCh, x, y;
  /* In order to make the loop multiply-bound we are reducing the vectorization width
     by extra values required for the kernel */
  const int32_t vectorizationWidth = ((2 * XCHAL_IVPN_SIMD_WIDTH) - kSizeU) + 1;

  /* loop across output channels and output height are unrolled twice
   * to produce four output vectors in 1 iteration
   */
  for (x = 0; x < outW; x += vectorizationWidth) /* Loop across output width */
  {
    for (y = 0; y < outH; y += 2)   /* Loop across output height */
    {
      /* in order to handle odd output height */
      int32_t enable2Row = XT_SALT(y, outH - 1);

      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y + x];

      /* initialize coeff and Bias data pointer */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 2)    /* Loop across Output depth */
      {
        /* In order to handle odd output depths */
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

        /* Load the bias values corresponding to two output channels */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 daccSum11, daccSum21, daccSum12, daccSum22;

        daccSum11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(daccSum11, hvecBias1, hvecBias1);

        daccSum12 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(daccSum12, hvecBias1, hvecBias1);

        daccSum21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(daccSum21, hvecBias2, hvecBias2);

        daccSum22 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(daccSum22, hvecBias2, hvecBias2);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + (coeffPitch3 * enable2ndCh));

        /* Input vector pointer initialization- 1st input channel */
        pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
        pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch1);
        pdvecIn3 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch1 * enable2Row);

        for (inCh = 0; inCh < numInCh - 1; inCh += 2)    /* Loop across input channels */
        {
          /* vectors for coeff and input loads */
          xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2;
          MORPH_IDT_2Nx8 dvecInData1, dvecInData2, dvecInData3;

          /* load all the 2x2 coefficients for 1st output channel*/
          valign vaCoeffData;
          vaCoeffData = IVP_LA2NX8_PP(pdvecCoeff1);
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData, pdvecCoeff1, 8);

          /* load all the 2x2 coefficients for 2nd output channel*/
          vaCoeffData = IVP_LA2NX8_PP(pdvecCoeff2);
          IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData, pdvecCoeff2, 8);

          /* load data from first input row */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecInData1, vaInData, pdvecIn1, inDataPitch2);

          /* load data from 2nd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
          MORPH_OP_LOAD_2Nx8(dvecInData2, vaInData, pdvecIn2, inDataPitch2);

          /* load data from 3rd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn3);
          MORPH_OP_LOAD_2Nx8(dvecInData3, vaInData, pdvecIn3, inDataPitch2);

          MORPH_IDT_2Nx8 dvecInData1temp, dvecInData2temp, dvecInData3temp;

          /* Reorder/ rotate the input required for filter kernel computation */
          dvecInData1temp = IVP_SEL2NX8I(dvecInData1, dvecInData1, IVP_SELI_8B_ROTATE_RIGHT_1);
          dvecInData2temp = IVP_SEL2NX8I(dvecInData2, dvecInData2, IVP_SELI_8B_ROTATE_RIGHT_1);
          dvecInData3temp = IVP_SEL2NX8I(dvecInData3, dvecInData3, IVP_SELI_8B_ROTATE_RIGHT_1);

          int32_t qmulScalar1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0);

          /* Compute Row 1 of 1st channel */
          MORPH_OP_MULQA(daccSum11, dvecInData2temp, dvecInData2, dvecInData1temp, dvecInData1, qmulScalar1);
          /* Compute Row 2 of 1st channel */
          MORPH_OP_MULQA(daccSum12, dvecInData3temp, dvecInData3, dvecInData2temp, dvecInData2, qmulScalar1);

          int32_t qmulScalar2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0);

          /* Compute Row 1 of 2nd channel */
          MORPH_OP_MULQA(daccSum21, dvecInData2temp, dvecInData2, dvecInData1temp, dvecInData1, qmulScalar2);
          /* Compute Row 2 of 2nd channel */
          MORPH_OP_MULQA(daccSum22, dvecInData3temp, dvecInData3, dvecInData2temp, dvecInData2, qmulScalar2);

          /* load data from first input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecInData1, vaInData, pdvecIn1, inDataPitch2);

          /* load data from 2nd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
          MORPH_OP_LOAD_2Nx8(dvecInData2, vaInData, pdvecIn2, inDataPitch2);

          /* load data from 3rd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn3);
          MORPH_OP_LOAD_2Nx8(dvecInData3, vaInData, pdvecIn3, inDataPitch2);

          /* Reorder/ rotate the input required for filter kernel computation */
          dvecInData1temp = IVP_SEL2NX8I(dvecInData1, dvecInData1, IVP_SELI_8B_ROTATE_RIGHT_1);
          dvecInData2temp = IVP_SEL2NX8I(dvecInData2, dvecInData2, IVP_SELI_8B_ROTATE_RIGHT_1);
          dvecInData3temp = IVP_SEL2NX8I(dvecInData3, dvecInData3, IVP_SELI_8B_ROTATE_RIGHT_1);

          qmulScalar1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1);

          /* Compute Row 1 of 1st channel */
          MORPH_OP_MULQA(daccSum11, dvecInData2temp, dvecInData2, dvecInData1temp, dvecInData1, qmulScalar1);
          /* Compute Row 2 of 1st channel */
          MORPH_OP_MULQA(daccSum12, dvecInData3temp, dvecInData3, dvecInData2temp, dvecInData2, qmulScalar1);

          qmulScalar2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1);

          /* Compute Row 1 of 2nd channel */
          MORPH_OP_MULQA(daccSum21, dvecInData2temp, dvecInData2, dvecInData1temp, dvecInData1, qmulScalar2);
          /* Compute Row 2 of 2nd channel */
          MORPH_OP_MULQA(daccSum22, dvecInData3temp, dvecInData3, dvecInData2temp, dvecInData2, qmulScalar2);
        }                   /* end of for (inCh = 0; inCh < numInCh; inCh++)*/
        if (inCh < numInCh) /*Control flow to handle final row for odd input channel count*/
        {
          xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2;
          MORPH_IDT_2Nx8 dvecInData1, dvecInData2, dvecInData3;

          /* load all the 2x2 coefficients for 1st output channel*/
          valign vaCoeffData = IVP_LA2NX8_PP(pdvecCoeff1);
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData, pdvecCoeff1, 4);

          /* load all the 2x2 coefficients for 2nd output channel*/
          vaCoeffData = IVP_LA2NX8_PP(pdvecCoeff2);
          IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData, pdvecCoeff2, 4);

          /* load data from first input row */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecInData1, vaInData, pdvecIn1, inDataPitch2);

          /* load data from 2nd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
          MORPH_OP_LOAD_2Nx8(dvecInData2, vaInData, pdvecIn2, inDataPitch2);

          /* load data from 3rd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn3);
          MORPH_OP_LOAD_2Nx8(dvecInData3, vaInData, pdvecIn3, inDataPitch2);

          MORPH_IDT_2Nx8 dvecInData1temp, dvecInData2temp, dvecInData3temp;

          /* Reorder/ rotate the input required for filter kernel computation */
          dvecInData1temp = IVP_SEL2NX8I(dvecInData1, dvecInData1, IVP_SELI_8B_ROTATE_RIGHT_1);
          dvecInData2temp = IVP_SEL2NX8I(dvecInData2, dvecInData2, IVP_SELI_8B_ROTATE_RIGHT_1);
          dvecInData3temp = IVP_SEL2NX8I(dvecInData3, dvecInData3, IVP_SELI_8B_ROTATE_RIGHT_1);

          int32_t qmulScalar1 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0);

          /* Compute Row 1 of 1st channel */
          MORPH_OP_MULQA(daccSum11, dvecInData2temp, dvecInData2, dvecInData1temp, dvecInData1, qmulScalar1);
          /* Compute Row 2 of 1st channel */
          MORPH_OP_MULQA(daccSum12, dvecInData3temp, dvecInData3, dvecInData2temp, dvecInData2, qmulScalar1);

          int32_t qmulScalar2 = IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0);

          /* Compute Row 1 of 2nd channel */
          MORPH_OP_MULQA(daccSum21, dvecInData2temp, dvecInData2, dvecInData1temp, dvecInData1, qmulScalar2);
          /* Compute Row 2 of 2nd channel */
          MORPH_OP_MULQA(daccSum22, dvecInData3temp, dvecInData3, dvecInData2temp, dvecInData2, qmulScalar2);
        }
        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut11L, dvecOut12L, dvecOut21L, dvecOut22L;
        xb_vec2Nx8 dvecOut11H, dvecOut12H, dvecOut21H, dvecOut22H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut11L, dvecOut11H, daccSum11, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut12L, dvecOut12H, daccSum12, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut21L, dvecOut21H, daccSum21, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut22L, dvecOut22H, daccSum22, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut11L, dvecOut11H, daccSum11, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut12L, dvecOut12H, daccSum12, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut21L, dvecOut21H, daccSum21, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut22L, dvecOut22H, daccSum22, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* variable length for output stores */
        int32_t varLen = XT_MIN(vectorizationWidth, outW - x);

        /* Storing the first output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut11L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAV2NX8_XP(dvecOut11H, vaOutData, pdvecOut, typeFlag * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2Row * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut12L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2Row);
        IVP_SAV2NX8_XP(dvecOut12H, vaOutData, pdvecOut, typeFlag * \
                       enable2Row * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);


        /* Storing the second output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut21L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
        IVP_SAV2NX8_XP(dvecOut21H, vaOutData, pdvecOut, typeFlag * enable2ndCh * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                              outDataPitch1 * enable2Row) * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut22L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * enable2Row * varLen);
        IVP_SAV2NX8_XP(dvecOut22H, vaOutData, pdvecOut, typeFlag * enable2ndCh * \
                       enable2Row * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 2 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 2 * coeffPitch3;
      }  /* end of for (outCh = 0; outCh < numOutCh; outCh += 2)*/
    }    /* end of for (y = 0; y < outH; y += 2)*/
  }      /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  return(XAI_ERROR_STATUS());
}

/*****************************************************************************
*  xaiConvolved(VQ)3D_S_3x3j1d1I8S8IX_MOW_WHD
*  **************************************************************************/

/******************************************************************************/
/* Description : P6 optimized generic implementation for 3x3 3D VQ convolution*/
/*               Based on MORPH pre-processor specifiers, code implementation */
/*               is generated during preprocessing stage. This method can be  */
/*               used to generate 3x3 MOW_WHD 3D dilated convolution function */
/*               and 3x3 MOW_WHD 3D VQ dilated convolution function for U8    */
/*               bit and S8 bit input data with input stride equal to 1       */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                */
/*               Output scale array, CNN convolution params structure         */
/* Outputs     : XI Error Code                                                */
/* InOuts      : Output Tile                                                  */
/* Assumptions : CoeffData is S8                                              */
/*               biasArray is signed 32b, value not exceeding signed 24b      */
/*               Output scale array is U16                                    */
/*               OutData is S8 / U8 / S16                                     */
/*               Kernel Size is 3x3xDxN                                       */
/*               Input and Output are in WHD format                           */
/*               Coeff is in WHDN format                                      */
/******************************************************************************/
/******************************************************************************************
* MOW fold 16 Stride 1 varaint                                                            *
* If inDataPitch1 is lesser than or equal to                                              *
* 16 this function is called.                                                             *
******************************************************************************************/

static _XAI_INLINE_ void MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_3x3j1d1), S8IX_MOW_WHD_FOLD16) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Pitches of Coefficient Data (WHDN) in dim1 and dim3 */
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);

  const uint8_t outShiftU  = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu = XAI_CNN_CONV_GET_FLAG_RELU(param);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-((kSizeU / 2) * inDataPitch1 + (kSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 *restrict pdvecIn;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1;
  xb_vec2Nx8* restrict pdvecCoeff2;

  /* Variable Declarations */
  int32_t inCh, outCh, y;

  /* Generating the shuffle pattern for coefficent loads.
     The idea is to populate zero value where the MUL4T should not affect
     Pattern : 0 1 2 32 3 4 5 32 6 7 8 32 X X X .... */
  xb_vec2Nx8 dvecIdx = IVP_SEL2NX8I(32, IVP_MOV2NX8_FROMNX16( \
                                      IVP_MOVNX16T(IVP_ADDNX16(IVP_ANDNX16(IVP_SEQNX16(), 3),
                                                               IVP_MULNX16PACKL(IVP_SRLINX16(IVP_SEQNX16(), 2), 3)), 32,
                                                   IVP_NEQNX16(IVP_ANDNX16(IVP_SEQNX16(), 3), 3))),
                                    IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0);


  /* Select sequence to re-arrange input data */
  xb_vec2Nx8 dvecSeq = 0;
  IVP_ADD2NX8T(dvecSeq, IVP_SEQ2NX8(), inDataPitch1, IVP_LT2NX8(IVP_SEQ2NX8(), 3 * inDataPitch1));
  IVP_ADD2NX8T(dvecSeq, IVP_SUB2NX8(IVP_SEQ2NX8(), 3 * inDataPitch1), (2 * XCHAL_IVPN_SIMD_WIDTH), \
               IVP_NOTB2N(IVP_LT2NX8(IVP_SEQ2NX8(), 3 * inDataPitch1)));

  /* loop across output channels is unrolled twice and
   * loop across output height is unrolled 4 times
   */
  for (y = 0; y < outH - 3; y += 4)   /* Loop across output height */
  {
    /* initialize output data pointer */
    int8_t *pOutput = &pOutData[(y * outDataPitch1) * bytesPerPixel];

    /* initialize input data pointer */
    MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y];

    /* initialize coeff and Bias data pointer */
    int8_t *pCoeff = &pCoeffData[0];
    int32_t *pBias = &pBiasData[0];

    for (outCh = 0; outCh < numOutCh; outCh += 2)    /* Loop across Output depth */
    {
      /* In order to handle odd output depths and heights */
      int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

      /* Load the bias values corresponding to two output channels */
      xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
      xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

      /* wide vectors(accumulators) initialized with bias */
      xb_vec2Nx24 dacc1, dacc2;

      dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
      IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);

      dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
      IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);

      /* priming of coeff load is done outside the innermost loop*/
      pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
      valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

      pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
      valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

      /* Input vector pointer initialization */
      pdvecIn = (MORPH_IDT_2Nx8 *) (pInput);

      for (inCh = 0; inCh < numInCh; inCh++)    /* Loop across input channels */
      {
        /* vectors for coeff and input loads */
        xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2;
        MORPH_IDT_2Nx8 dvecInData1, dvecInData2;

        /* load data from first 4 input rows */
        valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData1, vaInData, pdvecIn, 4 * inDataPitch1);

        /* load data from next 4 input rows */
        MORPH_OP_LOAD_2Nx8(dvecInData2, vaInData, pdvecIn, inDataPitch2 - (4 * inDataPitch1));

        /* load all the 3x3 coefficients for 2 output depths*/
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, 9);
        IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, 9);

        /* Rearrange them so that zero is inserted where the MUL4T should not have effect */
        dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);
        dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecIdx);

        /* dvecInData1 contains first 4 input rows and
         * dvecInData2 contains next 4 input rows.
         * dvecInData1: row0 | row1 | row2 | row3
         * dvecInData2: row4 | row5 | row6 | row7
         *
         * Input data is re arranged in such a manner that
         * dvecTemp1 contains: row1 | row2 | row3 | row4
         * dvecTemp2 contains: row2 | row3 | row4 | row5
         */
        xb_vec2Nx8 dvecTemp1, dvecTemp2;
        dvecTemp1 = IVP_SEL2NX8(dvecInData2, dvecInData1, dvecSeq);
        dvecTemp2 = IVP_SEL2NX8(IVP_SEL2NX8(0, dvecInData2, dvecSeq), dvecTemp1, dvecSeq);

        /* Multiply input data with coefficients from 1st output channel */
        MORPH_OP_MUL4TA(dacc1, dvecInData1, dvecInData1, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc1, dvecTemp1, dvecTemp1, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
        MORPH_OP_MUL4TA(dacc1, dvecTemp2, dvecTemp2, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));

        /* Multiply input data with coefficients from 2nd output channel */
        MORPH_OP_MUL4TA(dacc2, dvecInData1, dvecInData1, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
        MORPH_OP_MUL4TA(dacc2, dvecTemp1, dvecTemp1, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
        MORPH_OP_MUL4TA(dacc2, dvecTemp2, dvecTemp2, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
      }    /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

      /* Pack, Output Scale, Output Shift and clamping */
      xb_vec2Nx8 dvecOut1L, dvecOut2L;
      xb_vec2Nx8 dvecOut1H, dvecOut2H;
#if DILATED_VQ_CONV == VQ_TRUE
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                    pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                    pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                    outScale, outShiftU, minLim, maxLim, typeFlag);
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                    outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
      /* Storing the first output depth, first row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput);
      valign vaOutData = IVP_ZALIGN();
      IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the first output depth, second row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the first output depth, 3rd row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch1 * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), 2 * inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the first output depth, 4th row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch1 * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), 3 * inDataPitch1 * bytesPerPixel)),
                     vaOutData, pdvecOut, bytesPerPixel * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, first row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
      IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, second row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                            outDataPitch1) * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, 3rd row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                            2 * outDataPitch1) * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), 2 * inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, 4th row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                            3 * outDataPitch1) * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), 3 * inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);


      pOutput += 2 * outDataPitch2 * bytesPerPixel;
      pCoeff  += 2 * coeffPitch3;
    }  /* end of for (outCh = 0; outCh < numOutCh; outCh += 2)*/
  }    /* end of for (y = 0; y < outH - 3; y += 4)*/
  /* handle left out output rows */
  if (y < outH)
  {
    int32_t enable2ndRow = XT_SALT(y, outH - 1);
    int32_t enable3rdRow = XT_SALT(y, outH - 2);
    /* initialize output data pointer */
    int8_t *pOutput = &pOutData[(y * outDataPitch1) * bytesPerPixel];

    /* initialize coeff and Bias data pointer */
    int8_t *pCoeff = &pCoeffData[0];
    int32_t *pBias = &pBiasData[0];

    for (outCh = 0; outCh < numOutCh; outCh += 2)    /* Loop across Output depth */
    {
      /* In order to handle odd output depths and heights */
      int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

      /* Load the bias values corresponding to two output channels */
      xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
      xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

      /* wide vectors(accumulators) initialized with bias */
      xb_vec2Nx24 dacc1, dacc2;

      dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
      IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);

      dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
      IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);

      /* priming of coeff load is done outside the innermost loop*/
      pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
      valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

      pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
      valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y];

      for (inCh = 0; inCh < numInCh; inCh++)    /* Loop across input channels */
      {
        /* vectors for coeff and input loads */
        xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2;
        MORPH_IDT_2Nx8 dvecInData1, dvecInData2;

        /* load data from first 4 input rows */
        pdvecIn = (MORPH_IDT_2Nx8 *) (pInput);
        valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8_VARIABLE(dvecInData1, vaInData, pdvecIn, (3 + enable2ndRow) * inDataPitch1);

        /* load data from next 4 input rows */
        MORPH_OP_LOAD_2Nx8_VARIABLE(dvecInData2, vaInData, pdvecIn, (enable2ndRow + enable3rdRow) * inDataPitch1);
        pInput += inDataPitch2;

        /* load all the 3x3 coefficients for 2 output depths*/
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, 9);
        IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, 9);

        /* Rearrange them so that zero is inserted where the MUL4T should not have effect */
        dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);
        dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecIdx);

        /* dvecInData1 contains first 4 input rows and
         * dvecInData2 contains next 4 input rows.
         * dvecInData1: row0 | row1 | row2 | row3
         * dvecInData2: row4 | row5 | row6 | row7
         *
         * Input data is re arranged in such a manner that
         * dvecTemp1 contains: row1 | row2 | row3 | row4
         * dvecTemp2 contains: row2 | row3 | row4 | row5
         */
        xb_vec2Nx8 dvecTemp1, dvecTemp2;
        dvecTemp1 = IVP_SEL2NX8(dvecInData2, dvecInData1, dvecSeq);
        dvecTemp2 = IVP_SEL2NX8(IVP_SEL2NX8(0, dvecInData2, dvecSeq), dvecTemp1, dvecSeq);

        /* Multiply input data with coefficients from 1st output channel */
        MORPH_OP_MUL4TA(dacc1, dvecInData1, dvecInData1, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc1, dvecTemp1, dvecTemp1, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
        MORPH_OP_MUL4TA(dacc1, dvecTemp2, dvecTemp2, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));

        /* Multiply input data with coefficients from 2nd output channel */
        MORPH_OP_MUL4TA(dacc2, dvecInData1, dvecInData1, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
        MORPH_OP_MUL4TA(dacc2, dvecTemp1, dvecTemp1, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
        MORPH_OP_MUL4TA(dacc2, dvecTemp2, dvecTemp2, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
      }    /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

      /* Pack, Output Scale, Output Shift and clamping */
      xb_vec2Nx8 dvecOut1L, dvecOut2L;
      xb_vec2Nx8 dvecOut1H, dvecOut2H;
#if DILATED_VQ_CONV == VQ_TRUE
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                    pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                    pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                    outScale, outShiftU, minLim, maxLim, typeFlag);
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                    outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
      /* Storing the first output depth, first row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput);
      valign vaOutData = IVP_ZALIGN();
      IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the first output depth, second row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2ndRow * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the first output depth, 3rd row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch1 * enable3rdRow * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), 2 * inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * enable3rdRow * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, first row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
      IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, second row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                            outDataPitch1 * enable2ndRow) * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * enable2ndRow * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, 3rd row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                            2 * outDataPitch1 * enable3rdRow) * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), 2 * inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * enable3rdRow * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);


      pOutput += 2 * outDataPitch2 * bytesPerPixel;
      pCoeff  += 2 * coeffPitch3;
    } /* end of for (outCh = 0; outCh < numOutCh; outCh += 2)*/
  }   /* end of if(y < outH)*/
}

/******************************************************************************************
* MOW fold 32 Stride 1                                                                    *
* If inDataPitch1 is lesser than or equal to                                              *
* 32 this function is called.                                                             *
******************************************************************************************/

static _XAI_INLINE_ void MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_3x3j1d1), S8IX_MOW_WHD_FOLD32) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Pitches of Coefficient Data (WHDN) in dim1 and dim3 */
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);

  const uint8_t outShiftU  = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu = XAI_CNN_CONV_GET_FLAG_RELU(param);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-((kSizeU / 2) * inDataPitch1 + (kSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 *restrict pdvecIn;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1;
  xb_vec2Nx8* restrict pdvecCoeff2;

  /* Variable Declarations */
  int32_t inCh, outCh, y;

  /* Generating the shuffle pattern for coefficent loads.
     The idea is to populate zero value where the MUL4T should not affect
     Pattern : 0 1 2 32 3 4 5 32 6 7 8 32 X X X .... */
  xb_vec2Nx8 dvecIdx = IVP_SEL2NX8I(32, IVP_MOV2NX8_FROMNX16( \
                                      IVP_MOVNX16T(IVP_ADDNX16(IVP_ANDNX16(IVP_SEQNX16(), 3),
                                                               IVP_MULNX16PACKL(IVP_SRLINX16(IVP_SEQNX16(), 2), 3)), 32,
                                                   IVP_NEQNX16(IVP_ANDNX16(IVP_SEQNX16(), 3), 3))),
                                    IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0);


  /* Select sequence to re-arrange input data */
  xb_vec2Nx8 dvecSeq = 0;
  IVP_ADD2NX8T(dvecSeq, IVP_SEQ2NX8(), inDataPitch1, IVP_LT2NX8(IVP_SEQ2NX8(), inDataPitch1));
  IVP_ADD2NX8T(dvecSeq, IVP_SUB2NX8(IVP_SEQ2NX8(), inDataPitch1), (2 * XCHAL_IVPN_SIMD_WIDTH), \
               IVP_NOTB2N(IVP_LT2NX8(IVP_SEQ2NX8(), inDataPitch1)));


  /* loop across output channels and output height are unrolled twice
   * to produce four output vectors in 1 iteration
   */
  for (y = 0; y < outH; y += 2)   /* Loop across output height */
  {
    /* in order to hanlde odd output height */
    int32_t enable2Row = XT_SALT(y, outH - 1);
    /* initialize output data pointer */
    int8_t *pOutput = &pOutData[(y * outDataPitch1) * bytesPerPixel];

    /* initialize coeff and Bias data pointer */
    int8_t *pCoeff = &pCoeffData[0];
    int32_t *pBias = &pBiasData[0];

    for (outCh = 0; outCh < numOutCh; outCh += 2)    /* Loop across Output depth */
    {
      /* In order to handle odd output depths */
      int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

      /* Load the bias values corresponding to two output channels */
      xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
      xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

      /* wide vectors(accumulators) initialized with bias */
      xb_vec2Nx24 dacc1, dacc2;

      dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
      IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);

      dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
      IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);

      /* priming of coeff load is done outside the innermost loop*/
      pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
      valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

      pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
      valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y];

      for (inCh = 0; inCh < numInCh; inCh++)    /* Loop across input channels */
      {
        /* vectors for coeff and input loads */
        xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2;
        MORPH_IDT_2Nx8 dvecInData1, dvecInData2;

        /* load data from first 2 input rows */
        pdvecIn = (MORPH_IDT_2Nx8 *) (pInput);
        valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData1, vaInData, pdvecIn, 2 * inDataPitch1);

        /* load data from next 2 input rows */
        MORPH_OP_LOAD_2Nx8_VARIABLE(dvecInData2, vaInData, pdvecIn, inDataPitch1 \
                                    + inDataPitch1 * enable2Row);
        pInput += inDataPitch2;

        /* load all the 3x3 coefficients for 2 output depths*/
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, 9);
        IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, 9);

        /* Rearrange them so that zero is inserted where the MUL4T should not have effect */
        dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);
        dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecIdx);

        /* dvecInData1 contains first 2 input rows and
         * dvecInData2 contains next 2 input rows.
         * dvecInData1: row0 | row1
         * dvecInData2: row2 | row3
         *
         * dvecInData1 is multipled with 1st row of coffecient and
         * dvecInData2 is multipled with 3rd row of coeffecient.
         *
         * To multiply input data with 2nd coefficient row, it is required
         * to store row1 and row 2 in another vector
         *
         * dvecTemp: row1 | row2
         *
         * So first inDataPitch1 elements in the accumulator corresponds to
         * first output row and next inDataPitch1 number of elements corresponds
         * to 2nd output row.
         */
        xb_vec2Nx8 dvecTemp1;
        dvecTemp1 = IVP_SEL2NX8(dvecInData2, dvecInData1, dvecSeq);

        /* Multiply input data with coefficients from 1st output channel */
        MORPH_OP_MUL4TA(dacc1, dvecInData1, dvecInData1, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc1, dvecTemp1, dvecTemp1, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
        MORPH_OP_MUL4TA(dacc1, dvecInData2, dvecInData2, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));

        /* Multiply input data with coefficients from 2nd output channel */
        MORPH_OP_MUL4TA(dacc2, dvecInData1, dvecInData1, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
        MORPH_OP_MUL4TA(dacc2, dvecTemp1, dvecTemp1, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
        MORPH_OP_MUL4TA(dacc2, dvecInData2, dvecInData2, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
      }    /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

      /* Pack, Output Scale, Output Shift and clamping */
      xb_vec2Nx8 dvecOut1L, dvecOut2L;
      xb_vec2Nx8 dvecOut1H, dvecOut2H;
#if DILATED_VQ_CONV == VQ_TRUE
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                    pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                    pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                    outScale, outShiftU, minLim, maxLim, typeFlag);
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                    outScale, outShiftU, minLim, maxLim, typeFlag);
#endif

      /* Storing the first output depth, first row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput);
      valign vaOutData = IVP_ZALIGN();
      IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the first output depth, second row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2Row * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * enable2Row * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);


      /* Storing the second output depth, first row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
      IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, second row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                            outDataPitch1 * enable2Row) * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)),
                     vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * \
                     enable2Row * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      pOutput += 2 * outDataPitch2 * bytesPerPixel;
      pCoeff  += 2 * coeffPitch3;
    }  /* end of for (outCh = 0; outCh < numOutCh; outCh += 2)*/
  }    /* end of for (y = 0; y < outH; y += 2)*/
}

/****************** xaiConvolvedVQ3D_S_3x3j1d1_S8S8IX_MOW_WHD ******************/
/****************** xaiConvolvedVQ3D_S_3x3j1d1_U8S8IX_MOW_WHD ******************/
/******************* xaiConvolved3D_S_3x3j1d1_S8S8IX_MOW_WHD *******************/
/******************* xaiConvolved3D_S_3x3j1d1_U8S8IX_MOW_WHD *******************/

XAI_ERR_TYPE MAKE_NAME(MAKE_NAME_VQ(xaiConvolved, 3D_S_3x3j1d1), S8IX_MOW_WHD) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Error Checks */
  XAI_ERROR_CHECKS()
  {
    MORPH_IDT_CHECK(inTile);
    XAI_CHECK_CONV_OUTPUT_TILE3D(outTile);
    XAI_CHECK_TILE4D_S8(coeffTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(outTile);
    XAI_CHECK_TILE4D_IN_DRAM_BOUNDARY(coeffTile);
    XAI_CHECK_POINTER(param);
    XAI_CHECK_ARRAY_S32(biasArray);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(inTile, outTile);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(coeffTile, outTile);
    XAI_CHECK_KERNEL_SIZE(coeffTile, 3);
    XAI_CHECK_TILE3D_DATA_ORDER(inTile, XAI_WHD);
    XAI_CHECK_TILE3D_DATA_ORDER(outTile, XAI_WHD);
    XAI_CHECK_TILE4D_DATA_ORDER(coeffTile, XAI_WHDN);
    XAI_CHECK_DILATION(param, 1);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_DILATIONX(param) == XAI_CNN_CONV_GET_DILATIONY(param),                                           \
                    XAI_ERR_BADARG, "Dilation along width = %hhu and height = %hhu\nDilation along width and height should be equal", \
                    XAI_CNN_CONV_GET_DILATIONX(param), XAI_CNN_CONV_GET_DILATIONX(param));
    XAI_CHECK_STRIDE(param, 1);
    XAI_CHECK_ERROR((XAI_CNN_CONV_GET_STRIDEX(param) == XAI_CNN_CONV_GET_STRIDEY(param)),                                           \
                    XAI_ERR_BADARG, "\nStride along width = %hhu and height = %hhu\nStride along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_TILE3D_EDGE(inTile, 1);
    XAI_CHECK_CONSISTENCY_MOW_WHD(inTile, coeffTile, biasArray, outTile, param);
    XAI_CHECK_COEFFTILE_CONTIGUOUS(coeffTile, param);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_ACCUM_SHIFT(param) < 24,                                     \
                    XAI_ERR_NORM, "\nThe accumulator shift = %hhu, value should be less than 24", \
                    XAI_CNN_CONV_GET_ACCUM_SHIFT(param));
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_OUTPUT_SHIFT(param) < 32,                               \
                    XAI_ERR_NORM, "\nThe output shift = %hhu, value should be less than 32", \
                    XAI_CNN_CONV_GET_OUTPUT_SHIFT(param));
    XAI_CHECK_CONV_RELU_LIMITS_IX(param, outTile);
#if DILATED_VQ_CONV == VQ_TRUE
    XAI_CHECK_ARRAY_U16(outputScaleArray);
    XAI_CHECK_ERROR(XAI_ARRAY_GET_WIDTH(outputScaleArray) >= XAI_TILE4D_GET_DIM4(coeffTile),                                                                                          \
                    XAI_ERR_DATASIZE, "\nWidth of Output Scale Array = %d, Number of Kernels = %d\nWidth of Output Scale Array should be greater than or equal to Number of Kernels", \
                    XAI_ARRAY_GET_WIDTH(outputScaleArray), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_ERROR((((uintptr_t) (XAI_ARRAY_GET_DATA_PTR(outputScaleArray)) & \
                      0x1) == 0), XAI_ERR_NORM, "The output scale array is not aligned to 2 byte boundary");
#endif
  }
#if DILATED_VQ_CONV == VQ_FALSE
  if (XAI_CNN_CONV_GET_OUTPUT_SCALE(param) == 0)
  {
    int32_t fillValue;
    int32_t reluFlag = XAI_CNN_CONV_GET_FLAG_RELU(param);
    fillValue = reluFlag ? (CLAMP(0, XAI_CNN_CONV_GET_RELU_MIN(param), XAI_CNN_CONV_GET_RELU_MAX(param))) : 0;
    return(xaiFillTile3D(outTile, fillValue, 0));
  }
#endif

  /* check inDataPitch1, if it is less than or equal to 16,
   * call FOLD16 varaint and if it's greater than
   * 16 but less than or equal to 32 call FOLD32 variant otherwise continue
   */

  if (XAI_TILE3D_GET_DIM1_PITCH(inTile) <= 16)
  {
    MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_3x3j1d1), S8IX_MOW_WHD_FOLD16) MAKE_PARAMS(inTile, coeffTile, biasArray, outTile, param);
    return(XAI_ERROR_STATUS());
  }

  if (XAI_TILE3D_GET_DIM1_PITCH(inTile) <= 32)
  {
    MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_3x3j1d1), S8IX_MOW_WHD_FOLD32) MAKE_PARAMS(inTile, coeffTile, biasArray, outTile, param);
    return(XAI_ERROR_STATUS());
  }

  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Pitches of Coefficient Data (WHDN) in dim1 and dim3 */
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);

  const uint8_t outShiftU  = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu = XAI_CNN_CONV_GET_FLAG_RELU(param);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-((kSizeU / 2) * inDataPitch1 + (kSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 *restrict pdvecIn;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1;
  xb_vec2Nx8* restrict pdvecCoeff2;

  /* Variable Declarations */
  int32_t inCh, outCh, x, y;
  /* In order to make the loop multiply-bound we are reducing the vectorization width
     by extra values required for the kernel */
  const int32_t vectorizationWidth = ((2 * XCHAL_IVPN_SIMD_WIDTH) - kSizeU) + 1;

  /* Generating the shuffle pattern for coefficent loads.
     The idea is to populate zero value where the MUL4T should not affect
     Pattern : 0 1 2 32 3 4 5 32 6 7 8 32 X X X .... */
  xb_vec2Nx8 dvecIdx = IVP_SEL2NX8I(32, IVP_MOV2NX8_FROMNX16( \
                                      IVP_MOVNX16T(IVP_ADDNX16(IVP_ANDNX16(IVP_SEQNX16(), 3),
                                                               IVP_MULNX16PACKL(IVP_SRLINX16(IVP_SEQNX16(), 2), 3)), 32,
                                                   IVP_NEQNX16(IVP_ANDNX16(IVP_SEQNX16(), 3), 3))),
                                    IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0);

  /* loop across output channels and output height are unrolled twice
   * to produce four output vectors in 1 iteration
   */
  for (x = 0; x < outW; x += vectorizationWidth) /* Loop across output width */
  {
    for (y = 0; y < outH; y += 2)   /* Loop across output height */
    {
      /* in order to handle odd output height */
      int32_t enable2Row = XT_SALT(y, outH - 1);
      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y + x];

      /* initialize coeff and Bias data pointer */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 2)    /* Loop across Output depth */
      {
        /* In order to handle odd output depths */
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

        /* Load the bias values corresponding to two output channels */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;

        dacc12 = dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);

        dacc22 = dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc22, hvecBias2, hvecBias2);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

        /* Input vector pointer initialization */
        pdvecIn = (MORPH_IDT_2Nx8 *) (pInput);

        for (inCh = 0; inCh < numInCh; inCh++)    /* Loop across input channels */
        {
          /* vectors for coeff and input loads */
          xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2;
          MORPH_IDT_2Nx8 dvecInData1, dvecInData2, dvecInData3, dvecInData4;

          /* load data from first input row */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData1, vaInData, pdvecIn, inDataPitch1);

          /* load data from 2nd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData2, vaInData, pdvecIn, inDataPitch1);

          /* load data from 3rd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData3, vaInData, pdvecIn, inDataPitch1 * enable2Row);

          /* load data from 4th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData4, vaInData, pdvecIn, inDataPitch2 - (2 + enable2Row) * inDataPitch1);

          /* load all the 3x3 coefficients for 2 output depths*/
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, 9);
          IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, 9);

          /* Rearrange them so that zero is inserted where the MUL4T should not have effect */
          dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);
          dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecIdx);

          /* Multiply and accumulate 1st set of 3 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc11, dvecInData1, dvecInData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc12, dvecInData2, dvecInData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc21, dvecInData1, dvecInData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
          MORPH_OP_MUL4TA(dacc22, dvecInData2, dvecInData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

          /* Multiply and accumulate 2nd set of 3 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc11, dvecInData2, dvecInData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc12, dvecInData3, dvecInData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc21, dvecInData2, dvecInData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
          MORPH_OP_MUL4TA(dacc22, dvecInData3, dvecInData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));

          /* Multiply and accumulate 3rd set of 3 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc11, dvecInData3, dvecInData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
          MORPH_OP_MUL4TA(dacc12, dvecInData4, dvecInData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
          MORPH_OP_MUL4TA(dacc21, dvecInData3, dvecInData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
          MORPH_OP_MUL4TA(dacc22, dvecInData4, dvecInData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
        }    /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* variable length for output stores */
        int32_t varLen = XT_MIN(vectorizationWidth, outW - x);

        /* Storing the first output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2Row * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2Row * varLen);
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * enable2Row * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * varLen);
        IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * enable2ndCh * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                              outDataPitch1 * enable2Row) * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * \
                       enable2Row * varLen);
        IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * enable2ndCh * \
                       enable2Row * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 2 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 2 * coeffPitch3;
      }  /* end of for (outCh = 0; outCh < numOutCh; outCh += 2)*/
    }    /* end of for (y = 0; y < outH; y += 2)*/
  }      /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  return(XAI_ERROR_STATUS());
}

/*****************************************************************************
*  xaiConvolved(VQ)3D_S_3x3j2d1I8S8IX_MOW_WHD
*  **************************************************************************/

/******************************************************************************/
/* Description : P6 optimized implementation for 3x3 3D convolution with      */
/*               stride = 2. Based on MORPH pre-processor specifiers, code    */
/*               implementation is generated during preprocessing stage. This */
/*               method can be used to generate 3x3 3D dilated convolution    */
/*               function and 3x3 3D VQ dilated convolution function for U8   */
/*               bit and S8 bit input data.                                   */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                */
/*               Output scale array, CNN convolution params structure         */
/* Outputs     : XI Error Code                                                */
/* InOuts      : Output Tile                                                  */
/* Assumptions : CoeffData is S8                                              */
/*               biasArray is signed 32b, value not exceeding signed 24b      */
/*               Output scale array is U16                                    */
/*               OutData is S8 / U8 / S16                                     */
/*               Kernel Size is 3x3xDxN                                       */
/*               Input and Output are in WHD format                           */
/*               Coeff is in WHDN format                                      */
/******************************************************************************/

/******************* convolvedVQ3D_S_3x3j2d1_S8S8IX_MOW_WHD_INCHANNEL3 *****************/
/******************* convolvedVQ3D_S_3x3j2d1_U8S8IX_MOW_WHD_INCHANNEL3 *****************/
/******************* convolved3D_S_3x3j2d1_S8S8IX_MOW_WHD_INCHANNEL3   *****************/
/******************* convolved3D_S_3x3j2d1_U8S8IX_MOW_WHD_INCHANNEL3   *****************/
/*                  If number of input channel is 3 this function is called              */
/*****************************************************************************************/
static _XAI_INLINE_ void MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_3x3j2d1), S8IX_MOW_WHD_INCHANNEL3) \
  MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Pitches of Coefficient Data (WHDN) in dim1 and dim3 */
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t stride        = XAI_CNN_CONV_GET_STRIDE(param);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-((kSizeU / 2) * inDataPitch1 + (kSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8* restrict pdvecIn1;
  MORPH_IDT_2Nx8* restrict pdvecIn2;
  MORPH_IDT_2Nx8* restrict pdvecIn3;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff;
  xb_vecN_2x32v* restrict phvecBias;
  int32_t outCh, y, x;

  xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2, dvecCoeffData3;
  /* inCh = 1 */
  MORPH_IDT_2Nx8 dvecDataCh101, dvecDataCh102, dvecDataCh103;
  MORPH_IDT_2Nx8 dvecDataCh111, dvecDataCh112, dvecDataCh113;
  MORPH_IDT_2Nx8 dvecDataCh121, dvecDataCh122, dvecDataCh123;
  /* inCh = 2 */
  MORPH_IDT_2Nx8 dvecDataCh201, dvecDataCh202, dvecDataCh203;
  MORPH_IDT_2Nx8 dvecDataCh211, dvecDataCh212, dvecDataCh213;
  MORPH_IDT_2Nx8 dvecDataCh221, dvecDataCh222, dvecDataCh223;
  /* inCh = 3 */
  MORPH_IDT_2Nx8 dvecDataCh301, dvecDataCh302, dvecDataCh303;
  MORPH_IDT_2Nx8 dvecDataCh311, dvecDataCh312, dvecDataCh313;
  MORPH_IDT_2Nx8 dvecDataCh321, dvecDataCh322, dvecDataCh323;

  /* input vectors for inCh = 1 */
  xb_vec2Nx8 dvecInDataCh1_1, dvecInDataCh1_2, dvecInDataCh1_3, dvecInDataCh1_4, dvecInDataCh1_5;
  /* input vectors for inCh = 2 */
  xb_vec2Nx8 dvecInDataCh2_1, dvecInDataCh2_2, dvecInDataCh2_3, dvecInDataCh2_4, dvecInDataCh2_5;
  /* input vectors for inCh = 3 */
  xb_vec2Nx8 dvecInDataCh3_1, dvecInDataCh3_2, dvecInDataCh3_3, dvecInDataCh3_4, dvecInDataCh3_5;

  const int32_t vectorizationWidth = (((2 * XCHAL_IVPN_SIMD_WIDTH) - kSizeU) / stride) + 1;

  /* Generating the select pattern for coefficent loads.
   * Pattern : 27, 28, 29, 30, ....
   */
  xb_vec2Nx8 dvecSeq = IVP_ADD2NX8(IVP_SEQ2NX8(), coeffPitch3);

  for (x = 0; x < outW; x += vectorizationWidth) /* Loop across output width */
  {
    /* variable length for output stores */
    int32_t varLen = XT_MIN(vectorizationWidth, outW - x);
    int32_t remX   = bytesPerPixel * varLen;

    for (y = 0; y < outH; y += 2)
    {
      /* in order to handle odd output height */
      int32_t enable2outH = XT_SALT(y, outH - 1);
      int32_t remLoad     = inDataPitch1 * enable2outH;

      /* variables used for store */
      int32_t outVarLen    = varLen * enable2outH;
      int32_t outVarFlag   = outVarLen * typeFlag;
      int32_t outVarFlagx2 = outVarFlag * 2;
      enable2outH = outDataPitch1 * enable2outH * bytesPerPixel;

      /* Initialize input and output data pointers */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* input pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y * stride + x * stride];

      /* Load input data */
      /* InCh =1 */
      pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
      /* load data from 1st input row */
      valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
      IVP_LA2NX8_XP(dvecInDataCh1_1, vaInData, pdvecIn1, inDataPitch1);

      /* load data from 2nd input row */
      vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
      IVP_LA2NX8_XP(dvecInDataCh1_2, vaInData, pdvecIn1, inDataPitch1);

      /* load data from 3rd input row */
      vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
      IVP_LA2NX8_XP(dvecInDataCh1_3, vaInData, pdvecIn1, remLoad);

      /* load data from 4th input row */
      vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
      IVP_LA2NX8_XP(dvecInDataCh1_4, vaInData, pdvecIn1, remLoad);

      /* load data from 5th input row */
      vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
      IVP_LA2NX8_XP(dvecInDataCh1_5, vaInData, pdvecIn1, remLoad);

      /* 32 elements from 1st row and 32 elements from 2nd row are concatenated here
       * If 1st input row is 0,1,2,3,4,5,6,7,8,9,...63, and the 2nd input row is
       * 64,65,66,67.........126,127, Data should be arranged  as
       *
       * dvecIn100 : 0, 2, 4,...58,60,62,64,66,68,...122,124,126
       * dvecIn101 : 1, 3, 5,...59,61,63,65,67,69,...123,125,127
       * dvecIn102 : 2, 4, 6,...60,62,0 ,66,68,70,...124,126,0
       *
       *
       * Lower half of the vectors contain data from 1st input row and
       * upper half of the vectors contain data from 3rd input row.
       *
       */
      /* Form 2 vectors from the 2 output height rows - row 1 and row3 */
      IVP_DSEL2NX8I(dvecDataCh102, dvecDataCh101, dvecInDataCh1_3, dvecInDataCh1_1, IVP_DSELI_8B_DEINTERLEAVE_1);
      dvecDataCh103 = IVP_SEL2NX8I(dvecDataCh101, dvecDataCh101, IVP_SELI_8B_ROTATE_RIGHT_1);

      /* Form 2 vectors from the 2 output height rows - row 2 and row4 */
      IVP_DSEL2NX8I(dvecDataCh112, dvecDataCh111, dvecInDataCh1_4, dvecInDataCh1_2, IVP_DSELI_8B_DEINTERLEAVE_1);
      dvecDataCh113 = IVP_SEL2NX8I(dvecDataCh111, dvecDataCh111, IVP_SELI_8B_ROTATE_RIGHT_1);

      /* Form 2 vectors from the 2 output height rows - row 3 and row5 */
      IVP_DSEL2NX8I(dvecDataCh122, dvecDataCh121, dvecInDataCh1_5, dvecInDataCh1_3, IVP_DSELI_8B_DEINTERLEAVE_1);
      dvecDataCh123 = IVP_SEL2NX8I(dvecDataCh121, dvecDataCh121, IVP_SELI_8B_ROTATE_RIGHT_1);

      /* InCh = 2 */
      pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch2);
      /* load data from 1st input row */
      valign vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
      IVP_LA2NX8_XP(dvecInDataCh2_1, vaInData2, pdvecIn2, inDataPitch1);

      /* load data from 2nd input row */
      vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
      IVP_LA2NX8_XP(dvecInDataCh2_2, vaInData2, pdvecIn2, inDataPitch1);

      /* load data from 3rd input row */
      vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
      IVP_LA2NX8_XP(dvecInDataCh2_3, vaInData2, pdvecIn2, remLoad);

      /* load data from 4th input row */
      vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
      IVP_LA2NX8_XP(dvecInDataCh2_4, vaInData2, pdvecIn2, remLoad);

      /* load data from 5th input row */
      vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
      IVP_LA2NX8_XP(dvecInDataCh2_5, vaInData2, pdvecIn2, remLoad);

      /* Form 2 vectors from the 2 output height rows - row 1 and row3 */
      IVP_DSEL2NX8I(dvecDataCh202, dvecDataCh201, dvecInDataCh2_3, dvecInDataCh2_1, IVP_DSELI_8B_DEINTERLEAVE_1);
      dvecDataCh203 = IVP_SEL2NX8I(dvecDataCh201, dvecDataCh201, IVP_SELI_8B_ROTATE_RIGHT_1);

      /* Form 2 vectors from the 2 output height rows - row 2 and row4 */
      IVP_DSEL2NX8I(dvecDataCh212, dvecDataCh211, dvecInDataCh2_4, dvecInDataCh2_2, IVP_DSELI_8B_DEINTERLEAVE_1);
      dvecDataCh213 = IVP_SEL2NX8I(dvecDataCh211, dvecDataCh211, IVP_SELI_8B_ROTATE_RIGHT_1);

      /* Form 2 vectors from the 2 output height rows - row 3 and row5 */
      IVP_DSEL2NX8I(dvecDataCh222, dvecDataCh221, dvecInDataCh2_5, dvecInDataCh2_3, IVP_DSELI_8B_DEINTERLEAVE_1);
      dvecDataCh223 = IVP_SEL2NX8I(dvecDataCh221, dvecDataCh221, IVP_SELI_8B_ROTATE_RIGHT_1);

      /* InCh = 3 */
      pdvecIn3 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2);
      /* load data from 1st input row */
      valign vaInData3 = MORPH_OP_PRIME_2Nx8(pdvecIn3);
      IVP_LA2NX8_XP(dvecInDataCh3_1, vaInData3, pdvecIn3, inDataPitch1);

      /* load data from 2nd input row */
      vaInData3 = MORPH_OP_PRIME_2Nx8(pdvecIn3);
      IVP_LA2NX8_XP(dvecInDataCh3_2, vaInData3, pdvecIn3, inDataPitch1);

      /* load data from 3rd input row */
      vaInData3 = MORPH_OP_PRIME_2Nx8(pdvecIn3);
      IVP_LA2NX8_XP(dvecInDataCh3_3, vaInData3, pdvecIn3, remLoad);

      /* load data from 4th input row */
      vaInData3 = MORPH_OP_PRIME_2Nx8(pdvecIn3);
      IVP_LA2NX8_XP(dvecInDataCh3_4, vaInData3, pdvecIn3, remLoad);

      /* load data from 5th input row */
      vaInData3 = MORPH_OP_PRIME_2Nx8(pdvecIn3);
      IVP_LA2NX8_XP(dvecInDataCh3_5, vaInData3, pdvecIn3, remLoad);

      /* Form 2 vectors from the 2 output height rows - row 1 and row3 */
      IVP_DSEL2NX8I(dvecDataCh302, dvecDataCh301, dvecInDataCh3_3, dvecInDataCh3_1, IVP_DSELI_8B_DEINTERLEAVE_1);
      dvecDataCh303 = IVP_SEL2NX8I(dvecDataCh301, dvecDataCh301, IVP_SELI_8B_ROTATE_RIGHT_1);

      /* Form 2 vectors from the 2 output height rows - row 2 and row4 */
      IVP_DSEL2NX8I(dvecDataCh312, dvecDataCh311, dvecInDataCh3_4, dvecInDataCh3_2, IVP_DSELI_8B_DEINTERLEAVE_1);
      dvecDataCh313 = IVP_SEL2NX8I(dvecDataCh311, dvecDataCh311, IVP_SELI_8B_ROTATE_RIGHT_1);

      /* Form 2 vectors from the 2 output height rows - row 3 and row5 */
      IVP_DSEL2NX8I(dvecDataCh322, dvecDataCh321, dvecInDataCh3_5, dvecInDataCh3_3, IVP_DSELI_8B_DEINTERLEAVE_1);
      dvecDataCh323 = IVP_SEL2NX8I(dvecDataCh321, dvecDataCh321, IVP_SELI_8B_ROTATE_RIGHT_1);

      /* priming of coeff load is done outside the innermost loop*/
      pdvecCoeff = (xb_vec2Nx8 *) (pCoeffData);
      valign vaCoeffData = IVP_LA2NX8_PP(pdvecCoeff);

      /* priming of bias load is done outside the innermost loop*/
      phvecBias = (xb_vecN_2x32v *) (pBiasData);
      valign vaBias = IVP_LAN_2X32_PP(phvecBias);

      for (outCh = 0; outCh < numOutCh; outCh += 3)
      {
        /* In order to handle output depths*/
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
        int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);
        int32_t out2Ch      = outDataPitch2 * enable2ndCh * bytesPerPixel;
        int32_t out3Ch      = outDataPitch2 * enable3rdCh * bytesPerPixel * 2;

        /* Load the bias values corresponding to three output channels */
        xb_vecN_2x32v hvecBias; IVP_LAVN_2X32_XP(hvecBias, vaBias, phvecBias, 3 * 4);
        xb_vecN_2x32v hvecBias1 = IVP_REPN_2X32(hvecBias, 0);
        xb_vecN_2x32v hvecBias2 = IVP_REPN_2X32(hvecBias, 1);
        xb_vecN_2x32v hvecBias3 = IVP_REPN_2X32(hvecBias, 2);

        /* load all the 3x3 coefficients for outChannel - 1 and outChannel - 2 */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData, pdvecCoeff, 2 * coeffPitch3);
        /* select 3x3 coefficients for outChannel - 2 */
        dvecCoeffData2 = IVP_SEL2NX8(dvecCoeffData1, dvecCoeffData1, dvecSeq);
        /* load all the 3x3 coefficients for outChannel - 3*/
        IVP_LAV2NX8_XP(dvecCoeffData3, vaCoeffData, pdvecCoeff, coeffPitch3 * enable3rdCh);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);

        xb_vec2Nx24 dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);

        xb_vec2Nx24 dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
        IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);

        /* Values corresponding to first and second row are packed in one register
           so that same coefficient will get multiplied to them */
        /* Multiply and accumulate 1st set of 4 coefficients for all the outputs */
        MORPH_OP_MULQA(dacc1, dvecDataCh111, dvecDataCh103, dvecDataCh102, dvecDataCh101,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));

        MORPH_OP_MULQA(dacc2, dvecDataCh111, dvecDataCh103, dvecDataCh102, dvecDataCh101,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

        MORPH_OP_MULQA(dacc3, dvecDataCh111, dvecDataCh103, dvecDataCh102, dvecDataCh101,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 0));

        /* Multiply and accumulate 2nd set of 4 coefficients for all the outputs */
        MORPH_OP_MULQA(dacc1, dvecDataCh122, dvecDataCh121, dvecDataCh113, dvecDataCh112,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MULQA(dacc2, dvecDataCh122, dvecDataCh121, dvecDataCh113, dvecDataCh112,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));

        MORPH_OP_MULQA(dacc3, dvecDataCh122, dvecDataCh121, dvecDataCh113, dvecDataCh112,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 1));

        /* Multiply and accumulate 3rd set of 4 coefficients for all the outputs */
        MORPH_OP_MULQA(dacc1, dvecDataCh203, dvecDataCh202, dvecDataCh201, dvecDataCh123,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));

        MORPH_OP_MULQA(dacc2, dvecDataCh203, dvecDataCh202, dvecDataCh201, dvecDataCh123,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));

        MORPH_OP_MULQA(dacc3, dvecDataCh203, dvecDataCh202, dvecDataCh201, dvecDataCh123,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 2));

        /* Multiply and accumulate 4th set of 4 coefficients for all the outputs */
        MORPH_OP_MULQA(dacc1, dvecDataCh221, dvecDataCh213, dvecDataCh212, dvecDataCh211,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));

        MORPH_OP_MULQA(dacc2, dvecDataCh221, dvecDataCh213, dvecDataCh212, dvecDataCh211,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));

        MORPH_OP_MULQA(dacc3, dvecDataCh221, dvecDataCh213, dvecDataCh212, dvecDataCh211,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 3));

        /* Multiply and accumulate 5th set of 4 coefficients for all the outputs */
        MORPH_OP_MULQA(dacc1, dvecDataCh302, dvecDataCh301, dvecDataCh223, dvecDataCh222,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));

        MORPH_OP_MULQA(dacc2, dvecDataCh302, dvecDataCh301, dvecDataCh223, dvecDataCh222,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 4));

        MORPH_OP_MULQA(dacc3, dvecDataCh302, dvecDataCh301, dvecDataCh223, dvecDataCh222,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 4));

        /* Multiply and accumulate 6th set of 4 coefficients for all the outputs */
        MORPH_OP_MULQA(dacc1, dvecDataCh313, dvecDataCh312, dvecDataCh311, dvecDataCh303,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));

        MORPH_OP_MULQA(dacc2, dvecDataCh313, dvecDataCh312, dvecDataCh311, dvecDataCh303,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 5));

        MORPH_OP_MULQA(dacc3, dvecDataCh313, dvecDataCh312, dvecDataCh311, dvecDataCh303,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 5));

        /* Multiply and accumulate 7th set of 4 coefficients for all the outputs */
        MORPH_OP_MULQA(dacc1, 0, dvecDataCh323, dvecDataCh322, dvecDataCh321,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 6));

        MORPH_OP_MULQA(dacc2, 0, dvecDataCh323, dvecDataCh322, dvecDataCh321,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 6));

        MORPH_OP_MULQA(dacc3, 0, dvecDataCh323, dvecDataCh322, dvecDataCh321,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 6));

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut1H;
        xb_vec2Nx8 dvecOut2L, dvecOut2H;
        xb_vec2Nx8 dvecOut3L, dvecOut3H;

#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      pOutScaleData[outCh + 2 * enable3rdCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif

        /* Storing the first output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, remX);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + out2Ch);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, remX * enable2ndCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the third output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + out3Ch);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, remX * enable3rdCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2outH);
        IVP_SAV2NX8_XP(IVP_SEL2NX8I(dvecOut1L, dvecOut1L, IVP_SELI_EXTRACT_HI_HALVES),
                       vaOutData, pdvecOut, (outVarLen - outVarFlag));
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, outVarFlagx2);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + out2Ch + enable2outH);
        IVP_SAV2NX8_XP(IVP_SEL2NX8I(dvecOut2L, dvecOut2L, IVP_SELI_EXTRACT_HI_HALVES),
                       vaOutData, pdvecOut, enable2ndCh * (outVarLen - outVarFlag));
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, enable2ndCh * outVarFlagx2);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the third output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + out3Ch + enable2outH);
        IVP_SAV2NX8_XP(IVP_SEL2NX8I(dvecOut3L, dvecOut3L, IVP_SELI_EXTRACT_HI_HALVES),
                       vaOutData, pdvecOut, enable3rdCh * (outVarLen - outVarFlag));
        IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, enable3rdCh * outVarFlagx2);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 3 * outDataPitch2 * bytesPerPixel;
      }
    }
  }
}
/****************** xaiConvolvedVQ3D_S_3x3j2d1_S8S8IX_MOW_WHD ******************/
/****************** xaiConvolvedVQ3D_S_3x3j2d1_U8S8IX_MOW_WHD ******************/
/******************* xaiConvolved3D_S_3x3j2d1_S8S8IX_MOW_WHD *******************/
/******************* xaiConvolved3D_S_3x3j2d1_U8S8IX_MOW_WHD *******************/

XAI_ERR_TYPE MAKE_NAME(MAKE_NAME_VQ(xaiConvolved, 3D_S_3x3j2d1), S8IX_MOW_WHD) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Error Checks */
  XAI_ERROR_CHECKS()
  {
    MORPH_IDT_CHECK(inTile);
    XAI_CHECK_CONV_OUTPUT_TILE3D(outTile);
    XAI_CHECK_TILE4D_S8(coeffTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(outTile);
    XAI_CHECK_TILE4D_IN_DRAM_BOUNDARY(coeffTile);
    XAI_CHECK_POINTER(param);
    XAI_CHECK_ARRAY_S32(biasArray);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(inTile, outTile);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(coeffTile, outTile);
    XAI_CHECK_KERNEL_SIZE(coeffTile, 3);
    XAI_CHECK_TILE3D_DATA_ORDER(inTile, XAI_WHD);
    XAI_CHECK_TILE3D_DATA_ORDER(outTile, XAI_WHD);
    XAI_CHECK_TILE4D_DATA_ORDER(coeffTile, XAI_WHDN);
    XAI_CHECK_DILATION(param, 1);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_DILATIONX(param) == XAI_CNN_CONV_GET_DILATIONY(param),                                           \
                    XAI_ERR_BADARG, "Dilation along width = %hhu and height = %hhu\nDilation along width and height should be equal", \
                    XAI_CNN_CONV_GET_DILATIONX(param), XAI_CNN_CONV_GET_DILATIONY(param));
    XAI_CHECK_TILE3D_EDGE(inTile, 1);
    XAI_CHECK_STRIDE(param, 2);
    XAI_CHECK_ERROR((XAI_CNN_CONV_GET_STRIDEX(param) == XAI_CNN_CONV_GET_STRIDEY(param)),                                           \
                    XAI_ERR_BADARG, "\nStride along width = %hhu and height = %hhu\nStride along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_CONSISTENCY_MOW_WHD(inTile, coeffTile, biasArray, outTile, param);
    XAI_CHECK_COEFFTILE_CONTIGUOUS(coeffTile, param);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_ACCUM_SHIFT(param) < 24,                                     \
                    XAI_ERR_NORM, "\nThe accumulator shift = %hhu, value should be less than 24", \
                    XAI_CNN_CONV_GET_ACCUM_SHIFT(param));
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_OUTPUT_SHIFT(param) < 32,                               \
                    XAI_ERR_NORM, "\nThe output shift = %hhu, value should be less than 32", \
                    XAI_CNN_CONV_GET_OUTPUT_SHIFT(param));
    XAI_CHECK_CONV_RELU_LIMITS_IX(param, outTile);
#if DILATED_VQ_CONV == VQ_TRUE
    XAI_CHECK_ARRAY_U16(outputScaleArray);
    XAI_CHECK_ERROR(XAI_ARRAY_GET_WIDTH(outputScaleArray) >= XAI_TILE4D_GET_DIM4(coeffTile),                                                                                          \
                    XAI_ERR_DATASIZE, "\nWidth of Output Scale Array = %d, Number of Kernels = %d\nWidth of Output Scale Array should be greater than or equal to Number of Kernels", \
                    XAI_ARRAY_GET_WIDTH(outputScaleArray), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_ERROR((((uintptr_t) (XAI_ARRAY_GET_DATA_PTR(outputScaleArray)) & \
                      0x1) == 0), XAI_ERR_NORM, "The output scale array is not aligned to 2 byte boundary");
#endif
  }
#if DILATED_VQ_CONV == VQ_FALSE
  if (XAI_CNN_CONV_GET_OUTPUT_SCALE(param) == 0)
  {
    int32_t fillValue;
    int32_t reluFlag = XAI_CNN_CONV_GET_FLAG_RELU(param);
    fillValue = reluFlag ? (CLAMP(0, XAI_CNN_CONV_GET_RELU_MIN(param), XAI_CNN_CONV_GET_RELU_MAX(param))) : 0;
    return(xaiFillTile3D(outTile, fillValue, 0));
  }
#endif
  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Pitches of Coefficient Data (WHDN) in dim1 and dim3 */
  const int32_t coeffPitch2 = XAI_TILE4D_GET_DIM2_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t stride        = XAI_CNN_CONV_GET_STRIDE(param);

  if (XAI_TILE3D_GET_DIM3(inTile) == 3)
  {
    MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_3x3j2d1), S8IX_MOW_WHD_INCHANNEL3) MAKE_PARAMS(inTile, coeffTile, biasArray, outTile, param);
    return(XAI_ERROR_STATUS());
  }

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-((kSizeU / 2) * inDataPitch1 + (kSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8* restrict pdvecIn1;

  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1;
  xb_vec2Nx8* restrict pdvecCoeff2;
  xb_vec2Nx8* restrict pdvecCoeff3;

  /* Variable Declarations */
  int32_t inCh, outCh, x, y;
  /* In order to make the loop multiply-bound we are reducing the vectorization width
     by extra values required for the kernel */
  const int32_t vectorizationWidth = (((2 * XCHAL_IVPN_SIMD_WIDTH) - kSizeU) / stride) + 1;

  /* Generating the shuffle pattern for coefficent loads.
     The idea is to populate zero value where the MUL4T should not affect
     Pattern : 0 1 2 32 3 4 5 32 6 7 8 32 X X X .... */
  xb_vec2Nx8 dvecIdx = IVP_SEL2NX8I(32, IVP_MOV2NX8_FROMNX16( \
                                      IVP_MOVNX16T(IVP_ADDNX16(IVP_ANDNX16(IVP_SEQNX16(), 3),
                                                               IVP_MULNX16PACKL(IVP_SRLINX16(IVP_SEQNX16(), 2), 3)), 32,
                                                   IVP_NEQNX16(IVP_ANDNX16(IVP_SEQNX16(), 3), 3))),
                                    IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0);

  /* loop across output depth is unrolled by 3
   * , producing lanes from 3 output channels
   * in one iteration. Since vectorization width
   * is just half the width of the accumulator,
   * loop across output height is also unrolled by 2.
   * Unrolling across output height makes it possible
   * to utilize all the 64 MACs in the accumulator.
   *
   * Data loaded from the 2 input rows is concatenated
   * in such a manner that lower half of the output
   * vector gives the first output row and the upper
   * half of the output vector gives the next output row.
   */
  for (x = 0; x < outW; x += vectorizationWidth) /* Loop across output width */
  {
    for (y = 0; y < outH - 1; y += 2) /* Loop across output height */
    {
      /* Initialize i/p and o/p data pointers */
      int8_t *pOutput          = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y * stride + x * stride];

      /* initialize coeff and Bias data pointer */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 3)  /* Loop across Output depth */
      {
        /* In order to handle odd output depths*/
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
        int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);

        /* Load the bias values corresponding to two output channels */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
        xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc1, dacc2, dacc3;
        dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
        dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
        IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);

        /* priming of coeff load is done outside the innermost loop*/
        /* Coeff for 1st output channel */
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);
        /* Coeff for 2nd output channel */
        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);
        /* Coeff for 3rd output channel */
        pdvecCoeff3 = (xb_vec2Nx8 *) (pCoeff + 2 * coeffPitch3 * enable3rdCh);
        valign vaCoeffData3; vaCoeffData3 = IVP_LA2NX8_PP(pdvecCoeff3);

        /* Input vector pointer initialization */
        pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);


        for (inCh = 0; inCh < numInCh; inCh++)  /* Loop across input channels */
        {
          /* vectors for coeff and input loads */
          xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2, dvecCoeffData3;
          xb_vec2Nx8 dvecInData1, dvecInData2, dvecInData3, dvecInData4, dvecInData5;
          MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3;

          /* load data from 1st input row */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          IVP_LA2NX8_XP(dvecInData1, vaInData, pdvecIn1, inDataPitch1);

          /* load data from 2nd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          IVP_LA2NX8_XP(dvecInData2, vaInData, pdvecIn1, inDataPitch1);

          /* load data from 3rd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          IVP_LA2NX8_XP(dvecInData3, vaInData, pdvecIn1, inDataPitch1);

          /* load data from 4th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          IVP_LA2NX8_XP(dvecInData4, vaInData, pdvecIn1, inDataPitch1);

          /* load data from 5th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          IVP_LA2NX8_XP(dvecInData5, vaInData, pdvecIn1, inDataPitch2 - (4 * inDataPitch1));

          /* load all the 3x3 coefficients for 2 output depths*/
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch2);
          IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch2);
          IVP_LAV2NX8_XP(dvecCoeffData3, vaCoeffData3, pdvecCoeff3, coeffPitch2);

          /* Rearrange them so that zero is inserted where the MULQ should not have effect */
          dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);
          dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecIdx);
          dvecCoeffData3 = IVP_SHFL2NX8(dvecCoeffData3, dvecIdx);

          /* 32 elements from 1st row and 32 elements from 2nd row are concatenated here
           * If 1st input row is 0,1,2,3,4,5,6,7,8,9,...63, and the 2nd input row is
           * 64,65,66,67.........126,127, Data should be arranged  as
           *
           * dvecData1 : 0, 2, 4,...58,60,62,64,66,68,...122,124,126
           * dvecData2 : 1, 3, 5,...59,61,63,65,67,69,...123,125,127
           * dvecData3 : 3, 4, 6,...60,62,0 ,66,68,70,...124,126,0
           *
           *
           * Lower half of the vectors contain data from 1st input row and
           * upper half of the vectors contain data from 2nd output row.
           *
           */

          /* Form 2 vectors from the 2 output height rows - row 1 and row3 */
          IVP_DSEL2NX8I(dvecData2, dvecData1, dvecInData3, dvecInData1, IVP_DSELI_8B_DEINTERLEAVE_1);
          dvecData3 = IVP_SEL2NX8I(dvecData1, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);

          /* Values corresponding to first and second row are packed in one register
             so that same coefficient will get multiplied to them */
          /* Multiply and accumulate 1st set of 3 coefficients for all the outputs */
          MORPH_OP_MULQA(dacc1, 0, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MULQA(dacc2, 0, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
          MORPH_OP_MULQA(dacc3, 0, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 0));


          /* Form 2 vectors from the 2 output height rows - row 2 and row4 */
          IVP_DSEL2NX8I(dvecData2, dvecData1, dvecInData4, dvecInData2, IVP_DSELI_8B_DEINTERLEAVE_1);
          dvecData3 = IVP_SEL2NX8I(dvecData1, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);
          /* Multiply and accumulate 2nd set of 3 coefficients for all the outputs */
          MORPH_OP_MULQA(dacc1, 0, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MULQA(dacc2, 0, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
          MORPH_OP_MULQA(dacc3, 0, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 1));


          /* Form 2 vectors from the 2 output height rows - row 3 and row5 */
          IVP_DSEL2NX8I(dvecData2, dvecData1, dvecInData5, dvecInData3, IVP_DSELI_8B_DEINTERLEAVE_1);
          dvecData3 = IVP_SEL2NX8I(dvecData1, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);
          /* Multiply and accumulate 3rd set of 3 coefficients for all the outputs */
          MORPH_OP_MULQA(dacc1, 0, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
          MORPH_OP_MULQA(dacc2, 0, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
          MORPH_OP_MULQA(dacc3, 0, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 2));
        }  /* end of for (inCh = 0; inCh < numInCh; inCh++) */

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      pOutScaleData[outCh + 2 * enable3rdCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* variable length for output stores */
        int32_t varLen = XT_MIN(vectorizationWidth, outW - x);

        /* Storing the first output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the third output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * enable3rdCh * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);


        /* Storing the first output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8I(dvecOut1L, dvecOut1L, IVP_SELI_EXTRACT_HI_HALVES),
                       vaOutData, pdvecOut, (-typeFlag + 1) * varLen);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * 2 * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                              outDataPitch1) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8I(dvecOut2L, dvecOut2L, IVP_SELI_EXTRACT_HI_HALVES),
                       vaOutData, pdvecOut, enable2ndCh * (-typeFlag + 1) * varLen);
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, enable2ndCh * typeFlag * 2 * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the third output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (2 * outDataPitch2 * enable3rdCh + \
                                              outDataPitch1) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8I(dvecOut3L, dvecOut3L, IVP_SELI_EXTRACT_HI_HALVES),
                       vaOutData, pdvecOut, enable3rdCh * (-typeFlag + 1) * varLen);
        IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, enable3rdCh * typeFlag * 2 * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 3 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 3 * coeffPitch3;
      }  /* end of for (outCh = 0; outCh < numOutCh; outCh += 3) */
    }   /* end of for (y = 0; y < outH; y += 2) */
    if (y < outH)
    {
      /* Initialize i/p and o/p data pointers */
      int8_t *pOutput          = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y * stride + x * stride];

      /* initialize coeff and Bias data pointer */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 3)  /* Loop across Output depth */
      {
        /* In order to handle odd output depths*/
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
        int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);

        /* Load the bias values corresponding to two output channels */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
        xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc1, dacc2, dacc3;
        dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
        dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
        IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);

        /* priming of coeff load is done outside the innermost loop*/
        /* Coeff for 1st output channel */
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);
        /* Coeff for 2nd output channel */
        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);
        /* Coeff for 3rd output channel */
        pdvecCoeff3 = (xb_vec2Nx8 *) (pCoeff + 2 * coeffPitch3 * enable3rdCh);
        valign vaCoeffData3; vaCoeffData3 = IVP_LA2NX8_PP(pdvecCoeff3);

        /* Input vector pointer initialization */
        pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);


        for (inCh = 0; inCh < numInCh; inCh++)  /* Loop across input channels */
        {
          /* vectors for coeff and input loads */
          xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2, dvecCoeffData3;
          xb_vec2Nx8 dvecInData1, dvecInData2, dvecInData3;
          MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3;

          /* load data from 1st input row */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          IVP_LA2NX8_XP(dvecInData1, vaInData, pdvecIn1, inDataPitch1);

          /* load data from 2nd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          IVP_LA2NX8_XP(dvecInData2, vaInData, pdvecIn1, inDataPitch1);

          /* load data from 3rd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          IVP_LA2NX8_XP(dvecInData3, vaInData, pdvecIn1, inDataPitch2 - 2 * inDataPitch1);

          /* load all the 3x3 coefficients for 2 output depths*/
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch2);
          IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch2);
          IVP_LAV2NX8_XP(dvecCoeffData3, vaCoeffData3, pdvecCoeff3, coeffPitch2);

          /* Rearrange them so that zero is inserted where the MULQ should not have effect */
          dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);
          dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecIdx);
          dvecCoeffData3 = IVP_SHFL2NX8(dvecCoeffData3, dvecIdx);

          /* 32 elements from 1st row and 32 elements from 2nd row are concatenated here
           * If 1st input row is 0,1,2,3,4,5,6,7,8,9,...63, and the 2nd input row is
           * 64,65,66,67.........126,127, Data should be arranged  as
           *
           * dvecData1 : 0, 2, 4,...58,60,62,64,66,68,...122,124,126
           * dvecData2 : 1, 3, 5,...59,61,63,65,67,69,...123,125,127
           * dvecData3 : 2, 4, 6,...60,62,0 ,66,68,70,...124,126,0
           *
           *
           */

          /* Form 2 vectors from the 2 output height rows - row 1 and row3 */
          IVP_DSEL2NX8I(dvecData2, dvecData1, dvecInData3, dvecInData1, IVP_DSELI_8B_DEINTERLEAVE_1);
          dvecData3 = IVP_SEL2NX8I(dvecData1, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);

          /* Values corresponding to first and second row are packed in one register
             so that same coefficient will get multiplied to them */
          /* Multiply and accumulate 1st set of 3 coefficients for all the outputs */
          MORPH_OP_MULQA(dacc1, 0, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MULQA(dacc2, 0, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
          MORPH_OP_MULQA(dacc3, 0, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 0));


          /* Form 2 vectors from the 2 output height rows - row 2 and row4 */
          IVP_DSEL2NX8I(dvecData2, dvecData1, 0, dvecInData2, IVP_DSELI_8B_DEINTERLEAVE_1);
          dvecData3 = IVP_SEL2NX8I(dvecData1, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);
          /* Multiply and accumulate 2nd set of 3 coefficients for all the outputs */
          MORPH_OP_MULQA(dacc1, 0, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MULQA(dacc2, 0, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
          MORPH_OP_MULQA(dacc3, 0, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 1));


          /* Form 2 vectors from the 2 output height rows - row 3 and row5 */
          IVP_DSEL2NX8I(dvecData2, dvecData1, 0, dvecInData3, IVP_DSELI_8B_DEINTERLEAVE_1);
          dvecData3 = IVP_SEL2NX8I(dvecData1, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);
          /* Multiply and accumulate 3rd set of 3 coefficients for all the outputs */
          MORPH_OP_MULQA(dacc1, 0, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
          MORPH_OP_MULQA(dacc2, 0, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
          MORPH_OP_MULQA(dacc3, 0, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 2));
        }  /* end of for (inCh = 0; inCh < numInCh; inCh++) */

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      pOutScaleData[outCh + 2 * enable3rdCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* variable length for output stores */
        int32_t varLen = XT_MIN(vectorizationWidth, outW - x);

        /* Storing the first output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the third output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * enable3rdCh * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 3 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 3 * coeffPitch3;
      }  /* end of for (outCh = 0; outCh < numOutCh; outCh += 3) */
    }   /* end of if(y < outH) */
  }    /* end of for (x = 0; x < outW; x += vectorizationWidth) */
  return(XAI_ERROR_STATUS());
}

/******************************************************************************************
*   xaiConvolved(VQ)3D_S_3x3j4d1I8S8IX_MOW_WHD
*  ***************************************************************************************/

/******************************************************************************/
/* Description : P6 optimized generic implementation for 3x3 3D convolution.  */
/*               Based on MORPH pre-processor specifiers, code implementation */
/*               is generated during preprocessing stage. This method can be  */
/*               used to generate 3x3 3D dilated convolution function and 3x3 */
/*               3D VQ dilated convolution function for U8 bit and  S8 bit    */
/*               input data with input stride equal to 4                      */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                */
/*               Output scale array, CNN convolution params structure         */
/* Outputs     : XI Error Code                                                */
/* InOuts      : Output Tile                                                  */
/* Assumptions : CoeffData is S8                                              */
/*               biasArray is signed 32b, value not exceeding signed 24b      */
/*               Output scale array is U16                                    */
/*               OutData is S8 / U8 / S16                                     */
/*               Kernel Size is 3x3xDxN                                       */
/*               Input and Output are in WHD format                           */
/*               Coeff is in WHDN format                                      */
/******************************************************************************/

/****************** xaiConvolvedVQ3D_S_3x3j4d1_S8S8IX_MOW_WHD ******************/
/****************** xaiConvolvedVQ3D_S_3x3j4d1_U8S8IX_MOW_WHD ******************/
/******************* xaiConvolved3D_S_3x3j4d1_S8S8IX_MOW_WHD *******************/
/******************* xaiConvolved3D_S_3x3j4d1_U8S8IX_MOW_WHD *******************/

XAI_ERR_TYPE MAKE_NAME(MAKE_NAME_VQ(xaiConvolved, 3D_S_3x3j4d1), S8IX_MOW_WHD) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Error Checks */
  XAI_ERROR_CHECKS()
  {
    MORPH_IDT_CHECK(inTile);
    XAI_CHECK_CONV_OUTPUT_TILE3D(outTile);
    XAI_CHECK_TILE4D_S8(coeffTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(outTile);
    XAI_CHECK_TILE4D_IN_DRAM_BOUNDARY(coeffTile);
    XAI_CHECK_POINTER(param);
    XAI_CHECK_ARRAY_S32(biasArray);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(inTile, outTile);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(coeffTile, outTile);
    XAI_CHECK_KERNEL_SIZE(coeffTile, 3);
    XAI_CHECK_TILE3D_DATA_ORDER(inTile, XAI_WHD);
    XAI_CHECK_TILE3D_DATA_ORDER(outTile, XAI_WHD);
    XAI_CHECK_TILE4D_DATA_ORDER(coeffTile, XAI_WHDN);
    XAI_CHECK_DILATION(param, 1);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_DILATIONX(param) == XAI_CNN_CONV_GET_DILATIONY(param),                                           \
                    XAI_ERR_BADARG, "Dilation along width = %hhu and height = %hhu\nDilation along width and height should be equal", \
                    XAI_CNN_CONV_GET_DILATIONX(param), XAI_CNN_CONV_GET_DILATIONY(param));
    XAI_CHECK_TILE3D_EDGE(inTile, 1);
    XAI_CHECK_STRIDE(param, 4);
    XAI_CHECK_ERROR((XAI_CNN_CONV_GET_STRIDEX(param) == XAI_CNN_CONV_GET_STRIDEY(param)),                                           \
                    XAI_ERR_BADARG, "\nStride along width = %hhu and height = %hhu\nStride along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_CONSISTENCY_MOW_WHD(inTile, coeffTile, biasArray, outTile, param);
    XAI_CHECK_COEFFTILE_CONTIGUOUS(coeffTile, param);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_ACCUM_SHIFT(param) < 24,                                     \
                    XAI_ERR_NORM, "\nThe accumulator shift = %hhu, value should be less than 24", \
                    XAI_CNN_CONV_GET_ACCUM_SHIFT(param));
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_OUTPUT_SHIFT(param) < 32,                               \
                    XAI_ERR_NORM, "\nThe output shift = %hhu, value should be less than 32", \
                    XAI_CNN_CONV_GET_OUTPUT_SHIFT(param));
    XAI_CHECK_CONV_RELU_LIMITS_IX(param, outTile);
#if DILATED_VQ_CONV == VQ_TRUE
    XAI_CHECK_ARRAY_U16(outputScaleArray);
    XAI_CHECK_ERROR(XAI_ARRAY_GET_WIDTH(outputScaleArray) >= XAI_TILE4D_GET_DIM4(coeffTile),                                                                                          \
                    XAI_ERR_DATASIZE, "\nWidth of Output Scale Array = %d, Number of Kernels = %d\nWidth of Output Scale Array should be greater than or equal to Number of Kernels", \
                    XAI_ARRAY_GET_WIDTH(outputScaleArray), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_ERROR((((uintptr_t) (XAI_ARRAY_GET_DATA_PTR(outputScaleArray)) & \
                      0x1) == 0), XAI_ERR_NORM, "The output scale array is not aligned to 2 byte boundary");
#endif
  }
#if DILATED_VQ_CONV == VQ_FALSE
  if (XAI_CNN_CONV_GET_OUTPUT_SCALE(param) == 0)
  {
    int32_t fillValue;
    int32_t reluFlag = XAI_CNN_CONV_GET_FLAG_RELU(param);
    fillValue = reluFlag ? (CLAMP(0, XAI_CNN_CONV_GET_RELU_MIN(param), XAI_CNN_CONV_GET_RELU_MAX(param))) : 0;
    return(xaiFillTile3D(outTile, fillValue, 0));
  }
#endif

  /* Getting parameters from the tile structures */
  const int32_t inW = XAI_TILE3D_GET_DIM1(inTile) + \
                      XAI_TILE3D_GET_DIM1_EDGE1(inTile) + XAI_TILE3D_GET_DIM1_EDGE2(inTile);
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);

  const uint8_t outShiftU  = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t stride     = XAI_CNN_CONV_GET_STRIDE(param);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Pitches of Coefficient Data (WHDN) in dim1, dim2 and dim3 */
  const int32_t coeffPitch2 = XAI_TILE4D_GET_DIM2_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-((kSizeU / 2) * inDataPitch1 + (kSizeU / 2))];

  MORPH_IDT_2Nx8 *restrict pdvecInp1;
  MORPH_IDT_2Nx8 *restrict pdvecInp2;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1;
  xb_vec2Nx8* restrict pdvecCoeff2;

  /* accumulators for 2 output channels */
  xb_vec2Nx24 dacc1, dacc2;

  /* Variable Declarations */
  int32_t inCh, outCh, x, y;
  const int32_t vectorizationWidth = XCHAL_IVPN_SIMD_WIDTH;
  int32_t varLen;

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  /* Generating the shuffle pattern for coefficent loads.
     The idea is to populate zero value where the MUL4T should not affect
     Pattern : 0 1 2 32 3 4 5 32 6 7 8 32 X X X .... */
  xb_vec2Nx8 dvecIdx = IVP_SEL2NX8I(32, IVP_MOV2NX8_FROMNX16( \
                                      IVP_MOVNX16T(IVP_ADDNX16(IVP_ANDNX16(IVP_SEQNX16(), 3),
                                                               IVP_MULNX16PACKL(IVP_SRLINX16(IVP_SEQNX16(), 2), 3)), 32,
                                                   IVP_NEQNX16(IVP_ANDNX16(IVP_SEQNX16(), 3), 3))),
                                    IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0);

  /* loop across output depth is unrolled by 2
   * , producing lanes from 2 output channels
   * in one iteration. Since vectorization width
   * is just half the width of the accumulator,
   * loop across output height is also unrolled by 2.
   * Unrolling across output height makes it possible
   * to utilize all the 64 MACs in the accumulator.
   *
   * Data loaded from the 2 input rows is concatenated
   * in such a manner that lower half of the output
   * vector gives the first output row and the upper
   * half of the output vector gives the next output row.
   */

  /* Loop structure Start with loop across output channels */
  for (x = 0; x < outW; x += vectorizationWidth)   /* Loop across output width */
  {
    /* out of bound flag */
    int32_t flag = XT_SALT(2 * XCHAL_IVPN_SIMD_WIDTH, inW - stride * x);

    for (y = 0; y < outH; y += 2)   /* Loop across output Height */
    {
      /* To handle the odd number of output height */
      int32_t enable2ndRow = XT_SALT(y, outH - 1);

      /* Initialize i/p and o/p data pointers */
      int8_t *pOutput          = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y * stride + x * stride];

      /* initialize coeff and Bias data pointer */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 2)   /* Loop across output channels */
      {
        /* To handle cases where outCh is non-multiple of 2 */
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

        /* Input data vectors to generate 2 rows of output */
        MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3;
        /* Input data vectors for 1st row of output */
        xb_vec2Nx8 dvecIn11, dvecIn12;
        /* Input data vectors for 2nd row of output */
        xb_vec2Nx8 dvecIn21, dvecIn22;
        /* vectors for coefficients */
        xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2;
        valign vaData, vaOutData;

        /* load and replicate bias data for each output channel */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

        /* Initialize all the accumulators with bias values */
        dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);

        /* priming of 1st channel coeffs load */
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);
        /* priming of 2nd channel coeffs load */
        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

        /* Starting location initialized for the input data */
        pdvecInp1 = (MORPH_IDT_2Nx8 *) (pInput);
        pdvecInp2 = (MORPH_IDT_2Nx8 *) (pInput + stride * inDataPitch1 * enable2ndRow);

        for (inCh = 0; inCh < numInCh; inCh++)   /* Loop across input channels */
        {
          /* Loading of coefficients for 2 output channels */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch2);
          IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch2);

          /* Rearrange them so that zero is inserted where the MULQ should not have effect */
          dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);
          dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecIdx);

          /* Loading first output row input data */
          vaData = MORPH_OP_PRIME_2Nx8(pdvecInp1);
          MORPH_OP_LOAD_2Nx8(dvecIn11, vaData, pdvecInp1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecIn12, vaData, pdvecInp1, inDataPitch1 - (2 * XCHAL_IVPN_SIMD_WIDTH * flag));

          /* Loading second output row input data */
          vaData = MORPH_OP_PRIME_2Nx8(pdvecInp2);
          MORPH_OP_LOAD_2Nx8(dvecIn21, vaData, pdvecInp2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecIn22, vaData, pdvecInp2, inDataPitch1 - (2 * XCHAL_IVPN_SIMD_WIDTH * flag));

          /* 32 elements from 1st row and 32 elements from 2nd row are concatenated here
           * If 1st input row is 0,1,2,3,4,5,6,7,8,9,...127, and the 2nd input row is
           * 128,129,130,131.........252,253,254,255, Data should be arranged  as
           *
           * dvecData1 : 0, 4, 8,...124,128,132,136,...252
           * dvecData2 : 1, 5, 9,...125,129,133,137,...253
           * dvecData3 : 2, 6,10,...126,130,134,138,...254
           *
           * Lower half of the vectors contain data from 1st input row and
           * upper half of the vectors contain data from 2nd output row.
           *
           */
          IVP_DSEL2NX8I(dvecIn12, dvecIn11, dvecIn12, dvecIn11, IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecIn22, dvecIn21, dvecIn22, dvecIn21, IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData3, dvecData1, \
                        dvecIn21, dvecIn11, IVP_DSELI_8B_DEINTERLEAVE_1);
          dvecData2 = IVP_SEL2NX8I(dvecIn22, dvecIn12, IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0);

          /* Multiply and accumulate 1st set of 3 coefficients for all the outputs */
          MORPH_OP_MULQA(dacc1, 0, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MULQA(dacc2, 0, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

          /* Load second row for 1st output row*/
          vaData = MORPH_OP_PRIME_2Nx8(pdvecInp1);
          MORPH_OP_LOAD_2Nx8(dvecIn11, vaData, pdvecInp1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecIn12, vaData, pdvecInp1, inDataPitch1 - (2 * XCHAL_IVPN_SIMD_WIDTH * flag));

          /* Load second row for 2nd output row*/
          vaData = MORPH_OP_PRIME_2Nx8(pdvecInp2);
          MORPH_OP_LOAD_2Nx8(dvecIn21, vaData, pdvecInp2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecIn22, vaData, pdvecInp2, inDataPitch1 - (2 * XCHAL_IVPN_SIMD_WIDTH * flag));

          IVP_DSEL2NX8I(dvecIn12, dvecIn11, dvecIn12, dvecIn11, IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecIn22, dvecIn21, dvecIn22, dvecIn21, IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData3, dvecData1, \
                        dvecIn21, dvecIn11, IVP_DSELI_8B_DEINTERLEAVE_1);
          dvecData2 = IVP_SEL2NX8I(dvecIn22, dvecIn12, IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0);

          /* Multiply and accumulate 2nd set of 3 coefficients for all the outputs */
          MORPH_OP_MULQA(dacc1, 0, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MULQA(dacc2, 0, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));

          /* Load third row for 1st output row*/
          vaData = MORPH_OP_PRIME_2Nx8(pdvecInp1);
          MORPH_OP_LOAD_2Nx8(dvecIn11, vaData, pdvecInp1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecIn12, vaData, pdvecInp1, inDataPitch2 - 2 * inDataPitch1 - \
                             (2 * XCHAL_IVPN_SIMD_WIDTH * flag));

          /* Load third row for 2nd output row*/
          vaData = MORPH_OP_PRIME_2Nx8(pdvecInp2);
          MORPH_OP_LOAD_2Nx8(dvecIn21, vaData, pdvecInp2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecIn22, vaData, pdvecInp2, inDataPitch2 - 2 * inDataPitch1 - \
                             (2 * XCHAL_IVPN_SIMD_WIDTH * flag));

          IVP_DSEL2NX8I(dvecIn12, dvecIn11, dvecIn12, dvecIn11, IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecIn22, dvecIn21, dvecIn22, dvecIn21, IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData3, dvecData1, \
                        dvecIn21, dvecIn11, IVP_DSELI_8B_DEINTERLEAVE_1);
          dvecData2 = IVP_SEL2NX8I(dvecIn22, dvecIn12, IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0);

          /* Multiply and accumulate 3rd set of 3 coefficients for all the outputs */
          MORPH_OP_MULQA(dacc1, 0, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
          MORPH_OP_MULQA(dacc2, 0, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
        }   /* END for (inCh = 0; inCh < numInCh; inCh++) */

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* variable store count */
        varLen = XT_MIN(outW - x, vectorizationWidth);

        /* Store the first row , first output depth */
        pdvecOut  = (xb_vec2Nx8 *) (pOutput);
        vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Store the first row , 2nd output depth */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Get the 2nd output row elements which are in the upper half of output vectors */
        dvecOut1L = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecOut1L, IVP_SELI_8B_EXTRACT_HI_HALVES);
        dvecOut2L = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecOut2L, IVP_SELI_8B_EXTRACT_HI_HALVES);

        /* Store the 2nd row , 1st output depth */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2ndRow * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, (-typeFlag + 1) * varLen * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * 2 * varLen * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Store the 2nd row 32 outputs from 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, (-typeFlag + 1) * \
                       varLen * enable2ndCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable2ndCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 2 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 2 * coeffPitch3;
      } /* END for (outCh = 0; outCh < numOutCh; outCh += 2) */
    }   /* END for (y = 0; y < outH; y += 2) */
  }     /* END for (x = 0; x < outW; x += vectorizationWidth ) */
  return(XAI_ERROR_STATUS());
}

/*****************************************************************************
*  xaiConvolved(VQ)3D_S_3x3j1d2I8S8IX_MOW_WHD
*  **************************************************************************/

/********************************************************************************/
/* Description : P6 optimized generic implementation for 3x3 3D convolution with*/
/*               dilation = 2. Based on MORPH pre-processor specifiers, code    */
/*               implementation is generated during preprocessing stage. This   */
/*               method can be used to generate 3x3 3D dilated convolution      */
/*               function and 3x3 3D VQ dilated convolution function for U8 bit */
/*               and S8 bit input data with input stride equal to 1             */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                  */
/*               Output scale array, CNN convolution params structure           */
/* Outputs     : XI Error Code                                                  */
/* InOuts      : Output Tile                                                    */
/* Assumptions : CoeffData is S8                                                */
/*               biasArray is signed 32b, value not exceeding signed 24b        */
/*               Output scale array is U16                                      */
/*               OutData is S8 / U8 / S16                                       */
/*               Kernel Size is 3x3xDxN                                         */
/*               Input and Output are in WHD format                             */
/*               Coeff is in WHDN format                                        */
/********************************************************************************/

/****************** xaiConvolvedVQ3D_S_3x3j1d2_S8S8IX_MOW_WHD ******************/
/****************** xaiConvolvedVQ3D_S_3x3j1d2_U8S8IX_MOW_WHD ******************/
/******************* xaiConvolved3D_S_3x3j1d2_S8S8IX_MOW_WHD *******************/
/******************* xaiConvolved3D_S_3x3j1d2_U8S8IX_MOW_WHD *******************/

XAI_ERR_TYPE MAKE_NAME(MAKE_NAME_VQ(xaiConvolved, 3D_S_3x3j1d2), S8IX_MOW_WHD) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Error Checks */
  XAI_ERROR_CHECKS()
  {
    MORPH_IDT_CHECK(inTile);
    XAI_CHECK_CONV_OUTPUT_TILE3D(outTile);
    XAI_CHECK_TILE4D_S8(coeffTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(outTile);
    XAI_CHECK_TILE4D_IN_DRAM_BOUNDARY(coeffTile);
    XAI_CHECK_POINTER(param);
    XAI_CHECK_ARRAY_S32(biasArray);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(inTile, outTile);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(coeffTile, outTile);
    XAI_CHECK_KERNEL_SIZE(coeffTile, 3);
    XAI_CHECK_TILE3D_DATA_ORDER(inTile, XAI_WHD);
    XAI_CHECK_TILE3D_DATA_ORDER(outTile, XAI_WHD);
    XAI_CHECK_TILE4D_DATA_ORDER(coeffTile, XAI_WHDN);
    XAI_CHECK_TILE3D_EDGE(inTile, 2);
    XAI_CHECK_STRIDE(param, 1);
    XAI_CHECK_ERROR((XAI_CNN_CONV_GET_STRIDEX(param) == XAI_CNN_CONV_GET_STRIDEY(param)),                                         \
                    XAI_ERR_BADARG, "Stride along width = %hhu and height = %hhu\nStride along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_DILATION(param, 2);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_DILATIONX(param) == XAI_CNN_CONV_GET_DILATIONY(param),                                             \
                    XAI_ERR_BADARG, "\nDilation along width = %hhu and height = %hhu\nDilation along width and height should be equal", \
                    XAI_CNN_CONV_GET_DILATIONX(param), XAI_CNN_CONV_GET_DILATIONY(param));
    XAI_CHECK_CONSISTENCY_MOW_WHD(inTile, coeffTile, biasArray, outTile, param);
    XAI_CHECK_COEFFTILE_CONTIGUOUS(coeffTile, param);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_ACCUM_SHIFT(param) < 24,                                     \
                    XAI_ERR_NORM, "\nThe accumulator shift = %hhu, value should be less than 24", \
                    XAI_CNN_CONV_GET_ACCUM_SHIFT(param));
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_OUTPUT_SHIFT(param) < 32,                               \
                    XAI_ERR_NORM, "\nThe output shift = %hhu, value should be less than 32", \
                    XAI_CNN_CONV_GET_OUTPUT_SHIFT(param));
    XAI_CHECK_CONV_RELU_LIMITS_IX(param, outTile);
#if DILATED_VQ_CONV == VQ_TRUE
    XAI_CHECK_ARRAY_U16(outputScaleArray);
    XAI_CHECK_ERROR(XAI_ARRAY_GET_WIDTH(outputScaleArray) >= XAI_TILE4D_GET_DIM4(coeffTile),                                                                                          \
                    XAI_ERR_DATASIZE, "\nWidth of Output Scale Array = %d, Number of Kernels = %d\nWidth of Output Scale Array should be greater than or equal to Number of Kernels", \
                    XAI_ARRAY_GET_WIDTH(outputScaleArray), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_ERROR((((uintptr_t) (XAI_ARRAY_GET_DATA_PTR(outputScaleArray)) & \
                      0x1) == 0), XAI_ERR_NORM, "The output scale array is not aligned to 2 byte boundary");
#endif
  }
#if DILATED_VQ_CONV == VQ_FALSE
  if (XAI_CNN_CONV_GET_OUTPUT_SCALE(param) == 0)
  {
    int32_t fillValue;
    int32_t reluFlag = XAI_CNN_CONV_GET_FLAG_RELU(param);
    fillValue = reluFlag ? (CLAMP(0, XAI_CNN_CONV_GET_RELU_MIN(param), XAI_CNN_CONV_GET_RELU_MAX(param))) : 0;
    return(xaiFillTile3D(outTile, fillValue, 0));
  }
#endif
  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Pitches of Coefficient Data (WHDN) in dim1 and dim3 */
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t dilationU     = XAI_CNN_CONV_GET_DILATION(param);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Since the dilation value > 1 ,                                      */
  /* Effective Kernel size = dilation(KernelSize - 1) + 1                */
  /* Effective kernel size is used for calculating the min required edge */
  int32_t dilatedKSizeU = dilationU * (kSizeU - 1) + 1;

  /* Move pointer to the start of the data (including edge)              */
  pInData = &pInData[-((dilatedKSizeU / 2) * inDataPitch1 + (dilatedKSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 *restrict pdvecIn;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1;
  xb_vec2Nx8* restrict pdvecCoeff2;

  /* Variable Declarations */
  int32_t inCh, outCh, x, y;


  /* In order to make the loop multiply-bound we are reducing the vectorization width
     by extra values required for the kernel */
  const int32_t vectorizationWidth = 4 * XCHAL_IVPN_SIMD_WIDTH - dilatedKSizeU + 1;

  /* Generating the shuffle pattern for coefficient loads.
     The idea is to populate zero value where the MUL4T should not affect
     Pattern : 0 1 2 32 3 4 5 32 6 7 8 32 X X X .... */
  xb_vec2Nx8 dvecIdx = IVP_SEL2NX8I(32, IVP_MOV2NX8_FROMNX16( \
                                      IVP_MOVNX16T(IVP_ADDNX16(IVP_ANDNX16(IVP_SEQNX16(), 3),
                                                               IVP_MULNX16PACKL(IVP_SRLINX16(IVP_SEQNX16(), 2), 3)), 32,
                                                   IVP_NEQNX16(IVP_ANDNX16(IVP_SEQNX16(), 3), 3))),
                                    IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0);

  /* Generating two select interleave pattern to apply on accumulator values just before storing
   * For 8 bit output
   *     Pattern1 = 0  64 1  65 2  66    ....  31 95
   *     Pattern2 = 32 96 33 97 34 98  ...     63 127
   * For 16 bit output
   *     Pattern1 = 0  1  64 65  2 3  66 67 .... 30 31 94  95
   *     Pattern2 = 32 33 96 97 34 35 98 99  ... 62 63 126 127
   */
  /* 0 1 2 3 .. 62 63*/
  xb_vec2Nx8 dvecPattern1 = IVP_SEQ2NX8();
  /* 65 66 67 ...126 127*/
  xb_vec2Nx8 dvecPattern2 = IVP_ADD2NX8(dvecPattern1, 2 * XCHAL_IVPN_SIMD_WIDTH);

  if (!typeFlag)
  {
    MORPH_OP_DSELI(dvecPattern2, dvecPattern1, \
                   dvecPattern2, dvecPattern1, \
                   IVP_DSELI_8B_INTERLEAVE_1);
  }
  else
  {
    MORPH_OP_DSELI(dvecPattern2, dvecPattern1, \
                   dvecPattern2, dvecPattern1, \
                   IVP_DSELI_INTERLEAVE_1);
  }


  /* 4 * XCHAL_IVPN_SIMD_WIDTH bytes of input are loaded at a time
   * into two vectors. Also loop across output channels is unrolled twice,
   * thereby producing four output vectors in 1 iteration
   */
  for (x = 0; x < outW; x += vectorizationWidth) /* Loop across output width */
  {
    /* variable length for output stores */
    int32_t remX = XT_MIN(vectorizationWidth, outW - x);

    /* If (remX + kSizeEffU - 1) <= 2 * XCHAL_IVPN_SIMD_WIDTH,
     * i.e. if the number of input data bytes corresponding to remX number of outputs
     * is less than or equal to 2 * XCHAL_IVPN_SIMD_WIDTH, there is no need to load
     * the next 64 input bytes*/
    int32_t remXLoad = ((remX + dilatedKSizeU - 1) > 2 * XCHAL_IVPN_SIMD_WIDTH) ? 1 : 0;

    for (y = 0; y < outH; y++)    /* Loop across output height */
    {
      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y + x];

      /* initialize coeff and Bias data pointer */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 2)    /* Loop across Output depth */
      {
        /* In order to handle odd output depths */
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

        /* Load the bias values corresponding to two output channels */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;

        dacc12 = dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);

        dacc22 = dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc22, hvecBias2, hvecBias2);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

        /* Input vector pointer initialization */
        pdvecIn = (MORPH_IDT_2Nx8 *) (pInput);

        /* Load 128 bytes from row corresponding to each ky
         * dvecInData11 = a0 a1 a2 a3.... a63
         * dvecInData12 = a64 a65 a66 .... a127
         *
         * Separate odd and even indices
         * dvecInData11 = a0 a2 a4 a6.... a126
         * dvecInData12 = a1 a3 a5 a7.... a127
         *
         * Let the coefficients be
         * C0 C1 C2
         * C3 C4 C5
         * C6 C7 C8
         *
         * acc11 = [a0 a2 a4 a6.... a126] * C0 +
         *         [a2 a4 a6.... a126 X ] * C1 +
         *         [a4 a6.... a126 X  X ] * C2
         *
         * acc12 = [a1 a3 a5 a7.... a127] * C0 +
         *         [a3 a5 a7.... a127 X ] * C1 +
         *         [a5 a7.... a127 X  X ] * C2
         * Continue the same multiplication steps for ky = 1 [C3 C4 C5] and ky =2 [C6 C7 C8].
         * acc11 and acc12 contains convolved output corresponding to even and odd indices
         * respectively at the end of inchannel loop iterations.
         *
         * acc11 and acc12 are interleaved to obtain the outputs in correct order.
         *
         */
        for (inCh = 0; inCh < numInCh; inCh++)    /* Loop across input channels */
        {
          /* vectors for coeff and input loads */
          xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2;
          MORPH_IDT_2Nx8 dvecInData11, dvecInData12;
          MORPH_IDT_2Nx8 dvecInData21, dvecInData22;
          MORPH_IDT_2Nx8 dvecInData31, dvecInData32;

          /* load data 128 bytes from first input row  */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn, \
                             dilationU * inDataPitch1 - remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          /* Separate odd and even indices */
          MORPH_OP_DSELI(dvecInData12, dvecInData11, dvecInData12, dvecInData11, \
                         IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load data 128 bytes from 2nd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn, \
                             dilationU * inDataPitch1 - remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          /* Separate odd and even indices */
          MORPH_OP_DSELI(dvecInData22, dvecInData21, dvecInData22, dvecInData21, \
                         IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load data 128 bytes from 3rd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData31, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData32, vaInData, pdvecIn, inDataPitch2 - \
                             dilationU * 2 * inDataPitch1 - remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          /* Separate odd and even indices */
          MORPH_OP_DSELI(dvecInData32, dvecInData31, dvecInData32, dvecInData31, \
                         IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load all the 3x3 coefficients for 2 output depths*/
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, 9);
          IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, 9);

          /* Rearrange them so that zero is inserted where the MUL4T should not have effect */
          dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);
          dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecIdx);

          /* Multiply and accumulate 1st set of 3 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc11, dvecInData11, dvecInData11, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc12, dvecInData12, dvecInData12, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc21, dvecInData11, dvecInData11, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
          MORPH_OP_MUL4TA(dacc22, dvecInData12, dvecInData12, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

          /* Multiply and accumulate 2nd set of 3 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc11, dvecInData21, dvecInData21, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData22, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc21, dvecInData21, dvecInData21, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
          MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData22, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));

          /* Multiply and accumulate 3rd set of 3 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc11, dvecInData31, dvecInData31, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
          MORPH_OP_MUL4TA(dacc12, dvecInData32, dvecInData32, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
          MORPH_OP_MUL4TA(dacc21, dvecInData31, dvecInData31, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
          MORPH_OP_MUL4TA(dacc22, dvecInData32, dvecInData32, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
        }    /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvec1L, dvec2L, dvec3L, dvec4L;
        xb_vec2Nx8 dvec1H, dvec2H, dvec3H, dvec4H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec1L, dvec1H, dacc11, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec2L, dvec2H, dacc12, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec3L, dvec3H, dacc21, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec4L, dvec4H, dacc22, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec1L, dvec1H, dacc11, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec2L, dvec2H, dacc12, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec3L, dvec3H, dacc21, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec4L, dvec4H, dacc22, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* Interleave odd and even indices */
        xb_vec2Nx8 dvecOut1L = MORPH_OP_SEL(dvec2L, dvec1L, dvecPattern1);
        xb_vec2Nx8 dvecOut2L = MORPH_OP_SEL(dvec2L, dvec1L, dvecPattern2);
        xb_vec2Nx8 dvecOut1H = MORPH_OP_SEL(dvec2H, dvec1H, dvecPattern1);
        xb_vec2Nx8 dvecOut2H = MORPH_OP_SEL(dvec2H, dvec1H, dvecPattern2);
        xb_vec2Nx8 dvecOut3L = MORPH_OP_SEL(dvec4L, dvec3L, dvecPattern1);
        xb_vec2Nx8 dvecOut4L = MORPH_OP_SEL(dvec4L, dvec3L, dvecPattern2);
        xb_vec2Nx8 dvecOut3H = MORPH_OP_SEL(dvec4H, dvec3H, dvecPattern1);
        xb_vec2Nx8 dvecOut4H = MORPH_OP_SEL(dvec4H, dvec3H, dvecPattern2);

        /* Storing the first output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * remX);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * remX - \
                       2 * XCHAL_IVPN_SIMD_WIDTH);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                       (2 * remX - 4 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                       (2 * remX - 6 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * remX * enable2ndCh);
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, \
                       ((bytesPerPixel * remX) - 2 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
        IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                       (2 * remX - 4 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
        IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                       (2 * remX - 6 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 2 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 2 * coeffPitch3;
      }  /* end of for (outCh = 0; outCh < numOutCh; outCh += 2)*/
    }    /* end of for (y = 0; y < outH; y ++)*/
  }      /* end of for (x = 0; x < outW; x += vectorizationWidth)*/


  return(XAI_ERROR_STATUS());
}

/*****************************************************************************
*  xaiConvolved(VQ)3D_S_3x3j1d4I8S8IX_MOW_WHD
*  **************************************************************************/

/********************************************************************************/
/* Description : P6 optimized generic implementation for 3x3 3D convolution with*/
/*               dilation = 4. Based on MORPH pre-processor specifiers, code    */
/*               implementation is generated during preprocessing stage. This   */
/*               method can be used to generate 3x3 3D convolution dilated      */
/*               function and 3x3 3D VQ convolution dilated function for U8 bit */
/*               and S8 bit input data with input stride equal to 1             */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                  */
/*               Output scale array, CNN convolution params structure           */
/* Outputs     : XI Error Code                                                  */
/* InOuts      : Output Tile                                                    */
/* Assumptions : CoeffData is S8                                                */
/*               biasArray is signed 32b, value not exceeding signed 24b        */
/*               Output scale array is U16                                      */
/*               OutData is S8 / U8 / S16                                       */
/*               Kernel Size is 3x3xDxN                                         */
/*               Input and Output are in WHD format                             */
/*               Coeff is in WHDN format                                        */
/********************************************************************************/

/****************** xaiConvolvedVQ3D_S_3x3j1d4_S8S8IX_MOW_WHD ******************/
/****************** xaiConvolvedVQ3D_S_3x3j1d4_U8S8IX_MOW_WHD ******************/
/******************* xaiConvolved3D_S_3x3j1d4_S8S8IX_MOW_WHD *******************/
/******************* xaiConvolved3D_S_3x3j1d4_U8S8IX_MOW_WHD *******************/

XAI_ERR_TYPE MAKE_NAME(MAKE_NAME_VQ(xaiConvolved, 3D_S_3x3j1d4), S8IX_MOW_WHD) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Error Checks */
  XAI_ERROR_CHECKS()
  {
    MORPH_IDT_CHECK(inTile);
    XAI_CHECK_CONV_OUTPUT_TILE3D(outTile);
    XAI_CHECK_TILE4D_S8(coeffTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(outTile);
    XAI_CHECK_TILE4D_IN_DRAM_BOUNDARY(coeffTile);
    XAI_CHECK_POINTER(param);
    XAI_CHECK_ARRAY_S32(biasArray);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(inTile, outTile);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(coeffTile, outTile);
    XAI_CHECK_KERNEL_SIZE(coeffTile, 3);
    XAI_CHECK_TILE3D_DATA_ORDER(inTile, XAI_WHD);
    XAI_CHECK_TILE3D_DATA_ORDER(outTile, XAI_WHD);
    XAI_CHECK_TILE4D_DATA_ORDER(coeffTile, XAI_WHDN);
    XAI_CHECK_TILE3D_EDGE(inTile, 4);
    XAI_CHECK_STRIDE(param, 1);
    XAI_CHECK_ERROR((XAI_CNN_CONV_GET_STRIDEX(param) == XAI_CNN_CONV_GET_STRIDEY(param)),                                         \
                    XAI_ERR_BADARG, "Stride along width = %hhu and height = %hhu\nStride along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_DILATION(param, 4);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_DILATIONX(param) == XAI_CNN_CONV_GET_DILATIONY(param),                                             \
                    XAI_ERR_BADARG, "\nDilation along width = %hhu and height = %hhu\nDilation along width and height should be equal", \
                    XAI_CNN_CONV_GET_DILATIONX(param), XAI_CNN_CONV_GET_DILATIONY(param));
    XAI_CHECK_CONSISTENCY_MOW_WHD(inTile, coeffTile, biasArray, outTile, param);
    XAI_CHECK_COEFFTILE_CONTIGUOUS(coeffTile, param);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_ACCUM_SHIFT(param) < 24,                                     \
                    XAI_ERR_NORM, "\nThe accumulator shift = %hhu, value should be less than 24", \
                    XAI_CNN_CONV_GET_ACCUM_SHIFT(param));
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_OUTPUT_SHIFT(param) < 32,                               \
                    XAI_ERR_NORM, "\nThe output shift = %hhu, value should be less than 32", \
                    XAI_CNN_CONV_GET_OUTPUT_SHIFT(param));
    XAI_CHECK_CONV_RELU_LIMITS_IX(param, outTile);
#if DILATED_VQ_CONV == VQ_TRUE
    XAI_CHECK_ARRAY_U16(outputScaleArray);
    XAI_CHECK_ERROR(XAI_ARRAY_GET_WIDTH(outputScaleArray) >= XAI_TILE4D_GET_DIM4(coeffTile),                                                                                          \
                    XAI_ERR_DATASIZE, "\nWidth of Output Scale Array = %d, Number of Kernels = %d\nWidth of Output Scale Array should be greater than or equal to Number of Kernels", \
                    XAI_ARRAY_GET_WIDTH(outputScaleArray), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_ERROR((((uintptr_t) (XAI_ARRAY_GET_DATA_PTR(outputScaleArray)) & \
                      0x1) == 0), XAI_ERR_NORM, "The output scale array is not aligned to 2 byte boundary");
#endif
  }
#if DILATED_VQ_CONV == VQ_FALSE
  if (XAI_CNN_CONV_GET_OUTPUT_SCALE(param) == 0)
  {
    int32_t fillValue;
    int32_t reluFlag = XAI_CNN_CONV_GET_FLAG_RELU(param);
    fillValue = reluFlag ? (CLAMP(0, XAI_CNN_CONV_GET_RELU_MIN(param), XAI_CNN_CONV_GET_RELU_MAX(param))) : 0;
    return(xaiFillTile3D(outTile, fillValue, 0));
  }
#endif
  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Pitches of Coefficient Data (WHDN) in dim1 and dim3 */
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t dilationU     = XAI_CNN_CONV_GET_DILATION(param);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Since the dilation value > 1 ,                                      */
  /* Effective Kernel size = dilation(KernelSize - 1) + 1                */
  /* Effective kernel size is used for calculating the min required edge */
  int32_t dilatedKSizeU = dilationU * (kSizeU - 1) + 1;

  /* Move pointer to the start of the data (including edge)              */
  pInData = &pInData[-((dilatedKSizeU / 2) * inDataPitch1 + (dilatedKSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 *restrict pdvecIn;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1;
  xb_vec2Nx8* restrict pdvecCoeff2;

  /* Variable Declarations */
  int32_t inCh, outCh, x, y;


  /* In order to make the loop multiply-bound we are reducing the vectorization width
     by extra values required for the kernel */
  const int32_t vectorizationWidth = 4 * XCHAL_IVPN_SIMD_WIDTH - dilatedKSizeU + 1;

  /* Generating the shuffle pattern for coefficient loads.
     The idea is to populate zero value where the MUL4T should not affect
     Pattern : 0 1 2 32 3 4 5 32 6 7 8 32 X X X .... */
  xb_vec2Nx8 dvecIdx = IVP_SEL2NX8I(32, IVP_MOV2NX8_FROMNX16( \
                                      IVP_MOVNX16T(IVP_ADDNX16(IVP_ANDNX16(IVP_SEQNX16(), 3),
                                                               IVP_MULNX16PACKL(IVP_SRLINX16(IVP_SEQNX16(), 2), 3)), 32,
                                                   IVP_NEQNX16(IVP_ANDNX16(IVP_SEQNX16(), 3), 3))),
                                    IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0);

  /* 4 * XCHAL_IVPN_SIMD_WIDTH bytes of input are loaded at a time
   * into two vectors. Also loop across output channels is unrolled twice,
   * thereby producing four output vectors in 1 iteration
   */
  for (x = 0; x < outW; x += vectorizationWidth) /* Loop across output width */
  {
    /* variable length for output stores */
    int32_t remX = XT_MIN(vectorizationWidth, outW - x);

    /* If (remX + kSizeEffU - 1) <= 2 * XCHAL_IVPN_SIMD_WIDTH,
     * i.e. if the number of input data bytes corresponding to remX number of outputs
     * is less than or equal to 2 * XCHAL_IVPN_SIMD_WIDTH, there is no need to load
     * the next 64 input bytes*/
    int32_t remXLoad = ((remX + dilatedKSizeU - 1) > 2 * XCHAL_IVPN_SIMD_WIDTH) ? 1 : 0;

    for (y = 0; y < outH; y++)    /* Loop across output height */
    {
      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y + x];

      /* initialize coeff and Bias data pointer */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 2)    /* Loop across Output depth */
      {
        /* In order to handle odd output depths */
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

        /* Load the bias values corresponding to two output channels */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;

        dacc12 = dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);

        dacc22 = dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc22, hvecBias2, hvecBias2);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

        /* Input vector pointer initialization */
        pdvecIn = (MORPH_IDT_2Nx8 *) (pInput);

        /* Load 128 bytes from row corresponding to each ky
         * dvecInData11 = a0 a1 a2 a3      ...                   a63
         * dvecInData12 = a64 a65 a66      ...                   a127
         *
         * Deinterleave the indices
         * dvecInData11 = a0 a2 a4 a6      ...                   a126
         * dvecInData12 = a1 a3 a5 a7      ...                   a127
         *
         * Deinterleave the indices
         * dvecInData11 = a0 a4 a8   ...   a124 ... a1 a5  ...   a125
         * dvecInData12 = a2 a6 a10   ...  a126 ... a3 a7  ...   a127
         *
         * Let the coefficients be
         * C0 C1 C2
         * C3 C4 C5
         * C6 C7 C8
         *
         * acc11 = [a0 a4 a8   ...   a124 ... a1 a5  ...   a125] * C0 +
         *         [a4 a8   ...   a124 ... a1 a5  ...   a125 X ] * C1 +
         *         [a8   ...   a124 ... a1 a5  ...   a125 X  X ] * C2
         *
         * acc12 = [a2 a6 a10   ...  a126 ... a3 a7  ...   a127] * C0 +
         *         [a6 a10   ...  a126 ... a3 a7  ...   a127 X ] * C1 +
         *         [a10   ...  a126 ... a3 a7  ...   a127 X  X ] * C2
         * Continue the same multiplication steps for ky = 1 [C3 C4 C5] and ky =2 [C6 C7 C8].
         * acc11 and acc12 contains convolved output corresponding to even and odd indices
         * respectively at the end of inchannel loop iterations.
         *
         * acc11 and acc12 are interleaved to obtain the outputs in correct order.
         *
         * Follow same steps for obtaining outputs corresponding to next output channel
         */
        for (inCh = 0; inCh < numInCh; inCh++)    /* Loop across input channels */
        {
          /* vectors for coeff and input loads */
          xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2;
          MORPH_IDT_2Nx8 dvecInData11, dvecInData12;
          MORPH_IDT_2Nx8 dvecInData21, dvecInData22;
          MORPH_IDT_2Nx8 dvecInData31, dvecInData32;

          /* load data 128 bytes from first input row  */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn, \
                             dilationU * inDataPitch1 - remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          /* Separate odd and even indices */
          MORPH_OP_DSELI(dvecInData12, dvecInData11, dvecInData12, dvecInData11, \
                         IVP_DSELI_8B_DEINTERLEAVE_1);
          MORPH_OP_DSELI(dvecInData12, dvecInData11, dvecInData12, dvecInData11, \
                         IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load data 128 bytes from 2nd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn, \
                             dilationU * inDataPitch1 - remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          /* Separate odd and even indices */
          MORPH_OP_DSELI(dvecInData22, dvecInData21, dvecInData22, dvecInData21, \
                         IVP_DSELI_8B_DEINTERLEAVE_1);
          MORPH_OP_DSELI(dvecInData22, dvecInData21, dvecInData22, dvecInData21, \
                         IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load data 128 bytes from 3rd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData31, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData32, vaInData, pdvecIn, inDataPitch2 - \
                             dilationU * 2 * inDataPitch1 - remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          /* Separate odd and even indices */
          MORPH_OP_DSELI(dvecInData32, dvecInData31, dvecInData32, dvecInData31, \
                         IVP_DSELI_8B_DEINTERLEAVE_1);
          MORPH_OP_DSELI(dvecInData32, dvecInData31, dvecInData32, dvecInData31, \
                         IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load all the 3x3 coefficients for 2 output depths*/
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, 9);
          IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, 9);

          /* Rearrange them so that zero is inserted where the MUL4T should not have effect */
          dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);
          dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecIdx);

          /* Multiply and accumulate 1st set of 3 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc11, dvecInData11, dvecInData11, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc12, dvecInData12, dvecInData12, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc21, dvecInData11, dvecInData11, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
          MORPH_OP_MUL4TA(dacc22, dvecInData12, dvecInData12, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

          /* Multiply and accumulate 2nd set of 3 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc11, dvecInData21, dvecInData21, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData22, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc21, dvecInData21, dvecInData21, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
          MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData22, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));

          /* Multiply and accumulate 3rd set of 3 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc11, dvecInData31, dvecInData31, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
          MORPH_OP_MUL4TA(dacc12, dvecInData32, dvecInData32, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
          MORPH_OP_MUL4TA(dacc21, dvecInData31, dvecInData31, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
          MORPH_OP_MUL4TA(dacc22, dvecInData32, dvecInData32, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
        }    /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* Interleave odd and even indices */
        /* 8 bit output */
        if (!typeFlag)
        {
          /*
           * dacc11 and dacc12 contains accumulated values corresponding to same output row.
           * For 8bit output, dvecOutL contains the required output elements
           * dvecOut1L = [A0 A4 A8 ... A116 X X A1 A5 ... A117 X X] - 64 elements
           * dvecOut2L = [A2 A6 A10 ...A118 X X A3 A7 ... A119 X X] - 64 elements
           * Interleave the elements
           * dvecOut1L = [A0 A2 A4       ...    A116 A117 X X X X ] - 64 elements
           * dvecOut2L = [A1 A3 A7       ...    A118 A119 X X X X ] - 64 elements
           * Interleave the elements
           * dvecOut1L = [A0 A1 A2 A3                   ...                 ]- 64 elements
           * dvecOut2L = [  ...         A116 A117 A118 A119 X X X X X X X X ]- 64 elements
           *
           * Same steps for ouputs corresponding to second output channel.
           */
          MORPH_OP_DSELI(dvecOut2L, dvecOut1L, dvecOut2L, dvecOut1L, \
                         IVP_DSELI_8B_INTERLEAVE_1);
          MORPH_OP_DSELI(dvecOut2L, dvecOut1L, dvecOut2L, dvecOut1L, \
                         IVP_DSELI_8B_INTERLEAVE_1);
          MORPH_OP_DSELI(dvecOut4L, dvecOut3L, dvecOut4L, dvecOut3L, \
                         IVP_DSELI_8B_INTERLEAVE_1);
          MORPH_OP_DSELI(dvecOut4L, dvecOut3L, dvecOut4L, dvecOut3L, \
                         IVP_DSELI_8B_INTERLEAVE_1);
        }
        else /* 16bit output */
        {
          /*
           * dacc11 and dacc12 contains accumulated values corresponding to same output row.
           * dvecOut1L = [A0 A4 A8  ... A116 X X] - 32 16b elements
           * dvecOut1H = [A1 A5 A9  ... A117 X X] - 32 16b elements
           * dvecOut2L = [A2 A6 A10 ... A118 X X] - 32 16b elements
           * dvecOut2H = [A3 A7 A11 ... A119 X X] - 32 16b elements
           * Interleave the elements of dvecOut1L and dvecOut1H
           * dvecOut1L = [A0 A1 A4 A5         ...      ]
           * dvecOut1H = [ ...            A116 A117 X X]
           * Interleave the elements of dvecOut2L and dvecOut2H
           * dvecOut2L = [A2 A3 A6 A7               ...]
           * dvecOut2H = [ ...            A118 A119 X X]
           * Interleave2 the elements of dvecOut2L and dvecOut1L
           * dvecOut1L = [A0  A1  A2  A3                        ...          ]
           * dvecOut2L = [A32 A33 A34 A35                        ...         ]
           * Interleave2 the elements of dvecOut2H and dvecOut1H
           * dvecOut1H = [A64 A65 A66 A67                  ...               ]
           * dvecOut2H = [ ...            A116 A117 A118 A119 X X X X X X X X]
           *
           * Same steps for outputs corresponding to second output channel.
           */
          MORPH_OP_DSELI(dvecOut1H, dvecOut1L, dvecOut1H, dvecOut1L, \
                         IVP_DSELI_INTERLEAVE_1);
          MORPH_OP_DSELI(dvecOut2H, dvecOut2L, dvecOut2H, dvecOut2L, \
                         IVP_DSELI_INTERLEAVE_1);
          MORPH_OP_DSELI(dvecOut2L, dvecOut1L, dvecOut2L, dvecOut1L, \
                         IVP_DSELI_INTERLEAVE_2);
          MORPH_OP_DSELI(dvecOut2H, dvecOut1H, dvecOut2H, dvecOut1H, \
                         IVP_DSELI_INTERLEAVE_2);
          MORPH_OP_DSELI(dvecOut3H, dvecOut3L, dvecOut3H, dvecOut3L, \
                         IVP_DSELI_INTERLEAVE_1);
          MORPH_OP_DSELI(dvecOut4H, dvecOut4L, dvecOut4H, dvecOut4L, \
                         IVP_DSELI_INTERLEAVE_1);
          MORPH_OP_DSELI(dvecOut4L, dvecOut3L, dvecOut4L, dvecOut3L, \
                         IVP_DSELI_INTERLEAVE_2);
          MORPH_OP_DSELI(dvecOut4H, dvecOut3H, dvecOut4H, dvecOut3H, \
                         IVP_DSELI_INTERLEAVE_2);
        }


        /* Storing the first output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * remX);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * remX - \
                       2 * XCHAL_IVPN_SIMD_WIDTH);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                       (2 * remX - 4 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                       (2 * remX - 6 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * remX * enable2ndCh);
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, ((bytesPerPixel * remX) - \
                                                        2 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
        IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                       (2 * remX - 4 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
        IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                       (2 * remX - 6 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 2 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 2 * coeffPitch3;
      }  /* end of for (outCh = 0; outCh < numOutCh; outCh += 2)*/
    }    /* end of for (y = 0; y < outH; y ++)*/
  }      /* end of for (x = 0; x < outW; x += vectorizationWidth)*/


  return(XAI_ERROR_STATUS());
}

/******************************************************************************************
* MOW fold 16 Stride 1                                                                    *
* If inDataPitch1 is lesser than or equal to                                              *
* 16 this function is called.                                                             *
******************************************************************************************/

static _XAI_INLINE_ void MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_4x4j1d1), S8IX_MOW_WHD_FOLD16) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Pitches of Coefficient Data (WHDN) in dim1 and dim3 */
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  const uint8_t leftEdgeFlag = XAI_CNN_CONV_GET_FLAG_LEFTEDGE(param);
  const uint8_t topEdgeFlag  = XAI_CNN_CONV_GET_FLAG_TOPEDGE(param);
  int32_t leftEdge, topEdge;

  leftEdge = leftEdgeFlag ? (kSizeU / 2) : ((kSizeU / 2) - 1);
  topEdge  = topEdgeFlag ? (kSizeU / 2) : ((kSizeU / 2) - 1);

  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-(topEdge * inDataPitch1 + leftEdge)];


  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 *restrict pdvecIn1;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1;
  xb_vec2Nx8* restrict pdvecCoeff2;

  /* Variable Declarations */
  int32_t inCh, outCh, y;

  /* Select sequence to re-arrange input data */
  xb_vec2Nx8 dvecSeq = 0;
  IVP_ADD2NX8T(dvecSeq, IVP_SEQ2NX8(), inDataPitch1, IVP_LT2NX8(IVP_SEQ2NX8(), 3 * inDataPitch1));
  IVP_ADD2NX8T(dvecSeq, IVP_SUB2NX8(IVP_SEQ2NX8(), 3 * inDataPitch1), 64, \
               IVP_NOTB2N(IVP_LT2NX8(IVP_SEQ2NX8(), 3 * inDataPitch1)));

  /* loop across output channels are unrolled twice and 4 rows are accessed simultaneously
   * to produce four output vectors in 1 iteration
   */
  for (y = 0; y < outH - 3; y += 4)   /* Loop across output height */
  {
    /* initialize output data pointer */
    int8_t *pOutput = &pOutData[(y * outDataPitch1) * bytesPerPixel];

    /* initialize coeff and Bias data pointer */
    int8_t *pCoeff = &pCoeffData[0];
    int32_t *pBias = &pBiasData[0];

    for (outCh = 0; outCh < numOutCh; outCh += 2)    /* Loop across Output depth */
    {
      /* In order to handle odd output depths */
      int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

      /* Load the bias values corresponding to two output channels */
      xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
      xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

      /* wide vectors(accumulators) initialized with bias */
      xb_vec2Nx24 dacc1, dacc2;

      dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
      IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);

      dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
      IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);

      /* priming of coeff load is done outside the innermost loop*/
      pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
      valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

      pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
      valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y];

      for (inCh = 0; inCh < numInCh; inCh++)    /* Loop across input channels */
      {
        /* vectors for coeff and input loads */
        xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2;
        MORPH_IDT_2Nx8 dvecInData1, dvecInData2, dvecInData3, dvecInData4, dvecInData5;

        /* Initialize input data pointer */
        pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
        pInput  += inDataPitch2;

        /* load data from 4 input rows [Row0 | Row1 | Row2 | Row3] */
        valign vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        MORPH_OP_LOAD_2Nx8(dvecInData1, vaInData1, pdvecIn1, 4 * inDataPitch1);

        /* load data from next 4 input rows [Row4 | Row5 | Row6 | Row7] */
        MORPH_OP_LOAD_2Nx8(dvecInData5, vaInData1, pdvecIn1, 4 * inDataPitch1);

        /* dvecInData1 contains first 4 input rows
         * dvecInData1: row0 | row1 | row2 | row3
         *
         * dvecInData5 contains next 4 input rows
         * dvecInData5: row4 | row5 | row6 | row7
         *
         * Input data is re arranged in such a manner that
         * dvecInData2 contains: row1 | row2 | row3 | row4
         * dvecInData3 contains: row2 | row3 | row4 | row5
         * dvecInData4 contains: row3 | row4 | row5 | row6
         */

        /*Compute row [Row1 | Row2 | Row3 | Row4] */
        dvecInData2 = IVP_SEL2NX8(dvecInData5, dvecInData1, dvecSeq);

        /*Compute row [Row2 | Row3 | Row4 | Row5] */
        dvecInData3 = IVP_SEL2NX8(IVP_SEL2NX8(0, dvecInData5, dvecSeq), dvecInData2, dvecSeq);

        /*Compute row [Row3 | Row4 | Row5 | Row6] */
        dvecInData4 = IVP_SEL2NX8(IVP_SEL2NX8(0, dvecInData5, IVP_ADD2NX8(dvecSeq, inDataPitch1)), dvecInData3, dvecSeq);

        /* load all the 4x4 coefficients for 2 output depths*/
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, 16);
        IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, 16);

        /* Compute the output of 4 output rows, for the 1st output depth */
        MORPH_OP_MUL4TA(dacc1, dvecInData1, dvecInData1, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc1, dvecInData2, dvecInData2, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
        MORPH_OP_MUL4TA(dacc1, dvecInData3, dvecInData3, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
        MORPH_OP_MUL4TA(dacc1, dvecInData4, dvecInData4, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));

        /* Compute the output of 4 output rows, for the 2nd output depth */
        MORPH_OP_MUL4TA(dacc2, dvecInData1, dvecInData1, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
        MORPH_OP_MUL4TA(dacc2, dvecInData2, dvecInData2, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
        MORPH_OP_MUL4TA(dacc2, dvecInData3, dvecInData3, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
        MORPH_OP_MUL4TA(dacc2, dvecInData4, dvecInData4, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
      }    /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

      /* Pack, Output Scale, Output Shift and clamping */
      xb_vec2Nx8 dvecOut1L, dvecOut2L;
      xb_vec2Nx8 dvecOut1H, dvecOut2H;

#if DILATED_VQ_CONV == VQ_TRUE
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                    pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                    pOutScaleData[outCh + enable2ndCh ], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                    outScale, outShiftU, minLim, maxLim, typeFlag);
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                    outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
      /* Storing the first output depth, first row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput);
      valign vaOutData = IVP_ZALIGN();
      IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the first output depth, second row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the first output depth, third row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch1 * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), 2 * inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the first output depth, fourth row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch1 * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), 3 * inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, first row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
      IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, second row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                            outDataPitch1) * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)),
                     vaOutData, pdvecOut, bytesPerPixel * enable2ndCh \
                     * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, second row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                            2 * outDataPitch1) * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), 2 * inDataPitch1 * bytesPerPixel)),
                     vaOutData, pdvecOut, bytesPerPixel * enable2ndCh \
                     * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, second row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                            3 * outDataPitch1) * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), 3 * inDataPitch1 * bytesPerPixel)),
                     vaOutData, pdvecOut, bytesPerPixel * enable2ndCh \
                     * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      pOutput += 2 * outDataPitch2 * bytesPerPixel;
      pCoeff  += 2 * coeffPitch3;
    }  /* end of for (outCh = 0; outCh < numOutCh; outCh += 2)*/
  }    /* end of for (y = 0; y < outH; y += 2)*/

  if (y < outH) /* Handle the case when less than 4 output rows need to be processed */
  {
    int32_t enable2ndRow = XT_SALT(y, outH - 1);
    int32_t enable3rdRow = XT_SALT(y, outH - 2);

    /* initialize output data pointer */
    int8_t *pOutput = &pOutData[(y * outDataPitch1) * bytesPerPixel];

    /* initialize coeff and Bias data pointer */
    int8_t *pCoeff = &pCoeffData[0];
    int32_t *pBias = &pBiasData[0];

    for (outCh = 0; outCh < numOutCh; outCh += 2)    /* Loop across Output depth */
    {
      /* In order to handle odd output depths and heights */
      int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

      /* Load the bias values corresponding to two output channels */
      xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
      xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

      /* wide vectors(accumulators) initialized with bias */
      xb_vec2Nx24 dacc1, dacc2;

      dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
      IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);

      dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
      IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);

      /* priming of coeff load is done outside the innermost loop*/
      pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
      valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

      pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
      valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y];

      for (inCh = 0; inCh < numInCh; inCh++) /* Loop across input channels */
      {
        /* vectors for coeff and input loads */
        xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2;
        MORPH_IDT_2Nx8 dvecInData1, dvecInData2, dvecInData3, dvecInData4, dvecInData5;

        /* load the remaining input rows */
        pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);

        valign vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);

        MORPH_OP_LOAD_2Nx8(dvecInData1, vaInData1, pdvecIn1, 4 * inDataPitch1);
        MORPH_OP_LOAD_2Nx8_VARIABLE(dvecInData5, vaInData1, pdvecIn1, (enable3rdRow + enable2ndRow) * inDataPitch1);
        pInput += inDataPitch2;

        /* load all the 4x4 coefficients for 2 output depths*/
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, 16);
        IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, 16);


        /* dvecInData1 contains first 4 input rows and
         * dvecInData1: row0 | row1 | row2 | row3
         * dvecInData5: row4 | row5 | row6 | row7
         * row6 and row7 of dvecInData5 are always disabled.
         *
         * Input data is re arranged in such a manner that
         * dvecInData2 contains: row1 | row2 | row3 | row4
         * dvecInData3 contains: row2 | row3 | row4 | row5
         * dvecInData4 contains: row3 | row4 | row5 | row6
         */
        /*Compute row [Row1 | Row2 | Row3 | Row4] */
        dvecInData2 = IVP_SEL2NX8(dvecInData5, dvecInData1, dvecSeq);

        /*Compute row [Row2 | Row3 | Row4 | Row5] */
        dvecInData3 = IVP_SEL2NX8(IVP_SEL2NX8(0, dvecInData5, dvecSeq), dvecInData2, dvecSeq);

        /*Compute row [Row3 | Row4 | Row5 | Row6] */
        dvecInData4 = IVP_SEL2NX8(IVP_SEL2NX8(0, dvecInData5, IVP_ADD2NX8(dvecSeq, inDataPitch1)), dvecInData3, dvecSeq);


        /* Multiply input data with coefficients from 1st output channel */
        MORPH_OP_MUL4TA(dacc1, dvecInData1, dvecInData1, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc1, dvecInData2, dvecInData2, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
        MORPH_OP_MUL4TA(dacc1, dvecInData3, dvecInData3, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
        MORPH_OP_MUL4TA(dacc1, dvecInData4, dvecInData4, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));

        /* Multiply input data with coefficients from 2nd output channel */
        MORPH_OP_MUL4TA(dacc2, dvecInData1, dvecInData1, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
        MORPH_OP_MUL4TA(dacc2, dvecInData2, dvecInData2, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
        MORPH_OP_MUL4TA(dacc2, dvecInData3, dvecInData3, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
        MORPH_OP_MUL4TA(dacc2, dvecInData4, dvecInData4, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
      }    /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

      /* Pack, Output Scale, Output Shift and clamping */
      xb_vec2Nx8 dvecOut1L, dvecOut2L;
      xb_vec2Nx8 dvecOut1H, dvecOut2H;
#if DILATED_VQ_CONV == VQ_TRUE
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                    pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                    pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                    outScale, outShiftU, minLim, maxLim, typeFlag);
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                    outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
      /* Storing the first output depth, first row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput);
      valign vaOutData = IVP_ZALIGN();
      IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the first output depth, second row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2ndRow * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the first output depth, 3rd row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch1 * enable3rdRow * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), 2 * inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * enable3rdRow * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, first row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
      IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, second row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                            outDataPitch1 * enable2ndRow) * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * enable2ndRow * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, 3rd row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                            2 * outDataPitch1 * enable3rdRow) * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), 2 * inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * enable3rdRow * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      pOutput += 2 * outDataPitch2 * bytesPerPixel;
      pCoeff  += 2 * coeffPitch3;
    } /* end of for (outCh = 0; outCh < numOutCh; outCh += 2)*/
  }   //if(y < outH)
}

/******************************************************************************************
* MOW fold 32 Stride 1                                                                    *
* If inDataPitch1 is lesser than or equal to                                              *
* 32 this function is called.                                                             *
******************************************************************************************/

static _XAI_INLINE_ void MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_4x4j1d1), S8IX_MOW_WHD_FOLD32) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Pitches of Coefficient Data (WHDN) in dim1 and dim3 */
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  const uint8_t leftEdgeFlag = XAI_CNN_CONV_GET_FLAG_LEFTEDGE(param);
  const uint8_t topEdgeFlag  = XAI_CNN_CONV_GET_FLAG_TOPEDGE(param);
  int32_t leftEdge, topEdge;

  leftEdge = leftEdgeFlag ? (kSizeU / 2) : ((kSizeU / 2) - 1);
  topEdge  = topEdgeFlag ? (kSizeU / 2) : ((kSizeU / 2) - 1);

  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-(topEdge * inDataPitch1 + leftEdge)];


  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 *restrict pdvecIn1;
  MORPH_IDT_2Nx8 *restrict pdvecIn2;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1;
  xb_vec2Nx8* restrict pdvecCoeff2;

  /* Variable Declarations */
  int32_t inCh, outCh, y;
  int32_t inDataPitch1_2X = 2 * inDataPitch1;

  /* loop across output channels and output height are unrolled twice
   * to produce four output vectors in 1 iteration
   */
  for (y = 0; y < outH; y += 2)   /* Loop across output height */
  {
    /* in order to hanlde odd output height */
    int32_t enable2Row = XT_SALT(y, outH - 1);
    /* initialize output data pointer */
    int8_t *pOutput = &pOutData[(y * outDataPitch1) * bytesPerPixel];

    /* initialize coeff and Bias data pointer */
    int8_t *pCoeff = &pCoeffData[0];
    int32_t *pBias = &pBiasData[0];

    for (outCh = 0; outCh < numOutCh; outCh += 2)    /* Loop across Output depth */
    {
      /* In order to handle odd output depths */
      int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

      /* Load the bias values corresponding to two output channels */
      xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
      xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

      /* wide vectors(accumulators) initialized with bias */
      xb_vec2Nx24 dacc1, dacc2;

      dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
      IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);

      dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
      IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);

      /* priming of coeff load is done outside the innermost loop*/
      pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
      valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

      pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
      valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y];

      for (inCh = 0; inCh < numInCh; inCh++)    /* Loop across input channels */
      {
        /* vectors for coeff and input loads */
        xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2;
        MORPH_IDT_2Nx8 dvecInData1, dvecInData2, dvecInData3, dvecInData4;

        /* load data from first 2 input rows */
        pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
        pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch1);
        pInput  += inDataPitch2;

        /* load data from 2 input rows [Row0 | Row1] */
        valign vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        MORPH_OP_LOAD_2Nx8(dvecInData1, vaInData1, pdvecIn1, inDataPitch1_2X);

        /* load data from 2 input rows [Row1 | Row2] */
        valign vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        MORPH_OP_LOAD_2Nx8(dvecInData2, vaInData2, pdvecIn2, inDataPitch1_2X);

        /* load data from next 2 input rows [Row2 | Row3] */
        MORPH_OP_LOAD_2Nx8(dvecInData3, vaInData1, pdvecIn1, inDataPitch1_2X);

        /* load data from next 2 input rows [ex: Row3 | Row4] */
        MORPH_OP_LOAD_2Nx8(dvecInData4, vaInData2, pdvecIn2, inDataPitch1_2X);

        /* load all the 4x4 coefficients for 2 output depths*/
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, 16);
        IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, 16);

        /* 4 vector loads are used to load 5 rows of input. Two output channels are
           processed at a time. */
        MORPH_OP_MUL4TA(dacc1, dvecInData1, dvecInData1, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc1, dvecInData2, dvecInData2, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
        MORPH_OP_MUL4TA(dacc1, dvecInData3, dvecInData3, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
        MORPH_OP_MUL4TA(dacc1, dvecInData4, dvecInData4, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));

        MORPH_OP_MUL4TA(dacc2, dvecInData1, dvecInData1, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
        MORPH_OP_MUL4TA(dacc2, dvecInData2, dvecInData2, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
        MORPH_OP_MUL4TA(dacc2, dvecInData3, dvecInData3, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
        MORPH_OP_MUL4TA(dacc2, dvecInData4, dvecInData4, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
      }    /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

      /* Pack, Output Scale, Output Shift and clamping */
      xb_vec2Nx8 dvecOut1L, dvecOut2L;
      xb_vec2Nx8 dvecOut1H, dvecOut2H;
#if DILATED_VQ_CONV == VQ_TRUE
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                    pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                    pOutScaleData[outCh + enable2ndCh ], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                    outScale, outShiftU, minLim, maxLim, typeFlag);
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                    outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
      /* Storing the first output depth, first row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput);
      valign vaOutData = IVP_ZALIGN();
      IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the first output depth, second row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2Row * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * enable2Row * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, first row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
      IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second output depth, second row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                            outDataPitch1 * enable2Row) * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut2H, dvecOut2L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)),
                     vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * \
                     enable2Row * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      pOutput += 2 * outDataPitch2 * bytesPerPixel;
      pCoeff  += 2 * coeffPitch3;
    }  /* end of for (outCh = 0; outCh < numOutCh; outCh += 2)*/
  }    /* end of for (y = 0; y < outH; y += 2)*/
}

/*****************************************************************************
*  xaiConvolved(VQ)3D_S_4x4j1d1I8S8IX_MOW_WHD
*  **************************************************************************/
/********************************************************************************/
/* Description : P6 optimized generic implementation for 4x4 3D convolution with*/
/*               dilation = 1. Based on MORPH pre-processor specifiers, code    */
/*               implementation is generated during preprocessing stage. This   */
/*               method can be used to generate 4x4 3D convolution dilated      */
/*               function and 4x4 3D VQ convolution dilated function for U8 bit */
/*               and S8 bit input data with input stride equal to 1             */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                  */
/*               Output scale array, CNN convolution params structure           */
/* Outputs     : XI Error Code                                                  */
/* InOuts      : Output Tile                                                    */
/* Assumptions : CoeffData is S8                                                */
/*               biasArray is signed 32b, value not exceeding signed 24b        */
/*               Output scale array is U16                                      */
/*               OutData is S8 / U8 / S16                                       */
/*               Kernel Size is 4x4xDxN                                         */
/*               Input and Output are in WHD format                             */
/*               Coeff is in WHDN format                                        */
/********************************************************************************/

/****************** xaiConvolvedVQ3D_S_4x4j1d1_S8S8IX_MOW_WHD ******************/
/****************** xaiConvolvedVQ3D_S_4x4j1d1_U8S8IX_MOW_WHD ******************/
/******************* xaiConvolved3D_S_4x4j1d1_S8S8IX_MOW_WHD *******************/
/******************* xaiConvolved3D_S_4x4j1d1_U8S8IX_MOW_WHD *******************/

XAI_ERR_TYPE MAKE_NAME(MAKE_NAME_VQ(xaiConvolved, 3D_S_4x4j1d1), S8IX_MOW_WHD) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Error Checks */
  XAI_ERROR_CHECKS()
  {
    MORPH_IDT_CHECK(inTile);
    XAI_CHECK_CONV_OUTPUT_TILE3D(outTile);
    XAI_CHECK_TILE4D_S8(coeffTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(outTile);
    XAI_CHECK_TILE4D_IN_DRAM_BOUNDARY(coeffTile);
    XAI_CHECK_POINTER(param);
    XAI_CHECK_ARRAY_S32(biasArray);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(inTile, outTile);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(coeffTile, outTile);
    XAI_CHECK_KERNEL_SIZE(coeffTile, 4);
    XAI_CHECK_TILE3D_DATA_ORDER(inTile, XAI_WHD);
    XAI_CHECK_TILE3D_DATA_ORDER(outTile, XAI_WHD);
    XAI_CHECK_TILE4D_DATA_ORDER(coeffTile, XAI_WHDN);
    XAI_CHECK_DILATION(param, 1);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_DILATIONX(param) == XAI_CNN_CONV_GET_DILATIONY(param),                                           \
                    XAI_ERR_BADARG, "Dilation along width = %hhu and height = %hhu\nDilation along width and height should be equal", \
                    XAI_CNN_CONV_GET_DILATIONX(param), XAI_CNN_CONV_GET_DILATIONY(param));
    XAI_CHECK_STRIDE(param, 1);
    XAI_CHECK_ERROR((XAI_CNN_CONV_GET_STRIDEX(param) == XAI_CNN_CONV_GET_STRIDEY(param)),                                           \
                    XAI_ERR_BADARG, "\nStride along width = %hhu and height = %hhu\nStride along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_EDGES_MOW_WHD(inTile, coeffTile, param);
    XAI_CHECK_CONSISTENCY_MOW_WHD(inTile, coeffTile, biasArray, outTile, param);
    XAI_CHECK_COEFFTILE_CONTIGUOUS(coeffTile, param);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_ACCUM_SHIFT(param) < 24,                                     \
                    XAI_ERR_NORM, "\nThe accumulator shift = %hhu, value should be less than 24", \
                    XAI_CNN_CONV_GET_ACCUM_SHIFT(param));
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_OUTPUT_SHIFT(param) < 32,                               \
                    XAI_ERR_NORM, "\nThe output shift = %hhu, value should be less than 32", \
                    XAI_CNN_CONV_GET_OUTPUT_SHIFT(param));
    XAI_CHECK_CONV_RELU_LIMITS_IX(param, outTile);
#if DILATED_VQ_CONV == VQ_TRUE
    XAI_CHECK_ARRAY_U16(outputScaleArray);
    XAI_CHECK_ERROR(XAI_ARRAY_GET_WIDTH(outputScaleArray) >= XAI_TILE4D_GET_DIM4(coeffTile),                                                                                          \
                    XAI_ERR_DATASIZE, "\nWidth of Output Scale Array = %d, Number of Kernels = %d\nWidth of Output Scale Array should be greater than or equal to Number of Kernels", \
                    XAI_ARRAY_GET_WIDTH(outputScaleArray), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_ERROR((((uintptr_t) (XAI_ARRAY_GET_DATA_PTR(outputScaleArray)) & \
                      0x1) == 0), XAI_ERR_NORM, "The output scale array is not aligned to 2 byte boundary");
#endif
  }
#if DILATED_VQ_CONV == VQ_FALSE
  if (XAI_CNN_CONV_GET_OUTPUT_SCALE(param) == 0)
  {
    int32_t fillValue;
    int32_t reluFlag = XAI_CNN_CONV_GET_FLAG_RELU(param);
    fillValue = reluFlag ? (CLAMP(0, XAI_CNN_CONV_GET_RELU_MIN(param), XAI_CNN_CONV_GET_RELU_MAX(param))) : 0;
    return(xaiFillTile3D(outTile, fillValue, 0));
  }
#endif

  /* check inDataPitch1, if it is less than or equal to 16,
   * call FOLD32 variant otherwise continue
   */

  if (XAI_TILE3D_GET_DIM1_PITCH(inTile) <= 16)
  {
    MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_4x4j1d1), S8IX_MOW_WHD_FOLD16) MAKE_PARAMS(inTile, coeffTile, biasArray, outTile, param);
    return(XAI_ERROR_STATUS());
  }

  /* check inDataPitch1, if it is less than or equal to 32,
   * call FOLD32 variant otherwise continue
   */

  if (XAI_TILE3D_GET_DIM1_PITCH(inTile) <= 32)
  {
    MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_4x4j1d1), S8IX_MOW_WHD_FOLD32) MAKE_PARAMS(inTile, coeffTile, biasArray, outTile, param);
    return(XAI_ERROR_STATUS());
  }

  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Pitches of Coefficient Data (WHDN) in dim1 and dim3 */
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  const uint8_t leftEdgeFlag = XAI_CNN_CONV_GET_FLAG_LEFTEDGE(param);
  const uint8_t topEdgeFlag  = XAI_CNN_CONV_GET_FLAG_TOPEDGE(param);
  int32_t leftEdge, topEdge;

  leftEdge = leftEdgeFlag ? (kSizeU / 2) : ((kSizeU / 2) - 1);
  topEdge  = topEdgeFlag ? (kSizeU / 2) : ((kSizeU / 2) - 1);

  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-(topEdge * inDataPitch1 + leftEdge)];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 *restrict pdvecIn;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1;
  xb_vec2Nx8* restrict pdvecCoeff2;

  /* Variable Declarations */
  int32_t inCh, outCh, x, y;
  /* In order to make the loop multiply-bound we are reducing the vectorization width
     by extra values required for the kernel */
  const int32_t vectorizationWidth = ((2 * XCHAL_IVPN_SIMD_WIDTH) - kSizeU) + 1;

  /* loop across output channels and output height are unrolled twice
   * to produce four output vectors in 1 iteration
   */
  for (x = 0; x < outW; x += vectorizationWidth) /* Loop across output width */
  {
    for (y = 0; y < outH; y++)   /* Loop across output height */
    {
      /* in order to handle odd output height */

      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y + x];

      /* initialize coeff and Bias data pointer */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 2)    /* Loop across Output depth */
      {
        /* In order to handle odd output depths */
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

        /* Load the bias values corresponding to two output channels */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc11, dacc21;

        dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);

        dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

        /* Input vector pointer initialization */
        pdvecIn = (MORPH_IDT_2Nx8 *) (pInput);

        for (inCh = 0; inCh < numInCh; inCh++)    /* Loop across input channels */
        {
          /* vectors for coeff and input loads */
          xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2;
          MORPH_IDT_2Nx8 dvecInData1, dvecInData2, dvecInData3, dvecInData4;

          /* load data from first input row */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData1, vaInData, pdvecIn, inDataPitch1);

          /* load data from 2nd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData2, vaInData, pdvecIn, inDataPitch1);

          /* load data from 3rd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData3, vaInData, pdvecIn, inDataPitch1);

          /* load data from 4th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData4, vaInData, pdvecIn, inDataPitch2 - (3 * inDataPitch1));

          /* load all the 4x4 coefficients for 2 output depths*/
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, 16);
          IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, 16);

          /* Multiply and accumulate 1st set of 4 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc11, dvecInData1, dvecInData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));

          MORPH_OP_MUL4TA(dacc21, dvecInData1, dvecInData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

          /* Multiply and accumulate 2nd set of 4 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc11, dvecInData2, dvecInData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc21, dvecInData2, dvecInData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));

          /* Multiply and accumulate 3rd set of 4 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc11, dvecInData3, dvecInData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));

          MORPH_OP_MUL4TA(dacc21, dvecInData3, dvecInData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));

          /* Multiply and accumulate 3rd set of 4 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc11, dvecInData4, dvecInData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));

          MORPH_OP_MUL4TA(dacc21, dvecInData4, dvecInData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
        }    /* end of for (inCh = 0; inCh < numInCh; inCh++)*/


        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc21, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc21, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* variable length for output stores */
        int32_t varLen = XT_MIN(vectorizationWidth, outW - x);

        /* Storing the first output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * varLen);
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * enable2ndCh * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 2 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 2 * coeffPitch3;
      }  /* end of for (outCh = 0; outCh < numOutCh; outCh += 2)*/
    }    /* end of for (y = 0; y < outH; y += 2)*/
  }      /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  return(XAI_ERROR_STATUS());
}

/******************************************************************************************
* 5x5 MOW WHD Stride 1 - DEPTH 3                                                          *
* If number of input channels is equal to 3                                               *
* this function is called.                                                                *
******************************************************************************************/

static _XAI_INLINE_ void MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_5x5j1d1), S8IX_MOW_WHD_DEPTH3) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Pitch of Coefficient Data (WHDN) in dim3 */
  const int32_t coeffPitch2 = XAI_TILE4D_GET_DIM2_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Kernel Size (WHDN) */
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-((kSizeU / 2) * inDataPitch1 + (kSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8* restrict pdvecIn;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff;

  /* Variable Declarations */
  int32_t outCh, x, y;
  int32_t varLen;

  /* Vectorization width is 124 */
  const int32_t vectorizationWidth = ((4 * XCHAL_IVPN_SIMD_WIDTH) - kSizeU) + 1;

  /* The number of inchannels is 3. In the implementation 3 channels of
   * coefficient tile is loaded into two vectors and select operation
   * the values are arranged so that quad muls can be used.
   * First load(dveccoeff1) is used to load two channels of 5x5 coefficient
   * Second load(dveccoeff2) to load the third channel.
   * In dveccoeff1, 0 to 24 indices corresponds to channel 1 and 25 to 49
   * corresponds to channel 2.
   * Select pattern :
   * Pattern 1 :
   *   0,1,2,3 ,5,6,7,8 ,10,11,12,13 ,15,16,17,18 ,20,21,22,23 ,
   *   25,26,27,28, 30,31,32,33, 35,36,37,38, 40,41,42,43, 45,46,47,48
   *
   * Pattern 2 :
   *   0,1,2,3 ,5,6,7,8 ,10,11,12,13 ,15,16,17,18,  20,21,22,23 ,
   *   4,9,14,19, (4,9,14,19)+64, (4,9,14,19)+64+25, 24, 24+64, 24+64+25
   */



  xb_vec2Nx8 dvecPattern1, dvecPattern2, dvecTempPattern, dvecSelPattern;
  /*Pattern1 : 0,1,2,3 ,5,6,7,8 ,10,11,12,13 ,15,16,17,18 ,20,21,22,23 ,
              25,26,27,28, 30,31,32,33, 35,36,37,38, 40,41,42,43, 45,46,47,48 */
  dvecPattern1 = IVP_ADD2NX8(IVP_SEQ2NX8(), IVP_SRLI2NX8(IVP_SEQ2NX8(), 2));

  /*Pattern2 : 0,1,2,3 ,5,6,7,8 ,10,11,12,13 ,15,16,17,18,  20,21,22,23 ,
              4,9,14,19, (4,9,14,19)+64, (4,9,14,19)+64+25, 24, 24+64, 24+64+25 */

  /* dvecTempPattern 4,9,14,19, (4,9,14,19)+64, (4,9,14,19)+64+25*/
  dvecTempPattern = IVP_SLLI2NX8(IVP_ADD2NX8(IVP_AND2NX8(IVP_SEQ2NX8(), 3), 1), 2);
  dvecTempPattern = IVP_ADD2NX8(dvecTempPattern, IVP_AND2NX8(IVP_SEQ2NX8(), 3));
  IVP_ADD2NX8T(dvecTempPattern, dvecTempPattern, (2 * XCHAL_IVPN_SIMD_WIDTH), IVP_NOTB(IVP_LTR2N(4)));
  IVP_ADD2NX8T(dvecTempPattern, dvecTempPattern, 25, IVP_NOTB(IVP_LTR2N(8)));
  dvecSelPattern = IVP_SEQ2NX8();
  IVP_ADD2NX8T(dvecSelPattern, dvecSelPattern, ((xb_vec2Nx8U) (2 * XCHAL_IVPN_SIMD_WIDTH - 20)), IVP_NOTB(IVP_LTR2N(20)));
  dvecPattern2   = IVP_SEL2NX8(dvecTempPattern, dvecPattern1, dvecSelPattern);
  dvecSelPattern = IVP_SEQ2NX8();
  IVP_ADD2NX8T(dvecSelPattern, dvecSelPattern, ((xb_vec2Nx8U) (2 * XCHAL_IVPN_SIMD_WIDTH - 32)), IVP_NOTB(IVP_LTR2N(32)));
  dvecPattern2 = IVP_SEL2NX8(IVP_MOV2NX8_FROMNX16(IVP_MOVNX16_FROMN_2X32             \
                                                    (24 + (88 << 8) + (113 << 16))), \
                             dvecPattern2,
                             dvecSelPattern);

  /* loop across output height is unrolled twice and loops across inchannels,
   * kernel width and kernel height are completely unrolled
   */
  for (x = 0; x < outW; x += vectorizationWidth)  /* Loop across output width */
  {
    varLen = XT_MIN(vectorizationWidth, outW - x);
    /* In order to handle cases where input width <= 2*XCHAL_IVPN_SIMD_WIDTH, where
     * the 2nd load from the same row needs to be avoided.  */
    int32_t enable2ndCol = XT_SALT(2 * XCHAL_IVPN_SIMD_WIDTH, varLen + kSizeU - 1);

    for (y = 0; y < outH; y += 2) /* Loop across output height */
    {
      /* In order to handle odd output height */
      int32_t enable2ndRow = XT_SALT(y, outH - 1);

      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y + x];

      /* initialize coeff and Bias data pointer*/
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh++)  /* Loop across Output depth */
      {
        /* load and replicate bias data */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc1, dacc2, dacc3, dacc4;
        dacc1 = dacc2 = dacc3 = dacc4 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc2, hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc3, hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc4, hvecBias1, hvecBias1);

        /* Coefficient and Input data pointers */
        pdvecCoeff = (xb_vec2Nx8 *) (pCoeff);
        pdvecIn    = (MORPH_IDT_2Nx8 *) pInput;

        /* vectors for coeff and input loads */
        xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2;
        MORPH_IDT_2Nx8 dvecInData11, dvecInData21, dvecInData31, dvecInData41, dvecInData51;
        MORPH_IDT_2Nx8 dvecInData61, dvecInData71, dvecInData81, dvecInData91, dvecInDataA1;
        MORPH_IDT_2Nx8 dvecInData12, dvecInData22, dvecInData32, dvecInData42, dvecInData52;
        MORPH_IDT_2Nx8 dvecInData62, dvecInData72, dvecInData82, dvecInData92, dvecInDataA2;

        /* load 5x5 coefficients from three channels*/
        valign vaCoeffData; vaCoeffData = IVP_LA2NX8_PP(pdvecCoeff);
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData, pdvecCoeff, 2 * coeffPitch2);
        IVP_LA2NX8_IP(dvecCoeffData2, vaCoeffData, pdvecCoeff);

        /* Rearrange them so that 3 x 4 MUL4T, 4 MULQ can be used to perform entire operation */
        dvecCoeffData2 = IVP_SEL2NX8(dvecCoeffData1, dvecCoeffData2, dvecPattern2);
        dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecPattern1);

        /* Input Channel 1*/
        /* load data from first input row */
        valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 2nd input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 3rd input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData31, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData32, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 4th input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData41, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData42, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 5th input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData51, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData52, vaInData, pdvecIn, \
                           inDataPitch1 * enable2ndRow      \
                           - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 6th input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData61, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData62, vaInData, pdvecIn,                 \
                           inDataPitch2 - (4 + enable2ndRow) * inDataPitch1 \
                           - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);


        /* Multiply and accumulate 1st set of 4 coefficients for all the outputs */
        MORPH_OP_MUL4TA(dacc1, dvecInData12, dvecInData11, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc2, dvecInData12, dvecInData12, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc3, dvecInData22, dvecInData21, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc4, dvecInData22, dvecInData22, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));

        /* Multiply and accumulate 2nd set of 4 coefficients for all the outputs */
        MORPH_OP_MUL4TA(dacc1, dvecInData22, dvecInData21, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
        MORPH_OP_MUL4TA(dacc2, dvecInData22, dvecInData22, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
        MORPH_OP_MUL4TA(dacc3, dvecInData32, dvecInData31, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
        MORPH_OP_MUL4TA(dacc4, dvecInData32, dvecInData32, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* Multiply and accumulate 3rd set of 4 coefficients for all the outputs */
        MORPH_OP_MUL4TA(dacc1, dvecInData32, dvecInData31, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
        MORPH_OP_MUL4TA(dacc2, dvecInData32, dvecInData32, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
        MORPH_OP_MUL4TA(dacc3, dvecInData42, dvecInData41, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
        MORPH_OP_MUL4TA(dacc4, dvecInData42, dvecInData42, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));

        /* Multiply and accumulate 4th set of 4 coefficients for all the outputs */
        MORPH_OP_MUL4TA(dacc1, dvecInData42, dvecInData41, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
        MORPH_OP_MUL4TA(dacc2, dvecInData42, dvecInData42, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
        MORPH_OP_MUL4TA(dacc3, dvecInData52, dvecInData51, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
        MORPH_OP_MUL4TA(dacc4, dvecInData52, dvecInData52, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));

        /* Multiply and accumulate 5th set of 4 coefficients for all the outputs */
        MORPH_OP_MUL4TA(dacc1, dvecInData52, dvecInData51, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));
        MORPH_OP_MUL4TA(dacc2, dvecInData52, dvecInData52, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));
        MORPH_OP_MUL4TA(dacc3, dvecInData62, dvecInData61, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));
        MORPH_OP_MUL4TA(dacc4, dvecInData62, dvecInData62, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));

        /* Multiply and accumulate 6th set of 4 coefficients for all the outputs */
        MORPH_OP_MULQA(dacc1, IVP_SEL2NX8I(dvecInData42, dvecInData41, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData32, dvecInData31, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 6));

        MORPH_OP_MULQA(dacc2, IVP_SEL2NX8I(dvecInData42, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData32, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData22, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData12, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 6));

        MORPH_OP_MULQA(dacc3, IVP_SEL2NX8I(dvecInData52, dvecInData51, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData42, dvecInData41, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData32, dvecInData31, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 6));

        MORPH_OP_MULQA(dacc4, IVP_SEL2NX8I(dvecInData52, dvecInData52, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData42, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData32, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData22, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 6));

        /* Input data in channel 1, corresponding to 24th coefficient */
        dvecInData71 = IVP_SEL2NX8I(dvecInData52, dvecInData51, IVP_SELI_8B_ROTATE_RIGHT_4);
        dvecInData72 = IVP_SEL2NX8I(dvecInData52, dvecInData52, IVP_SELI_8B_ROTATE_RIGHT_4);
        dvecInData81 = IVP_SEL2NX8I(dvecInData62, dvecInData61, IVP_SELI_8B_ROTATE_RIGHT_4);
        dvecInData82 = IVP_SEL2NX8I(dvecInData62, dvecInData62, IVP_SELI_8B_ROTATE_RIGHT_4);

        /* Input Channel 2*/
        /* load data from first input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 2nd input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 3rd input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData31, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData32, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 4th input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData41, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData42, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 5th input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData51, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData52, vaInData, pdvecIn, \
                           inDataPitch1 * enable2ndRow      \
                           - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 6th input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData61, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData62, vaInData, pdvecIn,                 \
                           inDataPitch2 - (4 + enable2ndRow) * inDataPitch1 \
                           - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* Multiply and accumulate 1st set of 4 coefficients for all the outputs */
        MORPH_OP_MUL4TA(dacc1, dvecInData12, dvecInData11, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));
        MORPH_OP_MUL4TA(dacc2, dvecInData12, dvecInData12, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));
        MORPH_OP_MUL4TA(dacc3, dvecInData22, dvecInData21, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));
        MORPH_OP_MUL4TA(dacc4, dvecInData22, dvecInData22, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));

        /* Multiply and accumulate 2nd set of 4 coefficients for all the outputs */
        MORPH_OP_MUL4TA(dacc1, dvecInData22, dvecInData21, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 6));
        MORPH_OP_MUL4TA(dacc2, dvecInData22, dvecInData22, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 6));
        MORPH_OP_MUL4TA(dacc3, dvecInData32, dvecInData31, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 6));
        MORPH_OP_MUL4TA(dacc4, dvecInData32, dvecInData32, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 6));

        /* Multiply and accumulate 3rd set of 4 coefficients for all the outputs */
        MORPH_OP_MUL4TA(dacc1, dvecInData32, dvecInData31, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 7));
        MORPH_OP_MUL4TA(dacc2, dvecInData32, dvecInData32, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 7));
        MORPH_OP_MUL4TA(dacc3, dvecInData42, dvecInData41, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 7));
        MORPH_OP_MUL4TA(dacc4, dvecInData42, dvecInData42, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 7));

        /* Multiply and accumulate 4th set of 4 coefficients for all the outputs */
        MORPH_OP_MUL4TA(dacc1, dvecInData42, dvecInData41, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 8));
        MORPH_OP_MUL4TA(dacc2, dvecInData42, dvecInData42, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 8));
        MORPH_OP_MUL4TA(dacc3, dvecInData52, dvecInData51, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 8));
        MORPH_OP_MUL4TA(dacc4, dvecInData52, dvecInData52, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 8));

        /* Multiply and accumulate 5th set of 4 coefficients for all the outputs */
        MORPH_OP_MUL4TA(dacc1, dvecInData52, dvecInData51, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 9));
        MORPH_OP_MUL4TA(dacc2, dvecInData52, dvecInData52, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 9));
        MORPH_OP_MUL4TA(dacc3, dvecInData62, dvecInData61, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 9));
        MORPH_OP_MUL4TA(dacc4, dvecInData62, dvecInData62, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 9));

        /* Multiply and accumulate 6th set of 4 coefficients for all the outputs */
        MORPH_OP_MULQA(dacc1, IVP_SEL2NX8I(dvecInData42, dvecInData41, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData32, dvecInData31, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 7));

        MORPH_OP_MULQA(dacc2, IVP_SEL2NX8I(dvecInData42, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData32, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData22, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData12, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 7));

        MORPH_OP_MULQA(dacc3, IVP_SEL2NX8I(dvecInData52, dvecInData51, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData42, dvecInData41, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData32, dvecInData31, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 7));

        MORPH_OP_MULQA(dacc4, IVP_SEL2NX8I(dvecInData52, dvecInData52, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData42, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData32, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData22, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 7));

        /* Input data in channel 2, corresponding to 24th coefficient */
        dvecInData91 = IVP_SEL2NX8I(dvecInData52, dvecInData51, IVP_SELI_8B_ROTATE_RIGHT_4);
        dvecInData92 = IVP_SEL2NX8I(dvecInData52, dvecInData52, IVP_SELI_8B_ROTATE_RIGHT_4);
        dvecInDataA1 = IVP_SEL2NX8I(dvecInData62, dvecInData61, IVP_SELI_8B_ROTATE_RIGHT_4);
        dvecInDataA2 = IVP_SEL2NX8I(dvecInData62, dvecInData62, IVP_SELI_8B_ROTATE_RIGHT_4);

        /* Input Channel 3*/
        /* load data from first input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 2nd input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 3rd input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData31, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData32, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 4th input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData41, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData42, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 5th input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData51, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData52, vaInData, pdvecIn, \
                           inDataPitch1 * enable2ndRow      \
                           - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 6th input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData61, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData62, vaInData, pdvecIn,                 \
                           inDataPitch2 - (4 + enable2ndRow) * inDataPitch1 \
                           - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* Multiply and accumulate 1st set of 4 coefficients for all the outputs */
        MORPH_OP_MUL4TA(dacc1, dvecInData12, dvecInData11, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
        MORPH_OP_MUL4TA(dacc2, dvecInData12, dvecInData12, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
        MORPH_OP_MUL4TA(dacc3, dvecInData22, dvecInData21, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
        MORPH_OP_MUL4TA(dacc4, dvecInData22, dvecInData22, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

        /* Multiply and accumulate 2nd set of 4 coefficients for all the outputs */
        MORPH_OP_MUL4TA(dacc1, dvecInData22, dvecInData21, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
        MORPH_OP_MUL4TA(dacc2, dvecInData22, dvecInData22, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
        MORPH_OP_MUL4TA(dacc3, dvecInData32, dvecInData31, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
        MORPH_OP_MUL4TA(dacc4, dvecInData32, dvecInData32, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));

        /* Multiply and accumulate 3rd set of 4 coefficients for all the outputs */
        MORPH_OP_MUL4TA(dacc1, dvecInData32, dvecInData31, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
        MORPH_OP_MUL4TA(dacc2, dvecInData32, dvecInData32, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
        MORPH_OP_MUL4TA(dacc3, dvecInData42, dvecInData41, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
        MORPH_OP_MUL4TA(dacc4, dvecInData42, dvecInData42, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));

        /* Multiply and accumulate 4th set of 4 coefficients for all the outputs */
        MORPH_OP_MUL4TA(dacc1, dvecInData42, dvecInData41, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
        MORPH_OP_MUL4TA(dacc2, dvecInData42, dvecInData42, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
        MORPH_OP_MUL4TA(dacc3, dvecInData52, dvecInData51, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
        MORPH_OP_MUL4TA(dacc4, dvecInData52, dvecInData52, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));

        /* Multiply and accumulate 5th set of 4 coefficients for all the outputs */
        MORPH_OP_MUL4TA(dacc1, dvecInData52, dvecInData51, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 4));
        MORPH_OP_MUL4TA(dacc2, dvecInData52, dvecInData52, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 4));
        MORPH_OP_MUL4TA(dacc3, dvecInData62, dvecInData61, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 4));
        MORPH_OP_MUL4TA(dacc4, dvecInData62, dvecInData62, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 4));

        /* Multiply and accumulate 6th set of 4 coefficients for all the outputs */
        MORPH_OP_MULQA(dacc1, IVP_SEL2NX8I(dvecInData42, dvecInData41, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData32, dvecInData31, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 5));

        MORPH_OP_MULQA(dacc2, IVP_SEL2NX8I(dvecInData42, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData32, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData22, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData12, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 5));

        MORPH_OP_MULQA(dacc3, IVP_SEL2NX8I(dvecInData52, dvecInData51, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData42, dvecInData41, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData32, dvecInData31, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 5));

        MORPH_OP_MULQA(dacc4, IVP_SEL2NX8I(dvecInData52, dvecInData52, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData42, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData32, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData22, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 5));

        /* Multiply and accumulate the data corresponding to 24th coefficient */
        MORPH_OP_MULQA(dacc1, 0, dvecInData91, dvecInData71,
                       IVP_SEL2NX8I(dvecInData52, dvecInData51, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 8));

        MORPH_OP_MULQA(dacc2, 0, dvecInData92, dvecInData72,
                       IVP_SEL2NX8I(dvecInData52, dvecInData52, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 8));

        MORPH_OP_MULQA(dacc3, 0, dvecInDataA1, dvecInData81,
                       IVP_SEL2NX8I(dvecInData62, dvecInData61, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 8));

        MORPH_OP_MULQA(dacc4, 0, dvecInDataA2, dvecInData82,
                       IVP_SEL2NX8I(dvecInData62, dvecInData62, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 8));


        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* 1st row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * \
                       (varLen - 2 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                       2 * (varLen - 3 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* 2nd row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndRow * outDataPitch1 * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * varLen);
        IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * enable2ndRow * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * \
                       (varLen - 2 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * enable2ndRow * \
                       2 * (varLen - 3 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += outDataPitch2 * bytesPerPixel;
        pCoeff  += coeffPitch3;
      } /* end of for (outCh = 0; outCh < numOutCh; outCh++)*/
    }   /* end of for (y = 0; y < outH; y += 2)*/
  }    /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
}


/******************************************************************************************
*   xaiConvolved(VQ)3D_S_5x5j1d1I8S8IX_MOW_WHD_FOLD16
*  ***************************************************************************************/

/******************************************************************************/
/* Description : P6 optimized generic implementation for 5x5 3D convolution.  */
/*               Based on MORPH pre-processor specifiers, code implementation */
/*               is generated during preprocessing stage. This method can be  */
/*               used to generate 5x5 3D dilated convolution function and 5x5 */
/*               3D VQ dilated convolution function for U8 bit and S8 bit     */
/*               input data with input stride equal to 1.                     */
/*               If inDataPitch1 <= 16, this function variant is called.      */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                */
/*               Output scale array, CNN convolution params structure         */
/* InOuts      : Output Tile                                                  */
/* Assumptions : CoeffData is S8                                              */
/*               biasArray is signed 32b, value not exceeding signed 24b      */
/*               Output scale array is U16                                    */
/*               OutData is S8 / U8 / S16                                     */
/*               Kernel Size is 5x5xDxN                                       */
/*               Input and Output are in WHD format                           */
/*               Coeff is in WHDN format                                      */
/******************************************************************************/

static _XAI_INLINE_ void MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_5x5j1d1), S8IX_MOW_WHD_FOLD16) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Pitche of Coefficient Data (WHDN) in dim3 */
  const int32_t coeffPitch2 = XAI_TILE4D_GET_DIM2_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Kernel Size (WHDN) */
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-((kSizeU / 2) * inDataPitch1 + (kSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 * restrict pdvecIn;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1;

  /* Variable Declarations */
  int32_t inCh, outCh, y;

  /* generates the sequence 0,1,2,3 ,5,6,7,8 ,10,11,12,13 ,15,16,17,18
   * , 20,21,22,23 ,4,9,14,19 ,24. To be used to shuffle the coeff data,
   * So that last coeff from first 4 rows of coeffs can be used as one
   * 32 byte element and make use of quad multiplier outside the inner-
   * most loop.
   * c11, c12, c13, c14, c15
   * c21, c22, c23, c24, c25
   * c31, c32, c33, c34, c35
   * c41, c42, c43, c44, c45
   * c51, c52, c53, c54, c55
   *
   * c15, c25, c35, c45 and c55 are placed in contiguous fashion, so that
   * c15, c25, c35, and c45 can be used as one 32 byte element
   */
  xb_vec2Nx8 dvecIdx;
  dvecIdx = IVP_SEL2NX8I(IVP_SEL2NX8I(IVP_ADD2NX8U(IVP_SEQ2NX8(), 15),
                                      IVP_ADD2NX8U(IVP_SEQ2NX8(), 10),
                                      IVP_SELI_INTERLEAVE_2_LO),
                         IVP_SEL2NX8I(IVP_ADD2NX8U(IVP_SEQ2NX8(), 5), IVP_SEQ2NX8(),
                                      IVP_SELI_INTERLEAVE_2_LO),
                         IVP_SELI_INTERLEAVE_4_LO);

  dvecIdx = IVP_SEL2NX8I(IVP_SEL2NX8I(IVP_MOV2NX8U_FROMNX16(
                                        IVP_MOVNX16_FROMN_2X32(4 + (9 << 8) + (14 << 16) + \
                                                               (19 << 24))),
                                      IVP_ADD2NX8U(IVP_SEQ2NX8(), 20), IVP_SELI_INTERLEAVE_2_LO),
                         dvecIdx, IVP_SELI_8B_PACK_16);

  /* Select sequence to re-arrange input data */
  xb_vec2Nx8 dvecSeq1 = 0;
  IVP_ADD2NX8T(dvecSeq1, IVP_SEQ2NX8(), inDataPitch1, IVP_LT2NX8(IVP_SEQ2NX8(), 3 * inDataPitch1));
  IVP_ADD2NX8T(dvecSeq1, IVP_SUB2NX8(IVP_SEQ2NX8(), 3 * inDataPitch1), 2 * XCHAL_IVPN_SIMD_WIDTH, \
               IVP_NOTB2N(IVP_LT2NX8(IVP_SEQ2NX8(), 3 * inDataPitch1)));

  xb_vec2Nx8 dvecSeq2 = 0;
  IVP_ADD2NX8T(dvecSeq2, IVP_SEQ2NX8(), 2 * inDataPitch1, \
               IVP_LT2NX8(IVP_SEQ2NX8(), 2 * inDataPitch1));
  IVP_ADD2NX8T(dvecSeq2, IVP_SUB2NX8(IVP_SEQ2NX8(), 2 * inDataPitch1), 2 * XCHAL_IVPN_SIMD_WIDTH, \
               IVP_NOTB2N(IVP_LT2NX8(IVP_SEQ2NX8(), 2 * inDataPitch1)));

  xb_vec2Nx8 dvecSeq3 = 0;
  IVP_ADD2NX8T(dvecSeq3, IVP_SEQ2NX8(), 3 * inDataPitch1, \
               IVP_LT2NX8(IVP_SEQ2NX8(), 3 * inDataPitch1));
  IVP_ADD2NX8T(dvecSeq3, IVP_SUB2NX8(IVP_SEQ2NX8(), inDataPitch1), 2 * XCHAL_IVPN_SIMD_WIDTH, \
               IVP_NOTB2N(IVP_LT2NX8(IVP_SEQ2NX8(), inDataPitch1)));


  /* loop across output height is unrolled 4 times and
   * loop across kernel width and height is completely unrolled
   */
  for (y = 0; y < outH; y += 4) /* Loop across output height */
  {
    /* In order to handle odd output height */
    int32_t enable2ndRow = XT_SALT(y, outH - 1);
    int32_t enable3rdRow = XT_SALT(y, outH - 2);
    int32_t enable4thRow = XT_SALT(y, outH - 3);

    /* initialize output data pointer */
    int8_t *pOutput = &pOutData[(y * outDataPitch1) * bytesPerPixel];

    /* initialize coeff and Bias data pointer*/
    int8_t *pCoeff = &pCoeffData[0];
    int32_t *pBias = &pBiasData[0];

    for (outCh = 0; outCh < numOutCh; outCh++)  /* Loop across Output depth */
    {
      /* load and replicate bias data */
      xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4);

      /* wide vectors(accumulators) initialized with bias */
      xb_vec2Nx24 dacc1;
      dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
      IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);

      /* priming of coeff load is done outside the innermost loop*/
      pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
      valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y];
      pdvecIn = (MORPH_IDT_2Nx8 *) pInput;

      for (inCh = 0; inCh < numInCh; inCh++)  /* Loop across input channels */
      {
        /* vectors for coeff and input loads */
        xb_vec2Nx8 dvecCoeffData1;
        xb_vec2Nx8 dvecInData1, dvecInData2, dvecInData3, dvecInData4, dvecInData5;

        /* load data from 5 rows */
        valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData1, vaInData, pdvecIn, inDataPitch1);
        MORPH_OP_LOAD_2Nx8(dvecInData2, vaInData, pdvecIn, inDataPitch1);
        MORPH_OP_LOAD_2Nx8(dvecInData3, vaInData, pdvecIn, inDataPitch1);
        MORPH_OP_LOAD_2Nx8(dvecInData4, vaInData, pdvecIn, inDataPitch1);
        MORPH_OP_LOAD_2Nx8(dvecInData5, vaInData, pdvecIn, inDataPitch2 - (4 * inDataPitch1));

        /* dvecInData1: row0 | row1 | row2 | row3
         * dvecInData2: row1 | row2 | row3 | row4
         * dvecInData3: row2 | row3 | row4 | row5
         * dvecInData4: row3 | row4 | row5 | row6
         * dvecInData5: row4 | row5 | row6 | row7
         */

        /* load all the 5x5 coefficients */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch2);

        /*Rearrange them so that 4 MUL4T, 1 MULQ & 1 MUL can be used to perform entire operation*/
        dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);

        /* Multiply and accumulate using 1st set of 4 coefficients */
        MORPH_OP_MUL4TA(dacc1, dvecInData1, dvecInData1, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));

        /* Multiply and accumulate using 2nd set of 4 coefficients */
        MORPH_OP_MUL4TA(dacc1, dvecInData2, dvecInData2, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* Multiply and accumulate using 3rd set of 4 coefficients */
        MORPH_OP_MUL4TA(dacc1, dvecInData3, dvecInData3, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));

        /* Multiply and accumulate using 4th set of 4 coefficients */
        MORPH_OP_MUL4TA(dacc1, dvecInData4, dvecInData4, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));

        /* Multiply and accumulate using 5th set of 4 coefficients */
        MORPH_OP_MUL4TA(dacc1, dvecInData5, dvecInData5, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));

        /* Multiply and accumulate using 6th set of 4 coefficients */
        MORPH_OP_MULQA(dacc1, IVP_SEL2NX8I(dvecInData4, dvecInData4, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData3, dvecInData3, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData2, dvecInData2, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData1, dvecInData1, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));

        /* Multiply and accumulate using the final coefficient */
        MORPH_OP_MULA(dacc1, IVP_SEL2NX8I(dvecInData5, dvecInData5, IVP_SELI_8B_ROTATE_RIGHT_4),
                      IVP_EXTR2NX8(dvecCoeffData1, 24));
      }  /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

      /* Pack, Output Scale, Output Shift and clamping */
      xb_vec2Nx8 dvecOut1L, dvecOut1H;
#if DILATED_VQ_CONV == VQ_TRUE
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                    pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                    outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
      /* Storing the first row output */
      pdvecOut = (xb_vec2Nx8 *) (pOutput);
      valign vaOutData = IVP_ZALIGN();
      IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second row output */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndRow * outDataPitch1 * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L,                                      \
                                 IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the third row output */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + enable3rdRow * 2 * outDataPitch1 * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L,                                          \
                                 IVP_ADD2NX8(IVP_SEQ2NX8(), 2 * inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * enable3rdRow * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the fourth row output */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + enable4thRow * 3 * outDataPitch1 * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L,                                          \
                                 IVP_ADD2NX8(IVP_SEQ2NX8(), 3 * inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * enable4thRow * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      pOutput += outDataPitch2 * bytesPerPixel;
      pCoeff  += coeffPitch3;
    } /* end of for (outCh = 0; outCh < numOutCh; outCh ++)*/
  }   /* end of for (y = 0; y < outH; y += 4)*/
}

/******************************************************************************************
*   xaiConvolved(VQ)3D_S_5x5j1d1I8S8IX_MOW_WHD_FOLD32
*  ***************************************************************************************/

/******************************************************************************/
/* Description : P6 optimized generic implementation for 5x5 3D convolution.  */
/*               Based on MORPH pre-processor specifiers, code implementation */
/*               is generated during preprocessing stage. This method can be  */
/*               used to generate 5x5 3D dilated convolution function and 5x5 */
/*               3D VQ dilated convolution function for U8 bit and S8 bit     */
/*               input data with input stride equal to 1.                     */
/*               If inDataPitch1 <= 32, this function variant is called.      */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                */
/*               Output scale array, CNN convolution params structure         */
/* InOuts      : Output Tile                                                  */
/* Assumptions : CoeffData is S8                                              */
/*               biasArray is signed 32b, value not exceeding signed 24b      */
/*               Output scale array is U16                                    */
/*               OutData is S8 / U8 / S16                                     */
/*               Kernel Size is 5x5xDxN                                       */
/*               Input and Output are in WHD format                           */
/*               Coeff is in WHDN format                                      */
/******************************************************************************/

static _XAI_INLINE_ void MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_5x5j1d1), S8IX_MOW_WHD_FOLD32) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Pitche of Coefficient Data (WHDN) in dim3 */
  const int32_t coeffPitch2 = XAI_TILE4D_GET_DIM2_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Kernel Size (WHDN) */
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-((kSizeU / 2) * inDataPitch1 + (kSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 * restrict pdvecIn;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1;

  /* Variable Declarations */
  int32_t inCh, outCh, y;

  /* generates the sequence 0,1,2,3 ,5,6,7,8 ,10,11,12,13 ,15,16,17,18
   * , 20,21,22,23 ,4,9,14,19 ,24. To be used to shuffle the coeff data,
   * So that last coeff from first 4 rows of coeffs can be used as one
   * 32 byte element and make use of quad multiplier outside the inner-
   * most loop.
   * c11, c12, c13, c14, c15
   * c21, c22, c23, c24, c25
   * c31, c32, c33, c34, c35
   * c41, c42, c43, c44, c45
   * c51, c52, c53, c54, c55
   *
   * c15, c25, c35, c45 and c55 are placed in contigous fashion, so that
   * c15, c25, c35, and c45 can be used as one 32 byte element
   */
  xb_vec2Nx8 dvecIdx;
  dvecIdx = IVP_SEL2NX8I(IVP_SEL2NX8I(IVP_ADD2NX8U(IVP_SEQ2NX8(), 15),
                                      IVP_ADD2NX8U(IVP_SEQ2NX8(), 10),
                                      IVP_SELI_INTERLEAVE_2_LO),
                         IVP_SEL2NX8I(IVP_ADD2NX8U(IVP_SEQ2NX8(), 5), IVP_SEQ2NX8(),
                                      IVP_SELI_INTERLEAVE_2_LO),
                         IVP_SELI_INTERLEAVE_4_LO);

  dvecIdx = IVP_SEL2NX8I(IVP_SEL2NX8I(IVP_MOV2NX8U_FROMNX16(
                                        IVP_MOVNX16_FROMN_2X32(4 + (9 << 8) + (14 << 16) + \
                                                               (19 << 24))),
                                      IVP_ADD2NX8U(IVP_SEQ2NX8(), 20), IVP_SELI_INTERLEAVE_2_LO),
                         dvecIdx, IVP_SELI_8B_PACK_16);


  /* 3 Load operations are done t load the data    */
  /* 1st vector load vec1 - row0 | row1            */
  /* 2nd vector load vec3 - row2 | row3            */
  /* 3rd vector load vec5 - row4 | row5            */
  /* Select operation is used to get vec2 from     */
  /* vec1 and vec3; and vec4 from vec3 and vec5.   */
  /*                 vec2 - row1 | row2            */
  /*                 vec4 - row3 | row4            */

  xb_vec2Nx8 dvecSavSeq = IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel);
  /* loop across output height is unrolled twice and loop across kernel width and height is
   * completely unrolled
   */
  for (y = 0; y < outH; y += 2) /* Loop across output height */
  {
    /* In order to handle odd output height */
    int32_t enable2ndRow = XT_SALT(y, outH - 1);
    /* initialize output data pointer */
    int8_t *pOutput = &pOutData[(y * outDataPitch1) * bytesPerPixel];

    /* initialize coeff and Bias data pointer*/
    int8_t *pCoeff = &pCoeffData[0];
    int32_t *pBias = &pBiasData[0];

    for (outCh = 0; outCh < numOutCh; outCh++)  /* Loop across Output depth */
    {
      /* load and replicate bias data */
      xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4);

      /* wide vectors(accumulators) initialized with bias */
      xb_vec2Nx24 dacc1;
      dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
      IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);

      /* priming of coeff load is done outside the innermost loop*/
      pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
      valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y];
      pdvecIn = (MORPH_IDT_2Nx8 *) pInput;

      for (inCh = 0; inCh < numInCh; inCh++)  /* Loop across input channels */
      {
        /* vectors for coeff and input loads */
        xb_vec2Nx8 dvecCoeffData1;
        xb_vec2Nx8 dvecInData1, dvecInData2, dvecInData3, dvecInData4, dvecInData5;

        /* load data from five input rows */
        valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData1, vaInData, pdvecIn, inDataPitch1);
        MORPH_OP_LOAD_2Nx8(dvecInData2, vaInData, pdvecIn, inDataPitch1);
        MORPH_OP_LOAD_2Nx8(dvecInData3, vaInData, pdvecIn, inDataPitch1);
        MORPH_OP_LOAD_2Nx8(dvecInData4, vaInData, pdvecIn, inDataPitch1);
        MORPH_OP_LOAD_2Nx8(dvecInData5, vaInData, pdvecIn, inDataPitch2 - (4 * inDataPitch1));

        /* load all the 5x5 coefficients */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch2);

        /*Rearrange them so that 4 MUL4T, 1 MULQ & 1 MUL can be used to perform entire operation*/
        dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);

        /* Multiply and accumulate using 1st set of 4 coefficients */
        MORPH_OP_MUL4TA(dacc1, dvecInData1, dvecInData1, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));

        /* Multiply and accumulate using 2nd set of 4 coefficients */
        MORPH_OP_MUL4TA(dacc1, dvecInData2, dvecInData2, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* Multiply and accumulate using 3rd set of 4 coefficients */
        MORPH_OP_MUL4TA(dacc1, dvecInData3, dvecInData3, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));

        /* Multiply and accumulate using 4th set of 4 coefficients */
        MORPH_OP_MUL4TA(dacc1, dvecInData4, dvecInData4, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));

        /* Multiply and accumulate using 5th set of 4 coefficients */
        MORPH_OP_MUL4TA(dacc1, dvecInData5, dvecInData5, IVP_EXTRN_2X32( \
                          IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));

        /* Multiply and accumulate using 6th set of 4 coefficients */
        MORPH_OP_MULQA(dacc1, IVP_SEL2NX8I(dvecInData4, dvecInData4, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData3, dvecInData3, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData2, dvecInData2, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_SEL2NX8I(dvecInData1, dvecInData1, IVP_SELI_8B_ROTATE_RIGHT_4),
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));

        /* Multiply and accumulate using the final coefficient */
        MORPH_OP_MULA(dacc1, IVP_SEL2NX8I(dvecInData5, dvecInData5, IVP_SELI_8B_ROTATE_RIGHT_4),
                      IVP_EXTR2NX8(dvecCoeffData1, 24));
      }  /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

      /* Pack, Output Scale, Output Shift and clamping */
      xb_vec2Nx8 dvecOut1L;
      xb_vec2Nx8 dvecOut1H;
#if DILATED_VQ_CONV == VQ_TRUE
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                    pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                    outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
      /* Storing the first row output */
      pdvecOut = (xb_vec2Nx8 *) (pOutput);
      valign vaOutData = IVP_ZALIGN();
      IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the second row output */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndRow * outDataPitch1 * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, dvecSavSeq), vaOutData, pdvecOut, \
                     bytesPerPixel * enable2ndRow * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      pOutput += outDataPitch2 * bytesPerPixel;
      pCoeff  += coeffPitch3;
    } /* end of for (outCh = 0; outCh < numOutCh; outCh++)*/
  }   /* end of for (y = 0; y < outH; y += 2)*/
}
/******************************************************************************************
*  xaiConvolved(VQ)3D_S_5x5j1d1I8S8IX_MOW_WHD
*  ***************************************************************************************/

/******************************************************************************/
/* Description : P6 optimized generic implementation for 5x5 3D convolution.  */
/*               Based on MORPH pre-processor specifiers, code implementation */
/*               is generated during preprocessing stage. This method can be  */
/*               used to generate 5x5 3D dilated convolution function and 5x5 */
/*               3D VQ dilated convolution function for U8 bit and S8 bit     */
/*               input data with input stride equal to 1                      */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                */
/*               Output scale array, CNN convolution params structure         */
/* Outputs     : XI Error Code                                                */
/* InOuts      : Output Tile                                                  */
/* Assumptions : CoeffData is S8                                              */
/*               biasArray is signed 32b, value not exceeding signed 24b      */
/*               Output scale array is U16                                    */
/*               OutData is S8 / U8 / S16                                     */
/*               Kernel Size is 5x5xDxN                                       */
/*               Input and Output are in WHD format                           */
/*               Coeff is in WHDN format                                      */
/******************************************************************************/

/****************** xaiConvolvedVQ3D_S_5x5j1d1_S8S8IX_MOW_WHD ******************/
/****************** xaiConvolvedVQ3D_S_5x5j1d1_U8S8IX_MOW_WHD ******************/
/******************* xaiConvolved3D_S_5x5j1d1_S8S8IX_MOW_WHD *******************/
/******************* xaiConvolved3D_S_5x5j1d1_U8S8IX_MOW_WHD *******************/

XAI_ERR_TYPE MAKE_NAME(MAKE_NAME_VQ(xaiConvolved, 3D_S_5x5j1d1), S8IX_MOW_WHD) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Error Checks */
  XAI_ERROR_CHECKS()
  {
    MORPH_IDT_CHECK(inTile);
    XAI_CHECK_CONV_OUTPUT_TILE3D(outTile);
    XAI_CHECK_TILE4D_S8(coeffTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(outTile);
    XAI_CHECK_TILE4D_IN_DRAM_BOUNDARY(coeffTile);
    XAI_CHECK_POINTER(param);
    XAI_CHECK_ARRAY_S32(biasArray);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(inTile, outTile);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(coeffTile, outTile);
    XAI_CHECK_KERNEL_SIZE(coeffTile, 5);
    XAI_CHECK_TILE3D_DATA_ORDER(inTile, XAI_WHD);
    XAI_CHECK_TILE3D_DATA_ORDER(outTile, XAI_WHD);
    XAI_CHECK_TILE4D_DATA_ORDER(coeffTile, XAI_WHDN);
    XAI_CHECK_DILATION(param, 1);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_DILATIONX(param) == XAI_CNN_CONV_GET_DILATIONY(param),                                           \
                    XAI_ERR_BADARG, "Dilation along width = %hhu and height = %hhu\nDilation along width and height should be equal", \
                    XAI_CNN_CONV_GET_DILATIONX(param), XAI_CNN_CONV_GET_DILATIONY(param));
    XAI_CHECK_TILE3D_EDGE(inTile, 2);
    XAI_CHECK_STRIDE(param, 1);
    XAI_CHECK_ERROR((XAI_CNN_CONV_GET_STRIDEX(param) == XAI_CNN_CONV_GET_STRIDEY(param)),                                           \
                    XAI_ERR_BADARG, "\nStride along width = %hhu and height = %hhu\nStride along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_CONSISTENCY_MOW_WHD(inTile, coeffTile, biasArray, outTile, param);
    XAI_CHECK_COEFFTILE_CONTIGUOUS(coeffTile, param);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_ACCUM_SHIFT(param) < 24,                                   \
                    XAI_ERR_NORM, "The accumulator shift = %hhu, value should be less than 24", \
                    XAI_CNN_CONV_GET_ACCUM_SHIFT(param));
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_OUTPUT_SHIFT(param) < 32,                             \
                    XAI_ERR_NORM, "The output shift = %hhu, value should be less than 32", \
                    XAI_CNN_CONV_GET_OUTPUT_SHIFT(param));
    XAI_CHECK_CONV_RELU_LIMITS_IX(param, outTile);
#if DILATED_VQ_CONV == VQ_TRUE
    XAI_CHECK_ARRAY_U16(outputScaleArray);
    XAI_CHECK_ERROR(XAI_ARRAY_GET_WIDTH(outputScaleArray) >= XAI_TILE4D_GET_DIM4(coeffTile),                                                                                          \
                    XAI_ERR_DATASIZE, "\nWidth of Output Scale Array = %d, Number of Kernels = %d\nWidth of Output Scale Array should be greater than or equal to Number of Kernels", \
                    XAI_ARRAY_GET_WIDTH(outputScaleArray), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_ERROR((((uintptr_t) (XAI_ARRAY_GET_DATA_PTR(outputScaleArray)) & \
                      0x1) == 0), XAI_ERR_NORM, "The output scale array is not aligned to 2 byte boundary");
#endif
  }
#if DILATED_VQ_CONV == VQ_FALSE
  if (XAI_CNN_CONV_GET_OUTPUT_SCALE(param) == 0)
  {
    int32_t fillValue;
    int32_t reluFlag = XAI_CNN_CONV_GET_FLAG_RELU(param);
    fillValue = reluFlag ? (CLAMP(0, XAI_CNN_CONV_GET_RELU_MIN(param), XAI_CNN_CONV_GET_RELU_MAX(param))) : 0;
    return(xaiFillTile3D(outTile, fillValue, 0));
  }
#endif
  if (XAI_TILE3D_GET_DIM3(inTile) == 3)
  {
    MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_5x5j1d1), S8IX_MOW_WHD_DEPTH3) MAKE_PARAMS(inTile, coeffTile, biasArray, outTile, param);
    return(XAI_ERROR_STATUS());
  }
  if (XAI_TILE3D_GET_DIM1_PITCH(inTile) <= 16)
  {
    MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_5x5j1d1), S8IX_MOW_WHD_FOLD16) MAKE_PARAMS(inTile, coeffTile, biasArray, outTile, param);
    return(XAI_ERROR_STATUS());
  }
  else if (XAI_TILE3D_GET_DIM1_PITCH(inTile) <= 32)
  {
    MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_5x5j1d1), S8IX_MOW_WHD_FOLD32) MAKE_PARAMS(inTile, coeffTile, biasArray, outTile, param);
    return(XAI_ERROR_STATUS());
  }

  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Pitche of Coefficient Data (WHDN) in dim3 */
  const int32_t coeffPitch2 = XAI_TILE4D_GET_DIM2_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Kernel Size (WHDN) */
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);

  const uint8_t outShiftU  = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu = XAI_CNN_CONV_GET_FLAG_RELU(param);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-((kSizeU / 2) * inDataPitch1 + (kSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 * restrict pdvecIn;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1;

  /* Variable Declarations */
  int32_t inCh, outCh, x, y;
  int32_t varLen;

  /* In order to make the loop multiply-bound we are reducing the vectorization width
     by extra values required for the kernel */
  const int32_t vectorizationWidth60  = ((2 * XCHAL_IVPN_SIMD_WIDTH) - kSizeU) + 1;
  const int32_t vectorizationWidth124 = ((4 * XCHAL_IVPN_SIMD_WIDTH) - kSizeU) + 1;

  /* generates the sequence 0,1,2,3 ,5,6,7,8 ,10,11,12,13 ,15,16,17,18
   * , 20,21,22,23 ,4,9,14,19 ,24. To be used to shuffle the coeff data,
   * So that last coeff from first 4 rows of coeffs can be used as one
   * 32 byte element and make use of quad multiplier outside the inner-
   * most loop.
   * c11, c12, c13, c14, c15
   * c21, c22, c23, c24, c25
   * c31, c32, c33, c34, c35
   * c41, c42, c43, c44, c45
   * c51, c52, c53, c54, c55
   *
   * c15, c25, c35, c45 and c55 are placed in contigous fashion, so that
   * c15, c25, c35, and c45 can be used as one 32 byte element
   */
  xb_vec2Nx8 dvecIdx;
  dvecIdx = IVP_SEL2NX8I(IVP_SEL2NX8I(IVP_ADD2NX8U(IVP_SEQ2NX8(), 15),
                                      IVP_ADD2NX8U(IVP_SEQ2NX8(), 10),
                                      IVP_SELI_INTERLEAVE_2_LO),
                         IVP_SEL2NX8I(IVP_ADD2NX8U(IVP_SEQ2NX8(), 5), IVP_SEQ2NX8(),
                                      IVP_SELI_INTERLEAVE_2_LO),
                         IVP_SELI_INTERLEAVE_4_LO);

  dvecIdx = IVP_SEL2NX8I(IVP_SEL2NX8I(IVP_MOV2NX8U_FROMNX16(
                                        IVP_MOVNX16_FROMN_2X32(4 + (9 << 8) + (14 << 16) + \
                                                               (19 << 24))),
                                      IVP_ADD2NX8U(IVP_SEQ2NX8(), 20), IVP_SELI_INTERLEAVE_2_LO),
                         dvecIdx, IVP_SELI_8B_PACK_16);

  /* loop across output height is unrolled twice.
   * Loop across kernel width and height is
   * completely unrolled.
   * 128 bytes of input are loaded.
   */
  for (x = 0; x < outW - vectorizationWidth60; x += vectorizationWidth124)  /* Loop across output width */
  {
    varLen = XT_MIN(vectorizationWidth124, outW - x);
    /* In order to handle cases where input width <= 2*XCHAL_IVPN_SIMD_WIDTH, where
     * the 2nd load from the same row needs to be avoided.  */
    int32_t enable2ndCol = XT_SALT(2 * XCHAL_IVPN_SIMD_WIDTH, varLen + kSizeU - 1);

    for (y = 0; y < outH; y += 2) /* Loop across output height */
    {
      /* In order to handle odd output height */
      int32_t enable2ndRow = XT_SALT(y, outH - 1);

      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y + x];

      /* initialize coeff and Bias data pointer*/
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];


      for (outCh = 0; outCh < numOutCh; outCh++)  /* Loop across Output depth */
      {
        /* load and replicate bias data */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc1, dacc2, dacc3, dacc4;
        dacc1 = dacc2 = dacc3 = dacc4 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc2, hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc3, hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc4, hvecBias1, hvecBias1);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

        pdvecIn = (MORPH_IDT_2Nx8 *) pInput;

        for (inCh = 0; inCh < numInCh; inCh++)  /* Loop across input channels */
        {
          /* vectors for coeff and input loads */
          xb_vec2Nx8 dvecCoeffData1;
          xb_vec2Nx8 dvecInData11, dvecInData21, dvecInData31, dvecInData41, dvecInData51, dvecInData61;
          xb_vec2Nx8 dvecInData12, dvecInData22, dvecInData32, dvecInData42, dvecInData52, dvecInData62;

          /* load data from first input row */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn, \
                             enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn, \
                             inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /* load data from 2nd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn, \
                             enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn, \
                             inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /* load data from 3rd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData31, vaInData, pdvecIn, \
                             enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData32, vaInData, pdvecIn, \
                             inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /* load data from 4th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData41, vaInData, pdvecIn, \
                             enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData42, vaInData, pdvecIn, \
                             inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /* load data from 5th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData51, vaInData, pdvecIn, \
                             enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData52, vaInData, pdvecIn, \
                             inDataPitch1 * enable2ndRow      \
                             - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /* load data from 6th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData61, vaInData, pdvecIn, \
                             enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData62, vaInData, pdvecIn,                 \
                             inDataPitch2 - (4 + enable2ndRow) * inDataPitch1 \
                             - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /* load all the 5x5 coefficients */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch2);

          /* Rearrange them so that 4 MUL4T, 1 MULQ and 1 MUL can be used to perform entire operation */
          dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);

          /* Multiply and accumulate 1st set of 4 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc1, dvecInData12, dvecInData11, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, dvecInData12, dvecInData12, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc3, dvecInData22, dvecInData21, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc4, dvecInData22, dvecInData22, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));

          /* Multiply and accumulate 2nd set of 4 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc1, dvecInData22, dvecInData21, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc2, dvecInData22, dvecInData22, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc3, dvecInData32, dvecInData31, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc4, dvecInData32, dvecInData32, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* Multiply and accumulate 3rd set of 4 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc1, dvecInData32, dvecInData31, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
          MORPH_OP_MUL4TA(dacc2, dvecInData32, dvecInData32, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
          MORPH_OP_MUL4TA(dacc3, dvecInData42, dvecInData41, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
          MORPH_OP_MUL4TA(dacc4, dvecInData42, dvecInData42, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));

          /* Multiply and accumulate 4th set of 4 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc1, dvecInData42, dvecInData41, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
          MORPH_OP_MUL4TA(dacc2, dvecInData42, dvecInData42, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
          MORPH_OP_MUL4TA(dacc3, dvecInData52, dvecInData51, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
          MORPH_OP_MUL4TA(dacc4, dvecInData52, dvecInData52, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));

          /* Multiply and accumulate 5th set of 4 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc1, dvecInData52, dvecInData51, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));
          MORPH_OP_MUL4TA(dacc2, dvecInData52, dvecInData52, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));
          MORPH_OP_MUL4TA(dacc3, dvecInData62, dvecInData61, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));
          MORPH_OP_MUL4TA(dacc4, dvecInData62, dvecInData62, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));

          /* Multiply and accumulate 6th set of 4 coefficients for all the outputs */
          MORPH_OP_MULQA(dacc1, IVP_SEL2NX8I(dvecInData42, dvecInData41, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData32, dvecInData31, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));

          MORPH_OP_MULQA(dacc2, IVP_SEL2NX8I(dvecInData42, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData32, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData22, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData12, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));

          MORPH_OP_MULQA(dacc3, IVP_SEL2NX8I(dvecInData52, dvecInData51, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData42, dvecInData41, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData32, dvecInData31, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));

          MORPH_OP_MULQA(dacc4, IVP_SEL2NX8I(dvecInData52, dvecInData52, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData42, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData32, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData22, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));

          /* Multiply and accumulate the final coefficient for all the outputs */
          MORPH_OP_MULA(dacc1, IVP_SEL2NX8I(dvecInData52, dvecInData51, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_EXTR2NX8(dvecCoeffData1, 24));
          MORPH_OP_MULA(dacc2, IVP_SEL2NX8I(dvecInData52, dvecInData52, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_EXTR2NX8(dvecCoeffData1, 24));
          MORPH_OP_MULA(dacc3, IVP_SEL2NX8I(dvecInData62, dvecInData61, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_EXTR2NX8(dvecCoeffData1, 24));
          MORPH_OP_MULA(dacc4, IVP_SEL2NX8I(dvecInData62, dvecInData62, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_EXTR2NX8(dvecCoeffData1, 24));
        }  /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif

        /* 1st row  */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * (varLen - 2 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                       2 * (varLen - 3 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* 2nd row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndRow * outDataPitch1 * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * varLen);
        IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * enable2ndRow * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * \
                       (varLen - 2 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * enable2ndRow * \
                       2 * (varLen - 3 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += outDataPitch2 * bytesPerPixel;
        pCoeff  += coeffPitch3;
      } /* end of for (outCh = 0; outCh < numOutCh; outCh++)*/
    }   /* end of for (y = 0; y < outH; y += 2)*/
  }    /* end of for (x = 0; x < outW; x += vectorizationWidth)*/

  /* To handle cases where the remaining output width is less than or equal to 60.
   * loop across output height is unrolled twice. Loop across kernel width and height is
   * completely unrolled. 64 bytes of input are loaded.
   */
  if (x < outW)
  {
    for (y = 0; y < outH; y += 2) /* Loop across output height */
    {
      /* In order to handle odd output height */
      int32_t enable2ndRow = XT_SALT(y, outH - 1);

      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y + x];

      /* initialize coeff and Bias data pointer*/
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];


      for (outCh = 0; outCh < numOutCh; outCh++)  /* Loop across Output depth */
      {
        /* load and replicate bias data */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc1, dacc2;
        dacc1 = dacc2 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc2, hvecBias1, hvecBias1);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

        pdvecIn = (MORPH_IDT_2Nx8 *) pInput;

        for (inCh = 0; inCh < numInCh; inCh++)  /* Loop across input channels */
        {
          /* vectors for coeff and input loads */
          xb_vec2Nx8 dvecCoeffData1;
          xb_vec2Nx8 dvecInData1, dvecInData2, dvecInData3, dvecInData4, dvecInData5, dvecInData6;

          /* load data from first input row */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData1, vaInData, pdvecIn, inDataPitch1);

          /* load data from 2nd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData2, vaInData, pdvecIn, inDataPitch1);

          /* load data from 3rd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData3, vaInData, pdvecIn, inDataPitch1);

          /* load data from 4th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData4, vaInData, pdvecIn, inDataPitch1);

          /* load data from 5th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData5, vaInData, pdvecIn, inDataPitch1 * enable2ndRow);

          /* load data from 6th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData6, vaInData, pdvecIn, inDataPitch2 - (4 + enable2ndRow) * inDataPitch1);

          /* load all the 5x5 coefficients */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch2);

          /* Rearrange them so that 4 MUL4T, 1 MULQ and 1 MUL can be used to perform entire operation */
          dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);

          /* Multiply and accumulate 1st set of 4 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc1, dvecInData1, dvecInData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, dvecInData2, dvecInData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));

          /* Multiply and accumulate 2nd set of 4 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc1, dvecInData2, dvecInData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc2, dvecInData3, dvecInData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* Multiply and accumulate 3rd set of 4 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc1, dvecInData3, dvecInData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
          MORPH_OP_MUL4TA(dacc2, dvecInData4, dvecInData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));

          /* Multiply and accumulate 4th set of 4 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc1, dvecInData4, dvecInData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
          MORPH_OP_MUL4TA(dacc2, dvecInData5, dvecInData5, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));

          /* Multiply and accumulate 5th set of 4 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc1, dvecInData5, dvecInData5, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));
          MORPH_OP_MUL4TA(dacc2, dvecInData6, dvecInData6, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));

          /* Multiply and accumulate 6th set of 4 coefficients for all the outputs */
          MORPH_OP_MULQA(dacc1, IVP_SEL2NX8I(dvecInData4, dvecInData4, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData3, dvecInData3, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData2, dvecInData2, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData1, dvecInData1, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));

          MORPH_OP_MULQA(dacc2, IVP_SEL2NX8I(dvecInData5, dvecInData5, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData4, dvecInData4, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData3, dvecInData3, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData2, dvecInData2, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));

          /* Multiply and accumulate the final coefficient for all the outputs */
          MORPH_OP_MULA(dacc1, IVP_SEL2NX8I(dvecInData5, dvecInData5, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_EXTR2NX8(dvecCoeffData1, 24));
          MORPH_OP_MULA(dacc2, IVP_SEL2NX8I(dvecInData6, dvecInData6, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_EXTR2NX8(dvecCoeffData1, 24));
        }  /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* variable length for output stores */
        varLen = XT_MIN(vectorizationWidth60, outW - x);

        /* Storing the first depth output */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* first depth , 2nd row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndRow * outDataPitch1 * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * varLen);
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * enable2ndRow * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += outDataPitch2 * bytesPerPixel;
        pCoeff  += coeffPitch3;
      } /* end of for (outCh = 0; outCh < numOutCh; outCh++)*/
    }   /* end of for (y = 0; y < outH; y += 2)*/
  }     /* end of if( x < outW)*/
  return(XAI_ERROR_STATUS());
}

/******************************************************************************************
* 5x5 MOW WHD Stride 2 - DEPTH 3                                                          *
* If number of input channels is equal to 3                                               *
* this function is called.                                                                *
******************************************************************************************/

static _XAI_INLINE_ void MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_5x5j2d1), S8IX_MOW_WHD_DEPTH3) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Pitches of Coefficient Data (WHDN) in dim1 and dim3 */
  const int32_t coeffPitch2 = XAI_TILE4D_GET_DIM2_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t stride        = XAI_CNN_CONV_GET_STRIDE(param);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-((kSizeU / 2) * inDataPitch1 + (kSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8* restrict pdvecIn1;
  MORPH_IDT_2Nx8* restrict pdvecIn2;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1;
  xb_vec2Nx8* restrict pdvecCoeff2;
  xb_vec2Nx8* restrict pdvecCoeff3;
  xb_vec2Nx8* restrict pdvecCoeff4;

  /* Variable Declarations */
  int32_t outCh, x, y;
  /* In order to make the loop multiply-bound we are reducing the vectorization width
     by extra values required for the kernel */
  const int32_t vectorizationWidth = (((2 * XCHAL_IVPN_SIMD_WIDTH) - kSizeU) / stride) + 1;

  /* Since there are 25 coefficients for 1 output channel, we can make use of 6 quad multipliers
   * for generating 1 output. So we need to re-arrange the 25 coefficients in the pattern shown
   * Pattern : 0 1 2 3 5 6 7 8 10 11 12 13 15 16 17 18 20 21 22 23 4 9 14 19 24 */
  xb_vec2Nx8 dvecIdx;
  dvecIdx = IVP_SEL2NX8I(IVP_SEL2NX8I(IVP_ADD2NX8U(IVP_SEQ2NX8(), 15),
                                      IVP_ADD2NX8U(IVP_SEQ2NX8(), 10), IVP_SELI_INTERLEAVE_2_LO),
                         IVP_SEL2NX8I(IVP_ADD2NX8U(IVP_SEQ2NX8(), 5), IVP_SEQ2NX8(),
                                      IVP_SELI_INTERLEAVE_2_LO), IVP_SELI_INTERLEAVE_4_LO);

  dvecIdx = IVP_SEL2NX8I(IVP_SEL2NX8I(IVP_MOV2NX8U_FROMNX16(
                                        IVP_MOVNX16_FROMN_2X32(4 + (9 << 8) + (14 << 16) + (19 << 24))),
                                      IVP_ADD2NX8U(IVP_SEQ2NX8(), 20), IVP_SELI_INTERLEAVE_2_LO),
                         dvecIdx, IVP_SELI_8B_PACK_16);

  /* loop across output depth is unrolled by 4
   * , producing lanes from 4 output channels
   * in one iteration. Since vectorization width
   * is just half the width of the accumulator,
   * loop across output height is also unrolled by 2.
   * Unrolling across output height makes it possible
   * to utilize all the 64 MACs in the accumulator.
   *
   * Data loaded from the 2 input rows is concatenated
   * in such a manner that lower half of the output
   * vector gives the first output row and the upper
   * half of the output vector gives the next output row.
   */
  for (x = 0; x < outW; x += vectorizationWidth) /* Loop across output width */
  {
    for (y = 0; y < outH; y += 2)  /* Loop across output height */
    {
      /* In order to handle odd output heights */
      int32_t enable2Row = XT_SALT(y, outH - 1);

      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * stride * (y) + stride * (x)];

      /* initialize coeff and Bias data pointer */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 4)  /* Loop across Output depth */
      {
        /* In order to handle odd output depths */
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
        int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);
        int32_t enable4thCh = XT_SALT(outCh, numOutCh - 3);

        /* Load the bias values corresponding to two output channels */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
        xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4 * enable4thCh);
        xb_vecN_2x32v hvecBias4; IVP_LSRN_2X32_XP(hvecBias4, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc1, dacc2, dacc3, dacc4;
        dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
        dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
        IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);
        dacc4 = IVP_CVT24UNX32L(hvecBias4, hvecBias4);
        IVP_CVT24UNX32H(dacc4, hvecBias4, hvecBias4);

        /* priming for coeff load */
        /* Coeff for 1st output channel */
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);
        /* Coeff for 2nd output channel */
        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);
        /* Coeff for 3rd output channel */
        pdvecCoeff3 = (xb_vec2Nx8 *) (pCoeff + 2 * coeffPitch3 * enable3rdCh);
        valign vaCoeffData3; vaCoeffData3 = IVP_LA2NX8_PP(pdvecCoeff3);
        /* Coeff for 4th output channel */
        pdvecCoeff4 = (xb_vec2Nx8 *) (pCoeff + 3 * coeffPitch3 * enable4thCh);
        valign vaCoeffData4; vaCoeffData4 = IVP_LA2NX8_PP(pdvecCoeff4);


        /* Input vector pointer initialization */
        pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
        pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2);

        /* vectors for coeff and input loads */
        xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2, dvecCoeffData3, dvecCoeffData4;
        xb_vec2Nx8 dvecInData1, dvecInData2, dvecInData3, dvecInData4, \
                   dvecInData5, dvecInData6, dvecInData7;
        MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3, dvecData4;
        MORPH_IDT_2Nx8 dvecData51, dvecData52, dvecData53, dvecData54, dvecData55;

/**************************************** 1st inCh *********************************************/
        /* load data from 1st input row */
        valign vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        IVP_LA2NX8_XP(dvecInData1, vaInData1, pdvecIn1, inDataPitch1);

        /* load data from 2nd input row */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        IVP_LA2NX8_XP(dvecInData2, vaInData1, pdvecIn1, inDataPitch1);

        /* load data from 3rd input row */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        IVP_LA2NX8_XP(dvecInData3, vaInData1, pdvecIn1, inDataPitch1);

        /* load data from 4th input row */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        IVP_LA2NX8_XP(dvecInData4, vaInData1, pdvecIn1, inDataPitch1);

        /* load data from 5th input row */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        IVP_LA2NX8_XP(dvecInData5, vaInData1, pdvecIn1, inDataPitch1 * enable2Row);

        /* load data from 6th input row */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        IVP_LA2NX8_XP(dvecInData6, vaInData1, pdvecIn1, inDataPitch1 * enable2Row);

        /* load data from 7th input row */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        IVP_LA2NX8_XP(dvecInData7, vaInData1, pdvecIn1, \
                      inDataPitch2 - (4 + 2 * enable2Row) * inDataPitch1);

        /* load all the 5x5 coefficients for 4 output depths*/
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch2);
        IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch2);
        IVP_LAV2NX8_XP(dvecCoeffData3, vaCoeffData3, pdvecCoeff3, coeffPitch2);
        IVP_LAV2NX8_XP(dvecCoeffData4, vaCoeffData4, pdvecCoeff4, coeffPitch2);

        /* Rearrange them so that max no. of qual multipliers can be used */
        dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);
        dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecIdx);
        dvecCoeffData3 = IVP_SHFL2NX8(dvecCoeffData3, dvecIdx);
        dvecCoeffData4 = IVP_SHFL2NX8(dvecCoeffData4, dvecIdx);

        /* 32 elements from 1st row and 32 elements from 2nd row are concatenated here
         * If 1st input row is 0,1,2,3,4,5,6,7,8,9,...63, and the 2nd input row is
         * 64,65,66,67.........126,127, Data should be arranged  as
         *
         * dvecData1 : 0, 2, 4,...58,60,62,64,66,68,...122,124,126
         * dvecData2 : 1, 3, 5,...59,61,63,65,67,69,...123,125,127
         * dvecData3 : 3, 4, 6,...60,62,0 ,66,68,70,...124,126,0
         * dvecData4 : 4, 6, 8,...61,63,0 ,67,69,71,...125,127,0
         * dvecData5 : 5, 7, 9,...62,0 ,0 ,68,70,72,...126,0  ,0
         *
         * Lower half of the vectors contain data from 1st input row and
         * upper half of the vectors contain data from 2nd output row.
         *
         */
        IVP_DSEL2NX8I(dvecData2, dvecData1, dvecInData3, dvecInData1, IVP_DSELI_8B_DEINTERLEAVE_1);
        dvecData3 = IVP_SEL2NX8I(dvecData1, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);
        dvecData4 = IVP_SEL2NX8I(dvecData2, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* dvecData5 is kept separately and is used by quad multiplier finally */
        dvecData51 = IVP_SEL2NX8I(dvecData1, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_2);

        /* Values corresponding to first and second row are packed in one register
            so that same coefficient will get multiplied to them */
        /* Multiply and accumulate 4 coefficients from 1st set of 5 coeff for all the outputs */
        MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
        MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 0));
        MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 0));


        IVP_DSEL2NX8I(dvecData2, dvecData1, dvecInData4, dvecInData2, IVP_DSELI_8B_DEINTERLEAVE_1);
        IVP_DSEL2NX8I(dvecData52, dvecData3, dvecData1, dvecData1, IVP_DSELI_8B_ROTATE_RIGHT_2_1);
        dvecData4 = IVP_SEL2NX8I(dvecData2, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* Multiply and accumulate 4 coefficients from 2nd set of 5 coeff for all the outputs */
        MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
        MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
        MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 1));
        MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 1));


        IVP_DSEL2NX8I(dvecData2, dvecData1, dvecInData5, dvecInData3, IVP_DSELI_8B_DEINTERLEAVE_1);
        IVP_DSEL2NX8I(dvecData53, dvecData3, dvecData1, dvecData1, IVP_DSELI_8B_ROTATE_RIGHT_2_1);
        dvecData4 = IVP_SEL2NX8I(dvecData2, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* Multiply and accumulate 4 coefficients from 3rd set of 5 coeff for all the outputs */
        MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
        MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
        MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 2));
        MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 2));


        IVP_DSEL2NX8I(dvecData2, dvecData1, dvecInData6, dvecInData4, IVP_DSELI_8B_DEINTERLEAVE_1);
        IVP_DSEL2NX8I(dvecData54, dvecData3, dvecData1, dvecData1, IVP_DSELI_8B_ROTATE_RIGHT_2_1);
        dvecData4 = IVP_SEL2NX8I(dvecData2, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* Multiply and accumulate 4 coefficients from 4th set of 5 coeff for all the outputs */
        MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
        MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
        MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 3));
        MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 3));


        IVP_DSEL2NX8I(dvecData2, dvecData1, dvecInData7, dvecInData5, IVP_DSELI_8B_DEINTERLEAVE_1);
        IVP_DSEL2NX8I(dvecData55, dvecData3, dvecData1, dvecData1, IVP_DSELI_8B_ROTATE_RIGHT_2_1);
        dvecData4 = IVP_SEL2NX8I(dvecData2, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* Multiply and accumulate 4 coefficients from 5th set of 5 coeff for all the outputs */
        MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));
        MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 4));
        MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 4));
        MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 4));


        /* Multiply and acc last coefficient from 1st 4 sets of coeffs for all the outputs*/
        MORPH_OP_MULQA(dacc1, dvecData54, dvecData53, dvecData52, dvecData51,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));
        MORPH_OP_MULQA(dacc2, dvecData54, dvecData53, dvecData52, dvecData51,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 5));
        MORPH_OP_MULQA(dacc3, dvecData54, dvecData53, dvecData52, dvecData51,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 5));
        MORPH_OP_MULQA(dacc4, dvecData54, dvecData53, dvecData52, dvecData51,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 5));


        /* Multiply and acc last coefficient(24) with the last row from 2 output channels */
        MORPH_OP_MULA(dacc1, dvecData55, IVP_EXTR2NX8(dvecCoeffData1, 24));
        MORPH_OP_MULA(dacc2, dvecData55, IVP_EXTR2NX8(dvecCoeffData2, 24));
        MORPH_OP_MULA(dacc3, dvecData55, IVP_EXTR2NX8(dvecCoeffData3, 24));
        MORPH_OP_MULA(dacc4, dvecData55, IVP_EXTR2NX8(dvecCoeffData4, 24));

/**************************************** 2nd inCh *********************************************/
        /* load data from 1st input row */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        IVP_LA2NX8_XP(dvecInData1, vaInData1, pdvecIn1, inDataPitch1);

        /* load data from 2nd input row */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        IVP_LA2NX8_XP(dvecInData2, vaInData1, pdvecIn1, inDataPitch1);

        /* load data from 3rd input row */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        IVP_LA2NX8_XP(dvecInData3, vaInData1, pdvecIn1, inDataPitch1);

        /* load data from 4th input row */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        IVP_LA2NX8_XP(dvecInData4, vaInData1, pdvecIn1, inDataPitch1);

        /* load data from 5th input row */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        IVP_LA2NX8_XP(dvecInData5, vaInData1, pdvecIn1, inDataPitch1 * enable2Row);

        /* load data from 6th input row */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        IVP_LA2NX8_XP(dvecInData6, vaInData1, pdvecIn1, inDataPitch1 * enable2Row);

        /* load data from 7th input row */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        IVP_LA2NX8_XP(dvecInData7, vaInData1, pdvecIn1, \
                      inDataPitch2 - (4 + 2 * enable2Row) * inDataPitch1);

        /* load all the 5x5 coefficients for 4 output depths*/
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch2);
        IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch2);
        IVP_LAV2NX8_XP(dvecCoeffData3, vaCoeffData3, pdvecCoeff3, coeffPitch2);
        IVP_LAV2NX8_XP(dvecCoeffData4, vaCoeffData4, pdvecCoeff4, coeffPitch2);

        /* Rearrange them so that max no. of qual multipliers can be used */
        dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);
        dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecIdx);
        dvecCoeffData3 = IVP_SHFL2NX8(dvecCoeffData3, dvecIdx);
        dvecCoeffData4 = IVP_SHFL2NX8(dvecCoeffData4, dvecIdx);

        IVP_DSEL2NX8I(dvecData2, dvecData1, dvecInData3, dvecInData1, IVP_DSELI_8B_DEINTERLEAVE_1);
        dvecData3 = IVP_SEL2NX8I(dvecData1, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);
        dvecData4 = IVP_SEL2NX8I(dvecData2, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* dvecData5 is kept separately and is used by quad multiplier finally */
        dvecData51 = IVP_SEL2NX8I(dvecData1, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_2);

        /* Values corresponding to first and second row are packed in one register
            so that same coefficient will get multiplied to them */
        /* Multiply and accumulate 4 coefficients from 1st set of 5 coeff for all the outputs */
        MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
        MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 0));
        MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 0));


        IVP_DSEL2NX8I(dvecData2, dvecData1, dvecInData4, dvecInData2, IVP_DSELI_8B_DEINTERLEAVE_1);
        IVP_DSEL2NX8I(dvecData52, dvecData3, dvecData1, dvecData1, IVP_DSELI_8B_ROTATE_RIGHT_2_1);
        dvecData4 = IVP_SEL2NX8I(dvecData2, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* Multiply and accumulate 4 coefficients from 2nd set of 5 coeff for all the outputs */
        MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
        MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
        MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 1));
        MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 1));


        IVP_DSEL2NX8I(dvecData2, dvecData1, dvecInData5, dvecInData3, IVP_DSELI_8B_DEINTERLEAVE_1);
        IVP_DSEL2NX8I(dvecData53, dvecData3, dvecData1, dvecData1, IVP_DSELI_8B_ROTATE_RIGHT_2_1);
        dvecData4 = IVP_SEL2NX8I(dvecData2, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* Multiply and accumulate 4 coefficients from 3rd set of 5 coeff for all the outputs */
        MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
        MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
        MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 2));
        MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 2));


        IVP_DSEL2NX8I(dvecData2, dvecData1, dvecInData6, dvecInData4, IVP_DSELI_8B_DEINTERLEAVE_1);
        IVP_DSEL2NX8I(dvecData54, dvecData3, dvecData1, dvecData1, IVP_DSELI_8B_ROTATE_RIGHT_2_1);
        dvecData4 = IVP_SEL2NX8I(dvecData2, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* Multiply and accumulate 4 coefficients from 4th set of 5 coeff for all the outputs */
        MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
        MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
        MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 3));
        MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 3));


        IVP_DSEL2NX8I(dvecData2, dvecData1, dvecInData7, dvecInData5, IVP_DSELI_8B_DEINTERLEAVE_1);
        IVP_DSEL2NX8I(dvecData55, dvecData3, dvecData1, dvecData1, IVP_DSELI_8B_ROTATE_RIGHT_2_1);
        dvecData4 = IVP_SEL2NX8I(dvecData2, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* Multiply and accumulate 4 coefficients from 5th set of 5 coeff for all the outputs */
        MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));
        MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 4));
        MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 4));
        MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 4));


        /* Multiply and acc last coefficient from 1st 4 sets of coeffs for all the outputs*/
        MORPH_OP_MULQA(dacc1, dvecData54, dvecData53, dvecData52, dvecData51,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));
        MORPH_OP_MULQA(dacc2, dvecData54, dvecData53, dvecData52, dvecData51,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 5));
        MORPH_OP_MULQA(dacc3, dvecData54, dvecData53, dvecData52, dvecData51,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 5));
        MORPH_OP_MULQA(dacc4, dvecData54, dvecData53, dvecData52, dvecData51,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 5));


        /* Multiply and acc last coefficient(24) with the last row from 2 output channels */
        MORPH_OP_MULA(dacc1, dvecData55, IVP_EXTR2NX8(dvecCoeffData1, 24));
        MORPH_OP_MULA(dacc2, dvecData55, IVP_EXTR2NX8(dvecCoeffData2, 24));
        MORPH_OP_MULA(dacc3, dvecData55, IVP_EXTR2NX8(dvecCoeffData3, 24));
        MORPH_OP_MULA(dacc4, dvecData55, IVP_EXTR2NX8(dvecCoeffData4, 24));

/**************************************** 3rd inCh *********************************************/
        /* load data from 1st input row */
        valign vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        IVP_LA2NX8_XP(dvecInData1, vaInData2, pdvecIn2, inDataPitch1);

        /* load data from 2nd input row */
        vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        IVP_LA2NX8_XP(dvecInData2, vaInData2, pdvecIn2, inDataPitch1);

        /* load data from 3rd input row */
        vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        IVP_LA2NX8_XP(dvecInData3, vaInData2, pdvecIn2, inDataPitch1);

        /* load data from 4th input row */
        vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        IVP_LA2NX8_XP(dvecInData4, vaInData2, pdvecIn2, inDataPitch1);

        /* load data from 5th input row */
        vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        IVP_LA2NX8_XP(dvecInData5, vaInData2, pdvecIn2, inDataPitch1 * enable2Row);

        /* load data from 6th input row */
        vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        IVP_LA2NX8_XP(dvecInData6, vaInData2, pdvecIn2, inDataPitch1 * enable2Row);

        /* load data from 7th input row */
        vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        IVP_LA2NX8_XP(dvecInData7, vaInData2, pdvecIn2, \
                      inDataPitch2 - (4 + 2 * enable2Row) * inDataPitch1);

        /* load all the 5x5 coefficients for 4 output depths*/
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch2);
        IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch2);
        IVP_LAV2NX8_XP(dvecCoeffData3, vaCoeffData3, pdvecCoeff3, coeffPitch2);
        IVP_LAV2NX8_XP(dvecCoeffData4, vaCoeffData4, pdvecCoeff4, coeffPitch2);

        /* Rearrange them so that max no. of qual multipliers can be used */
        dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);
        dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecIdx);
        dvecCoeffData3 = IVP_SHFL2NX8(dvecCoeffData3, dvecIdx);
        dvecCoeffData4 = IVP_SHFL2NX8(dvecCoeffData4, dvecIdx);

        IVP_DSEL2NX8I(dvecData2, dvecData1, dvecInData3, dvecInData1, IVP_DSELI_8B_DEINTERLEAVE_1);
        dvecData3 = IVP_SEL2NX8I(dvecData1, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);
        dvecData4 = IVP_SEL2NX8I(dvecData2, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* dvecData5 is kept separately and is used by quad multiplier finally */
        dvecData51 = IVP_SEL2NX8I(dvecData1, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_2);

        /* Values corresponding to first and second row are packed in one register
            so that same coefficient will get multiplied to them */
        /* Multiply and accumulate 4 coefficients from 1st set of 5 coeff for all the outputs */
        MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
        MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 0));
        MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 0));


        IVP_DSEL2NX8I(dvecData2, dvecData1, dvecInData4, dvecInData2, IVP_DSELI_8B_DEINTERLEAVE_1);
        IVP_DSEL2NX8I(dvecData52, dvecData3, dvecData1, dvecData1, IVP_DSELI_8B_ROTATE_RIGHT_2_1);
        dvecData4 = IVP_SEL2NX8I(dvecData2, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* Multiply and accumulate 4 coefficients from 2nd set of 5 coeff for all the outputs */
        MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
        MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
        MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 1));
        MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 1));


        IVP_DSEL2NX8I(dvecData2, dvecData1, dvecInData5, dvecInData3, IVP_DSELI_8B_DEINTERLEAVE_1);
        IVP_DSEL2NX8I(dvecData53, dvecData3, dvecData1, dvecData1, IVP_DSELI_8B_ROTATE_RIGHT_2_1);
        dvecData4 = IVP_SEL2NX8I(dvecData2, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* Multiply and accumulate 4 coefficients from 3rd set of 5 coeff for all the outputs */
        MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
        MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
        MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 2));
        MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 2));

        IVP_DSEL2NX8I(dvecData2, dvecData1, dvecInData6, dvecInData4, IVP_DSELI_8B_DEINTERLEAVE_1);
        IVP_DSEL2NX8I(dvecData54, dvecData3, dvecData1, dvecData1, IVP_DSELI_8B_ROTATE_RIGHT_2_1);
        dvecData4 = IVP_SEL2NX8I(dvecData2, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* Multiply and accumulate 4 coefficients from 4th set of 5 coeff for all the outputs */
        MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
        MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
        MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 3));
        MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 3));


        IVP_DSEL2NX8I(dvecData2, dvecData1, dvecInData7, dvecInData5, IVP_DSELI_8B_DEINTERLEAVE_1);
        IVP_DSEL2NX8I(dvecData55, dvecData3, dvecData1, dvecData1, IVP_DSELI_8B_ROTATE_RIGHT_2_1);
        dvecData4 = IVP_SEL2NX8I(dvecData2, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);

        /* Multiply and accumulate 4 coefficients from 5th set of 5 coeff for all the outputs */
        MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));
        MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 4));
        MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 4));
        MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 4));


        /* Multiply and acc last coefficient from 1st 4 sets of coeffs for all the outputs*/
        MORPH_OP_MULQA(dacc1, dvecData54, dvecData53, dvecData52, dvecData51,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));
        MORPH_OP_MULQA(dacc2, dvecData54, dvecData53, dvecData52, dvecData51,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 5));
        MORPH_OP_MULQA(dacc3, dvecData54, dvecData53, dvecData52, dvecData51,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 5));
        MORPH_OP_MULQA(dacc4, dvecData54, dvecData53, dvecData52, dvecData51,
                       IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                        IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 5));


        /* Multiply and acc last coefficient(24) with the last row from 2 output channels */
        MORPH_OP_MULA(dacc1, dvecData55, IVP_EXTR2NX8(dvecCoeffData1, 24));
        MORPH_OP_MULA(dacc2, dvecData55, IVP_EXTR2NX8(dvecCoeffData2, 24));
        MORPH_OP_MULA(dacc3, dvecData55, IVP_EXTR2NX8(dvecCoeffData3, 24));
        MORPH_OP_MULA(dacc4, dvecData55, IVP_EXTR2NX8(dvecCoeffData4, 24));

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh ], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      pOutScaleData[outCh + 2 * enable3rdCh ], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      pOutScaleData[outCh + 3 * enable4thCh ], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* variable length for output stores */
        int32_t varLen = XT_MIN(vectorizationWidth, outW - x);

        /* Storing the first output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the third output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * enable3rdCh * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the fourth output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch2 * enable4thCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * enable4thCh * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2Row * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8I(dvecOut1L, dvecOut1L, IVP_SELI_EXTRACT_HI_HALVES),
                       vaOutData, pdvecOut, enable2Row * (-typeFlag + 1) * varLen);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, enable2Row * typeFlag * 2 * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                              outDataPitch1 * enable2Row) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8I(dvecOut2L, dvecOut2L, IVP_SELI_EXTRACT_HI_HALVES),
                       vaOutData, pdvecOut, enable2ndCh * enable2Row * (-typeFlag + 1) * varLen);
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, enable2ndCh * \
                       enable2Row * typeFlag * 2 * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the third output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (2 * outDataPitch2 * enable3rdCh + \
                                              outDataPitch1 * enable2Row) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8I(dvecOut3L, dvecOut3L, IVP_SELI_EXTRACT_HI_HALVES),
                       vaOutData, pdvecOut, enable3rdCh * enable2Row * (-typeFlag + 1) * varLen);
        IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, enable3rdCh * \
                       enable2Row * typeFlag * 2 * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the fourth output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (3 * outDataPitch2 * enable4thCh + \
                                              outDataPitch1 * enable2Row) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8I(dvecOut4L, dvecOut4L, IVP_SELI_EXTRACT_HI_HALVES),
                       vaOutData, pdvecOut, enable4thCh * enable2Row * (-typeFlag + 1) * varLen);
        IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, enable4thCh * \
                       enable2Row * typeFlag * 2 * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 4 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 4 * coeffPitch3;
      } /* end of for (outCh = 0; outCh < numOutCh; outCh += 4) */
    }   /* end of for (y = 0; y < outH; y += 2) */
  }     /* end of for (x = 0; x < outW; x += vectorizationWidth) */
}
/******************************************************************************************
*  xaiConvolved(VQ)3D_S_5x5j2d1I8S8IX_MOW_WHD
*  ***************************************************************************************/

/******************************************************************************/
/* Description : P6 optimized generic implementation for 5x5 3D convolution.  */
/*               Based on MORPH pre-processor specifiers, code implementation */
/*               is generated during preprocessing stage. This method can be  */
/*               used to generate 5x5 3D dilated convolution function and 5x5 */
/*               3D VQ dilated convolution function for U8 bit and S8 bit     */
/*               input data with input stride equal to 2                      */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                */
/*               Output scale array, CNN convolution params structure         */
/* Outputs     : XI Error Code                                                */
/* InOuts      : Output Tile                                                  */
/* Assumptions : CoeffData is S8                                              */
/*               biasArray is signed 32b, value not exceeding signed 24b      */
/*               Output scale array is U16                                    */
/*               OutData is S8 / U8 / S16                                     */
/*               Kernel Size is 5x5xDxN                                       */
/*               Input and Output are in WHD format                           */
/*               Coeff is in WHDN format                                      */
/******************************************************************************/

/****************** xaiConvolvedVQ3D_S_5x5j2d1_S8S8IX_MOW_WHD ******************/
/****************** xaiConvolvedVQ3D_S_5x5j2d1_U8S8IX_MOW_WHD ******************/
/******************* xaiConvolved3D_S_5x5j2d1_S8S8IX_MOW_WHD *******************/
/******************* xaiConvolved3D_S_5x5j2d1_U8S8IX_MOW_WHD *******************/

XAI_ERR_TYPE MAKE_NAME(MAKE_NAME_VQ(xaiConvolved, 3D_S_5x5j2d1), S8IX_MOW_WHD) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Error Checks */
  XAI_ERROR_CHECKS()
  {
    MORPH_IDT_CHECK(inTile);
    XAI_CHECK_CONV_OUTPUT_TILE3D(outTile);
    XAI_CHECK_TILE4D_S8(coeffTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(outTile);
    XAI_CHECK_TILE4D_IN_DRAM_BOUNDARY(coeffTile);
    XAI_CHECK_POINTER(param);
    XAI_CHECK_ARRAY_S32(biasArray);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(inTile, outTile);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(coeffTile, outTile);
    XAI_CHECK_KERNEL_SIZE(coeffTile, 5);
    XAI_CHECK_TILE3D_DATA_ORDER(inTile, XAI_WHD);
    XAI_CHECK_TILE3D_DATA_ORDER(outTile, XAI_WHD);
    XAI_CHECK_TILE4D_DATA_ORDER(coeffTile, XAI_WHDN);
    XAI_CHECK_DILATION(param, 1);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_DILATIONX(param) == XAI_CNN_CONV_GET_DILATIONY(param),                                           \
                    XAI_ERR_BADARG, "Dilation along width = %hhu and height = %hhu\nDilation along width and height should be equal", \
                    XAI_CNN_CONV_GET_DILATIONX(param), XAI_CNN_CONV_GET_DILATIONY(param));
    XAI_CHECK_TILE3D_EDGE(inTile, 2);
    XAI_CHECK_STRIDE(param, 2);
    XAI_CHECK_ERROR((XAI_CNN_CONV_GET_STRIDEX(param) == XAI_CNN_CONV_GET_STRIDEY(param)),                                           \
                    XAI_ERR_BADARG, "\nStride along width = %hhu and height = %hhu\nStride along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_CONSISTENCY_MOW_WHD(inTile, coeffTile, biasArray, outTile, param);
    XAI_CHECK_COEFFTILE_CONTIGUOUS(coeffTile, param);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_ACCUM_SHIFT(param) < 24,                                     \
                    XAI_ERR_NORM, "\nThe accumulator shift = %hhu, value should be less than 24", \
                    XAI_CNN_CONV_GET_ACCUM_SHIFT(param));
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_OUTPUT_SHIFT(param) < 32,                               \
                    XAI_ERR_NORM, "\nThe output shift = %hhu, value should be less than 32", \
                    XAI_CNN_CONV_GET_OUTPUT_SHIFT(param));
    XAI_CHECK_CONV_RELU_LIMITS_IX(param, outTile);
#if DILATED_VQ_CONV == VQ_TRUE
    XAI_CHECK_ARRAY_U16(outputScaleArray);
    XAI_CHECK_ERROR(XAI_ARRAY_GET_WIDTH(outputScaleArray) >= XAI_TILE4D_GET_DIM4(coeffTile),                                                                                          \
                    XAI_ERR_DATASIZE, "\nWidth of Output Scale Array = %d, Number of Kernels = %d\nWidth of Output Scale Array should be greater than or equal to Number of Kernels", \
                    XAI_ARRAY_GET_WIDTH(outputScaleArray), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_ERROR((((uintptr_t) (XAI_ARRAY_GET_DATA_PTR(outputScaleArray)) & \
                      0x1) == 0), XAI_ERR_NORM, "The output scale array is not aligned to 2 byte boundary");
#endif
  }
#if DILATED_VQ_CONV == VQ_FALSE
  if (XAI_CNN_CONV_GET_OUTPUT_SCALE(param) == 0)
  {
    int32_t fillValue;
    int32_t reluFlag = XAI_CNN_CONV_GET_FLAG_RELU(param);
    fillValue = reluFlag ? (CLAMP(0, XAI_CNN_CONV_GET_RELU_MIN(param), XAI_CNN_CONV_GET_RELU_MAX(param))) : 0;
    return(xaiFillTile3D(outTile, fillValue, 0));
  }
#endif
  if (XAI_TILE3D_GET_DIM3(inTile) == 3)
  {
    MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_5x5j2d1), S8IX_MOW_WHD_DEPTH3) MAKE_PARAMS(inTile, coeffTile, biasArray, outTile, param);
    return(XAI_ERROR_STATUS());
  }

  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Pitches of Coefficient Data (WHDN) in dim1 and dim3 */
  const int32_t coeffPitch2 = XAI_TILE4D_GET_DIM2_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t stride        = XAI_CNN_CONV_GET_STRIDE(param);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-((kSizeU / 2) * inDataPitch1 + (kSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8* restrict pdvecIn1;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1;
  xb_vec2Nx8* restrict pdvecCoeff2;
  xb_vec2Nx8* restrict pdvecCoeff3;

  /* Variable Declarations */
  int32_t inCh, outCh, x, y;
  /* In order to make the loop multiply-bound we are reducing the vectorization width
     by extra values required for the kernel */
  const int32_t vectorizationWidth = (((2 * XCHAL_IVPN_SIMD_WIDTH) - kSizeU) / stride) + 1;

  /* Since there are 25 coefficients for 1 output channel, we can make use of 6 quad multipliers
   * for generating 1 output. So we need to re-arrange the 25 coefficients in the pattern shown
   * Pattern : 0 1 2 3 5 6 7 8 10 11 12 13 15 16 17 18 20 21 22 23 4 9 14 19 24 */
  xb_vec2Nx8 dvecIdx;
  dvecIdx = IVP_SEL2NX8I(IVP_SEL2NX8I(IVP_ADD2NX8U(IVP_SEQ2NX8(), 15),
                                      IVP_ADD2NX8U(IVP_SEQ2NX8(), 10), IVP_SELI_INTERLEAVE_2_LO),
                         IVP_SEL2NX8I(IVP_ADD2NX8U(IVP_SEQ2NX8(), 5), IVP_SEQ2NX8(),
                                      IVP_SELI_INTERLEAVE_2_LO), IVP_SELI_INTERLEAVE_4_LO);

  dvecIdx = IVP_SEL2NX8I(IVP_SEL2NX8I(IVP_MOV2NX8U_FROMNX16(
                                        IVP_MOVNX16_FROMN_2X32(4 + (9 << 8) + (14 << 16) + (19 << 24))),
                                      IVP_ADD2NX8U(IVP_SEQ2NX8(), 20), IVP_SELI_INTERLEAVE_2_LO),
                         dvecIdx, IVP_SELI_8B_PACK_16);

  /* loop across output depth is unrolled by 3
   * , producing lanes from 3 output channels
   * in one iteration. Since vectorization width
   * is just half the width of the accumulator,
   * loop across output height is also unrolled by 2.
   * Unrolling across output height makes it possible
   * to utilize all the 64 MACs in the accumulator.
   *
   * Data loaded from the 2 input rows is concatenated
   * in such a manner that lower half of the output
   * vector gives the first output row and the upper
   * half of the output vector gives the next output row.
   */
  for (x = 0; x < outW; x += vectorizationWidth) /* Loop across output width */
  {
    for (y = 0; y < outH; y += 2) /* Loop across output height */
    {
      /* In order to handle odd output heights */
      int32_t enable2Row = XT_SALT(y, outH - 1);

      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * stride * (y) + stride * (x)];

      /* initialize coeff and Bias data pointer */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 3)  /* Loop across Output depth */
      {
        /* In order to handle odd output depths */
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
        int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);

        /* Load the bias values corresponding to two output channels */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
        xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc1, dacc2, dacc3;
        dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
        dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
        IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);

        /* priming of coeff load is done outside the innermost loop*/
        /* Coeff for 1st output channel */
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);
        /* Coeff for 2nd output channel */
        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);
        /* Coeff for 3rd output channel */
        pdvecCoeff3 = (xb_vec2Nx8 *) (pCoeff + 2 * coeffPitch3 * enable3rdCh);
        valign vaCoeffData3; vaCoeffData3 = IVP_LA2NX8_PP(pdvecCoeff3);

        /* Input vector pointer initialization */
        pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);

        for (inCh = 0; inCh < numInCh; inCh++)  /* Loop across input channels */
        {
          /* vectors for coeff and input loads */
          xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2, dvecCoeffData3;
          xb_vec2Nx8 dvecInData1, dvecInData2, dvecInData3, dvecInData4, \
                     dvecInData5, dvecInData6, dvecInData7;
          MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3, dvecData4;
          MORPH_IDT_2Nx8 dvecData51, dvecData52, dvecData53, dvecData54, dvecData55;

          /* load data from 1st input row */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          IVP_LA2NX8_XP(dvecInData1, vaInData, pdvecIn1, inDataPitch1);

          /* load data from 2nd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          IVP_LA2NX8_XP(dvecInData2, vaInData, pdvecIn1, inDataPitch1);

          /* load data from 3rd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          IVP_LA2NX8_XP(dvecInData3, vaInData, pdvecIn1, inDataPitch1);

          /* load data from 4th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          IVP_LA2NX8_XP(dvecInData4, vaInData, pdvecIn1, inDataPitch1);

          /* load data from 5th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          IVP_LA2NX8_XP(dvecInData5, vaInData, pdvecIn1, inDataPitch1 * enable2Row);

          /* load data from 6th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          IVP_LA2NX8_XP(dvecInData6, vaInData, pdvecIn1, inDataPitch1 * enable2Row);

          /* load data from 7th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          IVP_LA2NX8_XP(dvecInData7, vaInData, pdvecIn1, \
                        inDataPitch2 - (4 + 2 * enable2Row) * inDataPitch1);

          /* load all the 5x5 coefficients for 2 output depths*/
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch2);
          IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch2);
          IVP_LAV2NX8_XP(dvecCoeffData3, vaCoeffData3, pdvecCoeff3, coeffPitch2);

          /* Rearrange them so that max no. of qual multipliers can be used */
          dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);
          dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecIdx);
          dvecCoeffData3 = IVP_SHFL2NX8(dvecCoeffData3, dvecIdx);

          /* 32 elements from 1st row and 32 elements from 2nd row are concatenated here
           * If 1st input row is 0,1,2,3,4,5,6,7,8,9,...63, and the 2nd input row is
           * 64,65,66,67.........126,127, Data should be arranged  as
           *
           * dvecData1 : 0, 2, 4,...58,60,62,64,66,68,...122,124,126
           * dvecData2 : 1, 3, 5,...59,61,63,65,67,69,...123,125,127
           * dvecData3 : 3, 4, 6,...60,62,0 ,66,68,70,...124,126,0
           * dvecData4 : 4, 6, 8,...61,63,0 ,67,69,71,...125,127,0
           * dvecData5 : 5, 7, 9,...62,0 ,0 ,68,70,72,...126,0  ,0
           *
           * Lower half of the vectors contain data from 1st input row and
           * upper half of the vectors contain data from 2nd output row.
           *
           */

          IVP_DSEL2NX8I(dvecData2, dvecData1, dvecInData3, dvecInData1, IVP_DSELI_8B_DEINTERLEAVE_1);
          dvecData3 = IVP_SEL2NX8I(dvecData1, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);
          dvecData4 = IVP_SEL2NX8I(dvecData2, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);

          /* dvecData5 is kept separately and is used by quad multiplier finally */
          dvecData51 = IVP_SEL2NX8I(dvecData1, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_2);

          /* Values corresponding to first and second row are packed in one register
             so that same coefficient will get multiplied to them */
          /* Multiply and accumulate 4 coefficients from 1st set of 5 coeff for all the outputs */
          MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
          MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 0));


          IVP_DSEL2NX8I(dvecData2, dvecData1, dvecInData4, dvecInData2, IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData52, dvecData3, dvecData1, dvecData1, IVP_DSELI_8B_ROTATE_RIGHT_2_1);
          dvecData4 = IVP_SEL2NX8I(dvecData2, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);

          /* Multiply and accumulate 4 coefficients from 2nd set of 5 coeff for all the outputs */
          MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
          MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 1));


          IVP_DSEL2NX8I(dvecData2, dvecData1, dvecInData5, dvecInData3, IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData53, dvecData3, dvecData1, dvecData1, IVP_DSELI_8B_ROTATE_RIGHT_2_1);
          dvecData4 = IVP_SEL2NX8I(dvecData2, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);

          /* Multiply and accumulate 4 coefficients from 3rd set of 5 coeff for all the outputs */
          MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
          MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
          MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 2));


          IVP_DSEL2NX8I(dvecData2, dvecData1, dvecInData6, dvecInData4, IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData54, dvecData3, dvecData1, dvecData1, IVP_DSELI_8B_ROTATE_RIGHT_2_1);
          dvecData4 = IVP_SEL2NX8I(dvecData2, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);

          /* Multiply and accumulate 4 coefficients from 4th set of 5 coeff for all the outputs */
          MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
          MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
          MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 3));


          IVP_DSEL2NX8I(dvecData2, dvecData1, dvecInData7, dvecInData5, IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData55, dvecData3, dvecData1, dvecData1, IVP_DSELI_8B_ROTATE_RIGHT_2_1);
          dvecData4 = IVP_SEL2NX8I(dvecData2, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);

          /* Multiply and accumulate 4 coefficients from 5th set of 5 coeff for all the outputs */
          MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));
          MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 4));
          MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 4));


          /* Multiply and acc last coefficient from 1st 4 sets of coeffs for all the outputs*/
          MORPH_OP_MULQA(dacc1, dvecData54, dvecData53, dvecData52, dvecData51,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));
          MORPH_OP_MULQA(dacc2, dvecData54, dvecData53, dvecData52, dvecData51,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 5));
          MORPH_OP_MULQA(dacc3, dvecData54, dvecData53, dvecData52, dvecData51,
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16( \
                                          IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 5));


          /* Multiply and acc last coefficient(24) with the last row from 2 output channels */
          MORPH_OP_MULA(dacc1, dvecData55, IVP_EXTR2NX8(dvecCoeffData1, 24));
          MORPH_OP_MULA(dacc2, dvecData55, IVP_EXTR2NX8(dvecCoeffData2, 24));
          MORPH_OP_MULA(dacc3, dvecData55, IVP_EXTR2NX8(dvecCoeffData3, 24));
        }  /* end of for (inCh = 0; inCh < numInCh; inCh++) */

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      pOutScaleData[outCh + 2 * enable3rdCh ], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* variable length for output stores */
        int32_t varLen = XT_MIN(vectorizationWidth, outW - x);

        /* Storing the first output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the third output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * enable3rdCh * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);


        /* Storing the first output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2Row * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8I(dvecOut1L, dvecOut1L, IVP_SELI_EXTRACT_HI_HALVES),
                       vaOutData, pdvecOut, enable2Row * (-typeFlag + 1) * varLen);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, enable2Row * typeFlag * 2 * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                              outDataPitch1 * enable2Row) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8I(dvecOut2L, dvecOut2L, IVP_SELI_EXTRACT_HI_HALVES),
                       vaOutData, pdvecOut, enable2ndCh * enable2Row * (-typeFlag + 1) * varLen);
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, enable2ndCh * \
                       enable2Row * typeFlag * 2 * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the third output depth, second row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (2 * outDataPitch2 * enable3rdCh + \
                                              outDataPitch1 * enable2Row) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8I(dvecOut3L, dvecOut3L, IVP_SELI_EXTRACT_HI_HALVES),
                       vaOutData, pdvecOut, enable3rdCh * enable2Row * (-typeFlag + 1) * varLen);
        IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, enable3rdCh * \
                       enable2Row * typeFlag * 2 * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 3 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 3 * coeffPitch3;
      } /* end of for (outCh = 0; outCh < numOutCh; outCh += 3) */
    }   /* end of for (y = 0; y < outH; y += 2) */
  }     /* end of for (x = 0; x < outW; x += vectorizationWidth) */
  return(XAI_ERROR_STATUS());
}

/******************************************************************************************
*   xaiConvolved(VQ)3D_S_5x5j4d1I8S8IX_MOW_WHD
*  ***************************************************************************************/

/******************************************************************************/
/* Description : P6 optimized generic implementation for 5x5 3D convolution.  */
/*               Based on MORPH pre-processor specifiers, code implementation */
/*               is generated during preprocessing stage. This method can be  */
/*               used to generate 5x5 3D dilated convolution function and 5x5 */
/*               3D VQ dilated convolution function for U8 bit and S8 bit     */
/*               input data with input stride equal to 4                      */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                */
/*               Output scale array, CNN convolution params structure         */
/* Outputs     : XI Error Code                                                */
/* InOuts      : Output Tile                                                  */
/* Assumptions : CoeffData is S8                                              */
/*               biasArray is signed 32b, value not exceeding signed 24b      */
/*               Output scale array is U16                                    */
/*               OutData is S8 / U8 / S16                                     */
/*               Kernel Size is 5x5xDxN                                       */
/*               Input and Output are in WHD format                           */
/*               Coeff is in WHDN format                                      */
/******************************************************************************/

/****************** xaiConvolvedVQ3D_S_5x5j4d1_S8S8IX_MOW_WHD ******************/
/****************** xaiConvolvedVQ3D_S_5x5j4d1_U8S8IX_MOW_WHD ******************/
/******************* xaiConvolved3D_S_5x5j4d1_S8S8IX_MOW_WHD *******************/
/******************* xaiConvolved3D_S_5x5j4d1_U8S8IX_MOW_WHD *******************/

XAI_ERR_TYPE MAKE_NAME(MAKE_NAME_VQ(xaiConvolved, 3D_S_5x5j4d1), S8IX_MOW_WHD) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Error Checks */
  XAI_ERROR_CHECKS()
  {
    MORPH_IDT_CHECK(inTile);
    XAI_CHECK_CONV_OUTPUT_TILE3D(outTile);
    XAI_CHECK_TILE4D_S8(coeffTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(outTile);
    XAI_CHECK_TILE4D_IN_DRAM_BOUNDARY(coeffTile);
    XAI_CHECK_POINTER(param);
    XAI_CHECK_ARRAY_S32(biasArray);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(inTile, outTile);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(coeffTile, outTile);
    XAI_CHECK_KERNEL_SIZE(coeffTile, 5);
    XAI_CHECK_TILE3D_DATA_ORDER(inTile, XAI_WHD);
    XAI_CHECK_TILE3D_DATA_ORDER(outTile, XAI_WHD);
    XAI_CHECK_TILE4D_DATA_ORDER(coeffTile, XAI_WHDN);
    XAI_CHECK_DILATION(param, 1);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_DILATIONX(param) == XAI_CNN_CONV_GET_DILATIONY(param),                                           \
                    XAI_ERR_BADARG, "Dilation along width = %hhu and height = %hhu\nDilation along width and height should be equal", \
                    XAI_CNN_CONV_GET_DILATIONX(param), XAI_CNN_CONV_GET_DILATIONY(param));
    XAI_CHECK_TILE3D_EDGE(inTile, 2);
    XAI_CHECK_STRIDE(param, 4);
    XAI_CHECK_ERROR((XAI_CNN_CONV_GET_STRIDEX(param) == XAI_CNN_CONV_GET_STRIDEY(param)),                                           \
                    XAI_ERR_BADARG, "\nStride along width = %hhu and height = %hhu\nStride along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_CONSISTENCY_MOW_WHD(inTile, coeffTile, biasArray, outTile, param);
    XAI_CHECK_COEFFTILE_CONTIGUOUS(coeffTile, param);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_ACCUM_SHIFT(param) < 24,                                     \
                    XAI_ERR_NORM, "\nThe accumulator shift = %hhu, value should be less than 24", \
                    XAI_CNN_CONV_GET_ACCUM_SHIFT(param));
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_OUTPUT_SHIFT(param) < 32,                               \
                    XAI_ERR_NORM, "\nThe output shift = %hhu, value should be less than 32", \
                    XAI_CNN_CONV_GET_OUTPUT_SHIFT(param));
    XAI_CHECK_CONV_RELU_LIMITS_IX(param, outTile);
#if DILATED_VQ_CONV == VQ_TRUE
    XAI_CHECK_ARRAY_U16(outputScaleArray);
    XAI_CHECK_ERROR(XAI_ARRAY_GET_WIDTH(outputScaleArray) >= XAI_TILE4D_GET_DIM4(coeffTile),                                                                                          \
                    XAI_ERR_DATASIZE, "\nWidth of Output Scale Array = %d, Number of Kernels = %d\nWidth of Output Scale Array should be greater than or equal to Number of Kernels", \
                    XAI_ARRAY_GET_WIDTH(outputScaleArray), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_ERROR((((uintptr_t) (XAI_ARRAY_GET_DATA_PTR(outputScaleArray)) & \
                      0x1) == 0), XAI_ERR_NORM, "The output scale array is not aligned to 2 byte boundary");
#endif
  }
#if DILATED_VQ_CONV == VQ_FALSE
  if (XAI_CNN_CONV_GET_OUTPUT_SCALE(param) == 0)
  {
    int32_t fillValue;
    int32_t reluFlag = XAI_CNN_CONV_GET_FLAG_RELU(param);
    fillValue = reluFlag ? (CLAMP(0, XAI_CNN_CONV_GET_RELU_MIN(param), XAI_CNN_CONV_GET_RELU_MAX(param))) : 0;
    return(xaiFillTile3D(outTile, fillValue, 0));
  }
#endif

  /* Getting parameters from the tile structures */
  const int32_t inW = XAI_TILE3D_GET_DIM1(inTile) + \
                      XAI_TILE3D_GET_DIM1_EDGE1(inTile) + XAI_TILE3D_GET_DIM1_EDGE2(inTile);
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t stride        = XAI_CNN_CONV_GET_STRIDE(param);

  /* Pitches of Coefficient Data (WHDN) dim3 */
  const int32_t coeffPitch2 = XAI_TILE4D_GET_DIM2_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-((kSizeU / 2) * inDataPitch1 + (kSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 *restrict pdvecIn;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1, * restrict pdvecCoeff2, * restrict pdvecCoeff3;

  /* Variable Declarations */
  int32_t inCh, outCh, x, y;
  /* Number of output elements that can be generated
   * with 2 input vector loads(64 way).*/
  const int32_t vectorizationWidth = (((4 * XCHAL_IVPN_SIMD_WIDTH) - kSizeU) / stride) + 1;

  /* generates the sequence 0,1,2,3 ,5,6,7,8 ,10,11,12,13 ,15,16,17,18
   * , 20,21,22,23 ,4,9,14,19 ,24. To be used to shuffle the coeff data,
   * So that last coeff from first 4 rows of coeffs can be used as one
   * 32 byte element and make use of quad multiplier outside the inner-
   * most loop.
   * c11, c12, c13, c14, c15
   * c21, c22, c23, c24, c25
   * c31, c32, c33, c34, c35
   * c41, c42, c43, c44, c45
   * c51, c52, c53, c54, c55
   *
   * c15, c25, c35, c45 and c55 are placed in contigous fashion, so that
   * c15, c25, c35, and c45 can be used as one 32 byte element
   */
  xb_vec2Nx8 dvecIdx;
  dvecIdx = IVP_SEL2NX8I(IVP_SEL2NX8I(IVP_ADD2NX8U(IVP_SEQ2NX8(), 15),
                                      IVP_ADD2NX8U(IVP_SEQ2NX8(), 10),
                                      IVP_SELI_INTERLEAVE_2_LO),
                         IVP_SEL2NX8I(IVP_ADD2NX8U(IVP_SEQ2NX8(), 5), IVP_SEQ2NX8(),
                                      IVP_SELI_INTERLEAVE_2_LO),
                         IVP_SELI_INTERLEAVE_4_LO);

  dvecIdx = IVP_SEL2NX8I(IVP_SEL2NX8I(IVP_MOV2NX8U_FROMNX16(
                                        IVP_MOVNX16_FROMN_2X32(4 + (9 << 8) + (14 << 16) + \
                                                               (19 << 24))),
                                      IVP_ADD2NX8U(IVP_SEQ2NX8(), 20), IVP_SELI_INTERLEAVE_2_LO),
                         dvecIdx, IVP_SELI_8B_PACK_16);

  /* loop across output depth is unrolled by 3
   * , producing lanes from 3 output channels
   * in one iteration. Since vectorization width
   * is just half the width of the accumulator,
   * loop across output height is also unrolled by 2.
   * Unrolling across output height makes it possible
   * to utilize all the 64 MACs in the accumulator.
   *
   * Data loaded from the 2 input rows is concatenated
   * in such a manner that lower half of the output
   * vector gives the first output row and the upper
   * half of the output vector gives the next output row.
   */
  for (x = 0; x < outW; x += vectorizationWidth)      /* Loop across Output width */
  {
    /* out of bound flag */
    int32_t flag = XT_SALT(2 * XCHAL_IVPN_SIMD_WIDTH, inW - stride * x);

    for (y = 0; y < outH - 1; y += 2)    /* Loop across Output height */
    {
      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * stride * y + stride * x];

      /* initialize coeff & bias data pointer to outCh kernel */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 3) /* Loop across Output depth */
      {
        /* In order to handle odd output depths */
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
        int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);

        /* loads and replicate bias data */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
        xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc1, dacc2, dacc3;
        dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
        dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
        IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

        pdvecCoeff3 = (xb_vec2Nx8 *) (pCoeff + 2 * coeffPitch3 * enable3rdCh);
        valign vaCoeffData3; vaCoeffData3 = IVP_LA2NX8_PP(pdvecCoeff3);

        pdvecIn = (MORPH_IDT_2Nx8 *) (pInput);

        for (inCh = 0; inCh < numInCh; inCh++)   /* Loop across input channels */
        {
          /* variable declarations for input and coeff vectors */
          xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2, dvecCoeffData3;

          /* load coeff for all the 4 outptu channels*/
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch2);
          IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch2);
          IVP_LAV2NX8_XP(dvecCoeffData3, vaCoeffData3, pdvecCoeff3, coeffPitch2);

          /* shuffles the loaded coeff put them in proper order */
          dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);
          dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecIdx);
          dvecCoeffData3 = IVP_SHFL2NX8(dvecCoeffData3, dvecIdx);

          /* loads 1st input row */
          MORPH_IDT_2Nx8 dvecInData11, dvecInData12;
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn, \
                             inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

          /* loads 2nd input row */
          MORPH_IDT_2Nx8 dvecInData21, dvecInData22;
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn, \
                             inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

          /* loads 3rd input row */
          MORPH_IDT_2Nx8 dvecInData31, dvecInData32;
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData31, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecInData32, vaInData, pdvecIn, \
                             inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

          /* loads 4th input row */
          MORPH_IDT_2Nx8 dvecInData41, dvecInData42;
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData41, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecInData42, vaInData, pdvecIn, \
                             inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

          /* loads 5th input row */
          MORPH_IDT_2Nx8 dvecInData51, dvecInData52;
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData51, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecInData52, vaInData, pdvecIn, \
                             inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

          /* loads 6th input row */
          MORPH_IDT_2Nx8 dvecInData61, dvecInData62;
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData61, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecInData62, vaInData, pdvecIn, \
                             inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

          /* loads 7th input row */
          MORPH_IDT_2Nx8 dvecInData71, dvecInData72;
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData71, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecInData72, vaInData, pdvecIn, \
                             inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

          /* loads 8th input row */
          MORPH_IDT_2Nx8 dvecInData81, dvecInData82;
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData81, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecInData82, vaInData, pdvecIn, \
                             inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

          /* loads 9th input row */
          MORPH_IDT_2Nx8 dvecInData91, dvecInData92;
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData91, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecInData92, vaInData, pdvecIn, \
                             inDataPitch2 - 8 * inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

          /* 32 elements from 1st row and 32 elements from 2nd row are concatenated here
           * If 1st input row is 0,1,2,3,4,5,6,7,8,9,...127, and the 2nd input row is
           * 128,129,130,131.........252,253,254,255, Data should be arranged  as
           *
           * dvecData1 : 0, 4, 8,...120,124,128,132,136,...248,252
           * dvecData2 : 1, 5, 9,...121,125,129,133,137,...249,253
           * dvecData3 : 2, 6,10,...122,126,130,134,138,...250,254
           * dvecData4 : 3, 7,11,...123,127,131,135,139,...251,255
           * dvecData5 : 4, 8,11,...124,0  ,132,136,140,...252,0
           *
           * Lower half of the vectors contain data from 1st input row and
           * upper half of the vectors contain data from 2nd output row.
           *
           */
          MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3, dvecData4;
          MORPH_IDT_2Nx8 dvecData51, dvecData52, dvecData53, dvecData54, dvecData55;

          IVP_DSEL2NX8I(dvecData2, dvecData1,
                        IVP_SEL2NX8I(dvecInData52, dvecInData51, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData4, dvecData3,
                        IVP_SEL2NX8I(dvecInData52, dvecInData51, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* dvecData5 is kept separately and is used by quad multiplier finally */
          dvecData51 = IVP_SEL2NX8I(0, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);

          /* multiplies data from two rows(Lower and upper half of dvecData)
           * with coeff from all three output channels and accumulate. Lower
           * half of the accumulators contain data corresponding to the first
           * output row and upper half contains next output row */

          MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
          MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 0));

          /* Calculations for second row */
          IVP_DSEL2NX8I(dvecData2, dvecData1,
                        IVP_SEL2NX8I(dvecInData62, dvecInData61, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData4, dvecData3,
                        IVP_SEL2NX8I(dvecInData62, dvecInData61, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          dvecData52 = IVP_SEL2NX8I(0, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);

          MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
          MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 1));

          /* Calculations for third row */
          IVP_DSEL2NX8I(dvecData2, dvecData1,
                        IVP_SEL2NX8I(dvecInData72, dvecInData71, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_SEL2NX8I(dvecInData32, dvecInData31, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData4, dvecData3,
                        IVP_SEL2NX8I(dvecInData72, dvecInData71, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_SEL2NX8I(dvecInData32, dvecInData31, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          dvecData53 = IVP_SEL2NX8I(0, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);

          MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
          MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
          MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 2));

          /* Calculations for fourth row */
          IVP_DSEL2NX8I(dvecData2, dvecData1,
                        IVP_SEL2NX8I(dvecInData82, dvecInData81, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_SEL2NX8I(dvecInData42, dvecInData41, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData4, dvecData3,
                        IVP_SEL2NX8I(dvecInData82, dvecInData81, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_SEL2NX8I(dvecInData42, dvecInData41, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          dvecData54 = IVP_SEL2NX8I(0, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);

          MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
          MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
          MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 3));

          /* Calculations for fifth row */
          IVP_DSEL2NX8I(dvecData2, dvecData1,
                        IVP_SEL2NX8I(dvecInData92, dvecInData91, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_SEL2NX8I(dvecInData52, dvecInData51, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData4, dvecData3,
                        IVP_SEL2NX8I(dvecInData92, dvecInData91, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_SEL2NX8I(dvecInData52, dvecInData51, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          dvecData55 = IVP_SEL2NX8I(0, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);

          MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));
          MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 4));
          MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 4));

          /* multiplies last coeffs of 1st four rows with the input data */
          MORPH_OP_MULQA(dacc1, dvecData54, dvecData53, dvecData52, dvecData51, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));
          MORPH_OP_MULQA(dacc2, dvecData54, dvecData53, dvecData52, dvecData51, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 5));
          MORPH_OP_MULQA(dacc3, dvecData54, dvecData53, dvecData52, dvecData51, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 5));

          /* multiplies last coeff(24th) with the input data */
          MORPH_OP_MULA(dacc1, dvecData55, IVP_EXTR2NX8(dvecCoeffData1, 24));
          MORPH_OP_MULA(dacc2, dvecData55, IVP_EXTR2NX8(dvecCoeffData2, 24));
          MORPH_OP_MULA(dacc3, dvecData55, IVP_EXTR2NX8(dvecCoeffData3, 24));
        }     /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      pOutScaleData[outCh + 2 * enable3rdCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* variable store count */
        int32_t varLen = XT_MIN(outW - x, vectorizationWidth);

        /* Storing the first row outputs, first channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 3rd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable3rdCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* extract the upper half of the output vectors
         * and store in the next row
         */

        /* Storing the 2nd row outputs, first channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut1L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * 2 * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                              outDataPitch1) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut2L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable2ndCh);
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable2ndCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 3rd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (2 * outDataPitch2 * enable3rdCh + \
                                              outDataPitch1) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut3L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable3rdCh);
        IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable3rdCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 3 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 3 * coeffPitch3;
      }  /* end of (outCh = 0; outCh < numOutCh; outCh += 3)*/
    }    /* end of for (y = 0; y < outH - 1; y += 2)*/
    if (y < outH)
    {
      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * stride * y + stride * x];

      /* initialize coeff & bias data pointer to outCh kernel */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 3) /* Loop across Output depth */
      {
        /* In order to handle odd output depths */
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
        int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);

        /* loads and replicate bias data */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
        xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc1, dacc2, dacc3;
        dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
        dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
        IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

        pdvecCoeff3 = (xb_vec2Nx8 *) (pCoeff + 2 * coeffPitch3 * enable3rdCh);
        valign vaCoeffData3; vaCoeffData3 = IVP_LA2NX8_PP(pdvecCoeff3);

        pdvecIn = (MORPH_IDT_2Nx8 *) (pInput);

        for (inCh = 0; inCh < numInCh; inCh++)   /* Loop across input channels */
        {
          /* variable declarations for input and coeff vectors */
          xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2, dvecCoeffData3;

          /* load coeff for all the 4 outptu channels*/
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch2);
          IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch2);
          IVP_LAV2NX8_XP(dvecCoeffData3, vaCoeffData3, pdvecCoeff3, coeffPitch2);

          /* shuffles the loaded coeff put them in proper order */
          dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);
          dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecIdx);
          dvecCoeffData3 = IVP_SHFL2NX8(dvecCoeffData3, dvecIdx);

          /* loads 1st input row */
          MORPH_IDT_2Nx8 dvecInData11, dvecInData12;
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn, \
                             inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

          /* loads 2nd input row */
          MORPH_IDT_2Nx8 dvecInData21, dvecInData22;
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn, \
                             inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

          /* loads 3rd input row */
          MORPH_IDT_2Nx8 dvecInData31, dvecInData32;
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData31, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecInData32, vaInData, pdvecIn, \
                             inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

          /* loads 4th input row */
          MORPH_IDT_2Nx8 dvecInData41, dvecInData42;
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData41, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecInData42, vaInData, pdvecIn, \
                             inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

          /* loads 5th input row */
          MORPH_IDT_2Nx8 dvecInData51, dvecInData52;
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData51, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecInData52, vaInData, pdvecIn, inDataPitch2 - 4 * inDataPitch1 - \
                             2 * XCHAL_IVPN_SIMD_WIDTH * flag);

          /*
           * If 1st input row is 0,1,2,3,4,5,6,7,8,9,...127,
           *
           * dvecData1 : 0, 4, 8,...120,124
           * dvecData2 : 1, 5, 9,...121,125
           * dvecData3 : 2, 6,10,...122,126
           * dvecData4 : 3, 7,11,...123,127
           * dvecData5 : 4, 8,11,...124,0
           *
           */
          MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3, dvecData4;
          MORPH_IDT_2Nx8 dvecData51, dvecData52, dvecData53, dvecData54, dvecData55;

          IVP_DSEL2NX8I(dvecData2, dvecData1,
                        0,
                        IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData4, dvecData3,
                        0,
                        IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* dvecData5 is kept separately and is used by quad multiplier finally */
          dvecData51 = IVP_SEL2NX8I(0, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);

          /* multiplies data from input row with coeff from
           * all three output channels and accumulate. */

          MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
          MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 0));

          /* Calculations for second row */
          IVP_DSEL2NX8I(dvecData2, dvecData1,
                        0,
                        IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData4, dvecData3,
                        0,
                        IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          dvecData52 = IVP_SEL2NX8I(0, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);

          MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
          MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 1));

          /* Calculations for third row */
          IVP_DSEL2NX8I(dvecData2, dvecData1,
                        0,
                        IVP_SEL2NX8I(dvecInData32, dvecInData31, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData4, dvecData3,
                        0,
                        IVP_SEL2NX8I(dvecInData32, dvecInData31, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          dvecData53 = IVP_SEL2NX8I(0, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);

          MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
          MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
          MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 2));

          /* Calculations for fourth row */
          IVP_DSEL2NX8I(dvecData2, dvecData1,
                        0,
                        IVP_SEL2NX8I(dvecInData42, dvecInData41, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData4, dvecData3,
                        0,
                        IVP_SEL2NX8I(dvecInData42, dvecInData41, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          dvecData54 = IVP_SEL2NX8I(0, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);

          MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
          MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
          MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 3));

          /* Calculations for fifth row */
          IVP_DSEL2NX8I(dvecData2, dvecData1,
                        0,
                        IVP_SEL2NX8I(dvecInData52, dvecInData51, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData4, dvecData3,
                        0,
                        IVP_SEL2NX8I(dvecInData52, dvecInData51, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          dvecData55 = IVP_SEL2NX8I(0, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);

          MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));
          MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 4));
          MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 4));

          /* multiplies last coeffs of 1st four rows with the input data */
          MORPH_OP_MULQA(dacc1, dvecData54, dvecData53, dvecData52, dvecData51, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));
          MORPH_OP_MULQA(dacc2, dvecData54, dvecData53, dvecData52, dvecData51, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 5));
          MORPH_OP_MULQA(dacc3, dvecData54, dvecData53, dvecData52, dvecData51, IVP_EXTRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 5));

          /* multiplies last coeff(24th) with the input data */
          MORPH_OP_MULA(dacc1, dvecData55, IVP_EXTR2NX8(dvecCoeffData1, 24));
          MORPH_OP_MULA(dacc2, dvecData55, IVP_EXTR2NX8(dvecCoeffData2, 24));
          MORPH_OP_MULA(dacc3, dvecData55, IVP_EXTR2NX8(dvecCoeffData3, 24));
        }     /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      pOutScaleData[outCh + 2 * enable3rdCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* variable store count */
        int32_t varLen = XT_MIN(outW - x, vectorizationWidth);

        /* Storing the first row outputs, first channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 3rd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable3rdCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 3 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 3 * coeffPitch3;
      }  /* end of (outCh = 0; outCh < numOutCh; outCh += 3)*/
    }    /* end of if(y < outH)*/
  }      /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  return(XAI_ERROR_STATUS());
}


/******************************************************************************************
*   xaiConvolved(VQ)3D_S_5x5j1d2I8S8IX_MOW_WHD
*  ***************************************************************************************/

/******************************************************************************/
/* Description : P6 optimized generic implementation for 5x5 3D convolution   */
/*               with dilation = 2                                            */
/*               Based on MORPH pre-processor specifiers, code implementation */
/*               is generated during preprocessing stage. This method can be  */
/*               used to generate 5x5 3D dilated convolution function and 5x5 */
/*               3D VQ dilated convolution function for U8 bit and S8 bit     */
/*               input data with input stride equal to 1                      */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                */
/*               Output scale array, CNN convolution params structure         */
/* Outputs     : XI Error Code                                                */
/* InOuts      : Output Tile                                                  */
/* Assumptions : CoeffData is S8                                              */
/*               biasArray is signed 32b, value not exceeding signed 24b      */
/*               Output scale array is U16                                    */
/*               OutData is S8 / U8 / S16                                     */
/*               Kernel Size is 5x5xDxN                                       */
/*               Input and Output are in WHD format                           */
/*               Coeff is in WHDN format                                      */
/******************************************************************************/

/****************** xaiConvolvedVQ3D_S_5x5j1d2_S8S8IX_MOW_WHD ******************/
/****************** xaiConvolvedVQ3D_S_5x5j1d2_U8S8IX_MOW_WHD ******************/
/******************* xaiConvolved3D_S_5x5j1d2_S8S8IX_MOW_WHD *******************/
/******************* xaiConvolved3D_S_5x5j1d2_U8S8IX_MOW_WHD *******************/

XAI_ERR_TYPE MAKE_NAME(MAKE_NAME_VQ(xaiConvolved, 3D_S_5x5j1d2), S8IX_MOW_WHD) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Error Checks */
  XAI_ERROR_CHECKS()
  {
    MORPH_IDT_CHECK(inTile);
    XAI_CHECK_CONV_OUTPUT_TILE3D(outTile);
    XAI_CHECK_TILE4D_S8(coeffTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(outTile);
    XAI_CHECK_TILE4D_IN_DRAM_BOUNDARY(coeffTile);
    XAI_CHECK_POINTER(param);
    XAI_CHECK_ARRAY_S32(biasArray);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(inTile, outTile);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(coeffTile, outTile);
    XAI_CHECK_KERNEL_SIZE(coeffTile, 5);
    XAI_CHECK_TILE3D_DATA_ORDER(inTile, XAI_WHD);
    XAI_CHECK_TILE3D_DATA_ORDER(outTile, XAI_WHD);
    XAI_CHECK_TILE4D_DATA_ORDER(coeffTile, XAI_WHDN);
    XAI_CHECK_TILE3D_EDGE(inTile, 4);
    XAI_CHECK_STRIDE(param, 1);
    XAI_CHECK_ERROR((XAI_CNN_CONV_GET_STRIDEX(param) == XAI_CNN_CONV_GET_STRIDEY(param)),                                         \
                    XAI_ERR_BADARG, "Stride along width = %hhu and height = %hhu\nStride along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_DILATION(param, 2);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_DILATIONX(param) == XAI_CNN_CONV_GET_DILATIONY(param),                                             \
                    XAI_ERR_BADARG, "\nDilation along width = %hhu and height = %hhu\nDilation along width and height should be equal", \
                    XAI_CNN_CONV_GET_DILATIONX(param), XAI_CNN_CONV_GET_DILATIONY(param));
    XAI_CHECK_CONSISTENCY_MOW_WHD(inTile, coeffTile, biasArray, outTile, param);
    XAI_CHECK_COEFFTILE_CONTIGUOUS(coeffTile, param);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_ACCUM_SHIFT(param) < 24,                                     \
                    XAI_ERR_NORM, "\nThe accumulator shift = %hhu, value should be less than 24", \
                    XAI_CNN_CONV_GET_ACCUM_SHIFT(param));
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_OUTPUT_SHIFT(param) < 32,                               \
                    XAI_ERR_NORM, "\nThe output shift = %hhu, value should be less than 32", \
                    XAI_CNN_CONV_GET_OUTPUT_SHIFT(param));
    XAI_CHECK_CONV_RELU_LIMITS_IX(param, outTile);
#if DILATED_VQ_CONV == VQ_TRUE
    XAI_CHECK_ARRAY_U16(outputScaleArray);
    XAI_CHECK_ERROR(XAI_ARRAY_GET_WIDTH(outputScaleArray) >= XAI_TILE4D_GET_DIM4(coeffTile),                                                                                          \
                    XAI_ERR_DATASIZE, "\nWidth of Output Scale Array = %d, Number of Kernels = %d\nWidth of Output Scale Array should be greater than or equal to Number of Kernels", \
                    XAI_ARRAY_GET_WIDTH(outputScaleArray), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_ERROR((((uintptr_t) (XAI_ARRAY_GET_DATA_PTR(outputScaleArray)) & \
                      0x1) == 0), XAI_ERR_NORM, "The output scale array is not aligned to 2 byte boundary");
#endif
  }
#if DILATED_VQ_CONV == VQ_FALSE
  if (XAI_CNN_CONV_GET_OUTPUT_SCALE(param) == 0)
  {
    int32_t fillValue;
    int32_t reluFlag = XAI_CNN_CONV_GET_FLAG_RELU(param);
    fillValue = reluFlag ? (CLAMP(0, XAI_CNN_CONV_GET_RELU_MIN(param), XAI_CNN_CONV_GET_RELU_MAX(param))) : 0;
    return(xaiFillTile3D(outTile, fillValue, 0));
  }
#endif
  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Pitches of Coefficient Data (WHDN) in dim3 */
  const int32_t coeffPitch2 = XAI_TILE4D_GET_DIM2_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Kernel Size (WHDN) */
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t dilationU     = XAI_CNN_CONV_GET_DILATION(param);

  int32_t dilatedkSizeU = dilationU * (kSizeU - 1) + 1;

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-((dilatedkSizeU / 2) * inDataPitch1 + (dilatedkSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 * restrict pdvecIn;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1;
  xb_vec2Nx8* restrict pdvecCoeff2;

  /* Variable Declarations */
  int32_t inCh, outCh, x, y;

  /* In order to make the loop multiply-bound we are reducing the vectorization width
     by extra values required for the kernel */
  const int32_t vectorizationWidth = ((4 * XCHAL_IVPN_SIMD_WIDTH) - dilatedkSizeU) + 1;

  /* generates the sequence 0,1,2,3 ,5,6,7,8 ,10,11,12,13 ,15,16,17,18
   * , 20,21,22,23 ,4,9,14,19 ,24. To be used to shuffle the coeff data,
   * So that last coeff from first 4 rows of coeffs can be used as one
   * 32 bit element and make use of quad multiplier outside the inner-
   * most loop.
   * c11, c12, c13, c14, c15
   * c21, c22, c23, c24, c25
   * c31, c32, c33, c34, c35
   * c41, c42, c43, c44, c45
   * c51, c52, c53, c54, c55
   *
   * c15, c25, c35, c45 and c55 are placed in contigous fashion, so that
   * c15, c25, c35, and c45 can be used as one 32 bit element
   */
  xb_vec2Nx8 dvecIdx;
  dvecIdx = IVP_SEL2NX8I(IVP_SEL2NX8I(IVP_ADD2NX8U(IVP_SEQ2NX8(), 15),
                                      IVP_ADD2NX8U(IVP_SEQ2NX8(), 10),
                                      IVP_SELI_INTERLEAVE_2_LO),
                         IVP_SEL2NX8I(IVP_ADD2NX8U(IVP_SEQ2NX8(), 5), IVP_SEQ2NX8(),
                                      IVP_SELI_INTERLEAVE_2_LO),
                         IVP_SELI_INTERLEAVE_4_LO);

  dvecIdx = IVP_SEL2NX8I(IVP_SEL2NX8I(IVP_MOV2NX8U_FROMNX16(
                                        IVP_MOVNX16_FROMN_2X32(4 + (9 << 8) + (14 << 16) + \
                                                               (19 << 24))),
                                      IVP_ADD2NX8U(IVP_SEQ2NX8(), 20), IVP_SELI_INTERLEAVE_2_LO),
                         dvecIdx, IVP_SELI_8B_PACK_16);

  /* loop across output height is unrolled twice and loop across kernel width and height is
     completely unrolled*/

  /* 0 1 2 3 .. 62 63*/
  xb_vec2Nx8 dvecPattern1 = IVP_SEQ2NX8();
  /* 64 65 66 ...126 127*/
  xb_vec2Nx8 dvecPattern2 = IVP_ADD2NX8(dvecPattern1, 64);

  if (!typeFlag)
  {
    MORPH_OP_DSELI(dvecPattern2, dvecPattern1, \
                   dvecPattern2, dvecPattern1, \
                   IVP_DSELI_8B_INTERLEAVE_1);
  }
  else
  {
    MORPH_OP_DSELI(dvecPattern2, dvecPattern1, \
                   dvecPattern2, dvecPattern1, \
                   IVP_DSELI_INTERLEAVE_1);
  }
  for (x = 0; x < outW; x += vectorizationWidth)  /* Loop across output width */
  {
    int32_t remX = XT_MIN(vectorizationWidth, outW - x);

    /* If (remX + kSizeEffU - 1) <= 2 * XCHAL_IVPN_SIMD_WIDTH,
     * i.e. if the number of input data bytes corresponding to remX number of outputs
     * is less than or equal to 2 * XCHAL_IVPN_SIMD_WIDTH, there is no need to load
     * the next 64 input bytes*/
    int32_t remXLoad = ((remX + dilatedkSizeU - 1) > 2 * XCHAL_IVPN_SIMD_WIDTH) ? 1 : 0;

    for (y = 0; y < outH; y++) /* Loop across output height */
    {
      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y + x];

      /* initialize coeff and Bias data pointer*/
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 2)  /* Loop across Output depth */
      {
        /* In order to handle odd output depths */
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

        /* Load the bias values corresponding to two output channels */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;

        dacc12 = dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);

        dacc22 = dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc22, hvecBias2, hvecBias2);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

        pdvecIn = (MORPH_IDT_2Nx8 *) pInput;

        for (inCh = 0; inCh < numInCh; inCh++)  /* Loop across input channels */
        {
          /* vectors for coeff and input loads */
          xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2;
          xb_vec2Nx8 dvecInData11, dvecInData21, dvecInData31, dvecInData41, dvecInData51;
          xb_vec2Nx8 dvecInData12, dvecInData22, dvecInData32, dvecInData42, dvecInData52;

          /* load data from first input row */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn, dilationU * inDataPitch1 - \
                             remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /* load data from 2nd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn, dilationU * inDataPitch1 - \
                             remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /*Separate odd and even indices */
          IVP_DSEL2NX8I(dvecInData22, dvecInData21, dvecInData22, dvecInData21, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load data from 3rd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData31, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData32, vaInData, pdvecIn, dilationU * inDataPitch1 - \
                             remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /* load data from 4th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData41, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData42, vaInData, pdvecIn, dilationU * inDataPitch1 - \
                             remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /* load data from 5th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData51, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData52, vaInData, pdvecIn, inDataPitch2 - \
                             remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH - dilationU * 4 * inDataPitch1);

          /* load all the 5x5 coefficients */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch2);
          IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch2);

          /* Rearrange them so that 5 MUL4T,1 MULQ,1 MUL can be used to perform entire operation */
          dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);
          dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecIdx);

          /* Multiply and accumulate 1st set of 4 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc11, 0, IVP_SEL2NX8I(dvecInData12, dvecInData11,                        \
                                                  IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(dvecInData12, dvecInData11,                        \
                                                  IVP_SELI_8B_EXTRACT_1_OF_2_OFF_1), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));

          MORPH_OP_MUL4TA(dacc21, 0, IVP_SEL2NX8I(dvecInData12, dvecInData11,                        \
                                                  IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
          MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(dvecInData12, dvecInData11,                        \
                                                  IVP_SELI_8B_EXTRACT_1_OF_2_OFF_1), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

          /* Multiply and accumulate 2nd set of 4 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc11, 0, dvecInData21, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc12, 0, dvecInData22, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc21, 0, dvecInData21, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
          MORPH_OP_MUL4TA(dacc22, 0, dvecInData22, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));

          /* Multiply and accumulate 3rd set of 4 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc11, 0, IVP_SEL2NX8I(dvecInData32, dvecInData31,                        \
                                                  IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
          MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(dvecInData32, dvecInData31,                        \
                                                  IVP_SELI_8B_EXTRACT_1_OF_2_OFF_1), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));

          MORPH_OP_MUL4TA(dacc21, 0, IVP_SEL2NX8I(dvecInData32, dvecInData31,                        \
                                                  IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
          MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(dvecInData32, dvecInData31,                        \
                                                  IVP_SELI_8B_EXTRACT_1_OF_2_OFF_1), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));

          /* Multiply and accumulate 4th set of 4 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc11, 0, IVP_SEL2NX8I(dvecInData42, dvecInData41,                        \
                                                  IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
          MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(dvecInData42, dvecInData41,                        \
                                                  IVP_SELI_8B_EXTRACT_1_OF_2_OFF_1), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));

          MORPH_OP_MUL4TA(dacc21, 0, IVP_SEL2NX8I(dvecInData42, dvecInData41,                        \
                                                  IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
          MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(dvecInData42, dvecInData41,                        \
                                                  IVP_SELI_8B_EXTRACT_1_OF_2_OFF_1), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));

          /* Multiply and accumulate 5th set of 4 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc11, 0, IVP_SEL2NX8I(dvecInData52, dvecInData51,                        \
                                                  IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));
          MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(dvecInData52, dvecInData51,                        \
                                                  IVP_SELI_8B_EXTRACT_1_OF_2_OFF_1), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));

          MORPH_OP_MUL4TA(dacc21, 0, IVP_SEL2NX8I(dvecInData52, dvecInData51,                        \
                                                  IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 4));
          MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(dvecInData52, dvecInData51,                        \
                                                  IVP_SELI_8B_EXTRACT_1_OF_2_OFF_1), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 4));

          /* Multiply and accumulate 6th set of 4 coefficients for all the outputs */
          MORPH_OP_MULQA(dacc11,                                                             \
                         IVP_SEL2NX8I(dvecInData41, IVP_SEL2NX8I(dvecInData42, dvecInData41, \
                                                                 IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0), IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData31, IVP_SEL2NX8I(dvecInData32, dvecInData31, \
                                                                 IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0), IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData21, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData11, IVP_SEL2NX8I(dvecInData12, dvecInData11, \
                                                                 IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0), IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));

          MORPH_OP_MULQA(dacc12,                                                             \
                         IVP_SEL2NX8I(dvecInData42, IVP_SEL2NX8I(dvecInData42, dvecInData41, \
                                                                 IVP_SELI_8B_EXTRACT_1_OF_2_OFF_1), IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData32, IVP_SEL2NX8I(dvecInData32, dvecInData31, \
                                                                 IVP_SELI_8B_EXTRACT_1_OF_2_OFF_1), IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData22, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData12, IVP_SEL2NX8I(dvecInData12, dvecInData11, \
                                                                 IVP_SELI_8B_EXTRACT_1_OF_2_OFF_1), IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));

          MORPH_OP_MULQA(dacc21,                                                             \
                         IVP_SEL2NX8I(dvecInData41, IVP_SEL2NX8I(dvecInData42, dvecInData41, \
                                                                 IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0), IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData31, IVP_SEL2NX8I(dvecInData32, dvecInData31, \
                                                                 IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0), IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData21, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData11, IVP_SEL2NX8I(dvecInData12, dvecInData11, \
                                                                 IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0), IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 5));

          MORPH_OP_MULQA(dacc22,                                                             \
                         IVP_SEL2NX8I(dvecInData42, IVP_SEL2NX8I(dvecInData42, dvecInData41, \
                                                                 IVP_SELI_8B_EXTRACT_1_OF_2_OFF_1), IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData32, IVP_SEL2NX8I(dvecInData32, dvecInData31, \
                                                                 IVP_SELI_8B_EXTRACT_1_OF_2_OFF_1), IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData22, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData12, IVP_SEL2NX8I(dvecInData12, dvecInData11, \
                                                                 IVP_SELI_8B_EXTRACT_1_OF_2_OFF_1), IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 5));

          /* Multiply and accumulate the final coefficient for all the outputs */
          MORPH_OP_MULA(dacc11, IVP_SEL2NX8I(dvecInData51,                                                                \
                                             IVP_SEL2NX8I(dvecInData52, dvecInData51,                                     \
                                                          IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0), IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTR2NX8(dvecCoeffData1, 24));
          MORPH_OP_MULA(dacc12, IVP_SEL2NX8I(dvecInData52,                                                                \
                                             IVP_SEL2NX8I(dvecInData52, dvecInData51,                                     \
                                                          IVP_SELI_8B_EXTRACT_1_OF_2_OFF_1), IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTR2NX8(dvecCoeffData1, 24));

          MORPH_OP_MULA(dacc21, IVP_SEL2NX8I(dvecInData51,                                                                \
                                             IVP_SEL2NX8I(dvecInData52, dvecInData51,                                     \
                                                          IVP_SELI_8B_EXTRACT_1_OF_2_OFF_0), IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTR2NX8(dvecCoeffData2, 24));
          MORPH_OP_MULA(dacc22, IVP_SEL2NX8I(dvecInData52,                                                                \
                                             IVP_SEL2NX8I(dvecInData52, dvecInData51,                                     \
                                                          IVP_SELI_8B_EXTRACT_1_OF_2_OFF_1), IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTR2NX8(dvecCoeffData2, 24));
        }  /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvec1L, dvec2L, dvec3L, dvec4L;
        xb_vec2Nx8 dvec1H, dvec2H, dvec3H, dvec4H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec1L, dvec1H, dacc11, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec2L, dvec2H, dacc12, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec3L, dvec3H, dacc21, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec4L, dvec4H, dacc22, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec1L, dvec1H, dacc11, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec2L, dvec2H, dacc12, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec3L, dvec3H, dacc21, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec4L, dvec4H, dacc22, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* Interleave odd and even indices */
        xb_vec2Nx8 dvecOut1L = MORPH_OP_SEL(dvec2L, dvec1L, dvecPattern1);
        xb_vec2Nx8 dvecOut2L = MORPH_OP_SEL(dvec2L, dvec1L, dvecPattern2);
        xb_vec2Nx8 dvecOut1H = MORPH_OP_SEL(dvec2H, dvec1H, dvecPattern1);
        xb_vec2Nx8 dvecOut2H = MORPH_OP_SEL(dvec2H, dvec1H, dvecPattern2);
        xb_vec2Nx8 dvecOut3L = MORPH_OP_SEL(dvec4L, dvec3L, dvecPattern1);
        xb_vec2Nx8 dvecOut4L = MORPH_OP_SEL(dvec4L, dvec3L, dvecPattern2);
        xb_vec2Nx8 dvecOut3H = MORPH_OP_SEL(dvec4H, dvec3H, dvecPattern1);
        xb_vec2Nx8 dvecOut4H = MORPH_OP_SEL(dvec4H, dvec3H, dvecPattern2);

        /* Storing the first output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * remX);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * remX - \
                       2 * XCHAL_IVPN_SIMD_WIDTH);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                       (2 * remX - 4 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                       (2 * remX - 6 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * remX * enable2ndCh);
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, ((bytesPerPixel * remX) - \
                                                        2 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
        IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                       (2 * remX - 4 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
        IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                       (2 * remX - 6 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 2 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 2 * coeffPitch3;
      } /* end of for (outCh = 0; outCh < numOutCh; outCh++)*/
    }   /* end of for (y = 0; y < outH; y++)*/
  }     /* end of for (x = 0; x < outW; x += 2 * vectorizationWidth)*/
  return(XAI_ERROR_STATUS());
}

/******************************************************************************************
*   xaiConvolved(VQ)3D_S_5x5j1d4I8S8IX_MOW_WHD
*  ***************************************************************************************/

/******************************************************************************/
/* Description : P6 optimized generic implementation for 5x5 3D convolution   */
/*               with dilation = 4                                            */
/*               Based on MORPH pre-processor specifiers, code implementation */
/*               is generated during preprocessing stage. This method can be  */
/*               used to generate 5x5 3D dilated convolution function and 5x5 */
/*               3D VQ dilated convolution function for U8 bit and S8 bit     */
/*               input data with input stride equal to 1                      */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                */
/*               Output scale array, CNN convolution params structure         */
/* Outputs     : XI Error Code                                                */
/* InOuts      : Output Tile                                                  */
/* Assumptions : CoeffData is S8                                              */
/*               biasArray is signed 32b, value not exceeding signed 24b      */
/*               Output scale array is U16                                    */
/*               OutData is S8 / U8 / S16                                     */
/*               Kernel Size is 5x5xDxN                                       */
/*               Input and Output are in WHD format                           */
/*               Coeff is in WHDN format                                      */
/******************************************************************************/

/****************** xaiConvolvedVQ3D_S_5x5j1d4_S8S8IX_MOW_WHD ******************/
/****************** xaiConvolvedVQ3D_S_5x5j1d4_U8S8IX_MOW_WHD ******************/
/******************* xaiConvolved3D_S_5x5j1d4_S8S8IX_MOW_WHD *******************/
/******************* xaiConvolved3D_S_5x5j1d4_U8S8IX_MOW_WHD *******************/

XAI_ERR_TYPE MAKE_NAME(MAKE_NAME_VQ(xaiConvolved, 3D_S_5x5j1d4), S8IX_MOW_WHD) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Error Checks */
  XAI_ERROR_CHECKS()
  {
    MORPH_IDT_CHECK(inTile);
    XAI_CHECK_CONV_OUTPUT_TILE3D(outTile);
    XAI_CHECK_TILE4D_S8(coeffTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(outTile);
    XAI_CHECK_TILE4D_IN_DRAM_BOUNDARY(coeffTile);
    XAI_CHECK_POINTER(param);
    XAI_CHECK_ARRAY_S32(biasArray);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(inTile, outTile);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(coeffTile, outTile);
    XAI_CHECK_KERNEL_SIZE(coeffTile, 5);
    XAI_CHECK_TILE3D_DATA_ORDER(inTile, XAI_WHD);
    XAI_CHECK_TILE3D_DATA_ORDER(outTile, XAI_WHD);
    XAI_CHECK_TILE4D_DATA_ORDER(coeffTile, XAI_WHDN);
    XAI_CHECK_TILE3D_EDGE(inTile, 8);
    XAI_CHECK_STRIDE(param, 1);
    XAI_CHECK_ERROR((XAI_CNN_CONV_GET_STRIDEX(param) == XAI_CNN_CONV_GET_STRIDEY(param)),                                         \
                    XAI_ERR_BADARG, "Stride along width = %hhu and height = %hhu\nStride along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_DILATION(param, 4);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_DILATIONX(param) == XAI_CNN_CONV_GET_DILATIONY(param),                                             \
                    XAI_ERR_BADARG, "\nDilation along width = %hhu and height = %hhu\nDilation along width and height should be equal", \
                    XAI_CNN_CONV_GET_DILATIONX(param), XAI_CNN_CONV_GET_DILATIONY(param));
    XAI_CHECK_CONSISTENCY_MOW_WHD(inTile, coeffTile, biasArray, outTile, param);
    XAI_CHECK_COEFFTILE_CONTIGUOUS(coeffTile, param);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_ACCUM_SHIFT(param) < 24,                                     \
                    XAI_ERR_NORM, "\nThe accumulator shift = %hhu, value should be less than 24", \
                    XAI_CNN_CONV_GET_ACCUM_SHIFT(param));
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_OUTPUT_SHIFT(param) < 32,                               \
                    XAI_ERR_NORM, "\nThe output shift = %hhu, value should be less than 32", \
                    XAI_CNN_CONV_GET_OUTPUT_SHIFT(param));
    XAI_CHECK_CONV_RELU_LIMITS_IX(param, outTile);
#if DILATED_VQ_CONV == VQ_TRUE
    XAI_CHECK_ARRAY_U16(outputScaleArray);
    XAI_CHECK_ERROR(XAI_ARRAY_GET_WIDTH(outputScaleArray) >= XAI_TILE4D_GET_DIM4(coeffTile),                                                                                          \
                    XAI_ERR_DATASIZE, "\nWidth of Output Scale Array = %d, Number of Kernels = %d\nWidth of Output Scale Array should be greater than or equal to Number of Kernels", \
                    XAI_ARRAY_GET_WIDTH(outputScaleArray), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_ERROR((((uintptr_t) (XAI_ARRAY_GET_DATA_PTR(outputScaleArray)) & \
                      0x1) == 0), XAI_ERR_NORM, "The output scale array is not aligned to 2 byte boundary");
#endif
  }
#if DILATED_VQ_CONV == VQ_FALSE
  if (XAI_CNN_CONV_GET_OUTPUT_SCALE(param) == 0)
  {
    int32_t fillValue;
    int32_t reluFlag = XAI_CNN_CONV_GET_FLAG_RELU(param);
    fillValue = reluFlag ? (CLAMP(0, XAI_CNN_CONV_GET_RELU_MIN(param), XAI_CNN_CONV_GET_RELU_MAX(param))) : 0;
    return(xaiFillTile3D(outTile, fillValue, 0));
  }
#endif
  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Pitches of Coefficient Data (WHDN) in dim3 */
  const int32_t coeffPitch2 = XAI_TILE4D_GET_DIM2_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Kernel Size (WHDN) */
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t dilationU     = XAI_CNN_CONV_GET_DILATION(param);

  int32_t dilatedkSizeU = dilationU * (kSizeU - 1) + 1;

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-((dilatedkSizeU / 2) * inDataPitch1 + (dilatedkSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 * restrict pdvecIn;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1;
  xb_vec2Nx8* restrict pdvecCoeff2;

  /* Variable Declarations */
  int32_t inCh, outCh, x, y;


  /* In order to make the loop multiply-bound we are reducing the vectorization width
     by extra values required for the kernel */
  const int32_t vectorizationWidth = ((4 * XCHAL_IVPN_SIMD_WIDTH) - dilatedkSizeU) + 1;

  /* generates the sequence 0,1,2,3 ,5,6,7,8 ,10,11,12,13 ,15,16,17,18
   * , 20,21,22,23 ,4,9,14,19 ,24. To be used to shuffle the coeff data,
   * So that last coeff from first 4 rows of coeffs can be used as one
   * 32 bit element and make use of quad multiplier outside the inner-
   * most loop.
   * c11, c12, c13, c14, c15
   * c21, c22, c23, c24, c25
   * c31, c32, c33, c34, c35
   * c41, c42, c43, c44, c45
   * c51, c52, c53, c54, c55
   *
   * c15, c25, c35, c45 and c55 are placed in contigous fashion, so that
   * c15, c25, c35, and c45 can be used as one 32 bit element
   */
  xb_vec2Nx8 dvecIdx;
  dvecIdx = IVP_SEL2NX8I(IVP_SEL2NX8I(IVP_ADD2NX8U(IVP_SEQ2NX8(), 15),
                                      IVP_ADD2NX8U(IVP_SEQ2NX8(), 10),
                                      IVP_SELI_INTERLEAVE_2_LO),
                         IVP_SEL2NX8I(IVP_ADD2NX8U(IVP_SEQ2NX8(), 5), IVP_SEQ2NX8(),
                                      IVP_SELI_INTERLEAVE_2_LO),
                         IVP_SELI_INTERLEAVE_4_LO);

  dvecIdx = IVP_SEL2NX8I(IVP_SEL2NX8I(IVP_MOV2NX8U_FROMNX16(
                                        IVP_MOVNX16_FROMN_2X32(4 + (9 << 8) + (14 << 16) + \
                                                               (19 << 24))),
                                      IVP_ADD2NX8U(IVP_SEQ2NX8(), 20), IVP_SELI_INTERLEAVE_2_LO),
                         dvecIdx, IVP_SELI_8B_PACK_16);

  /* loop across output height is unrolled twice and loop across kernel width and height is
     completely unrolled*/

  for (x = 0; x < outW; x += vectorizationWidth)  /* Loop across output width */
  {
    int32_t remX = XT_MIN(vectorizationWidth, outW - x);

    /* If (remX + kSizeEffU - 1) <= 2 * XCHAL_IVPN_SIMD_WIDTH,
     * i.e. if the number of input data bytes corresponding to remX number of outputs
     * is less than or equal to 2 * XCHAL_IVPN_SIMD_WIDTH, there is no need to load
     * the next 64 input bytes*/
    int32_t remXLoad = ((remX + dilatedkSizeU - 1) > 2 * XCHAL_IVPN_SIMD_WIDTH) ? 1 : 0;

    for (y = 0; y < outH; y++) /* Loop across output height */
    {
      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y + x];

      /* initialize coeff and Bias data pointer*/
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 2)  /* Loop across Output depth */
      {
        /* In order to handle odd output depths */
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

        /* Load the bias values corresponding to two output channels */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;

        dacc12 = dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);

        dacc22 = dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc22, hvecBias2, hvecBias2);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

        pdvecIn = (MORPH_IDT_2Nx8 *) pInput;

        for (inCh = 0; inCh < numInCh; inCh++)  /* Loop across input channels */
        {
          /* vectors for coeff and input loads */
          xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2;
          xb_vec2Nx8 dvecInData11, dvecInData21, dvecInData31, dvecInData41, dvecInData51;
          xb_vec2Nx8 dvecInData12, dvecInData22, dvecInData32, dvecInData42, dvecInData52;

          /* load data from first input row */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn, dilationU * inDataPitch1 - \
                             remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /*Separate odd and even indices */
          IVP_DSEL2NX8I(dvecInData12, dvecInData11, dvecInData12, dvecInData11, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecInData12, dvecInData11, dvecInData12, dvecInData11, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load data from 2nd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn, dilationU * inDataPitch1 - \
                             remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /*Separate odd and even indices */
          IVP_DSEL2NX8I(dvecInData22, dvecInData21, dvecInData22, dvecInData21, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecInData22, dvecInData21, dvecInData22, dvecInData21, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load data from 3rd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData31, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData32, vaInData, pdvecIn, dilationU * inDataPitch1 - \
                             remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /*Separate odd and even indices */
          IVP_DSEL2NX8I(dvecInData32, dvecInData31, dvecInData32, dvecInData31, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecInData32, dvecInData31, dvecInData32, dvecInData31, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load data from 4th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData41, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData42, vaInData, pdvecIn, dilationU * inDataPitch1 - \
                             remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /*Separate odd and even indices */
          IVP_DSEL2NX8I(dvecInData42, dvecInData41, dvecInData42, dvecInData41, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecInData42, dvecInData41, dvecInData42, dvecInData41, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load data from 5th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData51, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData52, vaInData, pdvecIn, inDataPitch2 - \
                             remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH - dilationU * 4 * inDataPitch1);

          /*Separate odd and even indices */
          IVP_DSEL2NX8I(dvecInData52, dvecInData51, dvecInData52, dvecInData51, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecInData52, dvecInData51, dvecInData52, dvecInData51, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load all the 5x5 coefficients */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch2);
          IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch2);

          /* Rearrange them so that 5 MUL4T,1 MULQ,1 MUL can be used to perform entire operation */
          dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);
          dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecIdx);

          /* Multiply and accumulate 1st set of 4 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc11, 0, dvecInData11, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc12, 0, dvecInData12, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));

          MORPH_OP_MUL4TA(dacc21, 0, dvecInData11, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
          MORPH_OP_MUL4TA(dacc22, 0, dvecInData12, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

          /* Multiply and accumulate 2nd set of 4 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc11, 0, dvecInData21, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc12, 0, dvecInData22, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc21, 0, dvecInData21, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
          MORPH_OP_MUL4TA(dacc22, 0, dvecInData22, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));

          /* Multiply and accumulate 3rd set of 4 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc11, 0, dvecInData31, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
          MORPH_OP_MUL4TA(dacc12, 0, dvecInData32, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));

          MORPH_OP_MUL4TA(dacc21, 0, dvecInData31, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
          MORPH_OP_MUL4TA(dacc22, 0, dvecInData32, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));

          /* Multiply and accumulate 4th set of 4 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc11, 0, dvecInData41, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
          MORPH_OP_MUL4TA(dacc12, 0, dvecInData42, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));

          MORPH_OP_MUL4TA(dacc21, 0, dvecInData41, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
          MORPH_OP_MUL4TA(dacc22, 0, dvecInData42, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));

          /* Multiply and accumulate 5th set of 4 coefficients for all the outputs */
          MORPH_OP_MUL4TA(dacc11, 0, dvecInData51, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));
          MORPH_OP_MUL4TA(dacc12, 0, dvecInData52, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));

          MORPH_OP_MUL4TA(dacc21, 0, dvecInData51, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 4));
          MORPH_OP_MUL4TA(dacc22, 0, dvecInData52, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 4));

          /* Multiply and accumulate 6th set of 4 coefficients for all the outputs */
          MORPH_OP_MULQA(dacc11, \
                         IVP_SEL2NX8I(dvecInData41, dvecInData41, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData31, dvecInData31, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData21, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData11, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));

          MORPH_OP_MULQA(dacc12, \
                         IVP_SEL2NX8I(dvecInData42, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData32, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData22, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData12, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));

          MORPH_OP_MULQA(dacc21, \
                         IVP_SEL2NX8I(dvecInData41, dvecInData41, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData31, dvecInData31, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData21, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData11, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 5));

          MORPH_OP_MULQA(dacc22, \
                         IVP_SEL2NX8I(dvecInData42, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData32, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData22, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_SEL2NX8I(dvecInData12, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4),
                         IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 5));

          /* Multiply and accumulate the final coefficient for all the outputs */
          MORPH_OP_MULA(dacc11, IVP_SEL2NX8I(dvecInData51, dvecInData51, \
                                             IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTR2NX8(dvecCoeffData1, 24));
          MORPH_OP_MULA(dacc12, IVP_SEL2NX8I(dvecInData52, dvecInData52, \
                                             IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTR2NX8(dvecCoeffData1, 24));

          MORPH_OP_MULA(dacc21, IVP_SEL2NX8I(dvecInData51, dvecInData51, \
                                             IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTR2NX8(dvecCoeffData2, 24));
          MORPH_OP_MULA(dacc22, IVP_SEL2NX8I(dvecInData52, dvecInData52, \
                                             IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTR2NX8(dvecCoeffData2, 24));
        }  /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        if (!typeFlag)
        {
          MORPH_OP_DSELI(dvecOut2L, dvecOut1L, dvecOut2L, dvecOut1L, \
                         IVP_DSELI_8B_INTERLEAVE_1);
          MORPH_OP_DSELI(dvecOut2L, dvecOut1L, dvecOut2L, dvecOut1L, \
                         IVP_DSELI_8B_INTERLEAVE_1);
          MORPH_OP_DSELI(dvecOut4L, dvecOut3L, dvecOut4L, dvecOut3L, \
                         IVP_DSELI_8B_INTERLEAVE_1);
          MORPH_OP_DSELI(dvecOut4L, dvecOut3L, dvecOut4L, dvecOut3L, \
                         IVP_DSELI_8B_INTERLEAVE_1);
        }
        else
        {
          MORPH_OP_DSELI(dvecOut1H, dvecOut1L, dvecOut1H, dvecOut1L, \
                         IVP_DSELI_INTERLEAVE_1);
          MORPH_OP_DSELI(dvecOut2H, dvecOut2L, dvecOut2H, dvecOut2L, \
                         IVP_DSELI_INTERLEAVE_1);
          MORPH_OP_DSELI(dvecOut2L, dvecOut1L, dvecOut2L, dvecOut1L, \
                         IVP_DSELI_INTERLEAVE_2);
          MORPH_OP_DSELI(dvecOut2H, dvecOut1H, dvecOut2H, dvecOut1H, \
                         IVP_DSELI_INTERLEAVE_2);
          MORPH_OP_DSELI(dvecOut3H, dvecOut3L, dvecOut3H, dvecOut3L, \
                         IVP_DSELI_INTERLEAVE_1);
          MORPH_OP_DSELI(dvecOut4H, dvecOut4L, dvecOut4H, dvecOut4L, \
                         IVP_DSELI_INTERLEAVE_1);
          MORPH_OP_DSELI(dvecOut4L, dvecOut3L, dvecOut4L, dvecOut3L, \
                         IVP_DSELI_INTERLEAVE_2);
          MORPH_OP_DSELI(dvecOut4H, dvecOut3H, dvecOut4H, dvecOut3H, \
                         IVP_DSELI_INTERLEAVE_2);
        }

        /* Storing the first output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * remX);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * remX - \
                       2 * XCHAL_IVPN_SIMD_WIDTH);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                       (2 * remX - 4 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                       (2 * remX - 6 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the second output depth, first row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * remX * enable2ndCh);
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, ((bytesPerPixel * remX) - \
                                                        2 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
        IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                       (2 * remX - 4 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
        IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                       (2 * remX - 6 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 2 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 2 * coeffPitch3;
      } /* end of for (outCh = 0; outCh < numOutCh; outCh++)*/
    }   /* end of for (y = 0; y < outH; y++)*/
  }     /* end of for (x = 0; x < outW; x += 2 * vectorizationWidth)*/
  return(XAI_ERROR_STATUS());
}

/******************************************************************************************
*   xaiConvolved(VQ)3D_S_7x7j1d1I8S8IX_MOW_WHD
*  ***************************************************************************************/

/******************************************************************************/
/* Description : P6 optimized generic implementation for 7x7 3D convolution.  */
/*               Based on MORPH pre-processor specifiers, code implementation */
/*               is generated during preprocessing stage. This method can be  */
/*               used to generate 7x7 3D dilated convolution function and 7x7 */
/*               3D VQ dilated convolution function for U8 bit and S8 bit     */
/*               input data with input stride equal to 1                      */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                */
/*               Output scale array, CNN convolution params structure         */
/* Outputs     : XI Error Code                                                */
/* InOuts      : Output Tile                                                  */
/* Assumptions : CoeffData is S8                                              */
/*               biasArray is signed 32b, value not exceeding signed 24b      */
/*               Output scale array is U16                                    */
/*               OutData is S8 / U8 / S16                                     */
/*               Kernel Size is 7x7xDxN                                       */
/*               Input and Output are in WHD format                           */
/*               Coeff is in WHDN format                                      */
/******************************************************************************/

/******************************************************************************************
* 7x7 MOW WHD Stride 1 - DEPTH 3                                                          *
* If number of input channels is equal to 3                                               *
* this function is called.                                                                *
******************************************************************************************/

static _XAI_INLINE_ void MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_7x7j1d1), S8IX_MOW_WHD_DEPTH3) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);

  /* Pitches of Coefficient Data (WHDN) in dim1 and dim3 */
  const int32_t coeffPitch1 = XAI_TILE4D_GET_DIM1_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-((kSizeU / 2) * inDataPitch1 + (kSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 * restrict pdvecIn;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1;

  /* Variable Declarations */
  int32_t outCh, x, y;
  int32_t varLen;

  /* In order to make the loop multiply-bound we are reducing the vectorization width
     by extra values required for the kernel */
  const int32_t vectorizationWidth = ((4 * XCHAL_IVPN_SIMD_WIDTH) - kSizeU) + 1;

  /* Vectorization width taken is 122. Two loads from same row
   * Loop across output height is unrolled twice.
   * Thus a single iteration produces 4 output vector.
   * Input channels , kernel width and kernel height
   * are completely unrolled.
   */
  for (x = 0; x < outW; x += vectorizationWidth) /* Loop across Output width */
  {
    /* In order to handle cases where input width <= 64, where
     * the 2nd load from the same row needs to be avoided.  */
    varLen = XT_MIN(vectorizationWidth, outW - x);
    int32_t enable2ndCol = XT_SALT(2 * XCHAL_IVPN_SIMD_WIDTH, varLen + kSizeU - 1);

    for (y = 0; y < outH; y += 2)  /* Loop across Output height */
    {
      /* In order to handle odd output height */
      int32_t enable2ndRow = XT_SALT(y, outH - 1);
      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y + x];

      /* initialize coeff and Bias data pointer*/
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh++)  /* Loop across Output depth */
      {
        /* load and replicate bias data */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;
        dacc11 = dacc12 = dacc21 = dacc22 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc21, hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc22, hvecBias1, hvecBias1);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

        pdvecIn = (MORPH_IDT_2Nx8 *) pInput;

        /* 2 4-tap multipliers are used to accumulate 1 wide vector
         * first 4-tap multiplier makes use of first 4 coeff across
         * the kernel width. next 4 tap mulplier makes use last 3
         * coeff across the kernel width, and 4th byte is zero
         */

        MORPH_IDT_2Nx8 dvecInData11, dvecInData21, dvecInData31, dvecInData41, \
                       dvecInData51, dvecInData61, dvecInData71, dvecInData81;

        MORPH_IDT_2Nx8 dvecInData12, dvecInData22, dvecInData32, dvecInData42, \
                       dvecInData52, dvecInData62, dvecInData72, dvecInData82;

        /** Input Channel 1 **/
        /* load data from first input row */
        valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 2nd input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 3rd input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData31, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData32, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 4th input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData41, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData42, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 5th input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData51, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData52, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 6th input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData61, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData62, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 7th input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData71, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData72, vaInData, pdvecIn, \
                           inDataPitch1 * enable2ndRow - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 8th input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData81, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData82, vaInData, pdvecIn,                 \
                           inDataPitch2 - (6 + enable2ndRow) * inDataPitch1 \
                           - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load first row of the coeff */
        xb_vec2Nx8 dvecCoeffData1;
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

        /* Multiply input vectors with first coeff row */
        MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc12, 0, dvecInData12, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc21, dvecInData22, dvecInData21, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc22, 0, dvecInData22, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* load 2nd row of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

        /* Multiply input vectors with 2nd coeff row */
        MORPH_OP_MUL4TA(dacc11, dvecInData22, dvecInData21, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc12, 0, dvecInData22, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc21, dvecInData32, dvecInData31, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData32, dvecInData31, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc22, 0, dvecInData32, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* load 3rd row of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

        /* Multiply input vectors with 3rd coeff row */
        MORPH_OP_MUL4TA(dacc11, dvecInData32, dvecInData31, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData32, dvecInData31, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc12, 0, dvecInData32, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc21, dvecInData42, dvecInData41, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData42, dvecInData41, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc22, 0, dvecInData42, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* load 4th row of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

        /* Multiply input vectors with 4th coeff row */
        MORPH_OP_MUL4TA(dacc11, dvecInData42, dvecInData41, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData42, dvecInData41, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc12, 0, dvecInData42, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc21, dvecInData52, dvecInData51, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData52, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData52, dvecInData51, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc22, 0, dvecInData52, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData52, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* load 5th row of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

        /* Multiply input vectors with 5th coeff row */
        MORPH_OP_MUL4TA(dacc11, dvecInData52, dvecInData51, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData52, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData52, dvecInData51, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc12, 0, dvecInData52, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData52, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc21, dvecInData62, dvecInData61, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData62, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData62, dvecInData61, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc22, 0, dvecInData62, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData62, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* load 6th row of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

        /* Multiply input vectors with 6th coeff row */
        MORPH_OP_MUL4TA(dacc11, dvecInData62, dvecInData61, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData62, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData62, dvecInData61, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc12, 0, dvecInData62, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData62, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc21, dvecInData72, dvecInData71, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData72, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData72, dvecInData71, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc22, 0, dvecInData72, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData72, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* load 7th row of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);
        /* Multiply input vectors with 7th coeff row */
        MORPH_OP_MUL4TA(dacc11, dvecInData72, dvecInData71, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData72, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData72, dvecInData71, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc12, 0, dvecInData72, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData72, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc21, dvecInData82, dvecInData81, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData82, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData82, dvecInData81, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc22, 0, dvecInData82, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData82, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /** Input Channel 2 **/
        /* load data from 1st input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 2nd input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 3rd input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData31, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData32, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 4th input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData41, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData42, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 5th input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData51, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData52, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);


        /* load data from 6th input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData61, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData62, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 7th input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData71, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData72, vaInData, pdvecIn, \
                           inDataPitch1 * enable2ndRow - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 8th input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData81, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData82, vaInData, pdvecIn,                 \
                           inDataPitch2 - (6 + enable2ndRow) * inDataPitch1 \
                           - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load first row of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

        /* Multiply input vectors with first coeff row */
        MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc12, 0, dvecInData12, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc21, dvecInData22, dvecInData21, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc22, 0, dvecInData22, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* load 2nd row of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

        /* Multiply input vectors with 2nd coeff row */
        MORPH_OP_MUL4TA(dacc11, dvecInData22, dvecInData21, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc12, 0, dvecInData22, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc21, dvecInData32, dvecInData31, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData32, dvecInData31, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc22, 0, dvecInData32, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* load 3rd row of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

        /* Multiply input vectors with 3rd coeff row */
        MORPH_OP_MUL4TA(dacc11, dvecInData32, dvecInData31, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData32, dvecInData31, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc12, 0, dvecInData32, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc21, dvecInData42, dvecInData41, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData42, dvecInData41, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc22, 0, dvecInData42, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* load 4th row of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

        /* Multiply input vectors with 4th coeff row */
        MORPH_OP_MUL4TA(dacc11, dvecInData42, dvecInData41, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData42, dvecInData41, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc12, 0, dvecInData42, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc21, dvecInData52, dvecInData51, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData52, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData52, dvecInData51, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc22, 0, dvecInData52, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData52, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* load 5th row of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

        /* Multiply input vectors with 5th coeff row */
        MORPH_OP_MUL4TA(dacc11, dvecInData52, dvecInData51, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData52, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData52, dvecInData51, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc12, 0, dvecInData52, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData52, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc21, dvecInData62, dvecInData61, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData62, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData62, dvecInData61, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc22, 0, dvecInData62, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData62, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* load 6th row of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

        /* Multiply input vectors with 6th coeff row */
        MORPH_OP_MUL4TA(dacc11, dvecInData62, dvecInData61, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData62, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData62, dvecInData61, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc12, 0, dvecInData62, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData62, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc21, dvecInData72, dvecInData71, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData72, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData72, dvecInData71, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc22, 0, dvecInData72, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData72, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* load 7th row of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);
        /* Multiply input vectors with 7th coeff row */
        MORPH_OP_MUL4TA(dacc11, dvecInData72, dvecInData71, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData72, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData72, dvecInData71, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc12, 0, dvecInData72, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData72, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc21, dvecInData82, dvecInData81, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData82, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData82, dvecInData81, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc22, 0, dvecInData82, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData82, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /** Input Channel 3 **/
        /*load data from 1st input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 2nd input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 3rd input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData31, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData32, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 4th input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData41, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData42, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 5th input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData51, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData52, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);


        /* load data from 6th input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData61, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData62, vaInData, pdvecIn, \
                           inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 7th input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData71, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData72, vaInData, pdvecIn, \
                           inDataPitch1 * enable2ndRow - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load data from 8th input row */
        vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData81, vaInData, pdvecIn, \
                           enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
        MORPH_OP_LOAD_2Nx8(dvecInData82, vaInData, pdvecIn,                 \
                           inDataPitch2 - (6 + enable2ndRow) * inDataPitch1 \
                           - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

        /* load first row of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

        /* Multiply input vectors with first coeff row */
        MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc12, 0, dvecInData12, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc21, dvecInData22, dvecInData21, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc22, 0, dvecInData22, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* load 2nd row of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

        /* Multiply input vectors with 2nd coeff row */
        MORPH_OP_MUL4TA(dacc11, dvecInData22, dvecInData21, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc12, 0, dvecInData22, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc21, dvecInData32, dvecInData31, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData32, dvecInData31, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc22, 0, dvecInData32, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* load 3rd row of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

        /* Multiply input vectors with 3rd coeff row */
        MORPH_OP_MUL4TA(dacc11, dvecInData32, dvecInData31, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData32, dvecInData31, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc12, 0, dvecInData32, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc21, dvecInData42, dvecInData41, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData42, dvecInData41, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc22, 0, dvecInData42, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* load 4th row of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

        /* Multiply input vectors with 4th coeff row */
        MORPH_OP_MUL4TA(dacc11, dvecInData42, dvecInData41, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData42, dvecInData41, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc12, 0, dvecInData42, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc21, dvecInData52, dvecInData51, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData52, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData52, dvecInData51, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc22, 0, dvecInData52, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData52, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* load 5th row of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

        /* Multiply input vectors with 5th coeff row */
        MORPH_OP_MUL4TA(dacc11, dvecInData52, dvecInData51, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData52, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData52, dvecInData51, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc12, 0, dvecInData52, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData52, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc21, dvecInData62, dvecInData61, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData62, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData62, dvecInData61, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc22, 0, dvecInData62, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData62, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* load 6th row of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

        /* Multiply input vectors with 6th coeff row */
        MORPH_OP_MUL4TA(dacc11, dvecInData62, dvecInData61, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData62, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData62, dvecInData61, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc12, 0, dvecInData62, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData62, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc21, dvecInData72, dvecInData71, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData72, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData72, dvecInData71, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc22, 0, dvecInData72, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData72, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* load 7th row of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);
        /* Multiply input vectors with 7th coeff row */
        MORPH_OP_MUL4TA(dacc11, dvecInData72, dvecInData71, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData72, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData72, dvecInData71, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc12, 0, dvecInData72, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData72, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc21, dvecInData82, dvecInData81, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData82, IVP_SELI_8B_ROTATE_RIGHT_4),
                        IVP_SEL2NX8I(dvecInData82, dvecInData81, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        MORPH_OP_MUL4TA(dacc22, 0, dvecInData82, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData82, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* 1st row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * (varLen - 2 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                       2 * (varLen - 3 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* 2nd row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndRow * outDataPitch1 * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * varLen);
        IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * enable2ndRow * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * \
                       (varLen - 2 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * enable2ndRow * \
                       2 * (varLen - 3 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += outDataPitch2 * bytesPerPixel;
        pCoeff  += coeffPitch3;
      } /* end of for (outCh = 0; outCh < numOutCh; outCh++)*/
    }   /* end of for (y = 0; y < outH; y += 2)*/
  }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
}

/******************************************************************************************
* 7x7 MOW fold 32 Stride 1                                                                *
* If inDataPitch1 is lesser than or equal to                                              *
* 32 this function is called.                                                             *
******************************************************************************************/

static _XAI_INLINE_ void MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_7x7j1d1), S8IX_MOW_WHD_FOLD32) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);

  /* Pitches of Coefficient Data (WHDN) in dim1 and dim3 */
  const int32_t coeffPitch1 = XAI_TILE4D_GET_DIM1_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-((kSizeU / 2) * inDataPitch1 + (kSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 * restrict pdvecIn;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1;


  /* Variable Declarations */
  int32_t inCh, outCh, y;

  /* Select sequence to re-arrange input data */
  xb_vec2Nx8 dvecSeq = 0;
  IVP_ADD2NX8T(dvecSeq, IVP_SEQ2NX8(), inDataPitch1, IVP_LT2NX8(IVP_SEQ2NX8(), inDataPitch1));
  IVP_ADD2NX8T(dvecSeq, IVP_SUB2NX8(IVP_SEQ2NX8(), inDataPitch1), 64, \
               IVP_NOTB2N(IVP_LT2NX8(IVP_SEQ2NX8(), inDataPitch1)));

  /* loop across output height is unrolled twice
   * to produce two output vectors in 1 iteration
   */
  for (y = 0; y < outH; y += 2)  /* Loop across Output height */
  {
    /* In order to handle odd output height */
    int32_t enable2ndRow = XT_SALT(y, outH - 1);

    /* initialize output data pointer */
    int8_t *pOutput = &pOutData[(y * outDataPitch1) * bytesPerPixel];

    /* initialize coeff and Bias data pointer*/
    int8_t *pCoeff = &pCoeffData[0];
    int32_t *pBias = &pBiasData[0];

    for (outCh = 0; outCh < numOutCh; outCh++)  /* Loop across Output depth */
    {
      /* load and replicate bias data */
      xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4);

      /* wide vectors(accumulators) initialized with bias */
      xb_vec2Nx24 dacc1, dacc2;
      dacc1 = dacc2 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
      IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
      IVP_CVT24UNX32H(dacc2, hvecBias1, hvecBias1);

      /* priming of coeff load is done outside the innermost loop*/
      pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
      valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y];

      for (inCh = 0; inCh < numInCh; inCh++)  /* Loop across input depth */
      {
        /* 2 4-tap multipliers are used to accumulate 1 wide vector
         * first 4-tap multiplier makes use of first 4 coeff across
         * the kernel width. next 4 tap mulplier makes use last 3
         * coeff across the kernel width, and 4th byte is zero
         */

        xb_vec2Nx8 dvecInData1, dvecInData2, dvecInData3, dvecInData4;

        /* load data from first 2 input rows */
        pdvecIn = (MORPH_IDT_2Nx8 *) pInput;
        valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
        MORPH_OP_LOAD_2Nx8(dvecInData1, vaInData, pdvecIn, 2 * inDataPitch1);

        /* load data from next 2 input rows */
        MORPH_OP_LOAD_2Nx8(dvecInData2, vaInData, pdvecIn, 2 * inDataPitch1);

        /* load data from next 2 input rows */
        MORPH_OP_LOAD_2Nx8(dvecInData3, vaInData, pdvecIn, 2 * inDataPitch1);

        /* load data from next 2 input rows */
        MORPH_OP_LOAD_2Nx8_VARIABLE(dvecInData4, vaInData, pdvecIn, (1 + enable2ndRow) * inDataPitch1);
        pInput += inDataPitch2;

        /* load first row of the coeff */
        xb_vec2Nx8 dvecCoeffData1;
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

        xb_vec2Nx8 dvecTemp1, dvecTemp2, dvecTemp3;
        dvecTemp1 = IVP_SEL2NX8(dvecInData2, dvecInData1, dvecSeq);
        dvecTemp2 = IVP_SEL2NX8(dvecInData3, dvecInData2, dvecSeq);
        dvecTemp3 = IVP_SEL2NX8(dvecInData4, dvecInData3, dvecSeq);

        /* Multiply input vectors with first coeff row */
        MORPH_OP_MUL4TA(dacc1, 0, dvecInData1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(0, dvecInData1, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));


        /* load 2nd row of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

        /* Multiply input vectors with 2nd coeff row */
        MORPH_OP_MUL4TA(dacc1, 0, dvecTemp1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(0, dvecTemp1, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));


        /* load 3rdrow of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

        /* Multiply input vectors with 3rd coeff row */
        MORPH_OP_MUL4TA(dacc1, 0, dvecInData2, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(0, dvecInData2, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));


        /* load 4th row of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

        /* Multiply input vectors with 4th coeff row */
        MORPH_OP_MUL4TA(dacc1, 0, dvecTemp2, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(0, dvecTemp2, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* load 5th row of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

        /* Multiply input vectors with 5th coeff row */
        MORPH_OP_MUL4TA(dacc1, 0, dvecInData3, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(0, dvecInData3, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));


        /* load 6th row of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

        /* Multiply input vectors with 6th coeff row */
        MORPH_OP_MUL4TA(dacc1, 0, dvecTemp3, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(0, dvecTemp3, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));



        /* load 7th row of the coeff */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

        /* Multiply input vectors with 7th coeff row */
        MORPH_OP_MUL4TA(dacc1, 0, dvecInData4, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(0, dvecInData4, IVP_SELI_8B_ROTATE_RIGHT_4), \
                        IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
      }   /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

      /* Pack, Output Scale, Output Shift and clamping */
      xb_vec2Nx8 dvecOut1L;
      xb_vec2Nx8 dvecOut1H;
#if DILATED_VQ_CONV == VQ_TRUE
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                    pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
      PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                    outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
      /* Storing the first output depth, first row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput);
      valign vaOutData = IVP_ZALIGN();
      IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      /* Storing the first output depth, second row */
      pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2ndRow * bytesPerPixel);
      IVP_SAV2NX8_XP(IVP_SEL2NX8(dvecOut1H, dvecOut1L, IVP_ADD2NX8(IVP_SEQ2NX8(), inDataPitch1 * bytesPerPixel)), \
                     vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * outW);
      IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

      pOutput += outDataPitch2 * bytesPerPixel;
      pCoeff  += coeffPitch3;
    } /* end of for (outCh = 0; outCh < numOutCh; outCh++)*/
  }   /* end of for (y = 0; y < outH; y += 2)*/
}

/****************** xaiConvolvedVQ3D_S_7x7j1d1_S8S8IX_MOW_WHD ******************/
/****************** xaiConvolvedVQ3D_S_7x7j1d1_U8S8IX_MOW_WHD ******************/
/******************* xaiConvolved3D_S_7x7j1d1_S8S8IX_MOW_WHD *******************/
/******************* xaiConvolved3D_S_7x7j1d1_U8S8IX_MOW_WHD *******************/

XAI_ERR_TYPE MAKE_NAME(MAKE_NAME_VQ(xaiConvolved, 3D_S_7x7j1d1), S8IX_MOW_WHD) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Error Checks */
  XAI_ERROR_CHECKS()
  {
    MORPH_IDT_CHECK(inTile);
    XAI_CHECK_CONV_OUTPUT_TILE3D(outTile);
    XAI_CHECK_TILE4D_S8(coeffTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(outTile);
    XAI_CHECK_TILE4D_IN_DRAM_BOUNDARY(coeffTile);
    XAI_CHECK_POINTER(param);
    XAI_CHECK_ARRAY_S32(biasArray);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(inTile, outTile);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(coeffTile, outTile);
    XAI_CHECK_KERNEL_SIZE(coeffTile, 7);
    XAI_CHECK_TILE3D_DATA_ORDER(inTile, XAI_WHD);
    XAI_CHECK_TILE3D_DATA_ORDER(outTile, XAI_WHD);
    XAI_CHECK_TILE4D_DATA_ORDER(coeffTile, XAI_WHDN);
    XAI_CHECK_DILATION(param, 1);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_DILATIONX(param) == XAI_CNN_CONV_GET_DILATIONY(param),                                           \
                    XAI_ERR_BADARG, "Dilation along width = %hhu and height = %hhu\nDilation along width and height should be equal", \
                    XAI_CNN_CONV_GET_DILATIONX(param), XAI_CNN_CONV_GET_DILATIONY(param));
    XAI_CHECK_TILE3D_EDGE(inTile, 3);
    XAI_CHECK_STRIDE(param, 1);
    XAI_CHECK_ERROR((XAI_CNN_CONV_GET_STRIDEX(param) == XAI_CNN_CONV_GET_STRIDEY(param)),                                           \
                    XAI_ERR_BADARG, "\nStride along width = %hhu and height = %hhu\nStride along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_CONSISTENCY_MOW_WHD(inTile, coeffTile, biasArray, outTile, param);
    XAI_CHECK_COEFFTILE_CONTIGUOUS(coeffTile, param);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_ACCUM_SHIFT(param) < 24,                                     \
                    XAI_ERR_NORM, "\nThe accumulator shift = %hhu, value should be less than 24", \
                    XAI_CNN_CONV_GET_ACCUM_SHIFT(param));
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_OUTPUT_SHIFT(param) < 32,                               \
                    XAI_ERR_NORM, "\nThe output shift = %hhu, value should be less than 32", \
                    XAI_CNN_CONV_GET_OUTPUT_SHIFT(param));
    XAI_CHECK_CONV_RELU_LIMITS_IX(param, outTile);
#if DILATED_VQ_CONV == VQ_TRUE
    XAI_CHECK_ARRAY_U16(outputScaleArray);
    XAI_CHECK_ERROR(XAI_ARRAY_GET_WIDTH(outputScaleArray) >= XAI_TILE4D_GET_DIM4(coeffTile),                                                                                          \
                    XAI_ERR_DATASIZE, "\nWidth of Output Scale Array = %d, Number of Kernels = %d\nWidth of Output Scale Array should be greater than or equal to Number of Kernels", \
                    XAI_ARRAY_GET_WIDTH(outputScaleArray), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_ERROR((((uintptr_t) (XAI_ARRAY_GET_DATA_PTR(outputScaleArray)) & \
                      0x1) == 0), XAI_ERR_NORM, "The output scale array is not aligned to 2 byte boundary");
#endif
  }
#if DILATED_VQ_CONV == VQ_FALSE
  if (XAI_CNN_CONV_GET_OUTPUT_SCALE(param) == 0)
  {
    int32_t fillValue;
    int32_t reluFlag = XAI_CNN_CONV_GET_FLAG_RELU(param);
    fillValue = reluFlag ? (CLAMP(0, XAI_CNN_CONV_GET_RELU_MIN(param), XAI_CNN_CONV_GET_RELU_MAX(param))) : 0;
    return(xaiFillTile3D(outTile, fillValue, 0));
  }
#endif
  /* Call DEPTH3 varinat if input depth =3 */
  if (XAI_TILE3D_GET_DIM3(inTile) == 3)
  {
    MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_7x7j1d1), S8IX_MOW_WHD_DEPTH3) MAKE_PARAMS(inTile, coeffTile, biasArray, outTile, param);
    return(XAI_ERROR_STATUS());
  }
  /* check inDataPitch1, if it is less than or equal to 32,
   * call FOLD32 variant
   */
  if (XAI_TILE3D_GET_DIM1_PITCH(inTile) <= 32)
  {
    MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_7x7j1d1), S8IX_MOW_WHD_FOLD32) MAKE_PARAMS(inTile, coeffTile, biasArray, outTile, param);
    return(XAI_ERROR_STATUS());
  }

  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);

  /* Pitches of Coefficient Data (WHDN) in dim1 and dim3 */
  const int32_t coeffPitch1 = XAI_TILE4D_GET_DIM1_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-((kSizeU / 2) * inDataPitch1 + (kSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 * restrict pdvecIn;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1;

  /* Variable Declarations */
  int32_t inCh, outCh, x, y;
  int32_t varLen;

  /* In order to make the loop multiply-bound we are reducing the vectorization width
      by extra values required for the kernel */
  const int32_t vectorizationWidth58  = ((2 * XCHAL_IVPN_SIMD_WIDTH) - kSizeU) + 1;
  const int32_t vectorizationWidth122 = ((4 * XCHAL_IVPN_SIMD_WIDTH) - kSizeU) + 1;

  /* loop across output height is unrolled twice.
   * Loop across kernel width and height is
   * completely unrolled.
   * 128 bytes of input are loaded.
   */
  for (x = 0; x < outW - vectorizationWidth58; x += vectorizationWidth122)  /* Loop across Output width */
  {
    varLen = XT_MIN(vectorizationWidth122, outW - x);
    int32_t enable2ndCol = XT_SALT(2 * XCHAL_IVPN_SIMD_WIDTH, varLen + kSizeU - 1);
    for (y = 0; y < outH; y += 2)   /* Loop across Output height */
    {
      /* In order to handle odd output height */
      int32_t enable2ndRow = XT_SALT(y, outH - 1);
      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y + x];

      /* initialize coeff and Bias data pointer*/
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh++)   /* Loop across Output depth */
      {
        /* load and replicate bias data */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;
        dacc11 = dacc12 = dacc21 = dacc22 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc21, hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc22, hvecBias1, hvecBias1);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

        pdvecIn = (MORPH_IDT_2Nx8 *) pInput;

        for (inCh = 0; inCh < numInCh; inCh++)   /* Loop across input depth */
        {
          /* 2 4-tap multipliers are used to accumulate 1 wide vector
           * first 4-tap multiplier makes use of first 4 coeff across
           * the kernel width. next 4 tap mulplier makes use last 3
           * coeff across the kernel width, and 4th byte is zero
           */

          MORPH_IDT_2Nx8 dvecInData11, dvecInData21, dvecInData31, dvecInData41, dvecInData51, \
                         dvecInData61, dvecInData71, dvecInData81;

          MORPH_IDT_2Nx8 dvecInData12, dvecInData22, dvecInData32, dvecInData42, dvecInData52, \
                         dvecInData62, dvecInData72, dvecInData82;

          /* load data from first input row */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn, \
                             enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn, \
                             inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /* load data from 2nd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn, \
                             enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn, \
                             inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /* load data from 3rd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData31, vaInData, pdvecIn, \
                             enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData32, vaInData, pdvecIn, \
                             inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /* load data from 4th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData41, vaInData, pdvecIn, \
                             enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData42, vaInData, pdvecIn, \
                             inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /* load data from 5th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData51, vaInData, pdvecIn, \
                             enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData52, vaInData, pdvecIn, \
                             inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /* load data from 6th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData61, vaInData, pdvecIn, \
                             enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData62, vaInData, pdvecIn, \
                             inDataPitch1 - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /* load data from 7th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData71, vaInData, pdvecIn, \
                             enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData72, vaInData, pdvecIn, \
                             inDataPitch1 * enable2ndRow      \
                             - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /* load data from 8th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData81, vaInData, pdvecIn, \
                             enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData82, vaInData, pdvecIn,                 \
                             inDataPitch2 - (6 + enable2ndRow) * inDataPitch1 \
                             - enable2ndCol * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /* load first row of the coeff */
          xb_vec2Nx8 dvecCoeffData1;
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply input vectors with first coeff row */
          MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4),
                          IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc12, 0, dvecInData12, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc21, dvecInData22, dvecInData21, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4),
                          IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc22, 0, dvecInData22, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* load 2nd row of the coeff */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply input vectors with 2nd coeff row */
          MORPH_OP_MUL4TA(dacc11, dvecInData22, dvecInData21, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4),
                          IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc12, 0, dvecInData22, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc21, dvecInData32, dvecInData31, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4),
                          IVP_SEL2NX8I(dvecInData32, dvecInData31, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc22, 0, dvecInData32, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* load 3rd row of the coeff */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply input vectors with 3rd coeff row */
          MORPH_OP_MUL4TA(dacc11, dvecInData32, dvecInData31, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4),
                          IVP_SEL2NX8I(dvecInData32, dvecInData31, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc12, 0, dvecInData32, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData32, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc21, dvecInData42, dvecInData41, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4),
                          IVP_SEL2NX8I(dvecInData42, dvecInData41, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc22, 0, dvecInData42, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* load 4th row of the coeff */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply input vectors with 4th coeff row */
          MORPH_OP_MUL4TA(dacc11, dvecInData42, dvecInData41, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4),
                          IVP_SEL2NX8I(dvecInData42, dvecInData41, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc12, 0, dvecInData42, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData42, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc21, dvecInData52, dvecInData51, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData52, IVP_SELI_8B_ROTATE_RIGHT_4),
                          IVP_SEL2NX8I(dvecInData52, dvecInData51, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc22, 0, dvecInData52, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData52, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* load 5th row of the coeff */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply input vectors with 5th coeff row */
          MORPH_OP_MUL4TA(dacc11, dvecInData52, dvecInData51, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData52, IVP_SELI_8B_ROTATE_RIGHT_4),
                          IVP_SEL2NX8I(dvecInData52, dvecInData51, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc12, 0, dvecInData52, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData52, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));


          MORPH_OP_MUL4TA(dacc21, dvecInData62, dvecInData61, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData62, IVP_SELI_8B_ROTATE_RIGHT_4),
                          IVP_SEL2NX8I(dvecInData62, dvecInData61, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc22, 0, dvecInData62, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData62, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* load 6th row of the coeff */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply input vectors with 6th coeff row */
          MORPH_OP_MUL4TA(dacc11, dvecInData62, dvecInData61, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData62, IVP_SELI_8B_ROTATE_RIGHT_4),
                          IVP_SEL2NX8I(dvecInData62, dvecInData61, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc12, 0, dvecInData62, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData62, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc21, dvecInData72, dvecInData71, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData72, IVP_SELI_8B_ROTATE_RIGHT_4),
                          IVP_SEL2NX8I(dvecInData72, dvecInData71, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc22, 0, dvecInData72, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData72, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* load 7th row of the coeff */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);
          /* Multiply input vectors with 7th coeff row */
          MORPH_OP_MUL4TA(dacc11, dvecInData72, dvecInData71, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc11, IVP_SEL2NX8I(0, dvecInData72, IVP_SELI_8B_ROTATE_RIGHT_4),
                          IVP_SEL2NX8I(dvecInData72, dvecInData71, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc12, 0, dvecInData72, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc12, 0, IVP_SEL2NX8I(0, dvecInData72, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc21, dvecInData82, dvecInData81, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc21, IVP_SEL2NX8I(0, dvecInData82, IVP_SELI_8B_ROTATE_RIGHT_4),
                          IVP_SEL2NX8I(dvecInData82, dvecInData81, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc22, 0, dvecInData82, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc22, 0, IVP_SEL2NX8I(0, dvecInData82, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
        }    /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* 1st row  */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * (varLen - 2 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                       2 * (varLen - 3 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* 2nd row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndRow * outDataPitch1 * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * varLen);
        IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * enable2ndRow * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * \
                       (varLen - 2 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * enable2ndRow * \
                       2 * (varLen - 3 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += outDataPitch2 * bytesPerPixel;
        pCoeff  += coeffPitch3;
      }  /* end of for (outCh = 0; outCh < numOutCh; outCh++)*/
    }    /* end of for (y = 0; y < outH; y += 2)*/
  }      /* end of for (x = 0; x < outW; x += vectorizationWidth)*/


  /* To handle cases where the remaining output width is less than or equal to 58.
   * loop across output height is unrolled twice. Loop across kernel width and height is
   * completely unrolled. 64 bytes of input are loaded.
   */
  if (x < outW)
  {
    for (y = 0; y < outH; y += 2)  /* Loop across Output height */
    {
      /* In order to handle odd output height */
      int32_t enable2ndRow = XT_SALT(y, outH - 1);
      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y + x];

      /* initialize coeff and Bias data pointer*/
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh++)  /* Loop across Output depth */
      {
        /* load and replicate bias data */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc1, dacc2;
        dacc1 = dacc2 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc2, hvecBias1, hvecBias1);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

        pdvecIn = (MORPH_IDT_2Nx8 *) pInput;

        for (inCh = 0; inCh < numInCh; inCh++)  /* Loop across input depth */
        {
          /* 2 4-tap multipliers are used to accumulate 1 wide vector
           * first 4-tap multiplier makes use of first 4 coeff across
           * the kernel width. next 4 tap mulplier makes use last 3
           * coeff across the kernel width, and 4th byte is zero
           */

          xb_vec2Nx8 dvecInData1, dvecInData2, dvecInData3, dvecInData4, dvecInData5, \
                     dvecInData6, dvecInData7, dvecInData8;

          /* load data from first input row */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData1, vaInData, pdvecIn, inDataPitch1);

          /* load data from 2nd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData2, vaInData, pdvecIn, inDataPitch1);

          /* load data from 3rd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData3, vaInData, pdvecIn, inDataPitch1);

          /* load data from 4th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData4, vaInData, pdvecIn, inDataPitch1);

          /* load data from 5th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData5, vaInData, pdvecIn, inDataPitch1);

          /* load data from 6th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData6, vaInData, pdvecIn, inDataPitch1);

          /* load data from 7th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData7, vaInData, pdvecIn, inDataPitch1 * enable2ndRow);

          /* load data from 8th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData8, vaInData, pdvecIn, inDataPitch2 - (6 + enable2ndRow) * inDataPitch1);

          /* load first row of the coeff */
          xb_vec2Nx8 dvecCoeffData1;
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply input vectors with first coeff row */
          MORPH_OP_MUL4TA(dacc1, 0, dvecInData1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(0, dvecInData1, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc2, 0, dvecInData2, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, IVP_SEL2NX8I(0, dvecInData2, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* load 2nd row of the coeff */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply input vectors with 2nd coeff row */
          MORPH_OP_MUL4TA(dacc1, 0, dvecInData2, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(0, dvecInData2, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc2, 0, dvecInData3, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, IVP_SEL2NX8I(0, dvecInData3, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* load 3rdrow of the coeff */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply input vectors with 3rd coeff row */
          MORPH_OP_MUL4TA(dacc1, 0, dvecInData3, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(0, dvecInData3, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc2, 0, dvecInData4, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, IVP_SEL2NX8I(0, dvecInData4, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* load 4th row of the coeff */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply input vectors with 4th coeff row */
          MORPH_OP_MUL4TA(dacc1, 0, dvecInData4, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(0, dvecInData4, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc2, 0, dvecInData5, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, IVP_SEL2NX8I(0, dvecInData5, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* load 5th row of the coeff */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply input vectors with 5th coeff row */
          MORPH_OP_MUL4TA(dacc1, 0, dvecInData5, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(0, dvecInData5, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc2, 0, dvecInData6, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, IVP_SEL2NX8I(0, dvecInData6, IVP_SELI_8B_ROTATE_RIGHT_4),
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* load 6th row of the coeff */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply input vectors with 6th coeff row */
          MORPH_OP_MUL4TA(dacc1, 0, dvecInData6, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(0, dvecInData6, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc2, 0, dvecInData7, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, IVP_SEL2NX8I(0, dvecInData7, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* load 7th row of the coeff */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply input vectors with 7th coeff row */
          MORPH_OP_MUL4TA(dacc1, 0, dvecInData7, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(0, dvecInData7, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          MORPH_OP_MUL4TA(dacc2, 0, dvecInData8, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, IVP_SEL2NX8I(0, dvecInData8, IVP_SELI_8B_ROTATE_RIGHT_4), \
                          IVP_EXTRN_2X32(IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
        }   /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* variable length for output stores */
        varLen = XT_MIN(vectorizationWidth58, outW - x);

        /* Storing the first depth output */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* first depth , 2nd row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndRow * outDataPitch1 * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * varLen);
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * enable2ndRow * \
                       2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += outDataPitch2 * bytesPerPixel;
        pCoeff  += coeffPitch3;
      } /* end of for (outCh = 0; outCh < numOutCh; outCh++)*/
    }   /* end of for (y = 0; y < outH; y += 2)*/
  }     /* end of if(x < outW)*/
  return(XAI_ERROR_STATUS());
}

/******************************************************************************************
* 7x7 MOW WHD Stride 2 - DEPTH 3                                                          *
* If number of input channels is equal to 3                                               *
* this function is called.                                                                *
******************************************************************************************/

static _XAI_INLINE_ void MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_7x7j2d1), S8IX_MOW_WHD_DEPTH3) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t stride        = XAI_CNN_CONV_GET_STRIDE(param);

  /* Pitches of Coefficient Data (WHDN) dim3 */
  const int32_t coeffPitch2 = XAI_TILE4D_GET_DIM2_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-((kSizeU / 2) * inDataPitch1 + (kSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8* restrict pdvecIn1;
  MORPH_IDT_2Nx8* restrict pdvecIn2;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1, * restrict pdvecCoeff2;

  /* Variable Declarations */
  int32_t outCh, x, y;
  int32_t varLen;
  /* No. of output elements that can be processed from 2 input loads */
  const int32_t vectorizationWidth = (((2 * XCHAL_IVPN_SIMD_WIDTH) - kSizeU) / stride) + 1;

  /* generates the sequence to shuffle the coeff */
  /* 0 1 2 3 4 5 6 7  7 8 9 10 11 12 13 14  8 9 10 11 12 13 14 15 .. */
  xb_vec2Nx8 dvecShflIdx = IVP_SEL2NX8I(IVP_ADD2NX8U(IVP_SEQ2NX8(), 7), \
                                        IVP_SEQ2NX8(), IVP_SELI_8B_INTERLEAVE_8_LO);
  /* 0 2 4 6 8 10 12 14 14 16 18 20 22 24 26 28  28 30 32 34 36 38 40 42 42 44 46 48 50 52 ...  */
  dvecShflIdx = IVP_SEL2NX8I(IVP_SLLI2NX8(IVP_ADD2NX8U(dvecShflIdx, 14), 1), \
                             IVP_SLLI2NX8(dvecShflIdx, 1), IVP_SELI_8B_PACK_16);
  /* Assuming that 50th index will have zero values */
  /* Final shuffle index pattern will be
      0  2  4  6   1  3  5 50   8 10 12 50   7 9 11 13
     14 16 18 20  15 17 19 50  22 24 26 50  21 23 25 27
     28 30 32 34  29 31 33 50  36 38 40 50  35 37 39 41
     42 44 46 48  43 45 47 50
   */
  dvecShflIdx = IVP_SEL2NX8I(
    IVP_MOV2NX8T(50, IVP_ADD2NX8(dvecShflIdx, IVP_SEL2NX8I(-1, 1, IVP_SELI_8B_INTERLEAVE_4_LO)),
                 IVP_EQ2NX8(IVP_AND2NX8(IVP_SEQ2NX8(), 7), 3)),
    IVP_MOV2NX8T(50, dvecShflIdx, IVP_EQ2NX8(IVP_AND2NX8(IVP_SEQ2NX8(), 7), 7)),
    IVP_SELI_8B_INTERLEAVE_4_LO);

  /* The inner most loop runs across the kernel height and produces
   * 4 output vectors - 2 output rows from 2 output channels. Unrolling across the output
   * channels by 2 helps in re-using the already loaded input data. Unrolling across the
   * output height by 2 helps in re-using the already loaded coeff data.
   * The coefficients are arranged in such a way that MORPH_OP_MUL4TA can be used.
   */
  for (x = 0; x < outW; x += vectorizationWidth) /* Loop across output width */
  {
    for (y = 0; y < outH; y += 2) /* Loop across output height */
    {
      /* In order to handle odd output heights */
      int32_t enable2Row = XT_SALT(y, outH - 1);

      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * stride * (y) + stride * (x)];

      /* initialize coeff data pointer and bias data pointer to outCh kernel */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 2) /* Loop across output channels */
      {
        /* In order to handle odd output depths */
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

        /* Initialize the acc for 1st and 2nd output row of 1st channel with bias data */
        xb_vec2Nx24 dacc1;
        dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        /* Initialize the acc for 1st and 2nd output row of 2nd channel with bias data */
        xb_vec2Nx24 dacc2;
        dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);

        /* priming for coeff loads */
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

        pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
        pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2);

        xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2;
        xb_vec2Nx8 dvecI0, dvecI1;
        /******************************** 1st inCh **************************************/
        /* Load vectors from first row */
        valign vaInData1; vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        xb_vec2Nx8 dvecInData1; IVP_LA2NX8_XP(dvecInData1, vaInData1, pdvecIn1, inDataPitch1);

        /* Load vectors from 2nd row */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        xb_vec2Nx8 dvecInData2; IVP_LA2NX8_XP(dvecInData2, vaInData1, pdvecIn1, inDataPitch1);

        /* Load vectors from 3rd row */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        xb_vec2Nx8 dvecInData3; IVP_LA2NX8_XP(dvecInData3, vaInData1, pdvecIn1, inDataPitch1);

        /* Load vectors from 4th row */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        xb_vec2Nx8 dvecInData4; IVP_LA2NX8_XP(dvecInData4, vaInData1, pdvecIn1, inDataPitch1);

        /* Load vectors from 5th row */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        xb_vec2Nx8 dvecInData5; IVP_LA2NX8_XP(dvecInData5, vaInData1, pdvecIn1, inDataPitch1);

        /* Load vectors from 6th row */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        xb_vec2Nx8 dvecInData6; IVP_LA2NX8_XP(dvecInData6, vaInData1, pdvecIn1, inDataPitch1);

        /* Load vectors from 7th row */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        xb_vec2Nx8 dvecInData7; IVP_LA2NX8_XP(dvecInData7, vaInData1, pdvecIn1, \
                                              inDataPitch1 * enable2Row);

        /* Load vectors from 8th row, to be used by 2nd output height */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        xb_vec2Nx8 dvecInData8; IVP_LA2NX8_XP(dvecInData8, vaInData1, pdvecIn1, \
                                              inDataPitch1 * enable2Row);

        /* Load vectors from 9th row, to be used by 2nd output height */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        xb_vec2Nx8 dvecInData9; IVP_LA2NX8_XP(dvecInData9, vaInData1, pdvecIn1, \
                                              inDataPitch2 - (6 + 2 * enable2Row) * inDataPitch1);

        /* Load the 7x7 coefficients for 2 output channels */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch2);
        IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch2);

        /* rearrange the coeff in desired format, so that MUL4T can be used */
        dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecShflIdx);
        dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecShflIdx);

        /* Re-arrange the data in the desired format                              */
        /* Assume input as 0,1,2, .. 63 for two rows                              */
        /* After re-arrangement using DSEL operation, updated vectors would be    */
        /* dvecI0 : 0, 2, 4, ...                                                  */
        /* dvecI1 : 1, 3, 5, ...                                                  */
        IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData3, dvecInData1, IVP_DSELI_8B_DEINTERLEAVE_1);

        /* Mulitply 1st row with coeff from 1st output channel */
        MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* Mulitply 1st row with coeff from 2nd output channel */
        MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
        MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));


        /* rearrange input vectors */
        IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData4, dvecInData2, IVP_DSELI_8B_DEINTERLEAVE_1);


        /* Mulitply 2nd row with coeff from 1st output channel */
        MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
        MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));

        /* Mulitply 2nd row with coeff from 2nd output channel */
        MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
        MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));

        /* rearrange input vectors */
        IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData5, dvecInData3, IVP_DSELI_8B_DEINTERLEAVE_1);

        /* Mulitply 3rd row with coeff from 1st output channel */
        MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));
        MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));

        /* Mulitply 3rd row with coeff from 2nd output channel */
        MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 4));
        MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 5));

        /* rearrange input vectors */
        IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData6, dvecInData4, IVP_DSELI_8B_DEINTERLEAVE_1);

        /* Mulitply 4th row with coeff from 1st output channel */
        MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 7));
        MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 6));

        /* Mulitply 4th row with coeff from 2nd output channel */
        MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 7));
        MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 6));


        /* rearrange input vectors */
        IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData7, dvecInData5, IVP_DSELI_8B_DEINTERLEAVE_1);


        /* Mulitply 5th row with coeff from 1st output channel */
        MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 8));
        MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 9));

        /* Mulitply 5th row with coeff from 2nd output channel */
        MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 8));
        MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 9));


        /* rearrange input vectors */
        IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData8, dvecInData6, IVP_DSELI_8B_DEINTERLEAVE_1);

        /* Mulitply 6th row with coeff from 1st output channel */
        MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 11));
        MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 10));

        /* Mulitply 6th row with coeff from 2nd output channel */
        MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 11));
        MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 10));

        /* rearrange input vectors */
        IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData9, dvecInData7, IVP_DSELI_8B_DEINTERLEAVE_1);

        /* Mulitply 7th row with coeff from 1st output channel */
        MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 12));
        MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 13));

        /* Mulitply 7th row with coeff from 2nd output channel */
        MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 12));
        MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 13));

        /***************************** 2nd inCh **********************************************/
        /* Load vectors from first row */

        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        IVP_LA2NX8_XP(dvecInData1, vaInData1, pdvecIn1, inDataPitch1);

        /* Load vectors from 2nd row */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        IVP_LA2NX8_XP(dvecInData2, vaInData1, pdvecIn1, inDataPitch1);

        /* Load vectors from 3rd row */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        IVP_LA2NX8_XP(dvecInData3, vaInData1, pdvecIn1, inDataPitch1);

        /* Load vectors from 4th row */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        IVP_LA2NX8_XP(dvecInData4, vaInData1, pdvecIn1, inDataPitch1);

        /* Load vectors from 5th row */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        IVP_LA2NX8_XP(dvecInData5, vaInData1, pdvecIn1, inDataPitch1);

        /* Load vectors from 6th row */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        IVP_LA2NX8_XP(dvecInData6, vaInData1, pdvecIn1, inDataPitch1);

        /* Load vectors from 7th row */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        IVP_LA2NX8_XP(dvecInData7, vaInData1, pdvecIn1, inDataPitch1 * enable2Row);

        /* Load vectors from 8th row, to be used by 2nd output height */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        IVP_LA2NX8_XP(dvecInData8, vaInData1, pdvecIn1, inDataPitch1 * enable2Row);

        /* Load vectors from 9th row, to be used by 2nd output height */
        vaInData1 = MORPH_OP_PRIME_2Nx8(pdvecIn1);
        IVP_LA2NX8_IP(dvecInData9, vaInData1, pdvecIn1);

        /* Load the 7x7 coefficients for 2 output channels */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch2);
        IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch2);

        /* rearrange the coeff in desired format, so that MUL4T can be used */
        dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecShflIdx);
        dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecShflIdx);

        /* Re-arrange the data in the desired format                              */
        /* Assume input as 0,1,2, .. 63 for two rows                              */
        /* After re-arrangement using DSEL operation, updated vectors would be    */
        /* dvecI0 : 0, 2, 4, ...                                                  */
        /* dvecI1 : 1, 3, 5, ...                                                  */
        IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData3, dvecInData1, IVP_DSELI_8B_DEINTERLEAVE_1);

        /* Mulitply 1st row with coeff from 1st output channel */
        MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* Mulitply 1st row with coeff from 2nd output channel */
        MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
        MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));


        /* rearrange input vectors */
        IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData4, dvecInData2, IVP_DSELI_8B_DEINTERLEAVE_1);


        /* Mulitply 2nd row with coeff from 1st output channel */
        MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
        MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));

        /* Mulitply 2nd row with coeff from 2nd output channel */
        MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
        MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));

        /* rearrange input vectors */
        IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData5, dvecInData3, IVP_DSELI_8B_DEINTERLEAVE_1);

        /* Mulitply 3rd row with coeff from 1st output channel */
        MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));
        MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));

        /* Mulitply 3rd row with coeff from 2nd output channel */
        MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 4));
        MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 5));

        /* rearrange input vectors */
        IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData6, dvecInData4, IVP_DSELI_8B_DEINTERLEAVE_1);

        /* Mulitply 4th row with coeff from 1st output channel */
        MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 7));
        MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 6));

        /* Mulitply 4th row with coeff from 2nd output channel */
        MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 7));
        MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 6));


        /* rearrange input vectors */
        IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData7, dvecInData5, IVP_DSELI_8B_DEINTERLEAVE_1);


        /* Mulitply 5th row with coeff from 1st output channel */
        MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 8));
        MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 9));

        /* Mulitply 5th row with coeff from 2nd output channel */
        MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 8));
        MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 9));


        /* rearrange input vectors */
        IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData8, dvecInData6, IVP_DSELI_8B_DEINTERLEAVE_1);

        /* Mulitply 6th row with coeff from 1st output channel */
        MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 11));
        MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 10));

        /* Mulitply 6th row with coeff from 2nd output channel */
        MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 11));
        MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 10));

        /* rearrange input vectors */
        IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData9, dvecInData7, IVP_DSELI_8B_DEINTERLEAVE_1);

        /* Mulitply 7th row with coeff from 1st output channel */
        MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 12));
        MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 13));

        /* Mulitply 7th row with coeff from 2nd output channel */
        MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 12));
        MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 13));

        /******************************* 3rd inCh *********************************************/
        /* Load vectors from first row */
        valign vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        IVP_LA2NX8_XP(dvecInData1, vaInData2, pdvecIn2, inDataPitch1);

        /* Load vectors from 2nd row */
        vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        IVP_LA2NX8_XP(dvecInData2, vaInData2, pdvecIn2, inDataPitch1);

        /* Load vectors from 3rd row */
        vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        IVP_LA2NX8_XP(dvecInData3, vaInData2, pdvecIn2, inDataPitch1);

        /* Load vectors from 4th row */
        vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        IVP_LA2NX8_XP(dvecInData4, vaInData2, pdvecIn2, inDataPitch1);

        /* Load vectors from 5th row */
        vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        IVP_LA2NX8_XP(dvecInData5, vaInData2, pdvecIn2, inDataPitch1);

        /* Load vectors from 6th row */
        vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        IVP_LA2NX8_XP(dvecInData6, vaInData2, pdvecIn2, inDataPitch1);

        /* Load vectors from 7th row */
        vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        IVP_LA2NX8_XP(dvecInData7, vaInData2, pdvecIn2, inDataPitch1 * enable2Row);

        /* Load vectors from 8th row, to be used by 2nd output height */
        vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        IVP_LA2NX8_XP(dvecInData8, vaInData2, pdvecIn2, inDataPitch1 * enable2Row);

        /* Load vectors from 9th row, to be used by 2nd output height */
        vaInData2 = MORPH_OP_PRIME_2Nx8(pdvecIn2);
        IVP_LA2NX8_IP(dvecInData9, vaInData2, pdvecIn2);

        /* Load the 7x7 coefficients for 2 output channels */
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch2);
        IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch2);

        /* rearrange the coeff in desired format, so that MUL4T can be used */
        dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecShflIdx);
        dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecShflIdx);

        /* Re-arrange the data in the desired format                              */
        /* Assume input as 0,1,2, .. 63 for two rows                              */
        /* After re-arrangement using DSEL operation, updated vectors would be    */
        /* dvecI0 : 0, 2, 4, ...                                                  */
        /* dvecI1 : 1, 3, 5, ...                                                  */
        IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData3, dvecInData1, IVP_DSELI_8B_DEINTERLEAVE_1);

        /* Mulitply 1st row with coeff from 1st output channel */
        MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
        MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

        /* Mulitply 1st row with coeff from 2nd output channel */
        MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
        MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));


        /* rearrange input vectors */
        IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData4, dvecInData2, IVP_DSELI_8B_DEINTERLEAVE_1);


        /* Mulitply 2nd row with coeff from 1st output channel */
        MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
        MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));

        /* Mulitply 2nd row with coeff from 2nd output channel */
        MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
        MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));

        /* rearrange input vectors */
        IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData5, dvecInData3, IVP_DSELI_8B_DEINTERLEAVE_1);

        /* Mulitply 3rd row with coeff from 1st output channel */
        MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));
        MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));

        /* Mulitply 3rd row with coeff from 2nd output channel */
        MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 4));
        MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 5));

        /* rearrange input vectors */
        IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData6, dvecInData4, IVP_DSELI_8B_DEINTERLEAVE_1);

        /* Mulitply 4th row with coeff from 1st output channel */
        MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 7));
        MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 6));

        /* Mulitply 4th row with coeff from 2nd output channel */
        MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 7));
        MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 6));


        /* rearrange input vectors */
        IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData7, dvecInData5, IVP_DSELI_8B_DEINTERLEAVE_1);


        /* Mulitply 5th row with coeff from 1st output channel */
        MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 8));
        MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 9));

        /* Mulitply 5th row with coeff from 2nd output channel */
        MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 8));
        MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 9));


        /* rearrange input vectors */
        IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData8, dvecInData6, IVP_DSELI_8B_DEINTERLEAVE_1);

        /* Mulitply 6th row with coeff from 1st output channel */
        MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 11));
        MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 10));

        /* Mulitply 6th row with coeff from 2nd output channel */
        MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 11));
        MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 10));

        /* rearrange input vectors */
        IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData9, dvecInData7, IVP_DSELI_8B_DEINTERLEAVE_1);

        /* Mulitply 7th row with coeff from 1st output channel */
        MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 12));
        MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 13));

        /* Mulitply 7th row with coeff from 2nd output channel */
        MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 12));
        MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                          (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 13));


        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh ], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* variable length for output stores */
        varLen = XT_MIN(vectorizationWidth, outW - x);

        /* Storing the 1st row output from 1st channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row output from 1st channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2Row * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8I(dvecOut1L, dvecOut1L, IVP_SELI_EXTRACT_HI_HALVES), vaOutData, \
                       pdvecOut, (-typeFlag + 1) * varLen * enable2Row);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * 2 * varLen * enable2Row);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 1st row output from 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, enable2ndCh * bytesPerPixel * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row output from 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch1 * enable2Row + \
                                              outDataPitch2 * enable2ndCh) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8I(dvecOut2L, dvecOut2L, IVP_SELI_EXTRACT_HI_HALVES), vaOutData, \
                       pdvecOut, enable2ndCh * (-typeFlag + 1) * varLen * enable2Row);
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, enable2ndCh * typeFlag * 2 * varLen * \
                       enable2Row);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 2 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 2 * coeffPitch3;
      }   /* END for (outCh = 0; outCh < numOutCh; outCh += 2)*/
    }     /* END for (y = 0; y < outH ; y += 2)*/
  }       /* END for (x = 0; x < outW; x += vectorizationWidth)*/
}


/******************************************************************************************
*   xaiConvolved(VQ)3D_S_7x7j2d1I8S8IX_MOW_WHD
*  ***************************************************************************************/

/******************************************************************************/
/* Description : P6 optimized generic implementation for 7x7 3D convolution.  */
/*               Based on MORPH pre-processor specifiers, code implementation */
/*               is generated during preprocessing stage. This method can be  */
/*               used to generate 7x7 3D dilated convolution function and 7x7 */
/*               3D VQ dilated convolution function for U8 bit and S8 bit     */
/*               input data with input stride equal to 2                      */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                */
/*               Output scale array, CNN convolution params structure         */
/* Outputs     : XI Error Code                                                */
/* InOuts      : Output Tile                                                  */
/* Assumptions : CoeffData is S8                                              */
/*               biasArray is signed 32b, value not exceeding signed 24b      */
/*               Output scale array is U16                                    */
/*               OutData is S8 / U8 / S16                                     */
/*               Kernel Size is 7x7xDxN                                       */
/*               Input and Output are in WHD format                           */
/*               Coeff is in WHDN format                                      */
/******************************************************************************/

/****************** xaiConvolvedVQ3D_S_7x7j2d1_S8S8IX_MOW_WHD ******************/
/****************** xaiConvolvedVQ3D_S_7x7j2d1_U8S8IX_MOW_WHD ******************/
/******************* xaiConvolved3D_S_7x7j2d1_S8S8IX_MOW_WHD *******************/
/******************* xaiConvolved3D_S_7x7j2d1_U8S8IX_MOW_WHD *******************/

XAI_ERR_TYPE MAKE_NAME(MAKE_NAME_VQ(xaiConvolved, 3D_S_7x7j2d1), S8IX_MOW_WHD) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Error Checks */
  XAI_ERROR_CHECKS()
  {
//    MORPH_IDT_CHECK(inTile);
    XAI_CHECK_CONV_OUTPUT_TILE3D(outTile);
    XAI_CHECK_TILE4D_S8(coeffTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(outTile);
    XAI_CHECK_TILE4D_IN_DRAM_BOUNDARY(coeffTile);
    XAI_CHECK_POINTER(param);
    XAI_CHECK_ARRAY_S32(biasArray);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(inTile, outTile);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(coeffTile, outTile);
    XAI_CHECK_KERNEL_SIZE(coeffTile, 7);
    XAI_CHECK_TILE3D_DATA_ORDER(inTile, XAI_WHD);
    XAI_CHECK_TILE3D_DATA_ORDER(outTile, XAI_WHD);
    XAI_CHECK_TILE4D_DATA_ORDER(coeffTile, XAI_WHDN);
    XAI_CHECK_DILATION(param, 1);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_DILATIONX(param) == XAI_CNN_CONV_GET_DILATIONY(param),                                           \
                    XAI_ERR_BADARG, "Dilation along width = %hhu and height = %hhu\nDilation along width and height should be equal", \
                    XAI_CNN_CONV_GET_DILATIONX(param), XAI_CNN_CONV_GET_DILATIONY(param));
    XAI_CHECK_TILE3D_EDGE(inTile, 3);
    XAI_CHECK_STRIDE(param, 2);
    XAI_CHECK_ERROR((XAI_CNN_CONV_GET_STRIDEX(param) == XAI_CNN_CONV_GET_STRIDEY(param)),                                           \
                    XAI_ERR_BADARG, "\nStride along width = %hhu and height = %hhu\nStride along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_CONSISTENCY_MOW_WHD(inTile, coeffTile, biasArray, outTile, param);
    XAI_CHECK_COEFFTILE_CONTIGUOUS(coeffTile, param);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_ACCUM_SHIFT(param) < 24,                                     \
                    XAI_ERR_NORM, "\nThe accumulator shift = %hhu, value should be less than 24", \
                    XAI_CNN_CONV_GET_ACCUM_SHIFT(param));
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_OUTPUT_SHIFT(param) < 32,                               \
                    XAI_ERR_NORM, "\nThe output shift = %hhu, value should be less than 32", \
                    XAI_CNN_CONV_GET_OUTPUT_SHIFT(param));
    XAI_CHECK_CONV_RELU_LIMITS_IX(param, outTile);
#if DILATED_VQ_CONV == VQ_TRUE
    XAI_CHECK_ARRAY_U16(outputScaleArray);
    XAI_CHECK_ERROR(XAI_ARRAY_GET_WIDTH(outputScaleArray) >= XAI_TILE4D_GET_DIM4(coeffTile),                                                                                          \
                    XAI_ERR_DATASIZE, "\nWidth of Output Scale Array = %d, Number of Kernels = %d\nWidth of Output Scale Array should be greater than or equal to Number of Kernels", \
                    XAI_ARRAY_GET_WIDTH(outputScaleArray), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_ERROR((((uintptr_t) (XAI_ARRAY_GET_DATA_PTR(outputScaleArray)) & \
                      0x1) == 0), XAI_ERR_NORM, "The output scale array is not aligned to 2 byte boundary");
#endif
  }
#if DILATED_VQ_CONV == VQ_FALSE
  if (XAI_CNN_CONV_GET_OUTPUT_SCALE(param) == 0)
  {
    int32_t fillValue;
    int32_t reluFlag = XAI_CNN_CONV_GET_FLAG_RELU(param);
    fillValue = reluFlag ? (CLAMP(0, XAI_CNN_CONV_GET_RELU_MIN(param), XAI_CNN_CONV_GET_RELU_MAX(param))) : 0;
    return(xaiFillTile3D(outTile, fillValue, 0));
  }
#endif
  if (XAI_TILE3D_GET_DIM3(inTile) == 3)
  {
    MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_7x7j2d1), S8IX_MOW_WHD_DEPTH3) MAKE_PARAMS(inTile, coeffTile, biasArray, outTile, param);
    return(XAI_ERROR_STATUS());
  }

  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t stride        = XAI_CNN_CONV_GET_STRIDE(param);

  /* Pitches of Coefficient Data (WHDN) dim3 */
  const int32_t coeffPitch2 = XAI_TILE4D_GET_DIM2_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-((kSizeU / 2) * inDataPitch1 + (kSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8* restrict pdvecIn;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1, * restrict pdvecCoeff2;

  /* Variable Declarations */
  int32_t inCh, outCh, x, y;
  int32_t varLen;
  /* No. of output elements that can be processed from 2 input loads */
  const int32_t vectorizationWidth = (((2 * XCHAL_IVPN_SIMD_WIDTH) - kSizeU) / stride) + 1;

  /* generates the sequence to shuffle the coeff */
  /* 0 1 2 3 4 5 6 7  7 8 9 10 11 12 13 14  8 9 10 11 12 13 14 15 .. */
  xb_vec2Nx8 dvecShflIdx = IVP_SEL2NX8I(IVP_ADD2NX8U(IVP_SEQ2NX8(), 7), \
                                        IVP_SEQ2NX8(), IVP_SELI_8B_INTERLEAVE_8_LO);
  /* 0 2 4 6 8 10 12 14 14 16 18 20 22 24 26 28  28 30 32 34 36 38 40 42 42 44 46 48 50 52 ...  */
  dvecShflIdx = IVP_SEL2NX8I(IVP_SLLI2NX8(IVP_ADD2NX8U(dvecShflIdx, 14), 1), \
                             IVP_SLLI2NX8(dvecShflIdx, 1), IVP_SELI_8B_PACK_16);
  /* Assuming that 50th index will have zero values */
  /* Final shuffle index pattern will be
      0  2  4  6   1  3  5 50   8 10 12 50   7 9 11 13
     14 16 18 20  15 17 19 50  22 24 26 50  21 23 25 27
     28 30 32 34  29 31 33 50  36 38 40 50  35 37 39 41
     42 44 46 48  43 45 47 50
   */
  dvecShflIdx = IVP_SEL2NX8I(
    IVP_MOV2NX8T(50, IVP_ADD2NX8(dvecShflIdx, IVP_SEL2NX8I(-1, 1, IVP_SELI_8B_INTERLEAVE_4_LO)),
                 IVP_EQ2NX8(IVP_AND2NX8(IVP_SEQ2NX8(), 7), 3)),
    IVP_MOV2NX8T(50, dvecShflIdx, IVP_EQ2NX8(IVP_AND2NX8(IVP_SEQ2NX8(), 7), 7)),
    IVP_SELI_8B_INTERLEAVE_4_LO);

  /* The inner most loop runs across the kernel height and produces
   * 4 output vectors - 2 output rows from 2 output channels. Unrolling across the output
   * channels by 2 helps in re-using the already loaded input data. Unrolling across the
   * output height by 2 helps in re-using the already loaded coeff data.
   * The coefficients are arranged in such a way that MORPH_OP_MUL4TA can be used.
   */
  for (x = 0; x < outW; x += vectorizationWidth) /* Loop across output width */
  {
    for (y = 0; y < outH - 1; y += 2) /* Loop across output height */
    {
      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * stride * (y) + stride * (x)];

      /* initialize coeff data pointer and bias data pointer to outCh kernel */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 2) /* Loop across output channels */
      {
        /* In order to handle odd output depths */
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

        /* Initialize the acc for 1st and 2nd output row of 1st channel with bias data */
        xb_vec2Nx24 dacc1;
        dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        /* Initialize the acc for 1st and 2nd output row of 2nd channel with bias data */
        xb_vec2Nx24 dacc2;
        dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

        pdvecIn = (MORPH_IDT_2Nx8 *) (pInput);

        for (inCh = 0; inCh < numInCh; inCh++) /* Loop across input channels */
        {
          xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2;
          xb_vec2Nx8 dvecI0, dvecI1;

          /* Load vectors from first row */
          valign vaInData; vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          xb_vec2Nx8 dvecInData1; IVP_LA2NX8_XP(dvecInData1, vaInData, pdvecIn, inDataPitch1);

          /* Load vectors from 2nd row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          xb_vec2Nx8 dvecInData2; IVP_LA2NX8_XP(dvecInData2, vaInData, pdvecIn, inDataPitch1);

          /* Load vectors from 3rd row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          xb_vec2Nx8 dvecInData3; IVP_LA2NX8_XP(dvecInData3, vaInData, pdvecIn, inDataPitch1);

          /* Load vectors from 4th row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          xb_vec2Nx8 dvecInData4; IVP_LA2NX8_XP(dvecInData4, vaInData, pdvecIn, inDataPitch1);

          /* Load vectors from 5th row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          xb_vec2Nx8 dvecInData5; IVP_LA2NX8_XP(dvecInData5, vaInData, pdvecIn, inDataPitch1);

          /* Load vectors from 6th row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          xb_vec2Nx8 dvecInData6; IVP_LA2NX8_XP(dvecInData6, vaInData, pdvecIn, inDataPitch1);

          /* Load vectors from 7th row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          xb_vec2Nx8 dvecInData7; IVP_LA2NX8_XP(dvecInData7, vaInData, pdvecIn, inDataPitch1);

          /* Load vectors from 8th row, to be used by 2nd output height */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          xb_vec2Nx8 dvecInData8; IVP_LA2NX8_XP(dvecInData8, vaInData, pdvecIn, inDataPitch1);

          /* Load vectors from 9th row, to be used by 2nd output height */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          xb_vec2Nx8 dvecInData9; IVP_LA2NX8_XP(dvecInData9, vaInData, pdvecIn, \
                                                inDataPitch2 - 8 * inDataPitch1);

          /* Load the 7x7 coefficients for 2 output channels */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch2);
          IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch2);

          /* rearrange the coeff in desired format, so that MUL4T can be used */
          dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecShflIdx);
          dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecShflIdx);

          /* Re-arrange the data in the desired format                              */
          /* Assume input as 0,1,2, .. 63 for two rows                              */
          /* After re-arrangement using DSEL operation, updated vectors would be    */
          /* dvecI0 : 0, 2, 4, ...                                                  */
          /* dvecI1 : 1, 3, 5, ...                                                  */
          IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData3, dvecInData1, IVP_DSELI_8B_DEINTERLEAVE_1);

          /* Mulitply 1st row with coeff from 1st output channel */
          MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* Mulitply 1st row with coeff from 2nd output channel */
          MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));


          /* rearrange input vectors */
          IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData4, dvecInData2, IVP_DSELI_8B_DEINTERLEAVE_1);


          /* Mulitply 2nd row with coeff from 1st output channel */
          MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
          MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));

          /* Mulitply 2nd row with coeff from 2nd output channel */
          MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
          MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));

          /* rearrange input vectors */
          IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData5, dvecInData3, IVP_DSELI_8B_DEINTERLEAVE_1);

          /* Mulitply 3rd row with coeff from 1st output channel */
          MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));
          MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));

          /* Mulitply 3rd row with coeff from 2nd output channel */
          MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 4));
          MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 5));

          /* rearrange input vectors */
          IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData6, dvecInData4, IVP_DSELI_8B_DEINTERLEAVE_1);

          /* Mulitply 4th row with coeff from 1st output channel */
          MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 7));
          MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 6));

          /* Mulitply 4th row with coeff from 2nd output channel */
          MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 7));
          MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 6));


          /* rearrange input vectors */
          IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData7, dvecInData5, IVP_DSELI_8B_DEINTERLEAVE_1);


          /* Mulitply 5th row with coeff from 1st output channel */
          MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 8));
          MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 9));

          /* Mulitply 5th row with coeff from 2nd output channel */
          MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 8));
          MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 9));


          /* rearrange input vectors */
          IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData8, dvecInData6, IVP_DSELI_8B_DEINTERLEAVE_1);

          /* Mulitply 6th row with coeff from 1st output channel */
          MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 11));
          MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 10));

          /* Mulitply 6th row with coeff from 2nd output channel */
          MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 11));
          MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 10));

          /* rearrange input vectors */
          IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData9, dvecInData7, IVP_DSELI_8B_DEINTERLEAVE_1);

          /* Mulitply 7th row with coeff from 1st output channel */
          MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 12));
          MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 13));

          /* Mulitply 7th row with coeff from 2nd output channel */
          MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 12));
          MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 13));
        }   /* END for (inCh = 0; inCh < numInCh; inCh++)*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* variable length for output stores */
        varLen = XT_MIN(vectorizationWidth, outW - x);

        /* Storing the 1st row output from 1st channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row output from 1st channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8I(dvecOut1L, dvecOut1L, IVP_SELI_EXTRACT_HI_HALVES), vaOutData, \
                       pdvecOut, (-typeFlag + 1) * varLen);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * 2 * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 1st row output from 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, enable2ndCh * bytesPerPixel * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row output from 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch1 + \
                                              outDataPitch2 * enable2ndCh) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SEL2NX8I(dvecOut2L, dvecOut2L, IVP_SELI_EXTRACT_HI_HALVES), vaOutData, \
                       pdvecOut, enable2ndCh * (-typeFlag + 1) * varLen);
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, enable2ndCh * typeFlag * 2 * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 2 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 2 * coeffPitch3;
      } /* END for (outCh = 0; outCh < numOutCh; outCh += 2)*/
    }   /* END for (y = 0; y < outH - 1; y += 2)*/
    if (y < outH)
    {
      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * stride * (y) + stride * (x)];

      /* initialize coeff data pointer and bias data pointer to outCh kernel */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 2) /* Loop across output channels */
      {
        /* In order to handle odd output depths */
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

        /* Initialize the acc for 1st and 2nd output row of 1st channel with bias data */
        xb_vec2Nx24 dacc1;
        dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        /* Initialize the acc for 1st and 2nd output row of 2nd channel with bias data */
        xb_vec2Nx24 dacc2;
        dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

        pdvecIn = (MORPH_IDT_2Nx8 *) (pInput);

        for (inCh = 0; inCh < numInCh; inCh++) /* Loop across input channels */
        {
          xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2;
          xb_vec2Nx8 dvecI0, dvecI1;

          /* Load vectors from first row */
          valign vaInData; vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          xb_vec2Nx8 dvecInData1; IVP_LA2NX8_XP(dvecInData1, vaInData, pdvecIn, inDataPitch1);

          /* Load vectors from 2nd row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          xb_vec2Nx8 dvecInData2; IVP_LA2NX8_XP(dvecInData2, vaInData, pdvecIn, inDataPitch1);

          /* Load vectors from 3rd row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          xb_vec2Nx8 dvecInData3; IVP_LA2NX8_XP(dvecInData3, vaInData, pdvecIn, inDataPitch1);

          /* Load vectors from 4th row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          xb_vec2Nx8 dvecInData4; IVP_LA2NX8_XP(dvecInData4, vaInData, pdvecIn, inDataPitch1);

          /* Load vectors from 5th row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          xb_vec2Nx8 dvecInData5; IVP_LA2NX8_XP(dvecInData5, vaInData, pdvecIn, inDataPitch1);

          /* Load vectors from 6th row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          xb_vec2Nx8 dvecInData6; IVP_LA2NX8_XP(dvecInData6, vaInData, pdvecIn, inDataPitch1);

          /* Load vectors from 7th row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          xb_vec2Nx8 dvecInData7; IVP_LA2NX8_XP(dvecInData7, vaInData, pdvecIn, \
                                                inDataPitch2 - 6 * inDataPitch1);

          /* Load the 7x7 coefficients for 2 output channels */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch2);
          IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch2);

          /* rearrange the coeff in desired format, so that MUL4T can be used */
          dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecShflIdx);
          dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecShflIdx);

          /* Re-arrange the data in the desired format                              */
          /* Assume input as 0,1,2, .. 63 for two rows                              */
          /* After re-arrangement using DSEL operation, updated vectors would be    */
          /* dvecI0 : 0, 2, 4, ...                                                  */
          /* dvecI1 : 1, 3, 5, ...                                                  */
          IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData3, dvecInData1, IVP_DSELI_8B_DEINTERLEAVE_1);

          /* Mulitply 1st row with coeff from 1st output channel */
          MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* Mulitply 1st row with coeff from 2nd output channel */
          MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));


          /* rearrange input vectors */
          IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData4, dvecInData2, IVP_DSELI_8B_DEINTERLEAVE_1);


          /* Mulitply 2nd row with coeff from 1st output channel */
          MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
          MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));

          /* Mulitply 2nd row with coeff from 2nd output channel */
          MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
          MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));

          /* rearrange input vectors */
          IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData5, dvecInData3, IVP_DSELI_8B_DEINTERLEAVE_1);

          /* Mulitply 3rd row with coeff from 1st output channel */
          MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 4));
          MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 5));

          /* Mulitply 3rd row with coeff from 2nd output channel */
          MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 4));
          MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 5));

          /* rearrange input vectors */
          IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData6, dvecInData4, IVP_DSELI_8B_DEINTERLEAVE_1);

          /* Mulitply 4th row with coeff from 1st output channel */
          MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 7));
          MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 6));

          /* Mulitply 4th row with coeff from 2nd output channel */
          MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 7));
          MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 6));


          /* rearrange input vectors */
          IVP_DSEL2NX8I(dvecI1, dvecI0, dvecInData7, dvecInData5, IVP_DSELI_8B_DEINTERLEAVE_1);


          /* Mulitply 5th row with coeff from 1st output channel */
          MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 8));
          MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 9));

          /* Mulitply 5th row with coeff from 2nd output channel */
          MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 8));
          MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 9));


          /* rearrange input vectors */
          IVP_DSEL2NX8I(dvecI1, dvecI0, 0, dvecInData6, IVP_DSELI_8B_DEINTERLEAVE_1);

          /* Mulitply 6th row with coeff from 1st output channel */
          MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 11));
          MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 10));

          /* Mulitply 6th row with coeff from 2nd output channel */
          MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 11));
          MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 10));

          /* rearrange input vectors */
          IVP_DSEL2NX8I(dvecI1, dvecI0, 0, dvecInData7, IVP_DSELI_8B_DEINTERLEAVE_1);

          /* Mulitply 7th row with coeff from 1st output channel */
          MORPH_OP_MUL4TA(dacc1, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 12));
          MORPH_OP_MUL4TA(dacc1, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 13));

          /* Mulitply 7th row with coeff from 2nd output channel */
          MORPH_OP_MUL4TA(dacc2, 0, dvecI0, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 12));
          MORPH_OP_MUL4TA(dacc2, 0, dvecI1, IVP_EXTRN_2X32 \
                            (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 13));
        }   /* END for (inCh = 0; inCh < numInCh; inCh++)*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* variable length for output stores */
        varLen = XT_MIN(vectorizationWidth, outW - x);

        /* Storing the 1st row output from 1st channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 1st row output from 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, enable2ndCh * bytesPerPixel * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 2 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 2 * coeffPitch3;
      }   /* END for (outCh = 0; outCh < numOutCh; outCh += 2)*/
    }     /* end of if(y < outH) */
  }       /* END for (x = 0; x < outW; x += vectorizationWidth)*/
  return(XAI_ERROR_STATUS());
}

/******************************************************************************************
* 7x7 MOW WHD Stride 4 - DEPTH 3                                                          *
* If number of input channels is equal to 3                                               *
* this function is called.                                                                *
******************************************************************************************/

static _XAI_INLINE_ void MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_7x7j4d1), S8IX_MOW_WHD_DEPTH3) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Getting parameters from the tile structures */
  const int32_t inW = XAI_TILE3D_GET_DIM1(inTile) + \
                      XAI_TILE3D_GET_DIM1_EDGE1(inTile) + XAI_TILE3D_GET_DIM1_EDGE2(inTile);
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t stride        = XAI_CNN_CONV_GET_STRIDE(param);

  /* Pitches of Coefficient Data (WHDN) dim3 */
  const int32_t coeffPitch1 = XAI_TILE4D_GET_DIM1_PITCH(coeffTile);
  const int32_t coeffPitch2 = XAI_TILE4D_GET_DIM2_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-((kSizeU / 2) * inDataPitch1 + (kSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 *restrict pdvecIn;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1, *restrict pdvecCoeff2, *restrict pdvecCoeff3, \
  * restrict pdvecCoeff4;

  /* Variable Declarations */
  int32_t outCh, x, y, ky;
  int32_t varLen;
  /* Number of output elements that can be generated
   * with 2 input vector loads(64 way).*/
  const int32_t vectorizationWidth = (((4 * XCHAL_IVPN_SIMD_WIDTH) - kSizeU) / stride) + 1;

  /* loop across output depth is unrolled by 4
   * , producing lanes from 4 output channels
   * in one iteration. Since vectorization width
   * is just half the width of the accumulator,
   * loop across output height is also unrolled by 2.
   * Unrolling across output height makes it possible
   * to utilize all the 64 MACs in the accumulator.
   *
   * Data loaded from the 2 input rows is concatenated
   * in such a manner that lower half of the output
   * vector gives the first output row and the upper
   * half of the */
  for (x = 0; x < outW; x += vectorizationWidth)   /* Loop across Output width */
  {
    /* out of bound flag */
    int32_t flag = XT_SALT(2 * XCHAL_IVPN_SIMD_WIDTH, inW - stride * x);

    for (y = 0; y < outH; y += 2)    /* Loop across Output height */
    {
      /* In order to handle odd heights*/
      int32_t enable2ndRow = XT_SALT(y, outH - 1);
      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize coeff and Bias data pointer to */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 4)   /* Loop across Output depth */
      {
        /* In order to handle odd depths*/
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
        int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);
        int32_t enable4thCh = XT_SALT(outCh, numOutCh - 3);

        /* loads and replicate bias data */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
        xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4 * enable4thCh);
        xb_vecN_2x32v hvecBias4; IVP_LSRN_2X32_XP(hvecBias4, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc1, dacc2, dacc3, dacc4;
        dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
        dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
        IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);
        dacc4 = IVP_CVT24UNX32L(hvecBias4, hvecBias4);
        IVP_CVT24UNX32H(dacc4, hvecBias4, hvecBias4);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

        pdvecCoeff3 = (xb_vec2Nx8 *) (pCoeff + 2 * coeffPitch3 * enable3rdCh);
        valign vaCoeffData3; vaCoeffData3 = IVP_LA2NX8_PP(pdvecCoeff3);

        pdvecCoeff4 = (xb_vec2Nx8 *) (pCoeff + 3 * coeffPitch3 * enable4thCh);
        valign vaCoeffData4; vaCoeffData4 = IVP_LA2NX8_PP(pdvecCoeff4);
        /*************************** 1st inCh ******************************/
        /* initialize input data pointer */
        MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * stride * y + stride * x];

        /* variable declarations for input and coeff vectors */
        xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2, dvecCoeffData3, dvecCoeffData4;
        MORPH_IDT_2Nx8 dvecInData11, dvecInData12;
        MORPH_IDT_2Nx8 dvecInData21, dvecInData22;
        MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3, dvecData4, dvecData5, dvecData6, dvecData7;

        /* load coeff for all the 4 output channels*/
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch2);
        IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch2);
        IVP_LAV2NX8_XP(dvecCoeffData3, vaCoeffData3, pdvecCoeff3, coeffPitch2);
        IVP_LAV2NX8_XP(dvecCoeffData4, vaCoeffData4, pdvecCoeff4, coeffPitch2);

        for (ky = 0; ky < 7; ky++)   /* Loop across kernel height */
        {
          /* loads 1st input row */
          pdvecIn = (MORPH_IDT_2Nx8 *) (pInput);
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

          /* loads 5th(corresponding to the 2nd output row) input row */
          pdvecIn  = (MORPH_IDT_2Nx8 *) (pInput + stride * inDataPitch1 * enable2ndRow);
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          pInput += inDataPitch1;

          /* 32 elements from 1st row and 32 elements from 2nd row are concatenated here
           * If 1st input row is 0,1,2,3,4,5,6,7,8,9,...127, and the 2nd input row is
           * 128,129,130,131.........252,253,254,255, Data should be arranged  as
           *
           * dvecData1 : 0, 4, 8,...120,124,128,132,136,...248,252
           * dvecData2 : 1, 5, 9,...121,125,129,133,137,...249,253
           * dvecData3 : 2, 6,10,...122,126,130,134,138,...250,254
           * dvecData4 : 3, 7,11,...123,127,131,135,139,...251,255
           *
           * Lower half of the vectors contain data from 1st input row and
           * upper half of the vectors contain data from 2nd output row.
           *
           */

          IVP_DSEL2NX8I(dvecInData12, dvecInData11, dvecInData12, dvecInData11, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecInData22, dvecInData21, dvecInData22, dvecInData21, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData3, dvecData1, dvecInData21, dvecInData11, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData4, dvecData2, dvecInData22, dvecInData12, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          dvecData5 = IVP_SEL2NX8I(0, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);
          dvecData6 = IVP_SEL2NX8I(0, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);
          dvecData7 = IVP_SEL2NX8I(0, dvecData3, IVP_SELI_8B_ROTATE_RIGHT_1);

          /* multiplies data from two rows(Lower and upper half of dvecData)
           * with coeff from 1st output channel and accumulate */

          /* IVP_EXTRVRN_2X32 extracts the required coeff from the
           * coeff vector. In every iteration ky is updated therefore it
           * extracts coeff from the next coeff row in the successive ky
           * iterations. "ky * coeffPitch1 + 4" extracts coeffs next to
           * first four coeff in a row
           */

          MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRVRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)),    \
                           ky * coeffPitch1));
          MORPH_OP_MULQA(dacc1, 0, dvecData7, dvecData6, dvecData5, IVP_EXTRVRN_2X32      \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), \
                           (ky * coeffPitch1 + 4)));

          /* multiplies data from two rows(Lower and upper half of dvecData)
           * with coeff from 2nd output channel and accumulate */
          MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRVRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)),    \
                           ky * coeffPitch1));
          MORPH_OP_MULQA(dacc2, 0, dvecData7, dvecData6, dvecData5, IVP_EXTRVRN_2X32      \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), \
                           (ky * coeffPitch1 + 4)));

          /* multiplies data from two rows(Lower and upper half of dvecData)
           * with coeff from 3rd output channel and accumulate */
          MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRVRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)),    \
                           ky * coeffPitch1));
          MORPH_OP_MULQA(dacc3, 0, dvecData7, dvecData6, dvecData5, IVP_EXTRVRN_2X32      \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), \
                           (ky * coeffPitch1 + 4)));

          /* multiplies data from two rows(Lower and upper half of dvecData)
           * with coeff from 4th output channel and accumulate */
          MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRVRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)),    \
                           ky * coeffPitch1));
          MORPH_OP_MULQA(dacc4, 0, dvecData7, dvecData6, dvecData5, IVP_EXTRVRN_2X32      \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), \
                           (ky * coeffPitch1 + 4)));
        }   /* end of for (ky = 0; ky < 7; ky++)*/

        /********************************* 2nd inCh ***************************************/

        /* initialize input data pointer */
        pInput = &pInData[inDataPitch2 + inDataPitch1 * stride * y + stride * x];

        /* load coeff for all the 4 output channels*/
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch2);
        IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch2);
        IVP_LAV2NX8_XP(dvecCoeffData3, vaCoeffData3, pdvecCoeff3, coeffPitch2);
        IVP_LAV2NX8_XP(dvecCoeffData4, vaCoeffData4, pdvecCoeff4, coeffPitch2);

        for (ky = 0; ky < 7; ky++)   /* Loop across kernel height */
        {
          /* loads 1st input row */
          pdvecIn = (MORPH_IDT_2Nx8 *) (pInput);
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

          /* loads 5th(corresponding to the 2nd output row) input row */
          pdvecIn  = (MORPH_IDT_2Nx8 *) (pInput + stride * inDataPitch1 * enable2ndRow);
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          pInput += inDataPitch1;

          IVP_DSEL2NX8I(dvecInData12, dvecInData11, dvecInData12, dvecInData11, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecInData22, dvecInData21, dvecInData22, dvecInData21, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData3, dvecData1, dvecInData21, dvecInData11, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData4, dvecData2, dvecInData22, dvecInData12, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          dvecData5 = IVP_SEL2NX8I(0, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);
          dvecData6 = IVP_SEL2NX8I(0, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);
          dvecData7 = IVP_SEL2NX8I(0, dvecData3, IVP_SELI_8B_ROTATE_RIGHT_1);

          /* multiplies data from two rows(Lower and upper half of dvecData)
           * with coeff from 1st output channel and accumulate */

          /* IVP_EXTRVRN_2X32 extracts the required coeff from the
           * coeff vector. In every iteration ky is updated therefore it
           * extracts coeff from the next coeff row in the successive ky
           * iterations. "ky * coeffPitch1 + 4" extracts coeffs next to
           * first four coeff in a row
           */

          MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRVRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)),    \
                           ky * coeffPitch1));
          MORPH_OP_MULQA(dacc1, 0, dvecData7, dvecData6, dvecData5, IVP_EXTRVRN_2X32      \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), \
                           (ky * coeffPitch1 + 4)));

          /* multiplies data from two rows(Lower and upper half of dvecData)
           * with coeff from 2nd output channel and accumulate */
          MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRVRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)),    \
                           ky * coeffPitch1));
          MORPH_OP_MULQA(dacc2, 0, dvecData7, dvecData6, dvecData5, IVP_EXTRVRN_2X32      \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), \
                           (ky * coeffPitch1 + 4)));

          /* multiplies data from two rows(Lower and upper half of dvecData)
           * with coeff from 3rd output channel and accumulate */
          MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRVRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)),    \
                           ky * coeffPitch1));
          MORPH_OP_MULQA(dacc3, 0, dvecData7, dvecData6, dvecData5, IVP_EXTRVRN_2X32      \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), \
                           (ky * coeffPitch1 + 4)));

          /* multiplies data from two rows(Lower and upper half of dvecData)
           * with coeff from 4th output channel and accumulate */
          MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRVRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)),    \
                           ky * coeffPitch1));
          MORPH_OP_MULQA(dacc4, 0, dvecData7, dvecData6, dvecData5, IVP_EXTRVRN_2X32      \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), \
                           (ky * coeffPitch1 + 4)));
        }   /* end of for (ky = 0; ky < 7; ky++)*/

        /************************************ 3rd inCh *************************************/
        /* initialize input data pointer */
        pInput = &pInData[2 * inDataPitch2 + inDataPitch1 * stride * y + stride * x];

        /* load coeff for all the 4 output channels*/
        IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch2);
        IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch2);
        IVP_LAV2NX8_XP(dvecCoeffData3, vaCoeffData3, pdvecCoeff3, coeffPitch2);
        IVP_LAV2NX8_XP(dvecCoeffData4, vaCoeffData4, pdvecCoeff4, coeffPitch2);

        for (ky = 0; ky < 7; ky++)   /* Loop across kernel height */
        {
          /* loads 1st input row */
          pdvecIn = (MORPH_IDT_2Nx8 *) (pInput);
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

          /* loads 5th(corresponding to the 2nd output row) input row */
          pdvecIn  = (MORPH_IDT_2Nx8 *) (pInput + stride * inDataPitch1 * enable2ndRow);
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
          pInput += inDataPitch1;

          IVP_DSEL2NX8I(dvecInData12, dvecInData11, dvecInData12, dvecInData11, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecInData22, dvecInData21, dvecInData22, dvecInData21, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData3, dvecData1, dvecInData21, dvecInData11, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData4, dvecData2, dvecInData22, dvecInData12, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          dvecData5 = IVP_SEL2NX8I(0, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);
          dvecData6 = IVP_SEL2NX8I(0, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);
          dvecData7 = IVP_SEL2NX8I(0, dvecData3, IVP_SELI_8B_ROTATE_RIGHT_1);

          /* multiplies data from two rows(Lower and upper half of dvecData)
           * with coeff from 1st output channel and accumulate */

          /* IVP_EXTRVRN_2X32 extracts the required coeff from the
           * coeff vector. In every iteration ky is updated therefore it
           * extracts coeff from the next coeff row in the successive ky
           * iterations. "ky * coeffPitch1 + 4" extracts coeffs next to
           * first four coeff in a row
           */

          MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRVRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)),    \
                           ky * coeffPitch1));
          MORPH_OP_MULQA(dacc1, 0, dvecData7, dvecData6, dvecData5, IVP_EXTRVRN_2X32      \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), \
                           (ky * coeffPitch1 + 4)));

          /* multiplies data from two rows(Lower and upper half of dvecData)
           * with coeff from 2nd output channel and accumulate */
          MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRVRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)),    \
                           ky * coeffPitch1));
          MORPH_OP_MULQA(dacc2, 0, dvecData7, dvecData6, dvecData5, IVP_EXTRVRN_2X32      \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), \
                           (ky * coeffPitch1 + 4)));

          /* multiplies data from two rows(Lower and upper half of dvecData)
           * with coeff from 3rd output channel and accumulate */
          MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRVRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)),    \
                           ky * coeffPitch1));
          MORPH_OP_MULQA(dacc3, 0, dvecData7, dvecData6, dvecData5, IVP_EXTRVRN_2X32      \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), \
                           (ky * coeffPitch1 + 4)));

          /* multiplies data from two rows(Lower and upper half of dvecData)
           * with coeff from 4th output channel and accumulate */
          MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRVRN_2X32 \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)),    \
                           ky * coeffPitch1));
          MORPH_OP_MULQA(dacc4, 0, dvecData7, dvecData6, dvecData5, IVP_EXTRVRN_2X32      \
                           (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), \
                           (ky * coeffPitch1 + 4)));
        }   /* end of for (ky = 0; ky < 7; ky++)*/


        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      pOutScaleData[outCh + 2 * enable3rdCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      pOutScaleData[outCh + 3 * enable4thCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* variable store count */
        varLen = XT_MIN(outW - x, vectorizationWidth);

        /* store the first half of the output vectors
         * dvecOut1, dvecOut2, dvecOut3, dvecOut4
         */

        /* Storing the first row outputs, first channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndCh * outDataPitch2 * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 3rd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable3rdCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 4th channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch2 * enable4thCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable4thCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* extract the half of the output vectors
         * dvecOut1, dvecOut2, dvecOut3, dvecOut4
         * and store in the next row
         */

        /* Storing the 2nd row outputs, first channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2ndRow * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut1L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * 2 * varLen * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut2L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable2ndCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable2ndCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 3rd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (2 * outDataPitch2 * enable3rdCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut3L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable3rdCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable3rdCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 4th channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (3 * outDataPitch2 * enable4thCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut4L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable4thCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable4thCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 4 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 4 * coeffPitch3;
      } /* end of (outCh = 0; outCh < numOutCh; outCh += 4)*/
    }   /* end of for (y = 0; y < outH; y += 2)*/
  }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
}

/******************************************************************************************
*   xaiConvolved(VQ)3D_S_7x7j4d1I8S8IX_MOW_WHD
*  ***************************************************************************************/

/******************************************************************************/
/* Description : P6 optimized generic implementation for 7x7 3D convolution.  */
/*               Based on MORPH pre-processor specifiers, code implementation */
/*               is generated during preprocessing stage. This method can be  */
/*               used to generate 7x7 3D dilated convolution function and 7x7 */
/*               3D VQ dilated convolution function for U8 bit and S8 bit     */
/*               input data with input stride equal to 4                      */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                */
/*               Output scale array, CNN convolution params structure         */
/* Outputs     : XI Error Code                                                */
/* InOuts      : Output Tile                                                  */
/* Assumptions : CoeffData is S8                                              */
/*               biasArray is signed 32b, value not exceeding signed 24b      */
/*               Output scale array is U16                                    */
/*               OutData is S8 / U8 / S16                                     */
/*               Kernel Size is 7x7xDxN                                       */
/*               Input and Output are in WHD format                           */
/*               Coeff is in WHDN format                                      */
/******************************************************************************/

/****************** xaiConvolvedVQ3D_S_7x7j4d1_S8S8IX_MOW_WHD ******************/
/****************** xaiConvolvedVQ3D_S_7x7j4d1_U8S8IX_MOW_WHD ******************/
/******************* xaiConvolved3D_S_7x7j4d1_S8S8IX_MOW_WHD *******************/
/******************* xaiConvolved3D_S_7x7j4d1_U8S8IX_MOW_WHD *******************/

XAI_ERR_TYPE MAKE_NAME(MAKE_NAME_VQ(xaiConvolved, 3D_S_7x7j4d1), S8IX_MOW_WHD) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Error Checks */
  XAI_ERROR_CHECKS()
  {
    XAI_CHECK_TILE4D_S8(coeffTile);
    XAI_CHECK_CONV_OUTPUT_TILE3D(outTile);
    MORPH_IDT_CHECK(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(outTile);
    XAI_CHECK_TILE4D_IN_DRAM_BOUNDARY(coeffTile);
    XAI_CHECK_POINTER(param);
    XAI_CHECK_ARRAY_S32(biasArray);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(inTile, outTile);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(coeffTile, outTile);
    XAI_CHECK_KERNEL_SIZE(coeffTile, 7);
    XAI_CHECK_TILE3D_DATA_ORDER(inTile, XAI_WHD);
    XAI_CHECK_TILE3D_DATA_ORDER(outTile, XAI_WHD);
    XAI_CHECK_TILE4D_DATA_ORDER(coeffTile, XAI_WHDN);
    XAI_CHECK_DILATION(param, 1);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_DILATIONX(param) == XAI_CNN_CONV_GET_DILATIONY(param),                                           \
                    XAI_ERR_BADARG, "Dilation along width = %hhu and height = %hhu\nDilation along width and height should be equal", \
                    XAI_CNN_CONV_GET_DILATIONX(param), XAI_CNN_CONV_GET_DILATIONY(param));
    XAI_CHECK_TILE3D_EDGE(inTile, 3);
    XAI_CHECK_STRIDE(param, 4);
    XAI_CHECK_ERROR((XAI_CNN_CONV_GET_STRIDEX(param) == XAI_CNN_CONV_GET_STRIDEY(param)),                                           \
                    XAI_ERR_BADARG, "\nStride along width = %hhu and height = %hhu\nStride along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_CONSISTENCY_MOW_WHD(inTile, coeffTile, biasArray, outTile, param);
    XAI_CHECK_COEFFTILE_CONTIGUOUS(coeffTile, param);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_ACCUM_SHIFT(param) < 24,                                     \
                    XAI_ERR_NORM, "\nThe accumulator shift = %hhu, value should be less than 24", \
                    XAI_CNN_CONV_GET_ACCUM_SHIFT(param));
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_OUTPUT_SHIFT(param) < 32,                               \
                    XAI_ERR_NORM, "\nThe output shift = %hhu, value should be less than 32", \
                    XAI_CNN_CONV_GET_OUTPUT_SHIFT(param));
    XAI_CHECK_CONV_RELU_LIMITS_IX(param, outTile);
#if DILATED_VQ_CONV == VQ_TRUE
    XAI_CHECK_ARRAY_U16(outputScaleArray);
    XAI_CHECK_ERROR(XAI_ARRAY_GET_WIDTH(outputScaleArray) >= XAI_TILE4D_GET_DIM4(coeffTile),                                                                                          \
                    XAI_ERR_DATASIZE, "\nWidth of Output Scale Array = %d, Number of Kernels = %d\nWidth of Output Scale Array should be greater than or equal to Number of Kernels", \
                    XAI_ARRAY_GET_WIDTH(outputScaleArray), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_ERROR((((uintptr_t) (XAI_ARRAY_GET_DATA_PTR(outputScaleArray)) & \
                      0x1) == 0), XAI_ERR_NORM, "The output scale array is not aligned to 2 byte boundary");
#endif
  }
#if DILATED_VQ_CONV == VQ_FALSE
  if (XAI_CNN_CONV_GET_OUTPUT_SCALE(param) == 0)
  {
    int32_t fillValue;
    int32_t reluFlag = XAI_CNN_CONV_GET_FLAG_RELU(param);
    fillValue = reluFlag ? (CLAMP(0, XAI_CNN_CONV_GET_RELU_MIN(param), XAI_CNN_CONV_GET_RELU_MAX(param))) : 0;
    return(xaiFillTile3D(outTile, fillValue, 0));
  }
#endif
  if (XAI_TILE3D_GET_DIM3(inTile) == 3)
  {
    MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_7x7j4d1), S8IX_MOW_WHD_DEPTH3) MAKE_PARAMS(inTile, coeffTile, biasArray, outTile, param);
    return(XAI_ERROR_STATUS());
  }

  /* Getting parameters from the tile structures */
  const int32_t inW = XAI_TILE3D_GET_DIM1(inTile) + \
                      XAI_TILE3D_GET_DIM1_EDGE1(inTile) + XAI_TILE3D_GET_DIM1_EDGE2(inTile);
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t stride        = XAI_CNN_CONV_GET_STRIDE(param);

  /* Pitches of Coefficient Data (WHDN) dim3 */
  const int32_t coeffPitch1 = XAI_TILE4D_GET_DIM1_PITCH(coeffTile);
  const int32_t coeffPitch2 = XAI_TILE4D_GET_DIM2_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-((kSizeU / 2) * inDataPitch1 + (kSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 *restrict pdvecIn;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1, * restrict pdvecCoeff2, * restrict pdvecCoeff3, \
  * restrict pdvecCoeff4;

  /* Variable Declarations */
  int32_t inCh, outCh, x, y, ky;
  int32_t varLen;
  /* Number of output elements that can be generated
   * with 2 input vector loads(64 way).*/
  const int32_t vectorizationWidth = (((4 * XCHAL_IVPN_SIMD_WIDTH) - kSizeU) / stride) + 1;

  /* loop across output depth is unrolled by 4
   * , producing lanes from 4 output channels
   * in one iteration. Since vectorization width
   * is just half the width of the accumulator,
   * loop across output height is also unrolled by 2.
   * Unrolling across output height makes it possible
   * to utilize all the 64 MACs in the accumulator.
   *
   * Data loaded from the 2 input rows is concatenated
   * in such a manner that lower half of the output
   * vector gives the first output row and the upper
   * half of the */
  for (x = 0; x < outW; x += vectorizationWidth)   /* Loop across Output width */
  {
    /* out of bound flag */
    int32_t flag = XT_SALT(2 * XCHAL_IVPN_SIMD_WIDTH, inW - stride * x);

    for (y = 0; y < outH; y += 2)    /* Loop across Output height */
    {
      /* In order to handle odd heights*/
      int32_t enable2ndRow = XT_SALT(y, outH - 1);
      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize coeff and Bias data pointer to */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 4)   /* Loop across Output depth */
      {
        /* In order to handle odd depths*/
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
        int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);
        int32_t enable4thCh = XT_SALT(outCh, numOutCh - 3);

        /* loads and replicate bias data */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
        xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4 * enable4thCh);
        xb_vecN_2x32v hvecBias4; IVP_LSRN_2X32_XP(hvecBias4, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc1, dacc2, dacc3, dacc4;
        dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
        dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
        IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);
        dacc4 = IVP_CVT24UNX32L(hvecBias4, hvecBias4);
        IVP_CVT24UNX32H(dacc4, hvecBias4, hvecBias4);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

        pdvecCoeff3 = (xb_vec2Nx8 *) (pCoeff + 2 * coeffPitch3 * enable3rdCh);
        valign vaCoeffData3; vaCoeffData3 = IVP_LA2NX8_PP(pdvecCoeff3);

        pdvecCoeff4 = (xb_vec2Nx8 *) (pCoeff + 3 * coeffPitch3 * enable4thCh);
        valign vaCoeffData4; vaCoeffData4 = IVP_LA2NX8_PP(pdvecCoeff4);

        for (inCh = 0; inCh < numInCh; inCh++)   /* Loop across input channels */
        {
          /* initialize input data pointer */
          MORPH_IDT_SCALAR *pInput = &pInData[inCh * inDataPitch2 + \
                                              inDataPitch1 * stride * y + stride * x];

          /* variable declarations for input and coeff vectors */
          xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2, dvecCoeffData3, dvecCoeffData4;
          MORPH_IDT_2Nx8 dvecInData11, dvecInData12;
          MORPH_IDT_2Nx8 dvecInData21, dvecInData22;
          MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3, dvecData4, dvecData5, dvecData6, dvecData7;

          /* load coeff for all the 4 output channels*/
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch2);
          IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch2);
          IVP_LAV2NX8_XP(dvecCoeffData3, vaCoeffData3, pdvecCoeff3, coeffPitch2);
          IVP_LAV2NX8_XP(dvecCoeffData4, vaCoeffData4, pdvecCoeff4, coeffPitch2);

          for (ky = 0; ky < 7; ky++)   /* Loop across kernel height */
          {
            /* loads 1st input row */
            pdvecIn = (MORPH_IDT_2Nx8 *) (pInput);
            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
            MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* loads 5th(corresponding to the 2nd output row) input row */
            pdvecIn  = (MORPH_IDT_2Nx8 *) (pInput + stride * inDataPitch1 * enable2ndRow);
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
            MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            pInput += inDataPitch1;

            /* 32 elements from 1st row and 32 elements from 2nd row are concatenated here
             * If 1st input row is 0,1,2,3,4,5,6,7,8,9,...127, and the 2nd input row is
             * 128,129,130,131.........252,253,254,255, Data should be arranged  as
             *
             * dvecData1 : 0, 4, 8,...120,124,128,132,136,...248,252
             * dvecData2 : 1, 5, 9,...121,125,129,133,137,...249,253
             * dvecData3 : 2, 6,10,...122,126,130,134,138,...250,254
             * dvecData4 : 3, 7,11,...123,127,131,135,139,...251,255
             *
             * Lower half of the vectors contain data from 1st input row and
             * upper half of the vectors contain data from 2nd output row.
             *
             */

            IVP_DSEL2NX8I(dvecInData12, dvecInData11, dvecInData12, dvecInData11, \
                          IVP_DSELI_8B_DEINTERLEAVE_1);
            IVP_DSEL2NX8I(dvecInData22, dvecInData21, dvecInData22, dvecInData21, \
                          IVP_DSELI_8B_DEINTERLEAVE_1);
            IVP_DSEL2NX8I(dvecData3, dvecData1, dvecInData21, dvecInData11, \
                          IVP_DSELI_8B_DEINTERLEAVE_1);
            IVP_DSEL2NX8I(dvecData4, dvecData2, dvecInData22, dvecInData12, \
                          IVP_DSELI_8B_DEINTERLEAVE_1);

            dvecData5 = IVP_SEL2NX8I(0, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);
            dvecData6 = IVP_SEL2NX8I(0, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);
            dvecData7 = IVP_SEL2NX8I(0, dvecData3, IVP_SELI_8B_ROTATE_RIGHT_1);

            /* multiplies data from two rows(Lower and upper half of dvecData)
             * with coeff from 1st output channel and accumulate */

            /* IVP_EXTRVRN_2X32 extracts the required coeff from the
             * coeff vector. In every iteration ky is updated therefore it
             * extracts coeff from the next coeff row in the successive ky
             * iterations. "ky * coeffPitch1 + 4" extracts coeffs next to
             * first four coeff in a row
             */

            MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRVRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)),    \
                             ky * coeffPitch1));
            MORPH_OP_MULQA(dacc1, 0, dvecData7, dvecData6, dvecData5, IVP_EXTRVRN_2X32      \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), \
                             (ky * coeffPitch1 + 4)));

            /* multiplies data from two rows(Lower and upper half of dvecData)
             * with coeff from 2nd output channel and accumulate */
            MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRVRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)),    \
                             ky * coeffPitch1));
            MORPH_OP_MULQA(dacc2, 0, dvecData7, dvecData6, dvecData5, IVP_EXTRVRN_2X32      \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), \
                             (ky * coeffPitch1 + 4)));

            /* multiplies data from two rows(Lower and upper half of dvecData)
             * with coeff from 3rd output channel and accumulate */
            MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRVRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)),    \
                             ky * coeffPitch1));
            MORPH_OP_MULQA(dacc3, 0, dvecData7, dvecData6, dvecData5, IVP_EXTRVRN_2X32      \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), \
                             (ky * coeffPitch1 + 4)));

            /* multiplies data from two rows(Lower and upper half of dvecData)
             * with coeff from 4th output channel and accumulate */
            MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRVRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)),    \
                             ky * coeffPitch1));
            MORPH_OP_MULQA(dacc4, 0, dvecData7, dvecData6, dvecData5, IVP_EXTRVRN_2X32      \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), \
                             (ky * coeffPitch1 + 4)));
          }   /* end of for (ky = 0; ky < 7; ky++)*/
        }     /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      pOutScaleData[outCh + 2 * enable3rdCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      pOutScaleData[outCh + 3 * enable4thCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* variable store count */
        varLen = XT_MIN(outW - x, vectorizationWidth);

        /* store the first half of the output vectors
         * dvecOut1, dvecOut2, dvecOut3, dvecOut4
         */

        /* Storing the first row outputs, first channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndCh * outDataPitch2 * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 3rd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable3rdCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 4th channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch2 * enable4thCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable4thCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* extract the half of the output vectors
         * dvecOut1, dvecOut2, dvecOut3, dvecOut4
         * and store in the next row
         */

        /* Storing the 2nd row outputs, first channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2ndRow * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut1L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * 2 * varLen * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut2L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable2ndCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable2ndCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 3rd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (2 * outDataPitch2 * enable3rdCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut3L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable3rdCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable3rdCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 4th channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (3 * outDataPitch2 * enable4thCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut4L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable4thCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable4thCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 4 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 4 * coeffPitch3;
      } /* end of (outCh = 0; outCh < numOutCh; outCh += 4)*/
    }   /* end of for (y = 0; y < outH; y += 2)*/
  }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  return(XAI_ERROR_STATUS());
}


/******************************************************************************************
*   xaiConvolved(VQ)3D_S_7x7j1d2I8S8IX_MOW_WHD
*  ***************************************************************************************/

/******************************************************************************/
/* Description : P6 optimized generic implementation for 7x7 3D convolution   */
/*               with dilation = 2                                            */
/*               Based on MORPH pre-processor specifiers, code implementation */
/*               is generated during preprocessing stage. This method can be  */
/*               used to generate 5x5 3D dilated convolution function and 5x5 */
/*               3D VQ dilated convolution function for U8 bit and S8 bit     */
/*               input data with input stride equal to 1                      */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                */
/*               Output scale array, CNN convolution params structure         */
/* Outputs     : XI Error Code                                                */
/* InOuts      : Output Tile                                                  */
/* Assumptions : CoeffData is S8                                              */
/*               biasArray is signed 32b, value not exceeding signed 24b      */
/*               Output scale array is U16                                    */
/*               OutData is S8 / U8 / S16                                     */
/*               Kernel Size is 7x7xDxN                                       */
/*               Input and Output are in WHD format                           */
/*               Coeff is in WHDN format                                      */
/******************************************************************************/

/****************** xaiConvolvedVQ3D_S_7x7j1d2_S8S8IX_MOW_WHD ******************/
/****************** xaiConvolvedVQ3D_S_7x7j1d2_U8S8IX_MOW_WHD ******************/
/******************* xaiConvolved3D_S_7x7j1d2_S8S8IX_MOW_WHD *******************/
/******************* xaiConvolved3D_S_7x7j1d2_U8S8IX_MOW_WHD *******************/

XAI_ERR_TYPE MAKE_NAME(MAKE_NAME_VQ(xaiConvolved, 3D_S_7x7j1d2), S8IX_MOW_WHD) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Error Checks */
  XAI_ERROR_CHECKS()
  {
    MORPH_IDT_CHECK(inTile);
    XAI_CHECK_CONV_OUTPUT_TILE3D(outTile);
    XAI_CHECK_TILE4D_S8(coeffTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(outTile);
    XAI_CHECK_TILE4D_IN_DRAM_BOUNDARY(coeffTile);
    XAI_CHECK_POINTER(param);
    XAI_CHECK_ARRAY_S32(biasArray);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(inTile, outTile);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(coeffTile, outTile);
    XAI_CHECK_KERNEL_SIZE(coeffTile, 7);
    XAI_CHECK_TILE3D_DATA_ORDER(inTile, XAI_WHD);
    XAI_CHECK_TILE3D_DATA_ORDER(outTile, XAI_WHD);
    XAI_CHECK_TILE4D_DATA_ORDER(coeffTile, XAI_WHDN);
    XAI_CHECK_TILE3D_EDGE(inTile, 6);
    XAI_CHECK_STRIDE(param, 1);
    XAI_CHECK_ERROR((XAI_CNN_CONV_GET_STRIDEX(param) == XAI_CNN_CONV_GET_STRIDEY(param)),                                         \
                    XAI_ERR_BADARG, "Stride along width = %hhu and height = %hhu\nStride along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_DILATION(param, 2);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_DILATIONX(param) == XAI_CNN_CONV_GET_DILATIONY(param),                                             \
                    XAI_ERR_BADARG, "\nDilation along width = %hhu and height = %hhu\nDilation along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_CONSISTENCY_MOW_WHD(inTile, coeffTile, biasArray, outTile, param);
    XAI_CHECK_COEFFTILE_CONTIGUOUS(coeffTile, param);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_ACCUM_SHIFT(param) < 24,                                     \
                    XAI_ERR_NORM, "\nThe accumulator shift = %hhu, value should be less than 24", \
                    XAI_CNN_CONV_GET_ACCUM_SHIFT(param));
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_OUTPUT_SHIFT(param) < 32,                               \
                    XAI_ERR_NORM, "\nThe output shift = %hhu, value should be less than 32", \
                    XAI_CNN_CONV_GET_OUTPUT_SHIFT(param));
    XAI_CHECK_CONV_RELU_LIMITS_IX(param, outTile);
#if DILATED_VQ_CONV == VQ_TRUE
    XAI_CHECK_ARRAY_U16(outputScaleArray);
    XAI_CHECK_ERROR(XAI_ARRAY_GET_WIDTH(outputScaleArray) >= XAI_TILE4D_GET_DIM4(coeffTile),                                                                                          \
                    XAI_ERR_DATASIZE, "\nWidth of Output Scale Array = %d, Number of Kernels = %d\nWidth of Output Scale Array should be greater than or equal to Number of Kernels", \
                    XAI_ARRAY_GET_WIDTH(outputScaleArray), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_ERROR((((uintptr_t) (XAI_ARRAY_GET_DATA_PTR(outputScaleArray)) & \
                      0x1) == 0), XAI_ERR_NORM, "The output scale array is not aligned to 2 byte boundary");
#endif
  }
#if DILATED_VQ_CONV == VQ_FALSE
  if (XAI_CNN_CONV_GET_OUTPUT_SCALE(param) == 0)
  {
    int32_t fillValue;
    int32_t reluFlag = XAI_CNN_CONV_GET_FLAG_RELU(param);
    fillValue = reluFlag ? (CLAMP(0, XAI_CNN_CONV_GET_RELU_MIN(param), XAI_CNN_CONV_GET_RELU_MAX(param))) : 0;
    return(xaiFillTile3D(outTile, fillValue, 0));
  }
#endif
  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Pitches of Coefficient Data (WHDN) in dim3 */
  const int32_t coeffPitch1 = XAI_TILE4D_GET_DIM1_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Kernel Size (WHDN) */
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t dilationU     = XAI_CNN_CONV_GET_DILATION(param);

  int32_t dilatedkSizeU = dilationU * (kSizeU - 1) + 1;

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-((dilatedkSizeU / 2) * inDataPitch1 + (dilatedkSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 * restrict pdvecIn;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1;

  /* Variable Declarations */
  int32_t inCh, outCh, x, y;

  /* 0 1 2 3 .. 62 63*/
  xb_vec2Nx8 dvecPattern1 = IVP_SEQ2NX8();
  /* 64 65 66 67 ...126 127*/
  xb_vec2Nx8 dvecPattern2 = IVP_ADD2NX8(dvecPattern1, 64);

  if (!typeFlag)
  {
    MORPH_OP_DSELI(dvecPattern2, dvecPattern1, \
                   dvecPattern2, dvecPattern1, \
                   IVP_DSELI_8B_INTERLEAVE_1);
  }
  else
  {
    MORPH_OP_DSELI(dvecPattern2, dvecPattern1, \
                   dvecPattern2, dvecPattern1, \
                   IVP_DSELI_INTERLEAVE_1);
  }

  /* In order to make the loop multiply-bound we are reducing the vectorization width
     by extra values required for the kernel */
  const int32_t vectorizationWidth = ((4 * XCHAL_IVPN_SIMD_WIDTH) - dilatedkSizeU) + 1;

  for (x = 0; x < outW; x += vectorizationWidth)  /* Loop across output width */
  {
    int32_t remX = XT_MIN(vectorizationWidth, outW - x);

    /* If (remX + kSizeEffU - 1) <= 2 * XCHAL_IVPN_SIMD_WIDTH,
     * i.e. if the number of input data bytes corresponding to remX number of outputs
     * is less than or equal to 2 * XCHAL_IVPN_SIMD_WIDTH, there is no need to load
     * the next 64 input bytes*/
    int32_t remXLoad = ((remX + dilatedkSizeU - 1) > 2 * XCHAL_IVPN_SIMD_WIDTH) ? 1 : 0;

    for (y = 0; y < outH; y++) /* Loop across output height */
    {
      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y + x];

      /* initialize coeff and Bias data pointer*/
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh++)  /* Loop across Output depth */
      {
        /* load and replicate bias data */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc1, dacc2;
        dacc1 = dacc2 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc2, hvecBias1, hvecBias1);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

        pdvecIn = (MORPH_IDT_2Nx8 *) pInput;

        for (inCh = 0; inCh < numInCh; inCh++)  /* Loop across input channels */
        {
          /* vectors for coeff and input loads */
          xb_vec2Nx8 dvecCoeffData1;
          xb_vec2Nx8 dvecInData11, dvecInData21, dvecInData31, dvecInData41, \
                     dvecInData51, dvecInData61, dvecInData71;
          xb_vec2Nx8 dvecInData12, dvecInData22, dvecInData32, dvecInData42, \
                     dvecInData52, dvecInData62, dvecInData72;

          /* load data from first input row */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn, dilationU * inDataPitch1 - \
                             remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /*Separate odd and even indices */
          IVP_DSEL2NX8I(dvecInData12, dvecInData11, dvecInData12, dvecInData11, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load data from 2nd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn, dilationU * inDataPitch1 - \
                             remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /*Separate odd and even indices */
          IVP_DSEL2NX8I(dvecInData22, dvecInData21, dvecInData22, dvecInData21, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load data from 3rd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData31, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData32, vaInData, pdvecIn, dilationU * inDataPitch1 - \
                             remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /*Separate odd and even indices */
          IVP_DSEL2NX8I(dvecInData32, dvecInData31, dvecInData32, dvecInData31, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load data from 4th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData41, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData42, vaInData, pdvecIn, dilationU * inDataPitch1 - \
                             remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /*Separate odd and even indices */
          IVP_DSEL2NX8I(dvecInData42, dvecInData41, dvecInData42, dvecInData41, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load data from 5th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData51, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData52, vaInData, pdvecIn, dilationU * inDataPitch1 - \
                             remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /*Separate odd and even indices */
          IVP_DSEL2NX8I(dvecInData52, dvecInData51, dvecInData52, dvecInData51, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load data from 6th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData61, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData62, vaInData, pdvecIn, dilationU * inDataPitch1 - \
                             remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /*Separate odd and even indices */
          IVP_DSEL2NX8I(dvecInData62, dvecInData61, dvecInData62, dvecInData61, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load data from 7th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData71, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData72, vaInData, pdvecIn, inDataPitch2 - \
                             remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH - dilationU * 6 * inDataPitch1);

          /*Separate odd and even indices */
          IVP_DSEL2NX8I(dvecInData72, dvecInData71, dvecInData72, dvecInData71, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load 1st row of coefficients */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply and accumulate 1st set of 4 coefficients from 1st row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, dvecInData11, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, dvecInData12, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));

          /* Multiply and accumulate 2nd set of 4 coefficients from 1st row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(dvecInData11, dvecInData11,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc2, 0, IVP_SEL2NX8I(dvecInData12, dvecInData12,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* load 2nd row of coefficients */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply and accumulate 1st set of 4 coefficients from 2nd row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, dvecInData21, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, dvecInData22, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));

          /* Multiply and accumulate 2nd set of 4 coefficients from 2nd row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(dvecInData21, dvecInData21,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc2, 0, IVP_SEL2NX8I(dvecInData22, dvecInData22,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* load 3rd row of coefficients */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply and accumulate 1st set of 4 coefficients from 3rd row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, dvecInData31, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, dvecInData32, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));

          /* Multiply and accumulate 2nd set of 4 coefficients from 3rd row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(dvecInData31, dvecInData31,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc2, 0, IVP_SEL2NX8I(dvecInData32, dvecInData32,
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* load 4th row of coefficients */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply and accumulate 1st set of 4 coefficients from 4th row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, dvecInData41, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, dvecInData42, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));

          /* Multiply and accumulate 2nd set of 4 coefficients from 4th row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(dvecInData41, dvecInData41,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc2, 0, IVP_SEL2NX8I(dvecInData42, dvecInData42,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* load 5th row of coefficients */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply and accumulate 1st set of 4 coefficients from 5th row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, dvecInData51, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, dvecInData52, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));

          /* Multiply and accumulate 2nd set of 4 coefficients from 5th row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(dvecInData51, dvecInData51,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc2, 0, IVP_SEL2NX8I(dvecInData52, dvecInData52,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* load 6th row of coefficients */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply and accumulate 1st set of 4 coefficients from 6th row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, dvecInData61, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, dvecInData62, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));

          /* Multiply and accumulate 2nd set of 4 coefficients from 6th row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(dvecInData61, dvecInData61,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc2, 0, IVP_SEL2NX8I(dvecInData62, dvecInData62,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* load 7th row of coefficients */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply and accumulate 1st set of 4 coefficients from 7th row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, dvecInData71, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, dvecInData72, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));

          /* Multiply and accumulate 2nd set of 4 coefficients from 7th row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(dvecInData71, dvecInData71,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc2, 0, IVP_SEL2NX8I(dvecInData72, dvecInData72,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
        }  /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvec1L, dvec2L;
        xb_vec2Nx8 dvec1H, dvec2H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec1L, dvec1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec2L, dvec2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec1L, dvec1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec2L, dvec2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* Interleave odd and even indices */
        xb_vec2Nx8 dvecOut1L = MORPH_OP_SEL(dvec2L, dvec1L, dvecPattern1);
        xb_vec2Nx8 dvecOut2L = MORPH_OP_SEL(dvec2L, dvec1L, dvecPattern2);
        xb_vec2Nx8 dvecOut1H = MORPH_OP_SEL(dvec2H, dvec1H, dvecPattern1);
        xb_vec2Nx8 dvecOut2H = MORPH_OP_SEL(dvec2H, dvec1H, dvecPattern2);

        /* Storing the first depth output , 1st row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();

        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * remX);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * remX - \
                       2 * XCHAL_IVPN_SIMD_WIDTH);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                       (2 * remX - 4 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                       (2 * remX - 6 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += outDataPitch2 * bytesPerPixel;
        pCoeff  += coeffPitch3;
      } /* end of for (outCh = 0; outCh < numOutCh; outCh++)*/
    }   /* end of for (y = 0; y < outH; y++)*/
  }     /* end of for (x = 0; x < outW; x += 2 * vectorizationWidth)*/
  return(XAI_ERROR_STATUS());
}

/******************************************************************************************
*   xaiConvolved(VQ)3D_S_7x7j1d4I8MOW_WHD
*  ***************************************************************************************/
/******************************************************************************/
/* Description : P6 optimized generic implementation for 7x7 3D convolution   */
/*               with dilation = 4                                            */
/*               Based on MORPH pre-processor specifiers, code implementation */
/*               is generated during preprocessing stage. This method can be  */
/*               used to generate 7x7 3D dilated convolution function and 7x7 */
/*               3D VQ dilated convolution function for U8 bit and S8 bit     */
/*               input data with input stride equal to 1                      */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                */
/*               Output scale array, CNN convolution params structure         */
/* Outputs     : XI Error Code                                                */
/* InOuts      : Output Tile                                                  */
/* Assumptions : CoeffData is S8                                              */
/*               biasArray is signed 32b, value not exceeding signed 24b      */
/*               Output scale array is U16                                    */
/*               OutData is S8 / U8 / S16                                     */
/*               Kernel Size is 7x7xDxN                                       */
/*               Input and Output are in WHD format                           */
/*               Coeff is in WHDN format                                      */
/******************************************************************************/

/****************** xaiConvolvedVQ3D_S_7x7j1d4_S8S8IX_MOW_WHD ******************/
/****************** xaiConvolvedVQ3D_S_7x7j1d4_U8S8IX_MOW_WHD ******************/
/******************* xaiConvolved3D_S_7x7j1d4_S8S8IX_MOW_WHD *******************/
/******************* xaiConvolved3D_S_7x7j1d4_U8S8IX_MOW_WHD *******************/

XAI_ERR_TYPE MAKE_NAME(MAKE_NAME_VQ(xaiConvolved, 3D_S_7x7j1d4), S8IX_MOW_WHD) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Error Checks */
  XAI_ERROR_CHECKS()
  {
    MORPH_IDT_CHECK(inTile);
    XAI_CHECK_CONV_OUTPUT_TILE3D(outTile);
    XAI_CHECK_TILE4D_S8(coeffTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(outTile);
    XAI_CHECK_TILE4D_IN_DRAM_BOUNDARY(coeffTile);
    XAI_CHECK_POINTER(param);
    XAI_CHECK_ARRAY_S32(biasArray);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(inTile, outTile);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(coeffTile, outTile);
    XAI_CHECK_KERNEL_SIZE(coeffTile, 7);
    XAI_CHECK_TILE3D_DATA_ORDER(inTile, XAI_WHD);
    XAI_CHECK_TILE3D_DATA_ORDER(outTile, XAI_WHD);
    XAI_CHECK_TILE4D_DATA_ORDER(coeffTile, XAI_WHDN);
    XAI_CHECK_TILE3D_EDGE(inTile, 12);
    XAI_CHECK_STRIDE(param, 1);
    XAI_CHECK_ERROR((XAI_CNN_CONV_GET_STRIDEX(param) == XAI_CNN_CONV_GET_STRIDEY(param)),                                         \
                    XAI_ERR_BADARG, "Stride along width = %hhu and height = %hhu\nStride along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_DILATION(param, 4);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_DILATIONX(param) == XAI_CNN_CONV_GET_DILATIONY(param),                                             \
                    XAI_ERR_BADARG, "\nDilation along width = %hhu and height = %hhu\nDilation along width and height should be equal", \
                    XAI_CNN_CONV_GET_DILATIONX(param), XAI_CNN_CONV_GET_DILATIONY(param));
    XAI_CHECK_CONSISTENCY_MOW_WHD(inTile, coeffTile, biasArray, outTile, param);
    XAI_CHECK_COEFFTILE_CONTIGUOUS(coeffTile, param);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_ACCUM_SHIFT(param) < 24,                                     \
                    XAI_ERR_NORM, "\nThe accumulator shift = %hhu, value should be less than 24", \
                    XAI_CNN_CONV_GET_ACCUM_SHIFT(param));
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_OUTPUT_SHIFT(param) < 32,                               \
                    XAI_ERR_NORM, "\nThe output shift = %hhu, value should be less than 32", \
                    XAI_CNN_CONV_GET_OUTPUT_SHIFT(param));
    XAI_CHECK_CONV_RELU_LIMITS_IX(param, outTile);
#if DILATED_VQ_CONV == VQ_TRUE
    XAI_CHECK_ARRAY_U16(outputScaleArray);
    XAI_CHECK_ERROR(XAI_ARRAY_GET_WIDTH(outputScaleArray) >= XAI_TILE4D_GET_DIM4(coeffTile),                                                                                          \
                    XAI_ERR_DATASIZE, "\nWidth of Output Scale Array = %d, Number of Kernels = %d\nWidth of Output Scale Array should be greater than or equal to Number of Kernels", \
                    XAI_ARRAY_GET_WIDTH(outputScaleArray), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_ERROR((((uintptr_t) (XAI_ARRAY_GET_DATA_PTR(outputScaleArray)) & \
                      0x1) == 0), XAI_ERR_NORM, "The output scale array is not aligned to 2 byte boundary");
#endif
  }
#if DILATED_VQ_CONV == VQ_FALSE
  if (XAI_CNN_CONV_GET_OUTPUT_SCALE(param) == 0)
  {
    int32_t fillValue;
    int32_t reluFlag = XAI_CNN_CONV_GET_FLAG_RELU(param);
    fillValue = reluFlag ? (CLAMP(0, XAI_CNN_CONV_GET_RELU_MIN(param), XAI_CNN_CONV_GET_RELU_MAX(param))) : 0;
    return(xaiFillTile3D(outTile, fillValue, 0));
  }
#endif
  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Pitches of Coefficient Data (WHDN) in dim3 */
  const int32_t coeffPitch1 = XAI_TILE4D_GET_DIM1_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Kernel Size (WHDN) */
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t dilationU     = XAI_CNN_CONV_GET_DILATION(param);

  int32_t dilatedkSizeU = dilationU * (kSizeU - 1) + 1;

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Move pointer to the start of the data (including edge) */
  pInData = &pInData[-((dilatedkSizeU / 2) * inDataPitch1 + (dilatedkSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 * restrict pdvecIn;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1;

  /* Variable Declarations */
  int32_t inCh, outCh, x, y;

  /* In order to make the loop multiply-bound we are reducing the vectorization width
     by extra values required for the kernel */
  const int32_t vectorizationWidth = ((4 * XCHAL_IVPN_SIMD_WIDTH) - dilatedkSizeU) + 1;

  for (x = 0; x < outW; x += vectorizationWidth)  /* Loop across output width */
  {
    int32_t remX = XT_MIN(vectorizationWidth, outW - x);

    /* If (remX + kSizeEffU - 1) <= 2 * XCHAL_IVPN_SIMD_WIDTH,
     * i.e. if the number of input data bytes corresponding to remX number of outputs
     * is less than or equal to 2 * XCHAL_IVPN_SIMD_WIDTH, there is no need to load
     * the next 64 input bytes*/
    int32_t remXLoad = ((remX + dilatedkSizeU - 1) > 2 * XCHAL_IVPN_SIMD_WIDTH) ? 1 : 0;

    for (y = 0; y < outH; y++) /* Loop across output height */
    {
      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * y + x];

      /* initialize coeff and Bias data pointer*/
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh++)  /* Loop across Output depth */
      {
        /* load and replicate bias data */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc1, dacc2;
        dacc1 = dacc2 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc2, hvecBias1, hvecBias1);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

        pdvecIn = (MORPH_IDT_2Nx8 *) pInput;

        for (inCh = 0; inCh < numInCh; inCh++)  /* Loop across input channels */
        {
          /* vectors for coeff and input loads */
          xb_vec2Nx8 dvecCoeffData1;
          xb_vec2Nx8 dvecInData11, dvecInData21, dvecInData31, dvecInData41, \
                     dvecInData51, dvecInData61, dvecInData71;
          xb_vec2Nx8 dvecInData12, dvecInData22, dvecInData32, dvecInData42, \
                     dvecInData52, dvecInData62, dvecInData72;

          /* load data from first input row */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn, dilationU * inDataPitch1 - \
                             remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /*Separate odd and even indices */
          IVP_DSEL2NX8I(dvecInData12, dvecInData11, dvecInData12, dvecInData11, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecInData12, dvecInData11, dvecInData12, dvecInData11, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load data from 2nd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn, dilationU * inDataPitch1 - \
                             remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /*Separate odd and even indices */
          IVP_DSEL2NX8I(dvecInData22, dvecInData21, dvecInData22, dvecInData21, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecInData22, dvecInData21, dvecInData22, dvecInData21, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load data from 3rd input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData31, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData32, vaInData, pdvecIn, dilationU * inDataPitch1 - \
                             remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /*Separate odd and even indices */
          IVP_DSEL2NX8I(dvecInData32, dvecInData31, dvecInData32, dvecInData31, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecInData32, dvecInData31, dvecInData32, dvecInData31, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load data from 4th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData41, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData42, vaInData, pdvecIn, dilationU * inDataPitch1 - \
                             remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /*Separate odd and even indices */
          IVP_DSEL2NX8I(dvecInData42, dvecInData41, dvecInData42, dvecInData41, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecInData42, dvecInData41, dvecInData42, dvecInData41, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load data from 5th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData51, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData52, vaInData, pdvecIn, dilationU * inDataPitch1 - \
                             remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /*Separate odd and even indices */
          IVP_DSEL2NX8I(dvecInData52, dvecInData51, dvecInData52, dvecInData51, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecInData52, dvecInData51, dvecInData52, dvecInData51, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load data from 6th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData61, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData62, vaInData, pdvecIn, dilationU * inDataPitch1 - \
                             remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);

          /*Separate odd and even indices */
          IVP_DSEL2NX8I(dvecInData62, dvecInData61, dvecInData62, dvecInData61, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecInData62, dvecInData61, dvecInData62, dvecInData61, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load data from 7th input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn);
          MORPH_OP_LOAD_2Nx8(dvecInData71, vaInData, pdvecIn, remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH);
          MORPH_OP_LOAD_2Nx8(dvecInData72, vaInData, pdvecIn, inDataPitch2 - \
                             remXLoad * 2 * XCHAL_IVPN_SIMD_WIDTH - dilationU * 6 * inDataPitch1);

          /*Separate odd and even indices */
          IVP_DSEL2NX8I(dvecInData72, dvecInData71, dvecInData72, dvecInData71, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecInData72, dvecInData71, dvecInData72, dvecInData71, \
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load 1st row of coefficients */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply and accumulate 1st set of 4 coefficients from 1st row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, dvecInData11, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, dvecInData12, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));

          /* Multiply and accumulate 2nd set of 4 coefficients from 1st row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(dvecInData11, dvecInData11,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc2, 0, IVP_SEL2NX8I(dvecInData12, dvecInData12,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* load 2nd row of coefficients */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply and accumulate 1st set of 4 coefficients from 2nd row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, dvecInData21, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, dvecInData22, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));

          /* Multiply and accumulate 2nd set of 4 coefficients from 2nd row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(dvecInData21, dvecInData21,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc2, 0, IVP_SEL2NX8I(dvecInData22, dvecInData22,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* load 3rd row of coefficients */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply and accumulate 1st set of 4 coefficients from 3rd row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, dvecInData31, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, dvecInData32, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));

          /* Multiply and accumulate 2nd set of 4 coefficients from 3rd row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(dvecInData31, dvecInData31,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc2, 0, IVP_SEL2NX8I(dvecInData32, dvecInData32,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* load 4th row of coefficients */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply and accumulate 1st set of 4 coefficients from 4th row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, dvecInData41, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, dvecInData42, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));

          /* Multiply and accumulate 2nd set of 4 coefficients from 4th row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(dvecInData41, dvecInData41,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc2, 0, IVP_SEL2NX8I(dvecInData42, dvecInData42,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* load 5th row of coefficients */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply and accumulate 1st set of 4 coefficients from 5th row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, dvecInData51, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, dvecInData52, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));

          /* Multiply and accumulate 2nd set of 4 coefficients from 5th row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(dvecInData51, dvecInData51,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc2, 0, IVP_SEL2NX8I(dvecInData52, dvecInData52,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* load 6th row of coefficients */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply and accumulate 1st set of 4 coefficients from 6th row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, dvecInData61, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, dvecInData62, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));

          /* Multiply and accumulate 2nd set of 4 coefficients from 6th row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(dvecInData61, dvecInData61,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc2, 0, IVP_SEL2NX8I(dvecInData62, dvecInData62,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

          /* load 7th row of coefficients */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

          /* Multiply and accumulate 1st set of 4 coefficients from 7th row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, dvecInData71, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, dvecInData72, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));

          /* Multiply and accumulate 2nd set of 4 coefficients from 7th row for all the outputs */
          MORPH_OP_MUL4TA(dacc1, 0, IVP_SEL2NX8I(dvecInData71, dvecInData71,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc2, 0, IVP_SEL2NX8I(dvecInData72, dvecInData72,                  \
                                                 IVP_SELI_8B_ROTATE_RIGHT_4), IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
        }  /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        if (!typeFlag)
        {
          MORPH_OP_DSELI(dvecOut2L, dvecOut1L, dvecOut2L, dvecOut1L, \
                         IVP_DSELI_8B_INTERLEAVE_1);
          MORPH_OP_DSELI(dvecOut2L, dvecOut1L, dvecOut2L, dvecOut1L, \
                         IVP_DSELI_8B_INTERLEAVE_1);
        }
        else
        {
          MORPH_OP_DSELI(dvecOut1H, dvecOut1L, dvecOut1H, dvecOut1L, \
                         IVP_DSELI_INTERLEAVE_1);
          MORPH_OP_DSELI(dvecOut2H, dvecOut2L, dvecOut2H, dvecOut2L, \
                         IVP_DSELI_INTERLEAVE_1);
          MORPH_OP_DSELI(dvecOut2L, dvecOut1L, dvecOut2L, dvecOut1L, \
                         IVP_DSELI_INTERLEAVE_2);
          MORPH_OP_DSELI(dvecOut2H, dvecOut1H, dvecOut2H, dvecOut1H, \
                         IVP_DSELI_INTERLEAVE_2);
        }

        /* Storing the first depth output , 1st row */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();

        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * remX);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * remX - \
                       2 * XCHAL_IVPN_SIMD_WIDTH);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                       (2 * remX - 4 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                       (2 * remX - 6 * XCHAL_IVPN_SIMD_WIDTH));
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += outDataPitch2 * bytesPerPixel;
        pCoeff  += coeffPitch3;
      } /* end of for (outCh = 0; outCh < numOutCh; outCh++)*/
    }   /* end of for (y = 0; y < outH; y++)*/
  }     /* end of for (x = 0; x < outW; x += 2 * vectorizationWidth)*/
  return(XAI_ERROR_STATUS());
}


/******************************************************************************************
* MxN MOW WHD Stride 1 - DEPTH 3                                                          *
* If number of input channels is equal to 3                                               *
* this function is called.                                                                *
******************************************************************************************/

static _XAI_INLINE_ void MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_MxNj1d1), S8IX_MOW_WHD_DEPTH3) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Getting parameters from the tile structures */
  const int32_t inW = XAI_TILE3D_GET_DIM1(inTile) + \
                      XAI_TILE3D_GET_DIM1_EDGE1(inTile) + XAI_TILE3D_GET_DIM1_EDGE2(inTile);
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeX = XAI_TILE4D_GET_DIM1(coeffTile);
  const int32_t kSizeY = XAI_TILE4D_GET_DIM2(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t leftEdgeFlag  = XAI_CNN_CONV_GET_FLAG_LEFTEDGE(param);
  const uint8_t topEdgeFlag   = XAI_CNN_CONV_GET_FLAG_TOPEDGE(param);

  /* Pitches of Coefficient Data (WHDN) */
  const int32_t coeffPitch1 = XAI_TILE4D_GET_DIM1_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  uint8_t leftEdge, topEdge;
  if ((kSizeX % 2) != 0)
  {
    leftEdge = kSizeX / 2;
  }
  else
  {
    leftEdge = leftEdgeFlag ? (kSizeX / 2) : ((kSizeX / 2) - 1);
  }

  if ((kSizeY % 2) != 0)
  {
    topEdge = kSizeY / 2;
  }
  else
  {
    topEdge = topEdgeFlag ? (kSizeY / 2) : ((kSizeY / 2) - 1);
  }

  /* Move pointer to the start of the active data (including edge) */
  pInData = &pInData[-(topEdge * inDataPitch1 + leftEdge)];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 * restrict pdvecIn1;
  MORPH_IDT_2Nx8 * restrict pdvecIn2;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1, * restrict pdvecCoeff2;

  /* Variable Declarations */
  int32_t outCh, x, y, ky;
  const int32_t vectorizationWidth = 2 * XCHAL_IVPN_SIMD_WIDTH;
  int32_t varLen;

  if (kSizeX > 12)
  {
    /* loop across output channels is unrolled twice
     * to produce two output channels in 1 iteration.
     * Also loop across output height by 2 , thereby
     * producing 4 output vectors simultaneously.
     */
    for (x = 0; x < outW; x += vectorizationWidth)   /* Loop across Output width */
    {
      /* out of bound flag */
      int32_t flag = XT_SALT(64, inW - x);

      for (y = 0; y < outH; y += 2)    /* Loop across Output height */
      {
        /* handles odd output row */
        int32_t enable2ndRow = XT_SALT(y, outH - 1);

        /* initialize output data pointer */
        int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

        /* initialize input data pointer */
        MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * (y) + (x)];

        /* initialize coeff and bias data pointer*/
        int8_t *pCoeff = &pCoeffData[0];
        int32_t *pBias = &pBiasData[0];

        for (outCh = 0; outCh < numOutCh; outCh += 2)   /* Loop across Output depth */
        {
          /* handles odd output channel */
          int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

          xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
          xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

          /* wide vectors(accumulators) initialized with bias */
          xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;

          dacc12 = dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);

          dacc22 = dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc22, hvecBias2, hvecBias2);

          /* priming of coeff load is done outside the innermost loop*/
          pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
          valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

          pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
          valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

          /* variable declarations for input and coeff vectors */

          xb_vec2Nx8 dvecCoeffData11;
          xb_vec2Nx8 dvecCoeffData21;

          /* dvecInData11 refers to 1st input row, first 64(or lesser) elements
           * and dvecInData12 refers to next few left out elements of the same row
           * required to compute one 64 way output vector(To compute one 64 way
           * output vector, we require 64 + edge1 + edge2 number of input elements)
           */
          xb_vec2Nx8 dvecInData11, dvecInData12;
          xb_vec2Nx8 dvecInData21, dvecInData22;
          /***************************** 1st inCh ****************************/
          pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
          pdvecIn2 = (MORPH_IDT_2Nx8 *)  (pInput + inDataPitch1 * enable2ndRow);

          for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
          {
            /* loads 1st input row */
            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, inDataPitch1 - \
                               2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* loads 2nd input row */
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn2, inDataPitch1 - \
                               2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* load 1 row of coeff for 1st output channel */
            IVP_LAV2NX8_XP(dvecCoeffData11, vaCoeffData1, pdvecCoeff1, coeffPitch1);

            /* load 1 row of coeff for 2nd output channel */
            IVP_LAV2NX8_XP(dvecCoeffData21, vaCoeffData2, pdvecCoeff2, coeffPitch1);

            /* multiples loaded input data with first four coeff */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              0));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              0));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              0));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              0));

            /* right rotate the input vectors by 4
             * in order to multiply with next column of
             * coeff in the next iteration
             */
            dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);

            /* multiples input data with next four coeffs from the same row */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              1));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              1));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              1));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              1));

            /* right rotate the input vectors by 4
             * in order to multiply with next column of
             * coeff in the next iteration
             */
            dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);

            /* multiples input data with next four coeffs from the same row */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              2));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              2));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              2));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              2));

            /* right rotate the input vectors by 4
             * in order to multiply with next column of
             * coeff in the next iteration
             */
            dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);

            /* multiples input data with next four coeffs from the same row */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              3));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              3));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              3));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              3));
          } /* end of for (ky = 0; ky < kSizeY; ky++)*/

          /***************************** 2nd inCh ****************************/
          pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch2);
          pdvecIn2 = (MORPH_IDT_2Nx8 *)  (pInput + inDataPitch2 + inDataPitch1 * enable2ndRow);

          for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
          {
            /* loads 1st input row */
            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, inDataPitch1 - \
                               2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* loads 2nd input row */
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn2, inDataPitch1 - \
                               2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* load 1 row of coeff for 1st output channel */
            IVP_LAV2NX8_XP(dvecCoeffData11, vaCoeffData1, pdvecCoeff1, coeffPitch1);

            /* load 1 row of coeff for 2nd output channel */
            IVP_LAV2NX8_XP(dvecCoeffData21, vaCoeffData2, pdvecCoeff2, coeffPitch1);

            /* multiples loaded input data with first four coeff */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              0));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              0));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              0));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              0));

            /* right rotate the input vectors by 4
             * in order to multiply with next column of
             * coeff in the next iteration
             */
            dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);

            /* multiples input data with next four coeffs from the same row */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              1));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              1));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              1));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              1));

            /* right rotate the input vectors by 4
             * in order to multiply with next column of
             * coeff in the next iteration
             */
            dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);

            /* multiples input data with next four coeffs from the same row */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              2));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              2));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              2));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              2));

            /* right rotate the input vectors by 4
             * in order to multiply with next column of
             * coeff in the next iteration
             */
            dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);

            /* multiples input data with next four coeffs from the same row */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              3));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              3));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              3));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              3));
          } /* end of for (ky = 0; ky < kSizeY; ky++)*/

          /***************************** 3rd inCh ****************************/
          pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2);
          pdvecIn2 = (MORPH_IDT_2Nx8 *)  (pInput + 2 * inDataPitch2 + inDataPitch1 * enable2ndRow);

          for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
          {
            /* loads 1st input row */
            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, inDataPitch1 - \
                               2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* loads 2nd input row */
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn2, inDataPitch1 - \
                               2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* load 1 row of coeff for 1st output channel */
            IVP_LAV2NX8_XP(dvecCoeffData11, vaCoeffData1, pdvecCoeff1, coeffPitch1);

            /* load 1 row of coeff for 2nd output channel */
            IVP_LAV2NX8_XP(dvecCoeffData21, vaCoeffData2, pdvecCoeff2, coeffPitch1);

            /* multiples loaded input data with first four coeff */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              0));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              0));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              0));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              0));

            /* right rotate the input vectors by 4
             * in order to multiply with next column of
             * coeff in the next iteration
             */
            dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);

            /* multiples input data with next four coeffs from the same row */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              1));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              1));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              1));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              1));

            /* right rotate the input vectors by 4
             * in order to multiply with next column of
             * coeff in the next iteration
             */
            dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);

            /* multiples input data with next four coeffs from the same row */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              2));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              2));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              2));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              2));

            /* right rotate the input vectors by 4
             * in order to multiply with next column of
             * coeff in the next iteration
             */
            dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);

            /* multiples input data with next four coeffs from the same row */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              3));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              3));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              3));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              3));
          } /* end of for (ky = 0; ky < kSizeY; ky++)*/

          /* Pack, Output Scale, Output Shift and clamping */
          xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
          xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
          /* variable store count */
          varLen = XT_MIN(outW - x, vectorizationWidth);

          /* Storing the first row , first depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput);
          valign vaOutData = IVP_ZALIGN();
          IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
          IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the first row , 2nd depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndCh * outDataPitch2 * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * varLen);
          IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                         enable2ndCh * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the 2nd row , 1st depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndRow * outDataPitch1 * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * varLen);
          IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                         enable2ndRow * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the 2nd row , 2nd depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + (enable2ndCh * outDataPitch2 + \
                                                enable2ndRow * outDataPitch1) * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * \
                         enable2ndRow * enable2ndCh * varLen);
          IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                         enable2ndRow * enable2ndCh * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          pOutput += 2 * outDataPitch2 * bytesPerPixel;
          pCoeff  += 2 * coeffPitch3;
        } /* end of (outCh = 0; outCh < numOutCh; outCh += 2)*/
      }   /* end of for (y = 0; y < outH; y += 2)*/
    }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  }
  else if (kSizeX > 8)
  {
    /* loop across output channels is unrolled twice
     * to produce two output channels in 1 iteration.
     * Also loop across output height by 2 , thereby
     * producing 4 output vectors simultaneously.
     */
    for (x = 0; x < outW; x += vectorizationWidth)   /* Loop across Output width */
    {
      /* out of bound flag */
      int32_t flag = XT_SALT(64, inW - x);

      for (y = 0; y < outH; y += 2)    /* Loop across Output height */
      {
        /* handles odd output row */
        int32_t enable2ndRow = XT_SALT(y, outH - 1);
        /* initialize output data pointer */
        int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

        /* initialize input data pointer */
        MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * (y) + (x)];

        /* initialize coeff and bias data pointer*/
        int8_t *pCoeff = &pCoeffData[0];
        int32_t *pBias = &pBiasData[0];

        for (outCh = 0; outCh < numOutCh; outCh += 2)   /* Loop across Output depth */
        {
          /* handles odd output channel*/
          int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

          xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
          xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

          /* wide vectors(accumulators) initialized with bias */
          xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;

          dacc12 = dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);

          dacc22 = dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc22, hvecBias2, hvecBias2);

          /* priming of coeff load is done outside the innermost loop*/
          pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
          valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

          pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
          valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

          /* variable declarations for input and coeff vectors */

          xb_vec2Nx8 dvecCoeffData11;
          xb_vec2Nx8 dvecCoeffData21;

          /* dvecInData11 refers to 1st input row, first 64(or lesser) elements
           * and dvecInData12 refers to next few left out elements of the same row
           * required to compute one 64 way output vector(To compute one 64 way
           * output vector, we require 64 + edge1 + edge2 number of input elements)
           */
          xb_vec2Nx8 dvecInData11, dvecInData12;
          xb_vec2Nx8 dvecInData21, dvecInData22;
          /************************** 1st inCh *******************************/
          pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
          pdvecIn2 = (MORPH_IDT_2Nx8 *)  (pInput + inDataPitch1 * enable2ndRow);

          for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
          {
            /* loads 1st input row */
            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, inDataPitch1 - \
                               2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* loads 2nd input row */
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn2, inDataPitch1 - \
                               2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* load 1 row of coeff for 1st output channel */
            IVP_LAV2NX8_XP(dvecCoeffData11, vaCoeffData1, pdvecCoeff1, coeffPitch1);

            /* load 1 row of coeff for 2nd output channel */
            IVP_LAV2NX8_XP(dvecCoeffData21, vaCoeffData2, pdvecCoeff2, coeffPitch1);

            /* multiples loaded input data with first four coeff */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              0));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              0));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              0));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              0));

            /* right rotate the input vectors by 4
             * in order to multiply with next column of
             * coeff in the next iteration
             */
            dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);

            /* multiples input data with next four coeffs from the same row */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              1));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              1));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              1));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              1));

            /* right rotate the input vectors by 4
             * in order to multiply with next column of
             * coeff in the next iteration
             */
            dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);

            /* multiples input data with next four coeffs from the same row */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              2));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              2));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              2));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              2));
          } /* end of for (ky = 0; ky < kSizeY; ky++)*/

          /************************** 2nd inCh *******************************/
          pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch2);
          pdvecIn2 = (MORPH_IDT_2Nx8 *)  (pInput + inDataPitch2 + inDataPitch1 * enable2ndRow);

          for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
          {
            /* loads 1st input row */
            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, inDataPitch1 - \
                               2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* loads 2nd input row */
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn2, inDataPitch1 - \
                               2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* load 1 row of coeff for 1st output channel */
            IVP_LAV2NX8_XP(dvecCoeffData11, vaCoeffData1, pdvecCoeff1, coeffPitch1);

            /* load 1 row of coeff for 2nd output channel */
            IVP_LAV2NX8_XP(dvecCoeffData21, vaCoeffData2, pdvecCoeff2, coeffPitch1);

            /* multiples loaded input data with first four coeff */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              0));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              0));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              0));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              0));

            /* right rotate the input vectors by 4
             * in order to multiply with next column of
             * coeff in the next iteration
             */
            dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);

            /* multiples input data with next four coeffs from the same row */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              1));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              1));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              1));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              1));

            /* right rotate the input vectors by 4
             * in order to multiply with next column of
             * coeff in the next iteration
             */
            dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);

            /* multiples input data with next four coeffs from the same row */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              2));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              2));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              2));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              2));
          } /* end of for (ky = 0; ky < kSizeY; ky++)*/

          /************************** 3rd inCh *******************************/
          pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2);
          pdvecIn2 = (MORPH_IDT_2Nx8 *)  (pInput + 2 * inDataPitch2 + inDataPitch1 * enable2ndRow);

          for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
          {
            /* loads 1st input row */
            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, inDataPitch1 - \
                               2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* loads 2nd input row */
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn2, inDataPitch1 - \
                               2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* load 1 row of coeff for 1st output channel */
            IVP_LAV2NX8_XP(dvecCoeffData11, vaCoeffData1, pdvecCoeff1, coeffPitch1);

            /* load 1 row of coeff for 2nd output channel */
            IVP_LAV2NX8_XP(dvecCoeffData21, vaCoeffData2, pdvecCoeff2, coeffPitch1);

            /* multiples loaded input data with first four coeff */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              0));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              0));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              0));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              0));

            /* right rotate the input vectors by 4
             * in order to multiply with next column of
             * coeff in the next iteration
             */
            dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);

            /* multiples input data with next four coeffs from the same row */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              1));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              1));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              1));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              1));

            /* right rotate the input vectors by 4
             * in order to multiply with next column of
             * coeff in the next iteration
             */
            dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);

            /* multiples input data with next four coeffs from the same row */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              2));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              2));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              2));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              2));
          } /* end of for (ky = 0; ky < kSizeY; ky++)*/

          /* Pack, Output Scale, Output Shift and clamping */
          xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
          xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
          /* variable store count */
          varLen = XT_MIN(outW - x, vectorizationWidth);

          /* Storing the first row , first depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput);
          valign vaOutData = IVP_ZALIGN();
          IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
          IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the first row , 2nd depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndCh * outDataPitch2 * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * varLen);
          IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                         enable2ndCh * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the 2nd row , 1st depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndRow * outDataPitch1 * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * varLen);
          IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                         enable2ndRow * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the 2nd row , 2nd depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + (enable2ndCh * outDataPitch2 + \
                                                enable2ndRow * outDataPitch1) * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * \
                         enable2ndRow * enable2ndCh * varLen);
          IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                         enable2ndRow * enable2ndCh * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          pOutput += 2 * outDataPitch2 * bytesPerPixel;
          pCoeff  += 2 * coeffPitch3;
        } /* end of (outCh = 0; outCh < numOutCh; outCh += 2)*/
      }   /* end of for (y = 0; y < outH; y += 2)*/
    }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  }
  else if (kSizeX > 4)
  {
    /* loop across output channels is unrolled twice
     * to produce two output channels in 1 iteration.
     * Also loop across output height by 2 , thereby
     * producing 4 output vectors simultaneously.
     */
    for (x = 0; x < outW; x += vectorizationWidth)   /* Loop across Output width */
    {
      /* out of bound flag */
      int32_t flag = XT_SALT(64, inW - x);

      for (y = 0; y < outH; y += 2)    /* Loop across Output height */
      {
        /* handles odd output row */
        int32_t enable2ndRow = XT_SALT(y, outH - 1);

        /* initialize output data pointer */
        int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

        /* initialize input data pointer */
        MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * (y) + (x)];

        /* initialize coeff and bias data pointer*/
        int8_t *pCoeff = &pCoeffData[0];
        int32_t *pBias = &pBiasData[0];

        for (outCh = 0; outCh < numOutCh; outCh += 2)   /* Loop across Output depth */
        {
          /* handles odd output channel */
          int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

          xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
          xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

          /* wide vectors(accumulators) initialized with bias */
          xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;

          dacc12 = dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);

          dacc22 = dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc22, hvecBias2, hvecBias2);

          /* priming of coeff load is done outside the innermost loop*/
          pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
          valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

          pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
          valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

          /* variable declarations for input and coeff vectors */

          xb_vec2Nx8 dvecCoeffData11;
          xb_vec2Nx8 dvecCoeffData21;

          /* dvecInData11 refers to 1st input row, first 64(or lesser) elements
           * and dvecInData12 refers to next few left out elements of the same row
           * required to compute one 64 way output vector(To compute one 64 way
           * output vector, we require 64 + edge1 + edge2 number of input elements)
           */
          xb_vec2Nx8 dvecInData11, dvecInData12;
          xb_vec2Nx8 dvecInData21, dvecInData22;

          /******************************* 1st inCh ************************************/
          pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
          pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch1 * enable2ndRow);

          for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
          {
            /* loads 1st input row */
            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, inDataPitch1 - \
                               2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* loads 2nd input row */
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn2, inDataPitch1 - \
                               2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* load 1 row of coeff for 1st output channel */
            IVP_LAV2NX8_XP(dvecCoeffData11, vaCoeffData1, pdvecCoeff1, coeffPitch1);

            /* load 1 row of coeff for 2nd output channel */
            IVP_LAV2NX8_XP(dvecCoeffData21, vaCoeffData2, pdvecCoeff2, coeffPitch1);

            /* multiples loaded input data with first four coeff */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              0));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              0));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              0));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              0));

            /* right rotate the input vectors by 4
             * in order to multiply with next column of
             * coeff in the next iteration
             */
            dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);

            /* multiples input data with next four coeffs from the same row */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              1));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              1));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              1));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              1));
          } /* end of for (ky = 0; ky < kSizeY; ky++)*/

          /******************************* 2nd inCh ************************************/
          pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch2);
          pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch2 + inDataPitch1 * enable2ndRow);

          for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
          {
            /* loads 1st input row */
            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, inDataPitch1 - \
                               2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* loads 2nd input row */
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn2, inDataPitch1 - \
                               2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* load 1 row of coeff for 1st output channel */
            IVP_LAV2NX8_XP(dvecCoeffData11, vaCoeffData1, pdvecCoeff1, coeffPitch1);

            /* load 1 row of coeff for 2nd output channel */
            IVP_LAV2NX8_XP(dvecCoeffData21, vaCoeffData2, pdvecCoeff2, coeffPitch1);

            /* multiples loaded input data with first four coeff */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              0));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              0));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              0));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              0));

            /* right rotate the input vectors by 4
             * in order to multiply with next column of
             * coeff in the next iteration
             */
            dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);

            /* multiples input data with next four coeffs from the same row */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              1));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              1));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              1));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              1));
          } /* end of for (ky = 0; ky < kSizeY; ky++)*/

          /******************************* 3rd inCh ************************************/
          pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2);
          pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2 + inDataPitch1 * enable2ndRow);

          for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
          {
            /* loads 1st input row */
            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, inDataPitch1 - \
                               2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* loads 2nd input row */
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn2, inDataPitch1 - \
                               2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* load 1 row of coeff for 1st output channel */
            IVP_LAV2NX8_XP(dvecCoeffData11, vaCoeffData1, pdvecCoeff1, coeffPitch1);

            /* load 1 row of coeff for 2nd output channel */
            IVP_LAV2NX8_XP(dvecCoeffData21, vaCoeffData2, pdvecCoeff2, coeffPitch1);

            /* multiples loaded input data with first four coeff */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              0));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              0));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              0));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              0));

            /* right rotate the input vectors by 4
             * in order to multiply with next column of
             * coeff in the next iteration
             */
            dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);

            /* multiples input data with next four coeffs from the same row */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              1));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              1));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              1));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              1));
          } /* end of for (ky = 0; ky < kSizeY; ky++)*/

          /* Pack, Output Scale, Output Shift and clamping */
          xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
          xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
          /* variable store count */
          varLen = XT_MIN(outW - x, vectorizationWidth);

          /* Storing the first row , first depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput);
          valign vaOutData = IVP_ZALIGN();
          IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
          IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the first row , 2nd depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndCh * outDataPitch2 * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * varLen);
          IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                         enable2ndCh * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the 2nd row , 1st depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndRow * outDataPitch1 * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * varLen);
          IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                         enable2ndRow * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the 2nd row , 2nd depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + (enable2ndCh * outDataPitch2 + \
                                                enable2ndRow * outDataPitch1) * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * \
                         enable2ndRow * enable2ndCh * varLen);
          IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                         enable2ndRow * enable2ndCh * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          pOutput += 2 * outDataPitch2 * bytesPerPixel;
          pCoeff  += 2 * coeffPitch3;
        } /* end of (outCh = 0; outCh < numOutCh; outCh += 2)*/
      }   /* end of for (y = 0; y < outH; y += 2)*/
    }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  }
  else
  {
    /* loop across output channels is unrolled twice
     * to produce two output channels in 1 iteration.
     * Also loop across output height by 2 , thereby
     * producing 4 output vectors simultaneously.
     */
    for (x = 0; x < outW; x += vectorizationWidth)   /* Loop across Output width */
    {
      /* out of bound flag */
      int32_t flag = XT_SALT(64, inW - x);

      for (y = 0; y < outH; y += 2)    /* Loop across Output height */
      {
        /* handles odd output row */
        int32_t enable2ndRow = XT_SALT(y, outH - 1);

        /* initialize output data pointer */
        int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

        /* initialize input data pointer */
        MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * (y) + (x)];

        /* initialize coeff and bias data pointer*/
        int8_t *pCoeff = &pCoeffData[0];
        int32_t *pBias = &pBiasData[0];

        for (outCh = 0; outCh < numOutCh; outCh += 2)   /* Loop across Output depth */
        {
          /* handles odd output channel */
          int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

          xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
          xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);


          /* wide vectors(accumulators) initialized with bias */
          xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;

          dacc12 = dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);

          dacc22 = dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc22, hvecBias2, hvecBias2);

          /* priming of coeff load is done outside the innermost loop*/
          pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
          valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

          pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
          valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

          /* variable declarations for input and coeff vectors */

          xb_vec2Nx8 dvecCoeffData11;
          xb_vec2Nx8 dvecCoeffData21;

          /* dvecInData11 refers to 1st input row, first 64(or lesser) elements
           * and dvecInData12 refers to next few left out elements of the same row
           * required to compute one 64 way output vector(To compute one 64 way
           * output vector, we require 64 + edge1 + edge2 number of input elements)
           */
          xb_vec2Nx8 dvecInData11, dvecInData12;
          xb_vec2Nx8 dvecInData21, dvecInData22;

          /************************* 1st inCh *******************************/
          pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
          pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch1 * enable2ndRow);

          for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
          {
            /* loads 1st input row */
            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, inDataPitch1 - \
                               2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* loads 2nd input row */
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn2, inDataPitch1 - \
                               2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* load 1 row of coeff for 1st output channel */
            IVP_LAV2NX8_XP(dvecCoeffData11, vaCoeffData1, pdvecCoeff1, coeffPitch1);

            /* load 1 row of coeff for 2nd output channel */
            IVP_LAV2NX8_XP(dvecCoeffData21, vaCoeffData2, pdvecCoeff2, coeffPitch1);

            /* multiples loaded input data with first four coeff */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              0));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              0));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              0));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              0));
          } /* for (ky = 0; ky < kSizeY; ky++)*/

          /************************* 2nd inCh *******************************/
          pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch2);
          pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch2 + inDataPitch1 * enable2ndRow);

          for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
          {
            /* loads 1st input row */
            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, inDataPitch1 - \
                               2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* loads 2nd input row */
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn2, inDataPitch1 - \
                               2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* load 1 row of coeff for 1st output channel */
            IVP_LAV2NX8_XP(dvecCoeffData11, vaCoeffData1, pdvecCoeff1, coeffPitch1);

            /* load 1 row of coeff for 2nd output channel */
            IVP_LAV2NX8_XP(dvecCoeffData21, vaCoeffData2, pdvecCoeff2, coeffPitch1);

            /* multiples loaded input data with first four coeff */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              0));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              0));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              0));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              0));
          } /* for (ky = 0; ky < kSizeY; ky++)*/

          /************************* 3rd inCh *******************************/
          pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2);
          pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2 + inDataPitch1 * enable2ndRow);

          for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
          {
            /* loads 1st input row */
            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, inDataPitch1 - \
                               2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* loads 2nd input row */
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn2, inDataPitch1 - \
                               2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* load 1 row of coeff for 1st output channel */
            IVP_LAV2NX8_XP(dvecCoeffData11, vaCoeffData1, pdvecCoeff1, coeffPitch1);

            /* load 1 row of coeff for 2nd output channel */
            IVP_LAV2NX8_XP(dvecCoeffData21, vaCoeffData2, pdvecCoeff2, coeffPitch1);

            /* multiples loaded input data with first four coeff */
            MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              0));
            MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              0));

            MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                              0));
            MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                              (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                              0));
          } /* for (ky = 0; ky < kSizeY; ky++)*/

          /* Pack, Output Scale, Output Shift and clamping */
          xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
          xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
          /* variable store count */
          varLen = XT_MIN(outW - x, vectorizationWidth);

          /* Storing the first row , first depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput);
          valign vaOutData = IVP_ZALIGN();
          IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
          IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the first row , 2nd depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndCh * outDataPitch2 * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * varLen);
          IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                         enable2ndCh * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the 2nd row , 1st depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndRow * outDataPitch1 * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * varLen);
          IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                         enable2ndRow * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the 2nd row , 2nd depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + (enable2ndCh * outDataPitch2 + \
                                                enable2ndRow * outDataPitch1) * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * \
                         enable2ndRow * enable2ndCh * varLen);
          IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                         enable2ndRow * enable2ndCh * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          pOutput += 2 * outDataPitch2 * bytesPerPixel;
          pCoeff  += 2 * coeffPitch3;
        } /* end of (outCh = 0; outCh < numOutCh; outCh += 2)*/
      }   /* end of for (y = 0; y < outH; y += 2)*/
    }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  }
}

/******************************************************************************************
*   xaiConvolved(VQ)3D_S_MxNj1d1I8S8IX_MOW_WHD
*  ***************************************************************************************/
/******************************************************************************/
/* Description : P6 optimized generic implementation for MxN 3D convolution.  */
/*               Based on MORPH pre-processor specifiers, code implementation */
/*               is generated during preprocessing stage. This method can be  */
/*               used to generate MxN 3D dilated convolution function and MxN */
/*               3D VQ dilated convolution function for U8 bit and S8 bit     */
/*               input data with input stride equal to 1                      */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                */
/*               Output scale array, CNN convolution params structure         */
/* Outputs     : XI Error Code                                                */
/* InOuts      : Output Tile                                                  */
/* Assumptions : CoeffData is S8                                              */
/*               biasArray is signed 32b, value not exceeding signed 24b      */
/*               Output scale array is U16                                    */
/*               OutData is S8 / U8 / S16                                     */
/*               Kernel Size is MxNxDxN                                       */
/*               Input and Output are in WHD format                           */
/*               Coeff is in WHDN format                                      */
/******************************************************************************/

/****************** xaiConvolvedVQ3D_S_MxNj1d1_S8S8IX_MOW_WHD ******************/
/****************** xaiConvolvedVQ3D_S_MxNj1d1_U8S8IX_MOW_WHD ******************/
/******************* xaiConvolved3D_S_MxNj1d1_S8S8IX_MOW_WHD *******************/
/******************* xaiConvolved3D_S_MxNj1d1_U8S8IX_MOW_WHD *******************/

XAI_ERR_TYPE MAKE_NAME(MAKE_NAME_VQ(xaiConvolved, 3D_S_MxNj1d1), S8IX_MOW_WHD) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Error Checks */
  XAI_ERROR_CHECKS()
  {
    MORPH_IDT_CHECK(inTile);
    XAI_CHECK_CONV_OUTPUT_TILE3D(outTile);
    XAI_CHECK_TILE4D_S8(coeffTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(outTile);
    XAI_CHECK_TILE4D_IN_DRAM_BOUNDARY(coeffTile);
    XAI_CHECK_POINTER(param);
    XAI_CHECK_ARRAY_S32(biasArray);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(inTile, outTile);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(coeffTile, outTile);
    XAI_CHECK_ERROR(XAI_TILE4D_GET_DIM1(coeffTile) <= 16, XAI_ERR_KSIZE,           \
                    "Kernel width = %d, which should be less than or equal to 16", \
                    XAI_TILE4D_GET_DIM1(coeffTile));
    XAI_CHECK_ERROR(XAI_TILE4D_GET_DIM2(coeffTile) <= 16, XAI_ERR_KSIZE,              \
                    "\nKernel height = %d, which should be less than or equal to 16", \
                    XAI_TILE4D_GET_DIM2(coeffTile));
    XAI_CHECK_DILATION(param, 1);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_DILATIONX(param) == XAI_CNN_CONV_GET_DILATIONY(param),                                             \
                    XAI_ERR_BADARG, "\nDilation along width = %hhu and height = %hhu\nDilation along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_EDGES_MOW_WHD(inTile, coeffTile, param);
    XAI_CHECK_TILE3D_DATA_ORDER(inTile, XAI_WHD);
    XAI_CHECK_TILE3D_DATA_ORDER(outTile, XAI_WHD);
    XAI_CHECK_TILE4D_DATA_ORDER(coeffTile, XAI_WHDN);
    XAI_CHECK_STRIDE(param, 1);
    XAI_CHECK_ERROR((XAI_CNN_CONV_GET_STRIDEX(param) == XAI_CNN_CONV_GET_STRIDEY(param)),                                           \
                    XAI_ERR_BADARG, "\nStride along width = %hhu and height = %hhu\nStride along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_CONSISTENCY_MOW_WHD(inTile, coeffTile, biasArray, outTile, param);
    XAI_CHECK_COEFFTILE_CONTIGUOUS(coeffTile, param);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_ACCUM_SHIFT(param) < 24,                                     \
                    XAI_ERR_NORM, "\nThe accumulator shift = %hhu, value should be less than 24", \
                    XAI_CNN_CONV_GET_ACCUM_SHIFT(param));
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_OUTPUT_SHIFT(param) < 32,                               \
                    XAI_ERR_NORM, "\nThe output shift = %hhu, value should be less than 32", \
                    XAI_CNN_CONV_GET_OUTPUT_SHIFT(param));
    XAI_CHECK_CONV_RELU_LIMITS_IX(param, outTile);
#if DILATED_VQ_CONV == VQ_TRUE
    XAI_CHECK_ARRAY_U16(outputScaleArray);
    XAI_CHECK_ERROR(XAI_ARRAY_GET_WIDTH(outputScaleArray) >= XAI_TILE4D_GET_DIM4(coeffTile),                                                                                          \
                    XAI_ERR_DATASIZE, "\nWidth of Output Scale Array = %d, Number of Kernels = %d\nWidth of Output Scale Array should be greater than or equal to Number of Kernels", \
                    XAI_ARRAY_GET_WIDTH(outputScaleArray), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_ERROR((((uintptr_t) (XAI_ARRAY_GET_DATA_PTR(outputScaleArray)) & \
                      0x1) == 0), XAI_ERR_NORM, "The output scale array is not aligned to 2 byte boundary");
#endif
  }
#if DILATED_VQ_CONV == VQ_FALSE
  if (XAI_CNN_CONV_GET_OUTPUT_SCALE(param) == 0)
  {
    int32_t fillValue;
    int32_t reluFlag = XAI_CNN_CONV_GET_FLAG_RELU(param);
    fillValue = reluFlag ? (CLAMP(0, XAI_CNN_CONV_GET_RELU_MIN(param), XAI_CNN_CONV_GET_RELU_MAX(param))) : 0;
    return(xaiFillTile3D(outTile, fillValue, 0));
  }
#endif
  if (XAI_TILE3D_GET_DIM3(inTile) == 3)
  {
    MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_MxNj1d1), S8IX_MOW_WHD_DEPTH3) MAKE_PARAMS(inTile, coeffTile, biasArray, outTile, param);
    return(XAI_ERROR_STATUS());
  }

  /* Getting parameters from the tile structures */
  const int32_t inW = XAI_TILE3D_GET_DIM1(inTile) + \
                      XAI_TILE3D_GET_DIM1_EDGE1(inTile) + XAI_TILE3D_GET_DIM1_EDGE2(inTile);
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeX = XAI_TILE4D_GET_DIM1(coeffTile);
  const int32_t kSizeY = XAI_TILE4D_GET_DIM2(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t leftEdgeFlag  = XAI_CNN_CONV_GET_FLAG_LEFTEDGE(param);
  const uint8_t topEdgeFlag   = XAI_CNN_CONV_GET_FLAG_TOPEDGE(param);

  /* Pitches of Coefficient Data (WHDN) */
  const int32_t coeffPitch1 = XAI_TILE4D_GET_DIM1_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  uint8_t leftEdge, topEdge;
  if ((kSizeX % 2) != 0)
  {
    leftEdge = kSizeX / 2;
  }
  else
  {
    leftEdge = leftEdgeFlag ? (kSizeX / 2) : ((kSizeX / 2) - 1);
  }

  if ((kSizeY % 2) != 0)
  {
    topEdge = kSizeY / 2;
  }
  else
  {
    topEdge = topEdgeFlag ? (kSizeY / 2) : ((kSizeY / 2) - 1);
  }

  /* Move pointer to the start of the active data (including edge) */
  pInData = &pInData[-(topEdge * inDataPitch1 + leftEdge)];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 * restrict pdvecIn1;
  MORPH_IDT_2Nx8 * restrict pdvecIn2;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1, * restrict pdvecCoeff2;

  /* Variable Declarations */
  int32_t inCh, outCh, x, y, ky;
  const int32_t vectorizationWidth = 2 * XCHAL_IVPN_SIMD_WIDTH;
  int32_t varLen;

  if (kSizeX > 12)
  {
    /* loop across output channels is unrolled twice
     * to produce two output channels in 1 iteration.
     * Also loop across output height by 2 , thereby
     * producing 4 output vectors simultaneously.
     */
    for (x = 0; x < outW; x += vectorizationWidth)   /* Loop across Output width */
    {
      /* out of bound flag */
      int32_t flag = XT_SALT(2 * XCHAL_IVPN_SIMD_WIDTH, inW - x);

      for (y = 0; y < outH; y += 2)    /* Loop across Output height */
      {
        /* handles odd output row */
        int32_t enable2ndRow = XT_SALT(y, outH - 1);

        /* initialize output data pointer */
        int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

        /* initialize input data pointer */
        MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * (y) + (x)];

        /* initialize coeff and bias data pointer*/
        int8_t *pCoeff = &pCoeffData[0];
        int32_t *pBias = &pBiasData[0];

        for (outCh = 0; outCh < numOutCh; outCh += 2)   /* Loop across Output depth */
        {
          /* handles odd output channel */
          int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

          xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
          xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

          /* wide vectors(accumulators) initialized with bias */
          xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;

          dacc12 = dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);

          dacc22 = dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc22, hvecBias2, hvecBias2);

          /* priming of coeff load is done outside the innermost loop*/
          pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
          valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

          pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
          valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

          for (inCh = 0; inCh < numInCh; inCh++)   /* Loop across input channels */
          {
            /* variable declarations for input and coeff vectors */

            xb_vec2Nx8 dvecCoeffData11;
            xb_vec2Nx8 dvecCoeffData21;

            /* dvecInData11 refers to 1st input row, first 64(or lesser) elements
             * and dvecInData12 refers to next few left out elements of the same row
             * required to compute one 64 way output vector(To compute one 64 way
             * output vector, we require 64 + edge1 + edge2 number of input elements)
             */
            xb_vec2Nx8 dvecInData11, dvecInData12;
            xb_vec2Nx8 dvecInData21, dvecInData22;

            pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2);
            pdvecIn2 = (MORPH_IDT_2Nx8 *)  (pInput + inCh * inDataPitch2 + inDataPitch1 * enable2ndRow);

            for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
            {
              /* loads 1st input row */
              valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
              MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
              MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

              /* loads 2nd input row */
              vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
              MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
              MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn2, inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

              /* load 1 row of coeff for 1st output channel */
              IVP_LAV2NX8_XP(dvecCoeffData11, vaCoeffData1, pdvecCoeff1, coeffPitch1);

              /* load 1 row of coeff for 2nd output channel */
              IVP_LAV2NX8_XP(dvecCoeffData21, vaCoeffData2, pdvecCoeff2, coeffPitch1);

              /* multiples loaded input data with first four coeff */
              MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                0));
              MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                0));

              MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                0));
              MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                0));

              /* right rotate the input vectors by 4
               * in order to multiply with next column of
               * coeff in the next iteration
               */
              dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);

              /* multiples input data with next four coeffs from the same row */
              MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                1));
              MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                1));

              MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                1));
              MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                1));

              /* right rotate the input vectors by 4
               * in order to multiply with next column of
               * coeff in the next iteration
               */
              dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);

              /* multiples input data with next four coeffs from the same row */
              MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                2));
              MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                2));

              MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                2));
              MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                2));

              /* right rotate the input vectors by 4
               * in order to multiply with next column of
               * coeff in the next iteration
               */
              dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);

              /* multiples input data with next four coeffs from the same row */
              MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                3));
              MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                3));

              MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                3));
              MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                3));
            } /* end of for (ky = 0; ky < kSizeY; ky++)*/
          }   /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

          /* Pack, Output Scale, Output Shift and clamping */
          xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
          xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
          /* variable store count */
          varLen = XT_MIN(outW - x, vectorizationWidth);

          /* Storing the first row , first depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput);
          valign vaOutData = IVP_ZALIGN();
          IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
          IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the first row , 2nd depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndCh * outDataPitch2 * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * varLen);
          IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                         enable2ndCh * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the 2nd row , 1st depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndRow * outDataPitch1 * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * varLen);
          IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                         enable2ndRow * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the 2nd row , 2nd depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + (enable2ndCh * outDataPitch2 + \
                                                enable2ndRow * outDataPitch1) * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * \
                         enable2ndRow * enable2ndCh * varLen);
          IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                         enable2ndRow * enable2ndCh * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          pOutput += 2 * outDataPitch2 * bytesPerPixel;
          pCoeff  += 2 * coeffPitch3;
        } /* end of (outCh = 0; outCh < numOutCh; outCh += 2)*/
      }   /* end of for (y = 0; y < outH; y += 2)*/
    }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  }
  else if (kSizeX > 8)
  {
    /* loop across output channels is unrolled twice
     * to produce two output channels in 1 iteration.
     * Also loop across output height by 2 , thereby
     * producing 4 output vectors simultaneously.
     */
    for (x = 0; x < outW; x += vectorizationWidth)   /* Loop across Output width */
    {
      /* out of bound flag */
      int32_t flag = XT_SALT(2 * XCHAL_IVPN_SIMD_WIDTH, inW - x);

      for (y = 0; y < outH; y += 2)    /* Loop across Output height */
      {
        /* handles odd output row */
        int32_t enable2ndRow = XT_SALT(y, outH - 1);
        /* initialize output data pointer */
        int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

        /* initialize input data pointer */
        MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * (y) + (x)];

        /* initialize coeff and bias data pointer*/
        int8_t *pCoeff = &pCoeffData[0];
        int32_t *pBias = &pBiasData[0];

        for (outCh = 0; outCh < numOutCh; outCh += 2)   /* Loop across Output depth */
        {
          /* handles odd output channel*/
          int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

          xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
          xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

          /* wide vectors(accumulators) initialized with bias */
          xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;

          dacc12 = dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);

          dacc22 = dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc22, hvecBias2, hvecBias2);

          /* priming of coeff load is done outside the innermost loop*/
          pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
          valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

          pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
          valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

          for (inCh = 0; inCh < numInCh; inCh++)   /* Loop across input channels */
          {
            /* variable declarations for input and coeff vectors */

            xb_vec2Nx8 dvecCoeffData11;
            xb_vec2Nx8 dvecCoeffData21;

            /* dvecInData11 refers to 1st input row, first 64(or lesser) elements
             * and dvecInData12 refers to next few left out elements of the same row
             * required to compute one 64 way output vector(To compute one 64 way
             * output vector, we require 64 + edge1 + edge2 number of input elements)
             */
            xb_vec2Nx8 dvecInData11, dvecInData12;
            xb_vec2Nx8 dvecInData21, dvecInData22;

            pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2);
            pdvecIn2 = (MORPH_IDT_2Nx8 *)  (pInput + inCh * inDataPitch2 + inDataPitch1 * enable2ndRow);

            for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
            {
              /* loads 1st input row */
              valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
              MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
              MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

              /* loads 2nd input row */
              vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
              MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
              MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn2, inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

              /* load 1 row of coeff for 1st output channel */
              IVP_LAV2NX8_XP(dvecCoeffData11, vaCoeffData1, pdvecCoeff1, coeffPitch1);

              /* load 1 row of coeff for 2nd output channel */
              IVP_LAV2NX8_XP(dvecCoeffData21, vaCoeffData2, pdvecCoeff2, coeffPitch1);

              /* multiples loaded input data with first four coeff */
              MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                0));
              MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                0));

              MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                0));
              MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                0));

              /* right rotate the input vectors by 4
               * in order to multiply with next column of
               * coeff in the next iteration
               */
              dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);

              /* multiples input data with next four coeffs from the same row */
              MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                1));
              MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                1));

              MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                1));
              MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                1));

              /* right rotate the input vectors by 4
               * in order to multiply with next column of
               * coeff in the next iteration
               */
              dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);

              /* multiples input data with next four coeffs from the same row */
              MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                2));
              MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                2));

              MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                2));
              MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                2));
            } /* end of for (ky = 0; ky < kSizeY; ky++)*/
          }   /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

          /* Pack, Output Scale, Output Shift and clamping */
          xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
          xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
          /* variable store count */
          varLen = XT_MIN(outW - x, vectorizationWidth);

          /* Storing the first row , first depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput);
          valign vaOutData = IVP_ZALIGN();
          IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
          IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the first row , 2nd depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndCh * outDataPitch2 * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * varLen);
          IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                         enable2ndCh * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the 2nd row , 1st depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndRow * outDataPitch1 * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * varLen);
          IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                         enable2ndRow * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the 2nd row , 2nd depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + (enable2ndCh * outDataPitch2 + \
                                                enable2ndRow * outDataPitch1) * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * \
                         enable2ndRow * enable2ndCh * varLen);
          IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                         enable2ndRow * enable2ndCh * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          pOutput += 2 * outDataPitch2 * bytesPerPixel;
          pCoeff  += 2 * coeffPitch3;
        } /* end of (outCh = 0; outCh < numOutCh; outCh += 2)*/
      }   /* end of for (y = 0; y < outH; y += 2)*/
    }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  }
  else if (kSizeX > 4)
  {
    /* loop across output channels is unrolled twice
     * to produce two output channels in 1 iteration.
     * Also loop across output height by 2 , thereby
     * producing 4 output vectors simultaneously.
     */
    for (x = 0; x < outW; x += vectorizationWidth)   /* Loop across Output width */
    {
      /* out of bound flag */
      int32_t flag = XT_SALT(2 * XCHAL_IVPN_SIMD_WIDTH, inW - x);

      for (y = 0; y < outH; y += 2)    /* Loop across Output height */
      {
        /* handles odd output row */
        int32_t enable2ndRow = XT_SALT(y, outH - 1);

        /* initialize output data pointer */
        int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

        /* initialize input data pointer */
        MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * (y) + (x)];

        /* initialize coeff and bias data pointer*/
        int8_t *pCoeff = &pCoeffData[0];
        int32_t *pBias = &pBiasData[0];

        for (outCh = 0; outCh < numOutCh; outCh += 2)   /* Loop across Output depth */
        {
          /* handles odd output channel */
          int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

          xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
          xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

          /* wide vectors(accumulators) initialized with bias */
          xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;

          dacc12 = dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);

          dacc22 = dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc22, hvecBias2, hvecBias2);

          /* priming of coeff load is done outside the innermost loop*/
          pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
          valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

          pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
          valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

          for (inCh = 0; inCh < numInCh; inCh++)   /* Loop across input channels */
          {
            /* variable declarations for input and coeff vectors */

            xb_vec2Nx8 dvecCoeffData11;
            xb_vec2Nx8 dvecCoeffData21;

            /* dvecInData11 refers to 1st input row, first 64(or lesser) elements
             * and dvecInData12 refers to next few left out elements of the same row
             * required to compute one 64 way output vector(To compute one 64 way
             * output vector, we require 64 + edge1 + edge2 number of input elements)
             */
            xb_vec2Nx8 dvecInData11, dvecInData12;
            xb_vec2Nx8 dvecInData21, dvecInData22;

            pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2);
            pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2 + inDataPitch1 * enable2ndRow);

            for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
            {
              /* loads 1st input row */
              valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
              MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
              MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

              /* loads 2nd input row */
              vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
              MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
              MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn2, inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

              /* load 1 row of coeff for 1st output channel */
              IVP_LAV2NX8_XP(dvecCoeffData11, vaCoeffData1, pdvecCoeff1, coeffPitch1);

              /* load 1 row of coeff for 2nd output channel */
              IVP_LAV2NX8_XP(dvecCoeffData21, vaCoeffData2, pdvecCoeff2, coeffPitch1);

              /* multiples loaded input data with first four coeff */
              MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                0));
              MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                0));

              MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                0));
              MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                0));

              /* right rotate the input vectors by 4
               * in order to multiply with next column of
               * coeff in the next iteration
               */
              dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);

              /* multiples input data with next four coeffs from the same row */
              MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                1));
              MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                1));

              MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                1));
              MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                1));
            } /* end of for (ky = 0; ky < kSizeY; ky++)*/
          }   /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

          /* Pack, Output Scale, Output Shift and clamping */
          xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
          xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                        pOutScaleData[outCh ], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
          /* variable store count */
          varLen = XT_MIN(outW - x, vectorizationWidth);

          /* Storing the first row , first depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput);
          valign vaOutData = IVP_ZALIGN();
          IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
          IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the first row , 2nd depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndCh * outDataPitch2 * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * varLen);
          IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                         enable2ndCh * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the 2nd row , 1st depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndRow * outDataPitch1 * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * varLen);
          IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                         enable2ndRow * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the 2nd row , 2nd depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + (enable2ndCh * outDataPitch2 + \
                                                enable2ndRow * outDataPitch1) * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * \
                         enable2ndRow * enable2ndCh * varLen);
          IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                         enable2ndRow * enable2ndCh * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          pOutput += 2 * outDataPitch2 * bytesPerPixel;
          pCoeff  += 2 * coeffPitch3;
        } /* end of (outCh = 0; outCh < numOutCh; outCh += 2)*/
      }   /* end of for (y = 0; y < outH; y += 2)*/
    }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  }
  else
  {
    /* loop across output channels is unrolled twice
     * to produce two output channels in 1 iteration.
     * Also loop across output height by 2 , thereby
     * producing 4 output vectors simultaneously.
     */
    for (x = 0; x < outW; x += vectorizationWidth)   /* Loop across Output width */
    {
      /* out of bound flag */
      int32_t flag = XT_SALT(2 * XCHAL_IVPN_SIMD_WIDTH, inW - x);

      for (y = 0; y < outH; y += 2)    /* Loop across Output height */
      {
        /* handles odd output row */
        int32_t enable2ndRow = XT_SALT(y, outH - 1);

        /* initialize output data pointer */
        int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

        /* initialize input data pointer */
        MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * (y) + (x)];

        /* initialize coeff and bias data pointer*/
        int8_t *pCoeff = &pCoeffData[0];
        int32_t *pBias = &pBiasData[0];

        for (outCh = 0; outCh < numOutCh; outCh += 2)   /* Loop across Output depth */
        {
          /* handles odd output channel */
          int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

          xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
          xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);


          /* wide vectors(accumulators) initialized with bias */
          xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;

          dacc12 = dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);

          dacc22 = dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc22, hvecBias2, hvecBias2);

          /* priming of coeff load is done outside the innermost loop*/
          pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
          valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

          pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
          valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);


          for (inCh = 0; inCh < numInCh; inCh++)   /* Loop across input channels */
          {
            /* variable declarations for input and coeff vectors */

            xb_vec2Nx8 dvecCoeffData11;
            xb_vec2Nx8 dvecCoeffData21;

            /* dvecInData11 refers to 1st input row, first 64(or lesser) elements
             * and dvecInData12 refers to next few left out elements of the same row
             * required to compute one 64 way output vector(To compute one 64 way
             * output vector, we require 64 + edge1 + edge2 number of input elements)
             */
            xb_vec2Nx8 dvecInData11, dvecInData12;
            xb_vec2Nx8 dvecInData21, dvecInData22;

            pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2);
            pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2 + inDataPitch1 * enable2ndRow);

            for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
            {
              /* loads 1st input row */
              valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
              MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
              MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

              /* loads 2nd input row */
              vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
              MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
              MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn2, inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

              /* load 1 row of coeff for 1st output channel */
              IVP_LAV2NX8_XP(dvecCoeffData11, vaCoeffData1, pdvecCoeff1, coeffPitch1);

              /* load 1 row of coeff for 2nd output channel */
              IVP_LAV2NX8_XP(dvecCoeffData21, vaCoeffData2, pdvecCoeff2, coeffPitch1);

              /* multiples loaded input data with first four coeff */
              MORPH_OP_MUL4TA(dacc11, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                0));
              MORPH_OP_MUL4TA(dacc21, dvecInData12, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                0));

              MORPH_OP_MUL4TA(dacc12, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                0));
              MORPH_OP_MUL4TA(dacc22, dvecInData22, dvecInData21, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                0));
            } /* for (ky = 0; ky < kSizeY; ky++)*/
          }   /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

          /* Pack, Output Scale, Output Shift and clamping */
          xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
          xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
          /* variable store count */
          varLen = XT_MIN(outW - x, vectorizationWidth);

          /* Storing the first row , first depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput);
          valign vaOutData = IVP_ZALIGN();
          IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
          IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the first row , 2nd depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndCh * outDataPitch2 * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * enable2ndCh * varLen);
          IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                         enable2ndCh * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the 2nd row , 1st depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndRow * outDataPitch1 * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * enable2ndRow * varLen);
          IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                         enable2ndRow * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the 2nd row , 2nd depth output */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + (enable2ndCh * outDataPitch2 + \
                                                enable2ndRow * outDataPitch1) * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * \
                         enable2ndRow * enable2ndCh * varLen);
          IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                         enable2ndRow * enable2ndCh * 2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          pOutput += 2 * outDataPitch2 * bytesPerPixel;
          pCoeff  += 2 * coeffPitch3;
        } /* end of (outCh = 0; outCh < numOutCh; outCh += 2)*/
      }   /* end of for (y = 0; y < outH; y += 2)*/
    }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  }

  return(XAI_ERROR_STATUS());
}

/******************************************************************************************
* MxN MOW WHD Stride 2 - DEPTH 3                                                          *
* If number of input channels is equal to 3                                               *
* this function is called.                                                                *
******************************************************************************************/

static _XAI_INLINE_ void MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_MxNj2d1), S8IX_MOW_WHD_DEPTH3) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Getting parameters from the tile structures */
  const int32_t inW = XAI_TILE3D_GET_DIM1(inTile) + \
                      XAI_TILE3D_GET_DIM1_EDGE1(inTile) + XAI_TILE3D_GET_DIM1_EDGE2(inTile);
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeX = XAI_TILE4D_GET_DIM1(coeffTile);
  const int32_t kSizeY = XAI_TILE4D_GET_DIM2(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t stride        = XAI_CNN_CONV_GET_STRIDE(param);
  const uint8_t leftEdgeFlag  = XAI_CNN_CONV_GET_FLAG_LEFTEDGE(param);
  const uint8_t topEdgeFlag   = XAI_CNN_CONV_GET_FLAG_TOPEDGE(param);

  /* Pitches of Coefficient Data (WHDN) dim3 */
  const int32_t coeffPitch1 = XAI_TILE4D_GET_DIM1_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  uint8_t leftEdge, topEdge;
  if ((kSizeX % 2) != 0)
  {
    leftEdge = kSizeX / 2;
  }
  else
  {
    leftEdge = leftEdgeFlag ? (kSizeX / 2) : ((kSizeX / 2) - 1);
  }

  if ((kSizeY % 2) != 0)
  {
    topEdge = kSizeY / 2;
  }
  else
  {
    topEdge = topEdgeFlag ? (kSizeY / 2) : ((kSizeY / 2) - 1);
  }

  /* Move pointer to the start of the active data (including edge) */
  pInData = &pInData[-(topEdge * inDataPitch1 + leftEdge)];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8* restrict pdvecIn1;
  MORPH_IDT_2Nx8* restrict pdvecIn2;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1, * restrict pdvecCoeff2;

  /* Variable Declarations */
  int32_t outCh, x, y, ky;
  int32_t varLen;

  /* Number of output elements that can be generated
   * with 2 input vector loads(64 way).*/
  const int32_t vectorizationWidth = (((4 * XCHAL_IVPN_SIMD_WIDTH) - kSizeX) / stride) + 1;

  if (kSizeX > 8)
  {
    /* loop across output channels is unrolled twice
     * to produce two output channels in 1 iteration.
     * Also loop across output height by 2 , thereby
     * producing 4 output vectors simultaneously.
     */
    for (x = 0; x < outW; x += vectorizationWidth)    /* Loop across Output width */
    {
      /* out of bound flag */
      int32_t flag = XT_SALT(2 * XCHAL_IVPN_SIMD_WIDTH, inW - stride * x);

      for (y = 0; y < outH; y += 2)    /* Loop across Output height */
      {
        /* In order to handle odd output height  */
        int32_t enable2Row = XT_SALT(y, outH - 1);

        /* initialize output data pointer */
        int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

        /* initialize input data pointer */
        MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * stride * (y) + stride * (x)];

        /* initialize coeff and Bias data pointer */
        int8_t *pCoeff = &pCoeffData[0];
        int32_t *pBias = &pBiasData[0];

        for (outCh = 0; outCh < numOutCh; outCh += 2)   /* Loop across Output depth */
        {
          /* In order to handle odd output depth  */
          int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

          xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
          xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

          /* wide vectors(accumulators) initialized with bias */
          xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;

          dacc12 = dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);

          dacc22 = dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc22, hvecBias2, hvecBias2);

          /* priming of coeff load is done outside the innermost loop*/
          pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
          valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

          pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
          valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

          xb_vec2Nx8 dvecCoeffData1;
          xb_vec2Nx8 dvecCoeffData2;

          xb_vec2Nx8 dvecInData11, dvecInData12;
          xb_vec2Nx8 dvecInData21, dvecInData22;

          /************************* 1st inCh *****************************************/
          pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
          pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + stride * inDataPitch1 * enable2Row);

          for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
          {
            /* loads 1st input row */

            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            IVP_LA2NX8_XP(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            IVP_LA2NX8_XP(dvecInData12, vaInData, pdvecIn1, \
                          inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* loads Next(3rd) input row, corresponding to 2nd output row */

            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            IVP_LA2NX8_XP(dvecInData21, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            IVP_LA2NX8_XP(dvecInData22, vaInData, pdvecIn2, \
                          inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* Re-arrange the data in the desired format                                    */
            /* Assume input as 1,2,3,4,5,6,7...127                                          */
            /* After re-arrangement using DSEL operation, updated vectors would be */
            /* dvecInData1 : 1,  3,  5,...121                                              */
            /* dvecInData2 : 2,  4,  6,...122                                              */

            IVP_DSEL2NX8I(dvecInData12, dvecInData11,
                          dvecInData12, dvecInData11, IVP_DSELI_8B_DEINTERLEAVE_1);
            IVP_DSEL2NX8I(dvecInData22, dvecInData21,
                          dvecInData22, dvecInData21, IVP_DSELI_8B_DEINTERLEAVE_1);

            /* load 1st row of coeffs for both output channels */
            IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);
            IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch1);

            /* rearrange the coeff vectors. Separate even and odd coeff
             * so that MUL4T can be used
             */
            IVP_DSEL2NX8I(dvecCoeffData2, dvecCoeffData1,
                          dvecCoeffData2, dvecCoeffData1, IVP_DSELI_8B_DEINTERLEAVE_1);


            /* multiply 1st input row with 1st 8 coeff from 1st output channel*/
            MORPH_OP_MUL4TA(dacc11, 0, dvecInData11, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
            MORPH_OP_MUL4TA(dacc11, 0, dvecInData12, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

            /* multiply 2nd input row with 1st 8 coeff from 1st output channel*/
            MORPH_OP_MUL4TA(dacc12, 0, dvecInData21, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
            MORPH_OP_MUL4TA(dacc12, 0, dvecInData22, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

            /* multiply 1st input row with 1st 8 coeff from 2nd output channel*/
            MORPH_OP_MUL4TA(dacc21, 0, dvecInData11, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 8));
            MORPH_OP_MUL4TA(dacc21, 0, dvecInData12, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 8));

            /* multiply 2nd input row with 1st 8 coeff from 2nd output channel*/
            MORPH_OP_MUL4TA(dacc22, 0, dvecInData21, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 8));
            MORPH_OP_MUL4TA(dacc22, 0, dvecInData22, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 8));

            /* right rotate the input vectors
             * in order to multiply with next columns of
             * coeff in the next iteration
             */
            dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);


            /* multiply 1st input row with next 8 coeff from 1st output channel*/
            MORPH_OP_MUL4TA(dacc11, 0, dvecInData11, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
            MORPH_OP_MUL4TA(dacc11, 0, dvecInData12, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));

            /* multiply 2nd input row with next 8 coeff from 1st output channel*/
            MORPH_OP_MUL4TA(dacc12, 0, dvecInData21, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
            MORPH_OP_MUL4TA(dacc12, 0, dvecInData22, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));


            /* multiply 1st input row with next 8 coeff from 2nd output channel*/
            MORPH_OP_MUL4TA(dacc21, 0, dvecInData11, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 9));
            MORPH_OP_MUL4TA(dacc21, 0, dvecInData12, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 9));

            /* multiply 2nd input row with next 8 coeff from 2nd output channel*/
            MORPH_OP_MUL4TA(dacc22, 0, dvecInData21, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 9));
            MORPH_OP_MUL4TA(dacc22, 0, dvecInData22, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 9));
          }   /* for (ky = 0; ky < kSizeY; ky++)*/

          /************************* 2nd inCh *****************************************/
          pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch2);
          pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch2 + \
                                         stride * inDataPitch1 * enable2Row);

          for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
          {
            /* loads 1st input row */

            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            IVP_LA2NX8_XP(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            IVP_LA2NX8_XP(dvecInData12, vaInData, pdvecIn1, \
                          inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* loads Next(3rd) input row, corresponding to 2nd output row */

            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            IVP_LA2NX8_XP(dvecInData21, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            IVP_LA2NX8_XP(dvecInData22, vaInData, pdvecIn2, \
                          inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* Arrange input vectors required for Quad multiply*/
            IVP_DSEL2NX8I(dvecInData12, dvecInData11,
                          dvecInData12, dvecInData11, IVP_DSELI_8B_DEINTERLEAVE_1);
            IVP_DSEL2NX8I(dvecInData22, dvecInData21,
                          dvecInData22, dvecInData21, IVP_DSELI_8B_DEINTERLEAVE_1);

            /* load 1st row of coeffs for both output channels */
            IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);
            IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch1);

            /* rearrange the coeff vectors. Separate even and odd coeff
             * so that MUL4T can be used
             */
            IVP_DSEL2NX8I(dvecCoeffData2, dvecCoeffData1,
                          dvecCoeffData2, dvecCoeffData1, IVP_DSELI_8B_DEINTERLEAVE_1);


            /* multiply 1st input row with 1st 8 coeff from 1st output channel*/
            MORPH_OP_MUL4TA(dacc11, 0, dvecInData11, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
            MORPH_OP_MUL4TA(dacc11, 0, dvecInData12, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

            /* multiply 2nd input row with 1st 8 coeff from 1st output channel*/
            MORPH_OP_MUL4TA(dacc12, 0, dvecInData21, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
            MORPH_OP_MUL4TA(dacc12, 0, dvecInData22, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

            /* multiply 1st input row with 1st 8 coeff from 2nd output channel*/
            MORPH_OP_MUL4TA(dacc21, 0, dvecInData11, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 8));
            MORPH_OP_MUL4TA(dacc21, 0, dvecInData12, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 8));

            /* multiply 2nd input row with 1st 8 coeff from 2nd output channel*/
            MORPH_OP_MUL4TA(dacc22, 0, dvecInData21, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 8));
            MORPH_OP_MUL4TA(dacc22, 0, dvecInData22, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 8));

            /* right rotate the input vectors
             * in order to multiply with next columns of
             * coeff in the next iteration
             */
            dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);


            /* multiply 1st input row with next 8 coeff from 1st output channel*/
            MORPH_OP_MUL4TA(dacc11, 0, dvecInData11, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
            MORPH_OP_MUL4TA(dacc11, 0, dvecInData12, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));

            /* multiply 2nd input row with next 8 coeff from 1st output channel*/
            MORPH_OP_MUL4TA(dacc12, 0, dvecInData21, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
            MORPH_OP_MUL4TA(dacc12, 0, dvecInData22, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));


            /* multiply 1st input row with next 8 coeff from 2nd output channel*/
            MORPH_OP_MUL4TA(dacc21, 0, dvecInData11, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 9));
            MORPH_OP_MUL4TA(dacc21, 0, dvecInData12, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 9));

            /* multiply 2nd input row with next 8 coeff from 2nd output channel*/
            MORPH_OP_MUL4TA(dacc22, 0, dvecInData21, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 9));
            MORPH_OP_MUL4TA(dacc22, 0, dvecInData22, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 9));
          }   /* for (ky = 0; ky < kSizeY; ky++)*/

          /************************* 3rd inCh *****************************************/
          pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2);
          pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2 + \
                                         stride * inDataPitch1 * enable2Row);

          for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
          {
            /* loads 1st input row */

            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            IVP_LA2NX8_XP(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            IVP_LA2NX8_XP(dvecInData12, vaInData, pdvecIn1, \
                          inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* loads Next(3rd) input row, corresponding to 2nd output row */

            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            IVP_LA2NX8_XP(dvecInData21, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            IVP_LA2NX8_XP(dvecInData22, vaInData, pdvecIn2, \
                          inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* Arrange input vectors required for Quad multiply*/
            IVP_DSEL2NX8I(dvecInData12, dvecInData11,
                          dvecInData12, dvecInData11, IVP_DSELI_8B_DEINTERLEAVE_1);
            IVP_DSEL2NX8I(dvecInData22, dvecInData21,
                          dvecInData22, dvecInData21, IVP_DSELI_8B_DEINTERLEAVE_1);

            /* load 1st row of coeffs for both output channels */
            IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);
            IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch1);

            /* rearrange the coeff vectors. Separate even and odd coeff
             * so that MUL4T can be used
             */
            IVP_DSEL2NX8I(dvecCoeffData2, dvecCoeffData1,
                          dvecCoeffData2, dvecCoeffData1, IVP_DSELI_8B_DEINTERLEAVE_1);


            /* multiply 1st input row with 1st 8 coeff from 1st output channel*/
            MORPH_OP_MUL4TA(dacc11, 0, dvecInData11, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
            MORPH_OP_MUL4TA(dacc11, 0, dvecInData12, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

            /* multiply 2nd input row with 1st 8 coeff from 1st output channel*/
            MORPH_OP_MUL4TA(dacc12, 0, dvecInData21, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
            MORPH_OP_MUL4TA(dacc12, 0, dvecInData22, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

            /* multiply 1st input row with 1st 8 coeff from 2nd output channel*/
            MORPH_OP_MUL4TA(dacc21, 0, dvecInData11, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 8));
            MORPH_OP_MUL4TA(dacc21, 0, dvecInData12, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 8));

            /* multiply 2nd input row with 1st 8 coeff from 2nd output channel*/
            MORPH_OP_MUL4TA(dacc22, 0, dvecInData21, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 8));
            MORPH_OP_MUL4TA(dacc22, 0, dvecInData22, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 8));

            /* right rotate the input vectors
             * in order to multiply with next columns of
             * coeff in the next iteration
             */
            dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
            dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);


            /* multiply 1st input row with next 8 coeff from 1st output channel*/
            MORPH_OP_MUL4TA(dacc11, 0, dvecInData11, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
            MORPH_OP_MUL4TA(dacc11, 0, dvecInData12, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));

            /* multiply 2nd input row with next 8 coeff from 1st output channel*/
            MORPH_OP_MUL4TA(dacc12, 0, dvecInData21, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
            MORPH_OP_MUL4TA(dacc12, 0, dvecInData22, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));


            /* multiply 1st input row with next 8 coeff from 2nd output channel*/
            MORPH_OP_MUL4TA(dacc21, 0, dvecInData11, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 9));
            MORPH_OP_MUL4TA(dacc21, 0, dvecInData12, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 9));

            /* multiply 2nd input row with next 8 coeff from 2nd output channel*/
            MORPH_OP_MUL4TA(dacc22, 0, dvecInData21, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 9));
            MORPH_OP_MUL4TA(dacc22, 0, dvecInData22, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 9));
          }   /* for (ky = 0; ky < kSizeY; ky++)*/

          /* Pack, Output Scale, Output Shift and clamping */
          xb_vec2Nx8 dvecOut11L, dvecOut12L, dvecOut21L, dvecOut22L;
          xb_vec2Nx8 dvecOut11H, dvecOut12H, dvecOut21H, dvecOut22H;
#if DILATED_VQ_CONV == VQ_TRUE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut11L, dvecOut11H, dacc11, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut12L, dvecOut12H, dacc12, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut21L, dvecOut21H, dacc21, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut22L, dvecOut22H, dacc22, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut11L, dvecOut11H, dacc11, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut12L, dvecOut12H, dacc12, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut21L, dvecOut21H, dacc21, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut22L, dvecOut22H, dacc22, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
          /* variable length for output stores */
          varLen = XT_MIN(vectorizationWidth, outW - x);

          /* Storing the first output channel, first row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput);
          valign vaOutData = IVP_ZALIGN();
          IVP_SAV2NX8_XP(dvecOut11L, vaOutData, pdvecOut, bytesPerPixel * varLen);
          IVP_SAV2NX8_XP(dvecOut11H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the first output channel, second row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2Row * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut12L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2Row);
          IVP_SAV2NX8_XP(dvecOut12H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable2Row);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the 2nd output channel, first row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut21L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut21H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the 2nd output channel, 2nd row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                                outDataPitch1 * enable2Row) * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut22L, vaOutData, pdvecOut, bytesPerPixel * \
                         varLen * enable2ndCh * enable2Row);
          IVP_SAV2NX8_XP(dvecOut22H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh * enable2Row);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          pOutput += 2 * outDataPitch2 * bytesPerPixel;
          pCoeff  += 2 * coeffPitch3;
        } /* for (outCh = 0; outCh < numOutCh; outCh += 2)*/
      }   /* for (y = 0; y < outH; y += 2)*/
    }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  }
  else
  {
    /* loop across output channels is unrolled twice
     * to produce two output channels in 1 iteration.
     * Also loop across output height by 2 , thereby
     * producing 4 output vectors simultaneously.
     */
    for (x = 0; x < outW; x += vectorizationWidth)    /* Loop across Output width */
    {
      /* out of bound flag */
      int32_t flag = XT_SALT(2 * XCHAL_IVPN_SIMD_WIDTH, inW - stride * x);

      for (y = 0; y < outH; y += 2)    /* Loop across Output height */
      {
        /* In order to handle odd output height */
        int32_t enable2Row = XT_SALT(y, outH - 1);
        /* initialize output data pointer */
        int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

        /* initialize input data pointer */
        MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * stride * (y) + stride * (x)];

        /* initialize coeff and Bias data pointer */
        int8_t *pCoeff = &pCoeffData[0];
        int32_t *pBias = &pBiasData[0];

        for (outCh = 0; outCh < numOutCh; outCh += 2)   /* Loop across Output depth */
        {
          /* In order to handle odd output depth */
          int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

          xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
          xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

          /* wide vectors(accumulators) initialized with bias */
          xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;

          dacc12 = dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);

          dacc22 = dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc22, hvecBias2, hvecBias2);

          /* priming of coeff load is done outside the innermost loop*/
          pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
          valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

          pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
          valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

          xb_vec2Nx8 dvecCoeffData1;
          xb_vec2Nx8 dvecCoeffData2;

          xb_vec2Nx8 dvecInData11, dvecInData12;
          xb_vec2Nx8 dvecInData21, dvecInData22;
          /****************************** 1st inCh ******************************/
          pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
          pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + stride * inDataPitch1 * enable2Row);

          for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
          {
            /* loads 1st input row */

            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            IVP_LA2NX8_XP(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            IVP_LA2NX8_XP(dvecInData12, vaInData, pdvecIn1, \
                          inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* loads Next(3rd) input row, corresponding to 2nd output row */

            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            IVP_LA2NX8_XP(dvecInData21, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            IVP_LA2NX8_XP(dvecInData22, vaInData, pdvecIn2, \
                          inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* Re-arrange the data in the desired format                                    */
            /* Assume input as 1,2,3,4,5,6,7...127                                          */
            /* After re-arrangement using DSEL operation, updated vectors would be */
            /* dvecInData1 : 1,  3,  5,...121                                              */
            /* dvecInData2 : 2,  4,  6,...122                                              */

            IVP_DSEL2NX8I(dvecInData12, dvecInData11,
                          dvecInData12, dvecInData11, IVP_DSELI_8B_DEINTERLEAVE_1);
            IVP_DSEL2NX8I(dvecInData22, dvecInData21,
                          dvecInData22, dvecInData21, IVP_DSELI_8B_DEINTERLEAVE_1);

            /* load 1st row of coeffs for both output channels */
            IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);
            IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch1);

            /* rearrange the coeff vectors. Separate even and odd coeff
             * so that MUL4T can be used
             */
            IVP_DSEL2NX8I(dvecCoeffData2, dvecCoeffData1,
                          dvecCoeffData2, dvecCoeffData1, IVP_DSELI_8B_DEINTERLEAVE_1);


            /* multiply 1st input row with 1st 8 coeff from 1st output channel*/
            MORPH_OP_MUL4TA(dacc11, 0, dvecInData11, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
            MORPH_OP_MUL4TA(dacc11, 0, dvecInData12, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

            /* multiply 2nd input row with 1st 8 coeff from 1st output channel*/
            MORPH_OP_MUL4TA(dacc12, 0, dvecInData21, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
            MORPH_OP_MUL4TA(dacc12, 0, dvecInData22, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

            /* multiply 1st input row with 1st 8 coeff from 2nd output channel*/
            MORPH_OP_MUL4TA(dacc21, 0, dvecInData11, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 8));
            MORPH_OP_MUL4TA(dacc21, 0, dvecInData12, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 8));

            /* multiply 2nd input row with 1st 8 coeff from 2nd output channel*/
            MORPH_OP_MUL4TA(dacc22, 0, dvecInData21, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 8));
            MORPH_OP_MUL4TA(dacc22, 0, dvecInData22, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 8));
          }   /* for (ky = 0; ky < kSizeY; ky++)*/

          /****************************** 2nd inCh ******************************/
          pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch2);
          pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch2 + \
                                         stride * inDataPitch1 * enable2Row);

          for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
          {
            /* loads 1st input row */

            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            IVP_LA2NX8_XP(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            IVP_LA2NX8_XP(dvecInData12, vaInData, pdvecIn1, \
                          inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* loads Next(3rd) input row, corresponding to 2nd output row */

            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            IVP_LA2NX8_XP(dvecInData21, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            IVP_LA2NX8_XP(dvecInData22, vaInData, pdvecIn2, \
                          inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* Arrange input vectors required for Quad multiply*/
            IVP_DSEL2NX8I(dvecInData12, dvecInData11,
                          dvecInData12, dvecInData11, IVP_DSELI_8B_DEINTERLEAVE_1);
            IVP_DSEL2NX8I(dvecInData22, dvecInData21,
                          dvecInData22, dvecInData21, IVP_DSELI_8B_DEINTERLEAVE_1);

            /* load 1st row of coeffs for both output channels */
            IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);
            IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch1);

            /* rearrange the coeff vectors. Separate even and odd coeff
             * so that MUL4T can be used
             */
            IVP_DSEL2NX8I(dvecCoeffData2, dvecCoeffData1,
                          dvecCoeffData2, dvecCoeffData1, IVP_DSELI_8B_DEINTERLEAVE_1);


            /* multiply 1st input row with 1st 8 coeff from 1st output channel*/
            MORPH_OP_MUL4TA(dacc11, 0, dvecInData11, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
            MORPH_OP_MUL4TA(dacc11, 0, dvecInData12, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

            /* multiply 2nd input row with 1st 8 coeff from 1st output channel*/
            MORPH_OP_MUL4TA(dacc12, 0, dvecInData21, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
            MORPH_OP_MUL4TA(dacc12, 0, dvecInData22, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

            /* multiply 1st input row with 1st 8 coeff from 2nd output channel*/
            MORPH_OP_MUL4TA(dacc21, 0, dvecInData11, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 8));
            MORPH_OP_MUL4TA(dacc21, 0, dvecInData12, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 8));

            /* multiply 2nd input row with 1st 8 coeff from 2nd output channel*/
            MORPH_OP_MUL4TA(dacc22, 0, dvecInData21, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 8));
            MORPH_OP_MUL4TA(dacc22, 0, dvecInData22, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 8));
          }   /* for (ky = 0; ky < kSizeY; ky++)*/

          /****************************** 3rd inCh ******************************/
          pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2);
          pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2 + \
                                         stride * inDataPitch1 * enable2Row);

          for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
          {
            /* loads 1st input row */

            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            IVP_LA2NX8_XP(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            IVP_LA2NX8_XP(dvecInData12, vaInData, pdvecIn1, \
                          inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* loads Next(3rd) input row, corresponding to 2nd output row */

            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            IVP_LA2NX8_XP(dvecInData21, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
            IVP_LA2NX8_XP(dvecInData22, vaInData, pdvecIn2, \
                          inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

            /* Arrange input vectors required for Quad multiply*/
            IVP_DSEL2NX8I(dvecInData12, dvecInData11,
                          dvecInData12, dvecInData11, IVP_DSELI_8B_DEINTERLEAVE_1);
            IVP_DSEL2NX8I(dvecInData22, dvecInData21,
                          dvecInData22, dvecInData21, IVP_DSELI_8B_DEINTERLEAVE_1);

            /* load 1st row of coeffs for both output channels */
            IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);
            IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch1);

            /* rearrange the coeff vectors. Separate even and odd coeff
             * so that MUL4T can be used
             */
            IVP_DSEL2NX8I(dvecCoeffData2, dvecCoeffData1,
                          dvecCoeffData2, dvecCoeffData1, IVP_DSELI_8B_DEINTERLEAVE_1);


            /* multiply 1st input row with 1st 8 coeff from 1st output channel*/
            MORPH_OP_MUL4TA(dacc11, 0, dvecInData11, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
            MORPH_OP_MUL4TA(dacc11, 0, dvecInData12, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

            /* multiply 2nd input row with 1st 8 coeff from 1st output channel*/
            MORPH_OP_MUL4TA(dacc12, 0, dvecInData21, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
            MORPH_OP_MUL4TA(dacc12, 0, dvecInData22, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

            /* multiply 1st input row with 1st 8 coeff from 2nd output channel*/
            MORPH_OP_MUL4TA(dacc21, 0, dvecInData11, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 8));
            MORPH_OP_MUL4TA(dacc21, 0, dvecInData12, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 8));

            /* multiply 2nd input row with 1st 8 coeff from 2nd output channel*/
            MORPH_OP_MUL4TA(dacc22, 0, dvecInData21, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 8));
            MORPH_OP_MUL4TA(dacc22, 0, dvecInData22, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 8));
          }   /* for (ky = 0; ky < kSizeY; ky++)*/

          /* Pack, Output Scale, Output Shift and clamping */
          xb_vec2Nx8 dvecOut11L, dvecOut12L, dvecOut21L, dvecOut22L;
          xb_vec2Nx8 dvecOut11H, dvecOut12H, dvecOut21H, dvecOut22H;
#if DILATED_VQ_CONV == VQ_TRUE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut11L, dvecOut11H, dacc11, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut12L, dvecOut12H, dacc12, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut21L, dvecOut21H, dacc21, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut22L, dvecOut22H, dacc22, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut11L, dvecOut11H, dacc11, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut12L, dvecOut12H, dacc12, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut21L, dvecOut21H, dacc21, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut22L, dvecOut22H, dacc22, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
          /* variable length for output stores */
          varLen = XT_MIN(vectorizationWidth, outW - x);

          /* Storing the first output channel, first row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput);
          valign vaOutData = IVP_ZALIGN();
          IVP_SAV2NX8_XP(dvecOut11L, vaOutData, pdvecOut, bytesPerPixel * varLen);
          IVP_SAV2NX8_XP(dvecOut11H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the first output channel, second row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2Row * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut12L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2Row);
          IVP_SAV2NX8_XP(dvecOut12H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable2Row);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the 2nd output channel, first row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut21L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut21H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the 2nd output channel, 2nd row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                                outDataPitch1 * enable2Row) * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut22L, vaOutData, pdvecOut, bytesPerPixel * \
                         varLen * enable2ndCh * enable2Row);
          IVP_SAV2NX8_XP(dvecOut22H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh * enable2Row);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          pOutput += 2 * outDataPitch2 * bytesPerPixel;
          pCoeff  += 2 * coeffPitch3;
        } /* for (outCh = 0; outCh < numOutCh; outCh += 2)*/
      }   /* for (y = 0; y < outH; y += 2)*/
    }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  }
}

/******************************************************************************************
*   xaiConvolved(VQ)3D_S_MxNj2d1I8S8IX_MOW_WHD
*  ***************************************************************************************/
/******************************************************************************/
/* Description : P6 optimized generic implementation for MxN 3D convolution.  */
/*               Based on MORPH pre-processor specifiers, code implementation */
/*               is generated during preprocessing stage. This method can be  */
/*               used to generate MxN 3D dilated convolution function and MxN */
/*               3D VQ dilated convolution function for U8 bit and S8 bit     */
/*               input data with input stride equal to 2                      */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                */
/*               Output scale array, CNN convolution params structure         */
/* Outputs     : XI Error Code                                                */
/* InOuts      : Output Tile                                                  */
/* Assumptions : CoeffData is S8                                              */
/*               biasArray is signed 32b, value not exceeding signed 24b      */
/*               Output scale array is U16                                    */
/*               OutData is S8 / U8 / S16                                     */
/*               Kernel Size is MxNxDxN                                       */
/*               Input and Output are in WHD format                           */
/*               Coeff is in WHDN format                                      */
/******************************************************************************/

/****************** xaiConvolvedVQ3D_S_MxNj2d1_S8S8IX_MOW_WHD ******************/
/****************** xaiConvolvedVQ3D_S_MxNj2d1_U8S8IX_MOW_WHD ******************/
/******************* xaiConvolved3D_S_MxNj2d1_S8S8IX_MOW_WHD *******************/
/******************* xaiConvolved3D_S_MxNj2d1_U8S8IX_MOW_WHD *******************/

XAI_ERR_TYPE MAKE_NAME(MAKE_NAME_VQ(xaiConvolved, 3D_S_MxNj2d1), S8IX_MOW_WHD) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Error Checks */
  XAI_ERROR_CHECKS()
  {
    MORPH_IDT_CHECK(inTile);
    XAI_CHECK_CONV_OUTPUT_TILE3D(outTile);
    XAI_CHECK_TILE4D_S8(coeffTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(outTile);
    XAI_CHECK_TILE4D_IN_DRAM_BOUNDARY(coeffTile);
    XAI_CHECK_POINTER(param);
    XAI_CHECK_ARRAY_S32(biasArray);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(inTile, outTile);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(coeffTile, outTile);
    XAI_CHECK_ERROR(XAI_TILE4D_GET_DIM1(coeffTile) <= 16, XAI_ERR_KSIZE,           \
                    "Kernel width = %d, which should be less than or equal to 16", \
                    XAI_TILE4D_GET_DIM1(coeffTile));
    XAI_CHECK_ERROR(XAI_TILE4D_GET_DIM2(coeffTile) <= 16, XAI_ERR_KSIZE,              \
                    "\nKernel height = %d, which should be less than or equal to 16", \
                    XAI_TILE4D_GET_DIM2(coeffTile));
    XAI_CHECK_DILATION(param, 1);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_DILATIONX(param) == XAI_CNN_CONV_GET_DILATIONY(param),                                             \
                    XAI_ERR_BADARG, "\nDilation along width = %hhu and height = %hhu\nDilation along width and height should be equal", \
                    XAI_CNN_CONV_GET_DILATIONX(param), XAI_CNN_CONV_GET_DILATIONY(param));
    XAI_CHECK_EDGES_MOW_WHD(inTile, coeffTile, param);
    XAI_CHECK_TILE3D_DATA_ORDER(inTile, XAI_WHD);
    XAI_CHECK_TILE3D_DATA_ORDER(outTile, XAI_WHD);
    XAI_CHECK_TILE4D_DATA_ORDER(coeffTile, XAI_WHDN);
    XAI_CHECK_STRIDE(param, 2);
    XAI_CHECK_ERROR((XAI_CNN_CONV_GET_STRIDEX(param) == XAI_CNN_CONV_GET_STRIDEY(param)),                                           \
                    XAI_ERR_BADARG, "\nStride along width = %hhu and height = %hhu\nStride along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_CONSISTENCY_MOW_WHD(inTile, coeffTile, biasArray, outTile, param);
    XAI_CHECK_COEFFTILE_CONTIGUOUS(coeffTile, param);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_ACCUM_SHIFT(param) < 24,                                     \
                    XAI_ERR_NORM, "\nThe accumulator shift = %hhu, value should be less than 24", \
                    XAI_CNN_CONV_GET_ACCUM_SHIFT(param));
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_OUTPUT_SHIFT(param) < 32,                               \
                    XAI_ERR_NORM, "\nThe output shift = %hhu, value should be less than 32", \
                    XAI_CNN_CONV_GET_OUTPUT_SHIFT(param));
    XAI_CHECK_CONV_RELU_LIMITS_IX(param, outTile);
#if DILATED_VQ_CONV == VQ_TRUE
    XAI_CHECK_ARRAY_U16(outputScaleArray);
    XAI_CHECK_ERROR(XAI_ARRAY_GET_WIDTH(outputScaleArray) >= XAI_TILE4D_GET_DIM4(coeffTile),                                                                                          \
                    XAI_ERR_DATASIZE, "\nWidth of Output Scale Array = %d, Number of Kernels = %d\nWidth of Output Scale Array should be greater than or equal to Number of Kernels", \
                    XAI_ARRAY_GET_WIDTH(outputScaleArray), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_ERROR((((uintptr_t) (XAI_ARRAY_GET_DATA_PTR(outputScaleArray)) & \
                      0x1) == 0), XAI_ERR_NORM, "The output scale array is not aligned to 2 byte boundary");
#endif
  }
#if DILATED_VQ_CONV == VQ_FALSE
  if (XAI_CNN_CONV_GET_OUTPUT_SCALE(param) == 0)
  {
    int32_t fillValue;
    int32_t reluFlag = XAI_CNN_CONV_GET_FLAG_RELU(param);
    fillValue = reluFlag ? (CLAMP(0, XAI_CNN_CONV_GET_RELU_MIN(param), XAI_CNN_CONV_GET_RELU_MAX(param))) : 0;
    return(xaiFillTile3D(outTile, fillValue, 0));
  }
#endif

  if (XAI_TILE3D_GET_DIM3(inTile) == 3)
  {
    MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_MxNj2d1), S8IX_MOW_WHD_DEPTH3) MAKE_PARAMS(inTile, coeffTile, biasArray, outTile, param);
    return(XAI_ERROR_STATUS());
  }

  /* Getting parameters from the tile structures */
  const int32_t inW = XAI_TILE3D_GET_DIM1(inTile) + \
                      XAI_TILE3D_GET_DIM1_EDGE1(inTile) + XAI_TILE3D_GET_DIM1_EDGE2(inTile);
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeX = XAI_TILE4D_GET_DIM1(coeffTile);
  const int32_t kSizeY = XAI_TILE4D_GET_DIM2(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t stride        = XAI_CNN_CONV_GET_STRIDE(param);
  const uint8_t leftEdgeFlag  = XAI_CNN_CONV_GET_FLAG_LEFTEDGE(param);
  const uint8_t topEdgeFlag   = XAI_CNN_CONV_GET_FLAG_TOPEDGE(param);

  /* Pitches of Coefficient Data (WHDN) dim3 */
  const int32_t coeffPitch1 = XAI_TILE4D_GET_DIM1_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  uint8_t leftEdge, topEdge;
  if ((kSizeX % 2) != 0)
  {
    leftEdge = kSizeX / 2;
  }
  else
  {
    leftEdge = leftEdgeFlag ? (kSizeX / 2) : ((kSizeX / 2) - 1);
  }

  if ((kSizeY % 2) != 0)
  {
    topEdge = kSizeY / 2;
  }
  else
  {
    topEdge = topEdgeFlag ? (kSizeY / 2) : ((kSizeY / 2) - 1);
  }

  /* Move pointer to the start of the active data (including edge) */
  pInData = &pInData[-(topEdge * inDataPitch1 + leftEdge)];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8* restrict pdvecIn1;
  MORPH_IDT_2Nx8* restrict pdvecIn2;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1, * restrict pdvecCoeff2;

  /* Variable Declarations */
  int32_t inCh, outCh, x, y, ky;
  int32_t varLen;

  /* Number of output elements that can be generated
   * with 2 input vector loads(64 way).*/
  const int32_t vectorizationWidth = (((4 * XCHAL_IVPN_SIMD_WIDTH) - kSizeX) / stride) + 1;

  if (kSizeX > 8)
  {
    /* loop across output channels is unrolled twice
     * to produce two output channels in 1 iteration.
     * Also loop across output height by 2 , thereby
     * producing 4 output vectors simultaneously.
     */
    for (x = 0; x < outW; x += vectorizationWidth)    /* Loop across Output width */
    {
      /* out of bound flag */
      int32_t flag = XT_SALT(2 * XCHAL_IVPN_SIMD_WIDTH, inW - stride * x);

      for (y = 0; y < outH; y += 2)    /* Loop across Output height */
      {
        /* In order to handle odd output height  */
        int32_t enable2Row = XT_SALT(y, outH - 1);

        /* initialize output data pointer */
        int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

        /* initialize input data pointer */
        MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * stride * (y) + stride * (x)];

        /* initialize coeff and Bias data pointer */
        int8_t *pCoeff = &pCoeffData[0];
        int32_t *pBias = &pBiasData[0];

        for (outCh = 0; outCh < numOutCh; outCh += 2)   /* Loop across Output depth */
        {
          /* In order to handle odd output depth  */
          int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

          xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
          xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

          /* wide vectors(accumulators) initialized with bias */
          xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;

          dacc12 = dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);

          dacc22 = dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc22, hvecBias2, hvecBias2);

          /* priming of coeff load is done outside the innermost loop*/
          pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
          valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

          pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
          valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

          for (inCh = 0; inCh < numInCh; inCh++)   /* Loop across input channels */
          {
            xb_vec2Nx8 dvecCoeffData1;
            xb_vec2Nx8 dvecCoeffData2;

            xb_vec2Nx8 dvecInData11, dvecInData12;
            xb_vec2Nx8 dvecInData21, dvecInData22;

            pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2);
            pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2 + \
                                           stride * inDataPitch1 * enable2Row);

            for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
            {
              /* loads 1st input row */

              valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
              IVP_LA2NX8_XP(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
              IVP_LA2NX8_XP(dvecInData12, vaInData, pdvecIn1, \
                            inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

              /* loads Next(3rd) input row, corresponding to 2nd output row */

              vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
              IVP_LA2NX8_XP(dvecInData21, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
              IVP_LA2NX8_XP(dvecInData22, vaInData, pdvecIn2, \
                            inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

              /* Re-arrange the data in the desired format                                    */
              /* Assume input as 1,2,3,4,5,6,7...127                                          */
              /* After re-arrangement using DSEL operation, updated vectors would be */
              /* dvecInData1 : 1,  3,  5,...121                                              */
              /* dvecInData2 : 2,  4,  6,...122                                              */

              IVP_DSEL2NX8I(dvecInData12, dvecInData11,
                            dvecInData12, dvecInData11, IVP_DSELI_8B_DEINTERLEAVE_1);
              IVP_DSEL2NX8I(dvecInData22, dvecInData21,
                            dvecInData22, dvecInData21, IVP_DSELI_8B_DEINTERLEAVE_1);

              /* load 1st row of coeffs for both output channels */
              IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);
              IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch1);

              /* rearrange the coeff vectors. Separate even and odd coeff
               * so that MUL4T can be used
               */
              IVP_DSEL2NX8I(dvecCoeffData2, dvecCoeffData1,
                            dvecCoeffData2, dvecCoeffData1, IVP_DSELI_8B_DEINTERLEAVE_1);


              /* multiply 1st input row with 1st 8 coeff from 1st output channel*/
              MORPH_OP_MUL4TA(dacc11, 0, dvecInData11, IVP_EXTRN_2X32( \
                                IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
              MORPH_OP_MUL4TA(dacc11, 0, dvecInData12, IVP_EXTRN_2X32( \
                                IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

              /* multiply 2nd input row with 1st 8 coeff from 1st output channel*/
              MORPH_OP_MUL4TA(dacc12, 0, dvecInData21, IVP_EXTRN_2X32( \
                                IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
              MORPH_OP_MUL4TA(dacc12, 0, dvecInData22, IVP_EXTRN_2X32( \
                                IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

              /* multiply 1st input row with 1st 8 coeff from 2nd output channel*/
              MORPH_OP_MUL4TA(dacc21, 0, dvecInData11, IVP_EXTRN_2X32( \
                                IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 8));
              MORPH_OP_MUL4TA(dacc21, 0, dvecInData12, IVP_EXTRN_2X32( \
                                IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 8));

              /* multiply 2nd input row with 1st 8 coeff from 2nd output channel*/
              MORPH_OP_MUL4TA(dacc22, 0, dvecInData21, IVP_EXTRN_2X32( \
                                IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 8));
              MORPH_OP_MUL4TA(dacc22, 0, dvecInData22, IVP_EXTRN_2X32( \
                                IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 8));

              /* right rotate the input vectors
               * in order to multiply with next columns of
               * coeff in the next iteration
               */
              dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData21 = IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData22 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData22, IVP_SELI_8B_ROTATE_RIGHT_4);


              /* multiply 1st input row with next 8 coeff from 1st output channel*/
              MORPH_OP_MUL4TA(dacc11, 0, dvecInData11, IVP_EXTRN_2X32( \
                                IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
              MORPH_OP_MUL4TA(dacc11, 0, dvecInData12, IVP_EXTRN_2X32( \
                                IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));

              /* multiply 2nd input row with next 8 coeff from 1st output channel*/
              MORPH_OP_MUL4TA(dacc12, 0, dvecInData21, IVP_EXTRN_2X32( \
                                IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
              MORPH_OP_MUL4TA(dacc12, 0, dvecInData22, IVP_EXTRN_2X32( \
                                IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));


              /* multiply 1st input row with next 8 coeff from 2nd output channel*/
              MORPH_OP_MUL4TA(dacc21, 0, dvecInData11, IVP_EXTRN_2X32( \
                                IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 9));
              MORPH_OP_MUL4TA(dacc21, 0, dvecInData12, IVP_EXTRN_2X32( \
                                IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 9));

              /* multiply 2nd input row with next 8 coeff from 2nd output channel*/
              MORPH_OP_MUL4TA(dacc22, 0, dvecInData21, IVP_EXTRN_2X32( \
                                IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 9));
              MORPH_OP_MUL4TA(dacc22, 0, dvecInData22, IVP_EXTRN_2X32( \
                                IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 9));
            }   /* for (ky = 0; ky < kSizeY; ky++)*/
          }     /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

          /* Pack, Output Scale, Output Shift and clamping */
          xb_vec2Nx8 dvecOut11L, dvecOut12L, dvecOut21L, dvecOut22L;
          xb_vec2Nx8 dvecOut11H, dvecOut12H, dvecOut21H, dvecOut22H;
#if DILATED_VQ_CONV == VQ_TRUE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut11L, dvecOut11H, dacc11, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut12L, dvecOut12H, dacc12, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut21L, dvecOut21H, dacc21, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut22L, dvecOut22H, dacc22, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut11L, dvecOut11H, dacc11, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut12L, dvecOut12H, dacc12, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut21L, dvecOut21H, dacc21, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut22L, dvecOut22H, dacc22, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
          /* variable length for output stores */
          varLen = XT_MIN(vectorizationWidth, outW - x);

          /* Storing the first output channel, first row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput);
          valign vaOutData = IVP_ZALIGN();
          IVP_SAV2NX8_XP(dvecOut11L, vaOutData, pdvecOut, bytesPerPixel * varLen);
          IVP_SAV2NX8_XP(dvecOut11H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the first output channel, second row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2Row * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut12L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2Row);
          IVP_SAV2NX8_XP(dvecOut12H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable2Row);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the 2nd output channel, first row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut21L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut21H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the 2nd output channel, 2nd row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                                outDataPitch1 * enable2Row) * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut22L, vaOutData, pdvecOut, bytesPerPixel * \
                         varLen * enable2ndCh * enable2Row);
          IVP_SAV2NX8_XP(dvecOut22H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh * enable2Row);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          pOutput += 2 * outDataPitch2 * bytesPerPixel;
          pCoeff  += 2 * coeffPitch3;
        } /* for (outCh = 0; outCh < numOutCh; outCh += 2)*/
      }   /* for (y = 0; y < outH; y += 2)*/
    }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  }
  else
  {
    /* loop across output channels is unrolled twice
     * to produce two output channels in 1 iteration.
     * Also loop across output height by 2 , thereby
     * producing 4 output vectors simultaneously.
     */
    for (x = 0; x < outW; x += vectorizationWidth)    /* Loop across Output width */
    {
      /* out of bound flag */
      int32_t flag = XT_SALT(2 * XCHAL_IVPN_SIMD_WIDTH, inW - stride * x);

      for (y = 0; y < outH; y += 2)    /* Loop across Output height */
      {
        /* In order to handle odd output height */
        int32_t enable2Row = XT_SALT(y, outH - 1);
        /* initialize output data pointer */
        int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

        /* initialize input data pointer */
        MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * stride * (y) + stride * (x)];

        /* initialize coeff and Bias data pointer */
        int8_t *pCoeff = &pCoeffData[0];
        int32_t *pBias = &pBiasData[0];

        for (outCh = 0; outCh < numOutCh; outCh += 2)   /* Loop across Output depth */
        {
          /* In order to handle odd output depth */
          int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

          xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
          xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

          /* wide vectors(accumulators) initialized with bias */
          xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;

          dacc12 = dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);

          dacc22 = dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc22, hvecBias2, hvecBias2);

          /* priming of coeff load is done outside the innermost loop*/
          pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
          valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

          pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
          valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

          for (inCh = 0; inCh < numInCh; inCh++)   /* Loop across input channels */
          {
            xb_vec2Nx8 dvecCoeffData1;
            xb_vec2Nx8 dvecCoeffData2;

            xb_vec2Nx8 dvecInData11, dvecInData12;
            xb_vec2Nx8 dvecInData21, dvecInData22;

            pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2);
            pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2 + \
                                           stride * inDataPitch1 * enable2Row);

            for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
            {
              /* loads 1st input row */

              valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
              IVP_LA2NX8_XP(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
              IVP_LA2NX8_XP(dvecInData12, vaInData, pdvecIn1, \
                            inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

              /* loads Next(3rd) input row, corresponding to 2nd output row */

              vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
              IVP_LA2NX8_XP(dvecInData21, vaInData, pdvecIn2, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
              IVP_LA2NX8_XP(dvecInData22, vaInData, pdvecIn2, \
                            inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

              /* Re-arrange the data in the desired format                                    */
              /* Assume input as 1,2,3,4,5,6,7...127                                          */
              /* After re-arrangement using DSEL operation, updated vectors would be */
              /* dvecInData1 : 1,  3,  5,...121                                              */
              /* dvecInData2 : 2,  4,  6,...122                                              */

              IVP_DSEL2NX8I(dvecInData12, dvecInData11,
                            dvecInData12, dvecInData11, IVP_DSELI_8B_DEINTERLEAVE_1);
              IVP_DSEL2NX8I(dvecInData22, dvecInData21,
                            dvecInData22, dvecInData21, IVP_DSELI_8B_DEINTERLEAVE_1);

              /* load 1st row of coeffs for both output channels */
              IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);
              IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch1);

              /* rearrange the coeff vectors. Separate even and odd coeff
               * so that MUL4T can be used
               */
              IVP_DSEL2NX8I(dvecCoeffData2, dvecCoeffData1,
                            dvecCoeffData2, dvecCoeffData1, IVP_DSELI_8B_DEINTERLEAVE_1);


              /* multiply 1st input row with 1st 8 coeff from 1st output channel*/
              MORPH_OP_MUL4TA(dacc11, 0, dvecInData11, IVP_EXTRN_2X32( \
                                IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
              MORPH_OP_MUL4TA(dacc11, 0, dvecInData12, IVP_EXTRN_2X32( \
                                IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

              /* multiply 2nd input row with 1st 8 coeff from 1st output channel*/
              MORPH_OP_MUL4TA(dacc12, 0, dvecInData21, IVP_EXTRN_2X32( \
                                IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
              MORPH_OP_MUL4TA(dacc12, 0, dvecInData22, IVP_EXTRN_2X32( \
                                IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

              /* multiply 1st input row with 1st 8 coeff from 2nd output channel*/
              MORPH_OP_MUL4TA(dacc21, 0, dvecInData11, IVP_EXTRN_2X32( \
                                IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 8));
              MORPH_OP_MUL4TA(dacc21, 0, dvecInData12, IVP_EXTRN_2X32( \
                                IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 8));

              /* multiply 2nd input row with 1st 8 coeff from 2nd output channel*/
              MORPH_OP_MUL4TA(dacc22, 0, dvecInData21, IVP_EXTRN_2X32( \
                                IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 8));
              MORPH_OP_MUL4TA(dacc22, 0, dvecInData22, IVP_EXTRN_2X32( \
                                IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 8));
            }   /* for (ky = 0; ky < kSizeY; ky++)*/
          }     /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

          /* Pack, Output Scale, Output Shift and clamping */
          xb_vec2Nx8 dvecOut11L, dvecOut12L, dvecOut21L, dvecOut22L;
          xb_vec2Nx8 dvecOut11H, dvecOut12H, dvecOut21H, dvecOut22H;
#if DILATED_VQ_CONV == VQ_TRUE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut11L, dvecOut11H, dacc11, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut12L, dvecOut12H, dacc12, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut21L, dvecOut21H, dacc21, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut22L, dvecOut22H, dacc22, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut11L, dvecOut11H, dacc11, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut12L, dvecOut12H, dacc12, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut21L, dvecOut21H, dacc21, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut22L, dvecOut22H, dacc22, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
          /* variable length for output stores */
          varLen = XT_MIN(vectorizationWidth, outW - x);

          /* Storing the first output channel, first row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput);
          valign vaOutData = IVP_ZALIGN();
          IVP_SAV2NX8_XP(dvecOut11L, vaOutData, pdvecOut, bytesPerPixel * varLen);
          IVP_SAV2NX8_XP(dvecOut11H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the first output channel, second row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2Row * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut12L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2Row);
          IVP_SAV2NX8_XP(dvecOut12H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable2Row);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the 2nd output channel, first row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut21L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut21H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the 2nd output channel, 2nd row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                                outDataPitch1 * enable2Row) * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut22L, vaOutData, pdvecOut, bytesPerPixel * \
                         varLen * enable2ndCh * enable2Row);
          IVP_SAV2NX8_XP(dvecOut22H, vaOutData, pdvecOut, typeFlag * \
                         2 * (varLen - XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh * enable2Row);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          pOutput += 2 * outDataPitch2 * bytesPerPixel;
          pCoeff  += 2 * coeffPitch3;
        } /* for (outCh = 0; outCh < numOutCh; outCh += 2)*/
      }   /* for (y = 0; y < outH; y += 2)*/
    }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  }
  return(XAI_ERROR_STATUS());
}

/******************************************************************************************
* MxN MOW WHD Stride 4 - DEPTH 3                                                          *
* If number of input channels is equal to 3                                               *
* this function is called.                                                                *
******************************************************************************************/

static _XAI_INLINE_ void MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_MxNj4d1), S8IX_MOW_WHD_DEPTH3) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeX = XAI_TILE4D_GET_DIM1(coeffTile);
  const int32_t kSizeY = XAI_TILE4D_GET_DIM2(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t stride        = XAI_CNN_CONV_GET_STRIDE(param);
  const uint8_t leftEdgeFlag  = XAI_CNN_CONV_GET_FLAG_LEFTEDGE(param);
  const uint8_t topEdgeFlag   = XAI_CNN_CONV_GET_FLAG_TOPEDGE(param);

  /* Pitches of Coefficient Data (WHDN) dim3 */
  const int32_t coeffPitch1 = XAI_TILE4D_GET_DIM1_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  uint8_t leftEdge, topEdge;
  if ((kSizeX % 2) != 0)
  {
    leftEdge = kSizeX / 2;
  }
  else
  {
    leftEdge = leftEdgeFlag ? (kSizeX / 2) : ((kSizeX / 2) - 1);
  }

  if ((kSizeY % 2) != 0)
  {
    topEdge = kSizeY / 2;
  }
  else
  {
    topEdge = topEdgeFlag ? (kSizeY / 2) : ((kSizeY / 2) - 1);
  }

  /* Move pointer to the start of the active data (including edge) */
  pInData = &pInData[-(topEdge * inDataPitch1 + leftEdge)];


  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 *restrict pdvecIn1;
  MORPH_IDT_2Nx8 *restrict pdvecIn2;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1, * restrict pdvecCoeff2, \
  * restrict pdvecCoeff3, * restrict pdvecCoeff4;

  /* Variable Declarations */
  int32_t outCh, x, y, ky;
  int32_t varLen;

  /* Number of output elements that can be generated
   * with 2 input vector loads(64 way).*/
  const int32_t vectorizationWidth = (((4 * XCHAL_IVPN_SIMD_WIDTH) - kSizeX) / stride) + 1;

  /* Vearable count to handle the last iteration
   * of X loop seprately if only 1 i/p load is
   * sufficient
   */
  const int32_t remX = (((2 * XCHAL_IVPN_SIMD_WIDTH) - kSizeX) / stride) + 1;

  /* generates the shuffle sequence for the coeff, so that MUL4T can be used.
   * Rearranges coeff from c0,c1,..c13,c14 in the following manner:
   *
   * c0,c4,c8,c12
   * c1,c5,c9,c13
   * c2,c6,c10,c14
   * c3,c7,c11,0
   * */
  xb_vec2Nx8 dvecIdx = IVP_SEQ2NX8();
  xb_vec2Nx8 dvec1, dvec2;
  IVP_DSEL2NX8I(dvec2, dvec1, 0, dvecIdx, IVP_DSELI_8B_DEINTERLEAVE_1);
  IVP_DSEL2NX8I(dvecIdx, dvec1, 0, dvec1, IVP_DSELI_8B_DEINTERLEAVE_1);
  dvec1 = IVP_SEL2NX8I(dvecIdx, dvec1, IVP_SELI_8B_INTERLEAVE_4_LO);
  IVP_DSEL2NX8I(dvecIdx, dvec2, 0, dvec2, IVP_DSELI_8B_DEINTERLEAVE_1);
  dvec2   = IVP_SEL2NX8I(dvecIdx, dvec2, IVP_SELI_8B_INTERLEAVE_4_LO);
  dvecIdx = IVP_SEL2NX8I(dvec2, dvec1, IVP_SELI_8B_INTERLEAVE_4_LO);

  /* loop across output depth is unrolled by 4
   * , producing lanes from 4 output channels
   * in one iteration. Since vectorization width
   * is just half the width of the accumulator,
   * loop across output height is also unrolled by 2.
   * Unrolling across output height makes it possible
   * to utilize all the 64 MACs in the accumulator.
   *
   * Data loaded from the 2 input rows is concatenated
   * in such a manner that lower half of the output
   * vector gives the first output row and the upper
   * half of the */
  for (x = 0; x < outW - remX; x += vectorizationWidth)   /* Loop across Output width */
  {
    for (y = 0; y < outH; y += 2)     /* Loop across Output height */
    {
      /* In order to handle odd height*/
      int32_t enable2ndRow = XT_SALT(y, outH - 1);

      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * stride * y + stride * x];

      /* initialize coeff and Bias data pointer to */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 4)    /* Loop across Output depth */
      {
        /* In order to handle odd depths*/

        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
        int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);
        int32_t enable4thCh = XT_SALT(outCh, numOutCh - 3);

        /* loads and replicate bias data */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
        xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4 * enable4thCh);
        xb_vecN_2x32v hvecBias4; IVP_LSRN_2X32_XP(hvecBias4, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc1, dacc2, dacc3, dacc4;
        dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
        dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
        IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);
        dacc4 = IVP_CVT24UNX32L(hvecBias4, hvecBias4);
        IVP_CVT24UNX32H(dacc4, hvecBias4, hvecBias4);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

        pdvecCoeff3 = (xb_vec2Nx8 *) (pCoeff + 2 * coeffPitch3 * enable3rdCh);
        valign vaCoeffData3; vaCoeffData3 = IVP_LA2NX8_PP(pdvecCoeff3);

        pdvecCoeff4 = (xb_vec2Nx8 *) (pCoeff + 3 * coeffPitch3 * enable4thCh);
        valign vaCoeffData4; vaCoeffData4 = IVP_LA2NX8_PP(pdvecCoeff4);

        /* variable declarations for input and coeff vectors */
        xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2, dvecCoeffData3, dvecCoeffData4;

        MORPH_IDT_2Nx8 dvecInData11, dvecInData12;
        MORPH_IDT_2Nx8 dvecInData21, dvecInData22;

        MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3, dvecData4;
        /************************** 1st inCh **************************/
        pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
        pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + stride * inDataPitch1 * enable2ndRow);

        for (ky = 0; ky < kSizeY; ky++)    /* Loop across kernel height */
        {
          /* loads 1st input row */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8_IP(dvecInData11, vaInData, pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, inDataPitch1 - \
                             2 * XCHAL_IVPN_SIMD_WIDTH);

          /* loads 5th(corresponding to the 2nd output row) input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
          MORPH_OP_LOAD_2Nx8_IP(dvecInData21, vaInData, pdvecIn2);
          MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn2, inDataPitch1 - \
                             2 * XCHAL_IVPN_SIMD_WIDTH);


          /* 32 elements from 1st row and 32 elements from 2nd row are concatenated here
           * If 1st input row is 0,1,2,3,4,5,6,7,8,9,...127, and the 2nd input row is
           * 128,129,130,131.........252,253,254,255, Data should be arranged  as
           *
           * dvecData1 : 0, 4, 8,...120,124,128,132,136,...248,252
           * dvecData2 : 1, 5, 9,...121,125,129,133,137,...249,253
           * dvecData3 : 2, 6,10,...122,126,130,134,138,...250,254
           * dvecData4 : 3, 7,11,...123,127,131,135,139,...251,255
           *
           * Lower half of the vectors contain data from 1st input row and
           * upper half of the vectors contain data from 2nd output row.
           *
           */

          IVP_DSEL2NX8I(dvecData2, dvecData1,
                        IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData4, dvecData3,
                        IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load 1 row of coeff for all the the 4 output channels */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);
          IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch1);
          IVP_LAV2NX8_XP(dvecCoeffData3, vaCoeffData3, pdvecCoeff3, coeffPitch1);
          IVP_LAV2NX8_XP(dvecCoeffData4, vaCoeffData4, pdvecCoeff4, coeffPitch1);

          /* shuffles the coeff in desired manner */
          dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);
          dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecIdx);
          dvecCoeffData3 = IVP_SHFL2NX8(dvecCoeffData3, dvecIdx);
          dvecCoeffData4 = IVP_SHFL2NX8(dvecCoeffData4, dvecIdx);

          /* mulitples coeff c0,c4,c8,c12 with input data */
          MORPH_OP_MUL4TA(dacc1, 0, dvecData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, dvecData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
          MORPH_OP_MUL4TA(dacc3, 0, dvecData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 0));
          MORPH_OP_MUL4TA(dacc4, 0, dvecData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 0));

          /* mulitples coeff c1,c5,c9,c13 with input data */
          MORPH_OP_MUL4TA(dacc1, 0, dvecData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc2, 0, dvecData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
          MORPH_OP_MUL4TA(dacc3, 0, dvecData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 1));
          MORPH_OP_MUL4TA(dacc4, 0, dvecData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 1));

          /* mulitples coeff c2,c6,c10,c14 with input data */
          MORPH_OP_MUL4TA(dacc1, 0, dvecData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
          MORPH_OP_MUL4TA(dacc2, 0, dvecData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
          MORPH_OP_MUL4TA(dacc3, 0, dvecData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 2));
          MORPH_OP_MUL4TA(dacc4, 0, dvecData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 2));

          /* mulitples coeff c3,c7,c11,0 with input data */
          MORPH_OP_MUL4TA(dacc1, 0, dvecData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
          MORPH_OP_MUL4TA(dacc2, 0, dvecData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
          MORPH_OP_MUL4TA(dacc3, 0, dvecData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 3));
          MORPH_OP_MUL4TA(dacc4, 0, dvecData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 3));
        }  /* end of for (ky = 0; ky < kSizeY; ky++)*/

        /************************** 2nd inCh **************************/
        pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch2);
        pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch2 + \
                                       stride * inDataPitch1 * enable2ndRow);

        for (ky = 0; ky < kSizeY; ky++)    /* Loop across kernel height */
        {
          /* loads 1st input row */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8_IP(dvecInData11, vaInData, pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, inDataPitch1 - \
                             2 * XCHAL_IVPN_SIMD_WIDTH);

          /* loads 5th(corresponding to the 2nd output row) input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
          MORPH_OP_LOAD_2Nx8_IP(dvecInData21, vaInData, pdvecIn2);
          MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn2, inDataPitch1 - \
                             2 * XCHAL_IVPN_SIMD_WIDTH);

          /* Arrange input vectors required for Quad multiply*/
          IVP_DSEL2NX8I(dvecData2, dvecData1,
                        IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData4, dvecData3,
                        IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load 1 row of coeff for all the the 4 output channels */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);
          IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch1);
          IVP_LAV2NX8_XP(dvecCoeffData3, vaCoeffData3, pdvecCoeff3, coeffPitch1);
          IVP_LAV2NX8_XP(dvecCoeffData4, vaCoeffData4, pdvecCoeff4, coeffPitch1);

          /* shuffles the coeff in desired manner */
          dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);
          dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecIdx);
          dvecCoeffData3 = IVP_SHFL2NX8(dvecCoeffData3, dvecIdx);
          dvecCoeffData4 = IVP_SHFL2NX8(dvecCoeffData4, dvecIdx);

          /* mulitples coeff c0,c4,c8,c12 with input data */
          MORPH_OP_MUL4TA(dacc1, 0, dvecData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, dvecData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
          MORPH_OP_MUL4TA(dacc3, 0, dvecData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 0));
          MORPH_OP_MUL4TA(dacc4, 0, dvecData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 0));

          /* mulitples coeff c1,c5,c9,c13 with input data */
          MORPH_OP_MUL4TA(dacc1, 0, dvecData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc2, 0, dvecData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
          MORPH_OP_MUL4TA(dacc3, 0, dvecData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 1));
          MORPH_OP_MUL4TA(dacc4, 0, dvecData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 1));

          /* mulitples coeff c2,c6,c10,c14 with input data */
          MORPH_OP_MUL4TA(dacc1, 0, dvecData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
          MORPH_OP_MUL4TA(dacc2, 0, dvecData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
          MORPH_OP_MUL4TA(dacc3, 0, dvecData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 2));
          MORPH_OP_MUL4TA(dacc4, 0, dvecData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 2));

          /* mulitples coeff c3,c7,c11,0 with input data */
          MORPH_OP_MUL4TA(dacc1, 0, dvecData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
          MORPH_OP_MUL4TA(dacc2, 0, dvecData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
          MORPH_OP_MUL4TA(dacc3, 0, dvecData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 3));
          MORPH_OP_MUL4TA(dacc4, 0, dvecData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 3));
        }  /* end of for (ky = 0; ky < kSizeY; ky++)*/

        /************************** 3rd inCh **************************/
        pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2);
        pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2 + \
                                       stride * inDataPitch1 * enable2ndRow);

        for (ky = 0; ky < kSizeY; ky++)    /* Loop across kernel height */
        {
          /* loads 1st input row */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8_IP(dvecInData11, vaInData, pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, inDataPitch1 - \
                             2 * XCHAL_IVPN_SIMD_WIDTH);

          /* loads 5th(corresponding to the 2nd output row) input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
          MORPH_OP_LOAD_2Nx8_IP(dvecInData21, vaInData, pdvecIn2);
          MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn2, inDataPitch1 - \
                             2 * XCHAL_IVPN_SIMD_WIDTH);

          /* Arrange input vectors required for Quad multiply*/
          IVP_DSEL2NX8I(dvecData2, dvecData1,
                        IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData4, dvecData3,
                        IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load 1 row of coeff for all the the 4 output channels */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);
          IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch1);
          IVP_LAV2NX8_XP(dvecCoeffData3, vaCoeffData3, pdvecCoeff3, coeffPitch1);
          IVP_LAV2NX8_XP(dvecCoeffData4, vaCoeffData4, pdvecCoeff4, coeffPitch1);

          /* shuffles the coeff in desired manner */
          dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);
          dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecIdx);
          dvecCoeffData3 = IVP_SHFL2NX8(dvecCoeffData3, dvecIdx);
          dvecCoeffData4 = IVP_SHFL2NX8(dvecCoeffData4, dvecIdx);

          /* mulitples coeff c0,c4,c8,c12 with input data */
          MORPH_OP_MUL4TA(dacc1, 0, dvecData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, dvecData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
          MORPH_OP_MUL4TA(dacc3, 0, dvecData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 0));
          MORPH_OP_MUL4TA(dacc4, 0, dvecData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 0));

          /* mulitples coeff c1,c5,c9,c13 with input data */
          MORPH_OP_MUL4TA(dacc1, 0, dvecData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc2, 0, dvecData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
          MORPH_OP_MUL4TA(dacc3, 0, dvecData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 1));
          MORPH_OP_MUL4TA(dacc4, 0, dvecData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 1));

          /* mulitples coeff c2,c6,c10,c14 with input data */
          MORPH_OP_MUL4TA(dacc1, 0, dvecData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
          MORPH_OP_MUL4TA(dacc2, 0, dvecData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
          MORPH_OP_MUL4TA(dacc3, 0, dvecData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 2));
          MORPH_OP_MUL4TA(dacc4, 0, dvecData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 2));

          /* mulitples coeff c3,c7,c11,0 with input data */
          MORPH_OP_MUL4TA(dacc1, 0, dvecData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
          MORPH_OP_MUL4TA(dacc2, 0, dvecData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
          MORPH_OP_MUL4TA(dacc3, 0, dvecData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 3));
          MORPH_OP_MUL4TA(dacc4, 0, dvecData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 3));
        }  /* end of for (ky = 0; ky < kSizeY; ky++)*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      pOutScaleData[outCh + 2 * enable3rdCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      pOutScaleData[outCh + 3 * enable4thCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* variable store count */
        varLen = XT_MIN(outW - x, vectorizationWidth);

        /* store the first half of the output vectors
         * dvecOut1, dvecOut2, dvecOut3, dvecOut4
         */

        /* Storing the first row outputs, first channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndCh * outDataPitch2 * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 3rd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable3rdCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 4th channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch2 * enable4thCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable4thCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* extract the half of the output vectors
         * dvecOut1, dvecOut2, dvecOut3, dvecOut4
         * and store in the next row
         */

        /* Storing the 2nd row outputs, first channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2ndRow * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut1L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * 2 * varLen * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut2L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable2ndCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable2ndCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 3rd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (2 * outDataPitch2 * enable3rdCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut3L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable3rdCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable3rdCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 4th channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (3 * outDataPitch2 * enable4thCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut4L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable4thCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable4thCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 4 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 4 * coeffPitch3;
      }  /* end of (outCh = 0; outCh < numOutCh; outCh += 4)*/
    }    /* end of for (y = 0; y < outH; y += 2)*/
  }      /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  if (x < outW)
  {
    for (y = 0; y < outH; y += 2)     /* Loop across Output height */
    {
      /* In order to handle odd height*/
      int32_t enable2ndRow = XT_SALT(y, outH - 1);

      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * stride * y + stride * x];

      /* initialize coeff and Bias data pointer to */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 4)    /* Loop across Output depth */
      {
        /* In order to handle odd depths*/
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
        int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);
        int32_t enable4thCh = XT_SALT(outCh, numOutCh - 3);

        /* loads and replicate bias data */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
        xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4 * enable4thCh);
        xb_vecN_2x32v hvecBias4; IVP_LSRN_2X32_XP(hvecBias4, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc1, dacc2, dacc3, dacc4;
        dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
        dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
        IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);
        dacc4 = IVP_CVT24UNX32L(hvecBias4, hvecBias4);
        IVP_CVT24UNX32H(dacc4, hvecBias4, hvecBias4);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

        pdvecCoeff3 = (xb_vec2Nx8 *) (pCoeff + 2 * coeffPitch3 * enable3rdCh);
        valign vaCoeffData3; vaCoeffData3 = IVP_LA2NX8_PP(pdvecCoeff3);

        pdvecCoeff4 = (xb_vec2Nx8 *) (pCoeff + 3 * coeffPitch3 * enable4thCh);
        valign vaCoeffData4; vaCoeffData4 = IVP_LA2NX8_PP(pdvecCoeff4);

        /* variable declarations for input and coeff vectors */
        xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2, dvecCoeffData3, dvecCoeffData4;

        MORPH_IDT_2Nx8 dvecInData11;
        MORPH_IDT_2Nx8 dvecInData21;

        MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3, dvecData4;
        /**************************** 1st inCh ***************************/
        pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput);
        pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + \
                                       stride * inDataPitch1 * enable2ndRow);

        for (ky = 0; ky < kSizeY; ky++)    /* Loop across kernel height */
        {
          /* loads 1st input row */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, inDataPitch1);

          /* loads 5th(corresponding to the 2nd output row) input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
          MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn2, inDataPitch1);


          /* 32 elements from 1st row and 32 elements from 2nd row are concatenated here
           * If 1st input row is 0,1,2,3,4,5,6,7,8,9,...127, and the 2nd input row is
           * 128,129,130,131.........252,253,254,255, Data should be arranged  as
           *
           * dvecData1 : 0, 4, 8,...120,124,128,132,136,...248,252
           * dvecData2 : 1, 5, 9,...121,125,129,133,137,...249,253
           * dvecData3 : 2, 6,10,...122,126,130,134,138,...250,254
           * dvecData4 : 3, 7,11,...123,127,131,135,139,...251,255
           *
           * Lower half of the vectors contain data from 1st input row and
           * upper half of the vectors contain data from 2nd output row.
           *
           */

          IVP_DSEL2NX8I(dvecData2, dvecData1,
                        IVP_SEL2NX8I(dvecInData21, dvecInData21, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_SEL2NX8I(dvecInData11, dvecInData11, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData4, dvecData3,
                        IVP_SEL2NX8I(dvecInData21, dvecInData21, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_SEL2NX8I(dvecInData11, dvecInData11, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load 1 row of coeff for all the the 4 output channels */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);
          IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch1);
          IVP_LAV2NX8_XP(dvecCoeffData3, vaCoeffData3, pdvecCoeff3, coeffPitch1);
          IVP_LAV2NX8_XP(dvecCoeffData4, vaCoeffData4, pdvecCoeff4, coeffPitch1);

          /* shuffles the coeff in desired manner */
          dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);
          dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecIdx);
          dvecCoeffData3 = IVP_SHFL2NX8(dvecCoeffData3, dvecIdx);
          dvecCoeffData4 = IVP_SHFL2NX8(dvecCoeffData4, dvecIdx);

          /* mulitples coeff c0,c4,c8,c12 with input data */
          MORPH_OP_MUL4TA(dacc1, 0, dvecData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, dvecData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
          MORPH_OP_MUL4TA(dacc3, 0, dvecData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 0));
          MORPH_OP_MUL4TA(dacc4, 0, dvecData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 0));

          /* mulitples coeff c1,c5,c9,c13 with input data */
          MORPH_OP_MUL4TA(dacc1, 0, dvecData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc2, 0, dvecData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
          MORPH_OP_MUL4TA(dacc3, 0, dvecData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 1));
          MORPH_OP_MUL4TA(dacc4, 0, dvecData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 1));

          /* mulitples coeff c2,c6,c10,c14 with input data */
          MORPH_OP_MUL4TA(dacc1, 0, dvecData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
          MORPH_OP_MUL4TA(dacc2, 0, dvecData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
          MORPH_OP_MUL4TA(dacc3, 0, dvecData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 2));
          MORPH_OP_MUL4TA(dacc4, 0, dvecData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 2));

          /* mulitples coeff c3,c7,c11,0 with input data */
          MORPH_OP_MUL4TA(dacc1, 0, dvecData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
          MORPH_OP_MUL4TA(dacc2, 0, dvecData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
          MORPH_OP_MUL4TA(dacc3, 0, dvecData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 3));
          MORPH_OP_MUL4TA(dacc4, 0, dvecData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 3));
        }  /* end of for (ky = 0; ky < kSizeY; ky++)*/

        /**************************** 2nd inCh ***************************/
        pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch2);
        pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + inDataPitch2 + \
                                       stride * inDataPitch1 * enable2ndRow);

        for (ky = 0; ky < kSizeY; ky++)    /* Loop across kernel height */
        {
          /* loads 1st input row */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, inDataPitch1);

          /* loads 5th(corresponding to the 2nd output row) input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
          MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn2, inDataPitch1);

          /* Arrange input vectors required for Quad multiply*/
          IVP_DSEL2NX8I(dvecData2, dvecData1,
                        IVP_SEL2NX8I(dvecInData21, dvecInData21, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_SEL2NX8I(dvecInData11, dvecInData11, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData4, dvecData3,
                        IVP_SEL2NX8I(dvecInData21, dvecInData21, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_SEL2NX8I(dvecInData11, dvecInData11, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load 1 row of coeff for all the the 4 output channels */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);
          IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch1);
          IVP_LAV2NX8_XP(dvecCoeffData3, vaCoeffData3, pdvecCoeff3, coeffPitch1);
          IVP_LAV2NX8_XP(dvecCoeffData4, vaCoeffData4, pdvecCoeff4, coeffPitch1);

          /* shuffles the coeff in desired manner */
          dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);
          dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecIdx);
          dvecCoeffData3 = IVP_SHFL2NX8(dvecCoeffData3, dvecIdx);
          dvecCoeffData4 = IVP_SHFL2NX8(dvecCoeffData4, dvecIdx);

          /* mulitples coeff c0,c4,c8,c12 with input data */
          MORPH_OP_MUL4TA(dacc1, 0, dvecData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, dvecData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
          MORPH_OP_MUL4TA(dacc3, 0, dvecData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 0));
          MORPH_OP_MUL4TA(dacc4, 0, dvecData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 0));

          /* mulitples coeff c1,c5,c9,c13 with input data */
          MORPH_OP_MUL4TA(dacc1, 0, dvecData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc2, 0, dvecData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
          MORPH_OP_MUL4TA(dacc3, 0, dvecData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 1));
          MORPH_OP_MUL4TA(dacc4, 0, dvecData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 1));

          /* mulitples coeff c2,c6,c10,c14 with input data */
          MORPH_OP_MUL4TA(dacc1, 0, dvecData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
          MORPH_OP_MUL4TA(dacc2, 0, dvecData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
          MORPH_OP_MUL4TA(dacc3, 0, dvecData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 2));
          MORPH_OP_MUL4TA(dacc4, 0, dvecData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 2));

          /* mulitples coeff c3,c7,c11,0 with input data */
          MORPH_OP_MUL4TA(dacc1, 0, dvecData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
          MORPH_OP_MUL4TA(dacc2, 0, dvecData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
          MORPH_OP_MUL4TA(dacc3, 0, dvecData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 3));
          MORPH_OP_MUL4TA(dacc4, 0, dvecData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 3));
        }  /* end of for (ky = 0; ky < kSizeY; ky++)*/

        /**************************** 3rd inCh ***************************/
        pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2);
        pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + 2 * inDataPitch2 + \
                                       stride * inDataPitch1 * enable2ndRow);

        for (ky = 0; ky < kSizeY; ky++)    /* Loop across kernel height */
        {
          /* loads 1st input row */
          valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
          MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, inDataPitch1);

          /* loads 5th(corresponding to the 2nd output row) input row */
          vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
          MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn2, inDataPitch1);

          /* Arrange input vectors required for Quad multiply*/
          IVP_DSEL2NX8I(dvecData2, dvecData1,
                        IVP_SEL2NX8I(dvecInData21, dvecInData21, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_SEL2NX8I(dvecInData11, dvecInData11, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                        IVP_DSELI_8B_DEINTERLEAVE_1);
          IVP_DSEL2NX8I(dvecData4, dvecData3,
                        IVP_SEL2NX8I(dvecInData21, dvecInData21, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_SEL2NX8I(dvecInData11, dvecInData11, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                        IVP_DSELI_8B_DEINTERLEAVE_1);

          /* load 1 row of coeff for all the the 4 output channels */
          IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);
          IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch1);
          IVP_LAV2NX8_XP(dvecCoeffData3, vaCoeffData3, pdvecCoeff3, coeffPitch1);
          IVP_LAV2NX8_XP(dvecCoeffData4, vaCoeffData4, pdvecCoeff4, coeffPitch1);

          /* shuffles the coeff in desired manner */
          dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);
          dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecIdx);
          dvecCoeffData3 = IVP_SHFL2NX8(dvecCoeffData3, dvecIdx);
          dvecCoeffData4 = IVP_SHFL2NX8(dvecCoeffData4, dvecIdx);

          /* mulitples coeff c0,c4,c8,c12 with input data */
          MORPH_OP_MUL4TA(dacc1, 0, dvecData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
          MORPH_OP_MUL4TA(dacc2, 0, dvecData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
          MORPH_OP_MUL4TA(dacc3, 0, dvecData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 0));
          MORPH_OP_MUL4TA(dacc4, 0, dvecData1, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 0));

          /* mulitples coeff c1,c5,c9,c13 with input data */
          MORPH_OP_MUL4TA(dacc1, 0, dvecData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
          MORPH_OP_MUL4TA(dacc2, 0, dvecData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
          MORPH_OP_MUL4TA(dacc3, 0, dvecData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 1));
          MORPH_OP_MUL4TA(dacc4, 0, dvecData2, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 1));

          /* mulitples coeff c2,c6,c10,c14 with input data */
          MORPH_OP_MUL4TA(dacc1, 0, dvecData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
          MORPH_OP_MUL4TA(dacc2, 0, dvecData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
          MORPH_OP_MUL4TA(dacc3, 0, dvecData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 2));
          MORPH_OP_MUL4TA(dacc4, 0, dvecData3, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 2));

          /* mulitples coeff c3,c7,c11,0 with input data */
          MORPH_OP_MUL4TA(dacc1, 0, dvecData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
          MORPH_OP_MUL4TA(dacc2, 0, dvecData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
          MORPH_OP_MUL4TA(dacc3, 0, dvecData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 3));
          MORPH_OP_MUL4TA(dacc4, 0, dvecData4, IVP_EXTRN_2X32( \
                            IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 3));
        }  /* end of for (ky = 0; ky < kSizeY; ky++)*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      pOutScaleData[outCh + 2 * enable3rdCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      pOutScaleData[outCh + 3 * enable4thCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* variable store count */
        varLen = XT_MIN(outW - x, vectorizationWidth);

        /* store the first half of the output vectors
         * dvecOut1, dvecOut2, dvecOut3, dvecOut4
         */

        /* Storing the first row outputs, first channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndCh * outDataPitch2 * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 3rd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable3rdCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 4th channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch2 * enable4thCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable4thCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* extract the half of the output vectors
         * dvecOut1, dvecOut2, dvecOut3, dvecOut4
         * and store in the next row
         */

        /* Storing the 2nd row outputs, first channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2ndRow * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut1L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * 2 * varLen * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut2L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable2ndCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable2ndCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 3rd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (2 * outDataPitch2 * enable3rdCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut3L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable3rdCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable3rdCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 4th channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (3 * outDataPitch2 * enable4thCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut4L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable4thCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable4thCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 4 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 4 * coeffPitch3;
      }  /* end of (outCh = 0; outCh < numOutCh; outCh += 4)*/
    }    /* end of for (y = 0; y < outH; y += 2)*/
  }
}

/******************************************************************************************
   convolved3D_S_11x11j4d1_S8S8IX_MOW_WHD
   convolved3D_S_11x11j4d1_U8S8IX_MOW_WHD
   convolvedVQ3D_S_11x11j4d1_S8S8IX_MOW_WHD
   convolvedVQ3D_S_11x11j4d1_U8S8IX_MOW_WHD
* 11x11 MOW WHD Stride 4 dilation -1                                                      *
******************************************************************************************/

static _XAI_INLINE_ void MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_11x11j4d1), S8IX_MOW_WHD) \
  MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t stride        = XAI_CNN_CONV_GET_STRIDE(param);

  /* Pitches of Coefficient Data (WHDN) dim3 */
  const int32_t coeffPitch1 = XAI_TILE4D_GET_DIM1_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeU = XAI_TILE4D_GET_DIM1(coeffTile);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif

  /* Move pointer to the start of the active data (including edge) */
  pInData = &pInData[-((kSizeU / 2) * inDataPitch1 + (kSizeU / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 *restrict pdvecIn1;
  MORPH_IDT_2Nx8 *restrict pdvecIn2;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1, *restrict pdvecCoeff2, \
  * restrict pdvecCoeff3, *restrict pdvecCoeff4;

  /* Variable Declarations */
  int32_t inCh, outCh, x, y, ky;
  int32_t varLen;

  /* variable declarations for input and coeff vectors */
  MORPH_IDT_2Nx8 dvecCoeffData1, dvecCoeffData2, dvecCoeffData3;
  MORPH_IDT_2Nx8 dvecCoeffData4, dvecInData11, dvecInData12;
  MORPH_IDT_2Nx8 dvecInData21, dvecInData22;
  MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3, dvecData4;
  MORPH_IDT_2Nx8 dvecData5, dvecData6, dvecData7, dvecData8;
  MORPH_IDT_2Nx8 dvecData9, dvecData10, dvecData11;

  /* Number of output elements that can be generated
   * with 2 input vector loads(64 way).*/
  const int32_t vectorizationWidth = (((4 * XCHAL_IVPN_SIMD_WIDTH) - kSizeU) / stride) + 1;

  /* Vearable count to handle the last iteration
   * of X loop seprately if only 1 i/p load is
   * sufficient
   */
  const int32_t remX = (((2 * XCHAL_IVPN_SIMD_WIDTH) - kSizeU) / stride) + 1;

  /* loop across output depth is unrolled by 4
   * , producing lanes from 4 output channels
   * in one iteration. Since vectorization width
   * is just half the width of the accumulator,
   * loop across output height is also unrolled by 2.
   * Unrolling across output height makes it possible
   * to utilize all the 64 MACs in the accumulator.
   *
   * Data loaded from the 2 input rows is concatenated
   * in such a manner that lower half of the output
   * vector gives the first output row and the upper
   * half of the */
  for (x = 0; x < outW - remX; x += vectorizationWidth)   /* Loop across Output width */
  {
    for (y = 0; y < outH; y += 2)     /* Loop across Output height */
    {
      /* In order to handle odd height*/
      int32_t enable2ndRow = XT_SALT(y, outH - 1);

      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * stride * y + stride * x];

      /* initialize coeff and Bias data pointer to */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 4)    /* Loop across Output depth */
      {
        /* In order to handle odd depths*/
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
        int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);
        int32_t enable4thCh = XT_SALT(outCh, numOutCh - 3);

        /* loads and replicate bias data */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
        xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4 * enable4thCh);
        xb_vecN_2x32v hvecBias4; IVP_LSRN_2X32_XP(hvecBias4, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc1, dacc2, dacc3, dacc4;
        dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
        dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
        IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);
        dacc4 = IVP_CVT24UNX32L(hvecBias4, hvecBias4);
        IVP_CVT24UNX32H(dacc4, hvecBias4, hvecBias4);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        pdvecCoeff3 = (xb_vec2Nx8 *) (pCoeff + 2 * coeffPitch3 * enable3rdCh);
        pdvecCoeff4 = (xb_vec2Nx8 *) (pCoeff + 3 * coeffPitch3 * enable4thCh);

        for (inCh = 0; inCh < numInCh; inCh++)    /* Loop across input channels */
        {
          pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2);
          pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2 + \
                                         stride * inDataPitch1 * enable2ndRow);

          for (ky = 0; ky < 11; ky++)    /* Loop across kernel height */
          {
            /* loads 1st input row */
            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8_IP(dvecInData11, vaInData, pdvecIn1);
            MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1,
                               inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH);

            /* loads 5th(corresponding to the 2nd output row) input row */
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            MORPH_OP_LOAD_2Nx8_IP(dvecInData21, vaInData, pdvecIn2);
            MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn2,
                               inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH);

            /* 32 elements from 1st row and 32 elements from 2nd row are concatenated here
             * If 1st input row is 0,1,2,3,4,5,6,7,8,9,...127, and the 2nd input row is
             * 128,129,130,131.........252,253,254,255, Data should be arranged  as
             *
             * dvecData1 : 0, 4, 8,...120,124,128,132,136,...248,252
             * dvecData2 : 1, 5, 9,...121,125,129,133,137,...249,253
             * dvecData3 : 2, 6,10,...122,126,130,134,138,...250,254
             * dvecData4 : 3, 7,11,...123,127,131,135,139,...251,255
             *
             * Lower half of the vectors contain data from 1st input row and
             * upper half of the vectors contain data from 2nd output row.
             *
             */
            IVP_DSEL2NX8I(dvecInData12, dvecInData11, dvecInData12, dvecInData11, \
                          IVP_DSELI_8B_DEINTERLEAVE_1);
            IVP_DSEL2NX8I(dvecInData22, dvecInData21, dvecInData22, dvecInData21, \
                          IVP_DSELI_8B_DEINTERLEAVE_1);
            IVP_DSEL2NX8I(dvecData3, dvecData1, dvecInData21, dvecInData11, \
                          IVP_DSELI_8B_DEINTERLEAVE_1);
            IVP_DSEL2NX8I(dvecData4, dvecData2, dvecInData22, dvecInData12, \
                          IVP_DSELI_8B_DEINTERLEAVE_1);

            dvecData5 = IVP_SEL2NX8I(0, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);
            dvecData6 = IVP_SEL2NX8I(0, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);
            dvecData7 = IVP_SEL2NX8I(0, dvecData3, IVP_SELI_8B_ROTATE_RIGHT_1);
            dvecData8 = IVP_SEL2NX8I(0, dvecData4, IVP_SELI_8B_ROTATE_RIGHT_1);

            dvecData9  = IVP_SEL2NX8I(0, dvecData5, IVP_SELI_8B_ROTATE_RIGHT_1);
            dvecData10 = IVP_SEL2NX8I(0, dvecData6, IVP_SELI_8B_ROTATE_RIGHT_1);
            dvecData11 = IVP_SEL2NX8I(0, dvecData7, IVP_SELI_8B_ROTATE_RIGHT_1);

            /* load 1 row of coeff for all the the 4 output channels */
            valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);
            IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

            valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);
            IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch1);

            valign vaCoeffData3; vaCoeffData3 = IVP_LA2NX8_PP(pdvecCoeff3);
            IVP_LAV2NX8_XP(dvecCoeffData3, vaCoeffData3, pdvecCoeff3, coeffPitch1);

            valign vaCoeffData4; vaCoeffData4 = IVP_LA2NX8_PP(pdvecCoeff4);
            IVP_LAV2NX8_XP(dvecCoeffData4, vaCoeffData4, pdvecCoeff4, coeffPitch1);

            /* multiplies data from two rows(Lower and upper half of dvecData)
             * with coeff from 1st output channel and accumulate */

            /* IVP_EXTRVRN_2X32 extracts the required coeff from the
             * coeff vector. In every iteration ky is updated therefore it
             * extracts coeff from the next coeff row in the successive ky
             * iterations. "ky * coeffPitch1 + 4" extracts coeffs next to
             * first four coeff in a row
             */
            MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));

            MORPH_OP_MULQA(dacc1, dvecData8, dvecData7, dvecData6, dvecData5, IVP_EXTRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

            MORPH_OP_MULQA(dacc1, 0, dvecData11, dvecData10, dvecData9, IVP_EXTRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));

            /* multiplies data from two rows(Lower and upper half of dvecData)
             * with coeff from 2nd output channel and accumulate */
            MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

            MORPH_OP_MULQA(dacc2, dvecData8, dvecData7, dvecData6, dvecData5, IVP_EXTRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));

            MORPH_OP_MULQA(dacc2, 0, dvecData11, dvecData10, dvecData9, IVP_EXTRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));

            /* multiplies data from two rows(Lower and upper half of dvecData)
             * with coeff from 3rd output channel and accumulate */
            MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 0));

            MORPH_OP_MULQA(dacc3, dvecData8, dvecData7, dvecData6, dvecData5, IVP_EXTRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 1));

            MORPH_OP_MULQA(dacc3, 0, dvecData11, dvecData10, dvecData9, IVP_EXTRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 2));

            /* multiplies data from two rows(Lower and upper half of dvecData)
             * with coeff from 4th output channel and accumulate */
            MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 0));

            MORPH_OP_MULQA(dacc4, dvecData8, dvecData7, dvecData6, dvecData5, IVP_EXTRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 1));

            MORPH_OP_MULQA(dacc4, 0, dvecData11, dvecData10, dvecData9, IVP_EXTRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 2));
          }  /* end of for (ky = 0; ky < kSizeY; ky++)*/
        }    /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      pOutScaleData[outCh + 2 * enable3rdCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      pOutScaleData[outCh + 3 * enable4thCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* variable store count */
        varLen = XT_MIN(outW - x, vectorizationWidth);

        /* store the first half of the output vectors
         * dvecOut1, dvecOut2, dvecOut3, dvecOut4
         */

        /* Storing the first row outputs, first channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndCh * outDataPitch2 * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 3rd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable3rdCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 4th channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch2 * enable4thCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable4thCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* extract the half of the output vectors
         * dvecOut1, dvecOut2, dvecOut3, dvecOut4
         * and store in the next row
         */

        /* Storing the 2nd row outputs, first channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2ndRow * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut1L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * 2 * varLen * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut2L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable2ndCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable2ndCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 3rd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (2 * outDataPitch2 * enable3rdCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut3L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable3rdCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable3rdCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 4th channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (3 * outDataPitch2 * enable4thCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut4L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable4thCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable4thCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 4 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 4 * coeffPitch3;
      }  /* end of (outCh = 0; outCh < numOutCh; outCh += 4)*/
    }    /* end of for (y = 0; y < outH; y += 2)*/
  }      /* end of for (x = 0; x < outW; x += vectorizationWidth)*/

  if (x < outW)
  {
    for (y = 0; y < outH; y += 2)     /* Loop across Output height */
    {
      /* In order to handle odd height*/
      int32_t enable2ndRow = XT_SALT(y, outH - 1);

      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * stride * y + stride * x];

      /* initialize coeff and Bias data pointer to */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 4)    /* Loop across Output depth */
      {
        /* In order to handle odd depths*/
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
        int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);
        int32_t enable4thCh = XT_SALT(outCh, numOutCh - 3);

        /* loads and replicate bias data */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
        xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4 * enable4thCh);
        xb_vecN_2x32v hvecBias4; IVP_LSRN_2X32_XP(hvecBias4, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc1, dacc2, dacc3, dacc4;
        dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
        dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
        IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);
        dacc4 = IVP_CVT24UNX32L(hvecBias4, hvecBias4);
        IVP_CVT24UNX32H(dacc4, hvecBias4, hvecBias4);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        pdvecCoeff3 = (xb_vec2Nx8 *) (pCoeff + 2 * coeffPitch3 * enable3rdCh);
        pdvecCoeff4 = (xb_vec2Nx8 *) (pCoeff + 3 * coeffPitch3 * enable4thCh);

        for (inCh = 0; inCh < numInCh; inCh++)    /* Loop across input channels */
        {
          pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2);
          pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2 + \
                                         stride * inDataPitch1 * enable2ndRow);

          for (ky = 0; ky < 11; ky++)    /* Loop across kernel height */
          {
            /* loads 1st input row */
            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, inDataPitch1);

            /* loads 5th(corresponding to the 2nd output row) input row */
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn2, inDataPitch1);


            /* 32 elements from 1st row and 32 elements from 2nd row are concatenated here
             * If 1st input row is 0,1,2,3,4,5,6,7,8,9,...63, and the 2nd input row is
             * 64, 65, 66, 67.........124,125,126,127, Data should be arranged  as
             *
             * dvecData1 : 0, 4, 8,...120,124
             * dvecData2 : 1, 5, 9,...121,125
             * dvecData3 : 2, 6,10,...122,126
             * dvecData4 : 3, 7,11,...123,127
             *
             * Lower half of the vectors contain data from 1st input row and
             * upper half of the vectors contain data from 2nd output row.
             *
             */
            IVP_DSEL2NX8I(dvecInData12, dvecInData11, dvecInData11, dvecInData11, \
                          IVP_DSELI_8B_DEINTERLEAVE_1);

            IVP_DSEL2NX8I(dvecInData22, dvecInData21, dvecInData21, dvecInData21, \
                          IVP_DSELI_8B_DEINTERLEAVE_1);

            IVP_DSEL2NX8I(dvecData3, dvecData1, dvecInData21, dvecInData11, \
                          IVP_DSELI_8B_DEINTERLEAVE_1);

            IVP_DSEL2NX8I(dvecData4, dvecData2, dvecInData22, dvecInData12, \
                          IVP_DSELI_8B_DEINTERLEAVE_1);

            dvecData5 = IVP_SEL2NX8I(0, dvecData1, IVP_SELI_8B_ROTATE_RIGHT_1);
            dvecData6 = IVP_SEL2NX8I(0, dvecData2, IVP_SELI_8B_ROTATE_RIGHT_1);
            dvecData7 = IVP_SEL2NX8I(0, dvecData3, IVP_SELI_8B_ROTATE_RIGHT_1);
            dvecData8 = IVP_SEL2NX8I(0, dvecData4, IVP_SELI_8B_ROTATE_RIGHT_1);

            dvecData9  = IVP_SEL2NX8I(0, dvecData5, IVP_SELI_8B_ROTATE_RIGHT_1);
            dvecData10 = IVP_SEL2NX8I(0, dvecData6, IVP_SELI_8B_ROTATE_RIGHT_1);
            dvecData11 = IVP_SEL2NX8I(0, dvecData7, IVP_SELI_8B_ROTATE_RIGHT_1);

            /* load 1 row of coeff for all the the 4 output channels */
            valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);
            IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);

            valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);
            IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch1);

            valign vaCoeffData3; vaCoeffData3 = IVP_LA2NX8_PP(pdvecCoeff3);
            IVP_LAV2NX8_XP(dvecCoeffData3, vaCoeffData3, pdvecCoeff3, coeffPitch1);

            valign vaCoeffData4; vaCoeffData4 = IVP_LA2NX8_PP(pdvecCoeff4);
            IVP_LAV2NX8_XP(dvecCoeffData4, vaCoeffData4, pdvecCoeff4, coeffPitch1);

            /* multiplies data from two rows(Lower and upper half of dvecData)
             * with coeff from 1st output channel and accumulate */

            /* IVP_EXTRVRN_2X32 extracts the required coeff from the
             * coeff vector. In every iteration ky is updated therefore it
             * extracts coeff from the next coeff row in the successive ky
             * iterations. "ky * coeffPitch1 + 4" extracts coeffs next to
             * first four coeff in a row
             */
            MORPH_OP_MULQA(dacc1, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));

            MORPH_OP_MULQA(dacc1, dvecData8, dvecData7, dvecData6, dvecData5, IVP_EXTRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));

            MORPH_OP_MULQA(dacc1, 0, dvecData11, dvecData10, dvecData9, IVP_EXTRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));

            /* multiplies data from two rows(Lower and upper half of dvecData)
             * with coeff from 2nd output channel and accumulate */
            MORPH_OP_MULQA(dacc2, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));

            MORPH_OP_MULQA(dacc2, dvecData8, dvecData7, dvecData6, dvecData5, IVP_EXTRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));

            MORPH_OP_MULQA(dacc2, 0, dvecData11, dvecData10, dvecData9, IVP_EXTRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));

            /* multiplies data from two rows(Lower and upper half of dvecData)
             * with coeff from 3rd output channel and accumulate */
            MORPH_OP_MULQA(dacc3, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 0));

            MORPH_OP_MULQA(dacc3, dvecData8, dvecData7, dvecData6, dvecData5, IVP_EXTRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 1));

            MORPH_OP_MULQA(dacc3, 0, dvecData11, dvecData10, dvecData9, IVP_EXTRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 2));

            /* multiplies data from two rows(Lower and upper half of dvecData)
             * with coeff from 4th output channel and accumulate */
            MORPH_OP_MULQA(dacc4, dvecData4, dvecData3, dvecData2, dvecData1, IVP_EXTRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 0));

            MORPH_OP_MULQA(dacc4, dvecData8, dvecData7, dvecData6, dvecData5, IVP_EXTRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 1));

            MORPH_OP_MULQA(dacc4, 0, dvecData11, dvecData10, dvecData9, IVP_EXTRN_2X32 \
                             (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 2));
          }  /* end of for (ky = 0; ky < kSizeY; ky++)*/
        }      /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      pOutScaleData[outCh + 2 * enable3rdCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      pOutScaleData[outCh + 3 * enable4thCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* variable store count */
        varLen = XT_MIN(outW - x, vectorizationWidth);

        /* store the first half of the output vectors
         * dvecOut1, dvecOut2, dvecOut3, dvecOut4
         */

        /* Storing the first row outputs, first channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndCh * outDataPitch2 * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 3rd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable3rdCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 4th channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch2 * enable4thCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable4thCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* extract the half of the output vectors
         * dvecOut1, dvecOut2, dvecOut3, dvecOut4
         * and store in the next row
         */

        /* Storing the 2nd row outputs, first channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2ndRow * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut1L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * 2 * varLen * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut2L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable2ndCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable2ndCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 3rd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (2 * outDataPitch2 * enable3rdCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut3L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable3rdCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable3rdCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 4th channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (3 * outDataPitch2 * enable4thCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut4L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable4thCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable4thCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 4 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 4 * coeffPitch3;
      }  /* end of (outCh = 0; outCh < numOutCh; outCh += 4)*/
    }    /* end of for (y = 0; y < outH; y += 2)*/
  }
}

/******************************************************************************************
*   xaiConvolved(VQ)3D_S_MxNj4d1I8S8IX_MOW_WHD
*  ***************************************************************************************/

/******************************************************************************/
/* Description : P6 optimized generic implementation for MxN 3D convolution.  */
/*               Based on MORPH pre-processor specifiers, code implementation */
/*               is generated during preprocessing stage. This method can be  */
/*               used to generate MxN 3D dilated convolution function and MxN */
/*               3D VQ dilated convolution function for U8 bit and S8 bit     */
/*               input data with input stride equal to 4                      */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                */
/*               Output scale array, CNN convolution params structure         */
/* Outputs     : XI Error Code                                                */
/* InOuts      : Output Tile                                                  */
/* Assumptions : CoeffData is S8                                              */
/*               biasArray is signed 32b, value not exceeding signed 24b      */
/*               Output scale array is U16                                    */
/*               OutData is S8 / U8 / S16                                     */
/*               Kernel Size is MxNxDxN                                       */
/*               Input and Output are in WHD format                           */
/*               Coeff is in WHDN format                                      */
/******************************************************************************/

/****************** xaiConvolvedVQ3D_S_MxNj4d1_S8S8IX_MOW_WHD ******************/
/****************** xaiConvolvedVQ3D_S_MxNj4d1_U8S8IX_MOW_WHD ******************/
/******************* xaiConvolved3D_S_MxNj4d1_S8S8IX_MOW_WHD *******************/
/******************* xaiConvolved3D_S_MxNj4d1_U8S8IX_MOW_WHD *******************/

XAI_ERR_TYPE MAKE_NAME(MAKE_NAME_VQ(xaiConvolved, 3D_S_MxNj4d1), S8IX_MOW_WHD) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Error Checks */
  XAI_ERROR_CHECKS()
  {
    XAI_CHECK_TILE4D_S8(coeffTile);
    XAI_CHECK_CONV_OUTPUT_TILE3D(outTile);
    MORPH_IDT_CHECK(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(outTile);
    XAI_CHECK_TILE4D_IN_DRAM_BOUNDARY(coeffTile);
    XAI_CHECK_POINTER(param);
    XAI_CHECK_ARRAY_S32(biasArray);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(inTile, outTile);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(coeffTile, outTile);
    XAI_CHECK_ERROR(XAI_TILE4D_GET_DIM1(coeffTile) <= 16, XAI_ERR_KSIZE,           \
                    "kernel width = %d, which should be less than or equal to 16", \
                    XAI_TILE4D_GET_DIM1(coeffTile));
    XAI_CHECK_ERROR(XAI_TILE4D_GET_DIM2(coeffTile) <= 16, XAI_ERR_KSIZE,               \
                    "\nkernel height = %d,  which should be less than or equal to 16", \
                    XAI_TILE4D_GET_DIM2(coeffTile));
    XAI_CHECK_DILATION(param, 1);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_DILATIONX(param) == XAI_CNN_CONV_GET_DILATIONY(param),                                         \
                    XAI_ERR_BADARG, "\nDilation along width = %u and height = %u\nDilation along width and height should be equal", \
                    XAI_CNN_CONV_GET_DILATIONX(param), XAI_CNN_CONV_GET_DILATIONY(param));
    XAI_CHECK_EDGES_MOW_WHD(inTile, coeffTile, param);
    XAI_CHECK_TILE3D_DATA_ORDER(inTile, XAI_WHD);
    XAI_CHECK_TILE3D_DATA_ORDER(outTile, XAI_WHD);
    XAI_CHECK_TILE4D_DATA_ORDER(coeffTile, XAI_WHDN);
    XAI_CHECK_STRIDE(param, 4);
    XAI_CHECK_ERROR((XAI_CNN_CONV_GET_STRIDEX(param) == XAI_CNN_CONV_GET_STRIDEY(param)),                                       \
                    XAI_ERR_BADARG, "\nStride along width = %u and height = %u\nStride along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_CONSISTENCY_MOW_WHD(inTile, coeffTile, biasArray, outTile, param);
    XAI_CHECK_COEFFTILE_CONTIGUOUS(coeffTile, param);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_ACCUM_SHIFT(param) < 24,                                   \
                    XAI_ERR_NORM, "\nThe accumulator shift = %u, value should be less than 24", \
                    XAI_CNN_CONV_GET_ACCUM_SHIFT(param));
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_OUTPUT_SHIFT(param) < 32,                             \
                    XAI_ERR_NORM, "\nThe output shift = %u, value should be less than 32", \
                    XAI_CNN_CONV_GET_OUTPUT_SHIFT(param));
    XAI_CHECK_CONV_RELU_LIMITS_IX(param, outTile);
#if DILATED_VQ_CONV == VQ_TRUE
    XAI_CHECK_ARRAY_U16(outputScaleArray);
    XAI_CHECK_ERROR(XAI_ARRAY_GET_WIDTH(outputScaleArray) >= XAI_TILE4D_GET_DIM4(coeffTile),                                                                                          \
                    XAI_ERR_DATASIZE, "\nWidth of Output Scale Array = %d, Number of Kernels = %d\nWidth of Output Scale Array should be greater than or equal to Number of Kernels", \
                    XAI_ARRAY_GET_WIDTH(outputScaleArray), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_ERROR((((uintptr_t) (XAI_ARRAY_GET_DATA_PTR(outputScaleArray)) & \
                      0x1) == 0), XAI_ERR_NORM, "The output scale array is not aligned to 2 byte boundary");
#endif
  }
#if DILATED_VQ_CONV == VQ_FALSE
  if (XAI_CNN_CONV_GET_OUTPUT_SCALE(param) == 0)
  {
    int32_t fillValue;
    int32_t reluFlag = XAI_CNN_CONV_GET_FLAG_RELU(param);
    fillValue = reluFlag ? (CLAMP(0, XAI_CNN_CONV_GET_RELU_MIN(param), XAI_CNN_CONV_GET_RELU_MAX(param))) : 0;
    return(xaiFillTile3D(outTile, fillValue, 0));
  }
#endif
  if (XAI_TILE4D_GET_DIM1(coeffTile) == 11 && XAI_TILE4D_GET_DIM2(coeffTile) == 11 &&
      XAI_CNN_CONV_GET_STRIDEX(param) == 4)
  {
    MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_11x11j4d1), S8IX_MOW_WHD) MAKE_PARAMS(inTile, coeffTile, biasArray, outTile, param);
    return(XAI_ERROR_STATUS());
  }

  if (XAI_TILE3D_GET_DIM3(inTile) == 3)
  {
    MAKE_NAME(MAKE_NAME_VQ(convolved, 3D_S_MxNj4d1), S8IX_MOW_WHD_DEPTH3) MAKE_PARAMS(inTile, coeffTile, biasArray, outTile, param);
    return(XAI_ERROR_STATUS());
  }


  /* Getting parameters from the tile structures */
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeX = XAI_TILE4D_GET_DIM1(coeffTile);
  const int32_t kSizeY = XAI_TILE4D_GET_DIM2(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t stride        = XAI_CNN_CONV_GET_STRIDE(param);
  const uint8_t leftEdgeFlag  = XAI_CNN_CONV_GET_FLAG_LEFTEDGE(param);
  const uint8_t topEdgeFlag   = XAI_CNN_CONV_GET_FLAG_TOPEDGE(param);

  /* Pitches of Coefficient Data (WHDN) dim3 */
  const int32_t coeffPitch1 = XAI_TILE4D_GET_DIM1_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  uint8_t leftEdge, topEdge;
  if ((kSizeX % 2) != 0)
  {
    leftEdge = kSizeX / 2;
  }
  else
  {
    leftEdge = leftEdgeFlag ? (kSizeX / 2) : ((kSizeX / 2) - 1);
  }

  if ((kSizeY % 2) != 0)
  {
    topEdge = kSizeY / 2;
  }
  else
  {
    topEdge = topEdgeFlag ? (kSizeY / 2) : ((kSizeY / 2) - 1);
  }

  /* Move pointer to the start of the active data (including edge) */
  pInData = &pInData[-(topEdge * inDataPitch1 + leftEdge)];


  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 *restrict pdvecIn1;
  MORPH_IDT_2Nx8 *restrict pdvecIn2;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1, * restrict pdvecCoeff2, \
  * restrict pdvecCoeff3, * restrict pdvecCoeff4;

  /* Variable Declarations */
  int32_t inCh, outCh, x, y, ky;
  int32_t varLen;

  /* Number of output elements that can be generated
   * with 2 input vector loads(64 way).*/
  const int32_t vectorizationWidth = (((4 * XCHAL_IVPN_SIMD_WIDTH) - kSizeX) / stride) + 1;

  /* Vearable count to handle the last iteration
   * of X loop seprately if only 1 i/p load is
   * sufficient
   */
  const int32_t remX = (((2 * XCHAL_IVPN_SIMD_WIDTH) - kSizeX) / stride) + 1;

  /* generates the shuffle sequence for the coeff, so that MUL4T can be used.
   * Rearranges coeff from c0,c1,..c13,c14 in the following manner:
   *
   * c0,c4,c8,c12
   * c1,c5,c9,c13
   * c2,c6,c10,c14
   * c3,c7,c11,0
   * */
  xb_vec2Nx8 dvecIdx = IVP_SEQ2NX8();
  xb_vec2Nx8 dvec1, dvec2;
  IVP_DSEL2NX8I(dvec2, dvec1, 0, dvecIdx, IVP_DSELI_8B_DEINTERLEAVE_1);
  IVP_DSEL2NX8I(dvecIdx, dvec1, 0, dvec1, IVP_DSELI_8B_DEINTERLEAVE_1);
  dvec1 = IVP_SEL2NX8I(dvecIdx, dvec1, IVP_SELI_8B_INTERLEAVE_4_LO);
  IVP_DSEL2NX8I(dvecIdx, dvec2, 0, dvec2, IVP_DSELI_8B_DEINTERLEAVE_1);
  dvec2   = IVP_SEL2NX8I(dvecIdx, dvec2, IVP_SELI_8B_INTERLEAVE_4_LO);
  dvecIdx = IVP_SEL2NX8I(dvec2, dvec1, IVP_SELI_8B_INTERLEAVE_4_LO);

  /* loop across output depth is unrolled by 4
   * , producing lanes from 4 output channels
   * in one iteration. Since vectorization width
   * is just half the width of the accumulator,
   * loop across output height is also unrolled by 2.
   * Unrolling across output height makes it possible
   * to utilize all the 64 MACs in the accumulator.
   *
   * Data loaded from the 2 input rows is concatenated
   * in such a manner that lower half of the output
   * vector gives the first output row and the upper
   * half of the */
  for (x = 0; x < outW - remX; x += vectorizationWidth)   /* Loop across Output width */
  {
    for (y = 0; y < outH; y += 2)     /* Loop across Output height */
    {
      /* In order to handle odd height*/
      int32_t enable2ndRow = XT_SALT(y, outH - 1);

      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * stride * y + stride * x];

      /* initialize coeff and Bias data pointer to */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 4)    /* Loop across Output depth */
      {
        /* In order to handle odd depths*/

        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
        int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);
        int32_t enable4thCh = XT_SALT(outCh, numOutCh - 3);

        /* loads and replicate bias data */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
        xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4 * enable4thCh);
        xb_vecN_2x32v hvecBias4; IVP_LSRN_2X32_XP(hvecBias4, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc1, dacc2, dacc3, dacc4;
        dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
        dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
        IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);
        dacc4 = IVP_CVT24UNX32L(hvecBias4, hvecBias4);
        IVP_CVT24UNX32H(dacc4, hvecBias4, hvecBias4);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

        pdvecCoeff3 = (xb_vec2Nx8 *) (pCoeff + 2 * coeffPitch3 * enable3rdCh);
        valign vaCoeffData3; vaCoeffData3 = IVP_LA2NX8_PP(pdvecCoeff3);

        pdvecCoeff4 = (xb_vec2Nx8 *) (pCoeff + 3 * coeffPitch3 * enable4thCh);
        valign vaCoeffData4; vaCoeffData4 = IVP_LA2NX8_PP(pdvecCoeff4);

        for (inCh = 0; inCh < numInCh; inCh++)    /* Loop across input channels */
        {
          /* variable declarations for input and coeff vectors */
          xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2, dvecCoeffData3, dvecCoeffData4;

          MORPH_IDT_2Nx8 dvecInData11, dvecInData12;
          MORPH_IDT_2Nx8 dvecInData21, dvecInData22;

          MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3, dvecData4;

          pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2);
          pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2 + \
                                         stride * inDataPitch1 * enable2ndRow);

          for (ky = 0; ky < kSizeY; ky++)    /* Loop across kernel height */
          {
            /* loads 1st input row */
            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8_IP(dvecInData11, vaInData, pdvecIn1);
            MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH);

            /* loads 5th(corresponding to the 2nd output row) input row */
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            MORPH_OP_LOAD_2Nx8_IP(dvecInData21, vaInData, pdvecIn2);
            MORPH_OP_LOAD_2Nx8(dvecInData22, vaInData, pdvecIn2, inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH);


            /* 32 elements from 1st row and 32 elements from 2nd row are concatenated here
             * If 1st input row is 0,1,2,3,4,5,6,7,8,9,...127, and the 2nd input row is
             * 128,129,130,131.........252,253,254,255, Data should be arranged  as
             *
             * dvecData1 : 0, 4, 8,...120,124,128,132,136,...248,252
             * dvecData2 : 1, 5, 9,...121,125,129,133,137,...249,253
             * dvecData3 : 2, 6,10,...122,126,130,134,138,...250,254
             * dvecData4 : 3, 7,11,...123,127,131,135,139,...251,255
             *
             * Lower half of the vectors contain data from 1st input row and
             * upper half of the vectors contain data from 2nd output row.
             *
             */

            IVP_DSEL2NX8I(dvecData2, dvecData1,
                          IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                          IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                          IVP_DSELI_8B_DEINTERLEAVE_1);
            IVP_DSEL2NX8I(dvecData4, dvecData3,
                          IVP_SEL2NX8I(dvecInData22, dvecInData21, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                          IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                          IVP_DSELI_8B_DEINTERLEAVE_1);

            /* load 1 row of coeff for all the the 4 output channels */
            IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);
            IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch1);
            IVP_LAV2NX8_XP(dvecCoeffData3, vaCoeffData3, pdvecCoeff3, coeffPitch1);
            IVP_LAV2NX8_XP(dvecCoeffData4, vaCoeffData4, pdvecCoeff4, coeffPitch1);

            /* shuffles the coeff in desired manner */
            dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);
            dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecIdx);
            dvecCoeffData3 = IVP_SHFL2NX8(dvecCoeffData3, dvecIdx);
            dvecCoeffData4 = IVP_SHFL2NX8(dvecCoeffData4, dvecIdx);

            /* mulitples coeff c0,c4,c8,c12 with input data */
            MORPH_OP_MUL4TA(dacc1, 0, dvecData1, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
            MORPH_OP_MUL4TA(dacc2, 0, dvecData1, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
            MORPH_OP_MUL4TA(dacc3, 0, dvecData1, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 0));
            MORPH_OP_MUL4TA(dacc4, 0, dvecData1, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 0));

            /* mulitples coeff c1,c5,c9,c13 with input data */
            MORPH_OP_MUL4TA(dacc1, 0, dvecData2, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
            MORPH_OP_MUL4TA(dacc2, 0, dvecData2, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
            MORPH_OP_MUL4TA(dacc3, 0, dvecData2, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 1));
            MORPH_OP_MUL4TA(dacc4, 0, dvecData2, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 1));

            /* mulitples coeff c2,c6,c10,c14 with input data */
            MORPH_OP_MUL4TA(dacc1, 0, dvecData3, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
            MORPH_OP_MUL4TA(dacc2, 0, dvecData3, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
            MORPH_OP_MUL4TA(dacc3, 0, dvecData3, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 2));
            MORPH_OP_MUL4TA(dacc4, 0, dvecData3, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 2));

            /* mulitples coeff c3,c7,c11,0 with input data */
            MORPH_OP_MUL4TA(dacc1, 0, dvecData4, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
            MORPH_OP_MUL4TA(dacc2, 0, dvecData4, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
            MORPH_OP_MUL4TA(dacc3, 0, dvecData4, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 3));
            MORPH_OP_MUL4TA(dacc4, 0, dvecData4, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 3));
          }  /* end of for (ky = 0; ky < kSizeY; ky++)*/
        }      /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      pOutScaleData[outCh + 2 * enable3rdCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      pOutScaleData[outCh + 3 * enable4thCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* variable store count */
        varLen = XT_MIN(outW - x, vectorizationWidth);

        /* store the first half of the output vectors
         * dvecOut1, dvecOut2, dvecOut3, dvecOut4
         */

        /* Storing the first row outputs, first channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndCh * outDataPitch2 * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 3rd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable3rdCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 4th channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch2 * enable4thCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable4thCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* extract the half of the output vectors
         * dvecOut1, dvecOut2, dvecOut3, dvecOut4
         * and store in the next row
         */

        /* Storing the 2nd row outputs, first channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2ndRow * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut1L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * 2 * varLen * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut2L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable2ndCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable2ndCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 3rd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (2 * outDataPitch2 * enable3rdCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut3L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable3rdCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable3rdCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 4th channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (3 * outDataPitch2 * enable4thCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut4L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable4thCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable4thCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 4 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 4 * coeffPitch3;
      }  /* end of (outCh = 0; outCh < numOutCh; outCh += 4)*/
    }    /* end of for (y = 0; y < outH; y += 2)*/
  }      /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  if (x < outW)
  {
    for (y = 0; y < outH; y += 2)     /* Loop across Output height */
    {
      /* In order to handle odd height*/
      int32_t enable2ndRow = XT_SALT(y, outH - 1);

      /* initialize output data pointer */
      int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

      /* initialize input data pointer */
      MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * stride * y + stride * x];

      /* initialize coeff and Bias data pointer to */
      int8_t *pCoeff = &pCoeffData[0];
      int32_t *pBias = &pBiasData[0];

      for (outCh = 0; outCh < numOutCh; outCh += 4)    /* Loop across Output depth */
      {
        /* In order to handle odd depths*/
        int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);
        int32_t enable3rdCh = XT_SALT(outCh, numOutCh - 2);
        int32_t enable4thCh = XT_SALT(outCh, numOutCh - 3);

        /* loads and replicate bias data */
        xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
        xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4 * enable3rdCh);
        xb_vecN_2x32v hvecBias3; IVP_LSRN_2X32_XP(hvecBias3, pBias, 4 * enable4thCh);
        xb_vecN_2x32v hvecBias4; IVP_LSRN_2X32_XP(hvecBias4, pBias, 4);

        /* wide vectors(accumulators) initialized with bias */
        xb_vec2Nx24 dacc1, dacc2, dacc3, dacc4;
        dacc1 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
        IVP_CVT24UNX32H(dacc1, hvecBias1, hvecBias1);
        dacc2 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
        IVP_CVT24UNX32H(dacc2, hvecBias2, hvecBias2);
        dacc3 = IVP_CVT24UNX32L(hvecBias3, hvecBias3);
        IVP_CVT24UNX32H(dacc3, hvecBias3, hvecBias3);
        dacc4 = IVP_CVT24UNX32L(hvecBias4, hvecBias4);
        IVP_CVT24UNX32H(dacc4, hvecBias4, hvecBias4);

        /* priming of coeff load is done outside the innermost loop*/
        pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
        valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

        pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
        valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

        pdvecCoeff3 = (xb_vec2Nx8 *) (pCoeff + 2 * coeffPitch3 * enable3rdCh);
        valign vaCoeffData3; vaCoeffData3 = IVP_LA2NX8_PP(pdvecCoeff3);

        pdvecCoeff4 = (xb_vec2Nx8 *) (pCoeff + 3 * coeffPitch3 * enable4thCh);
        valign vaCoeffData4; vaCoeffData4 = IVP_LA2NX8_PP(pdvecCoeff4);

        for (inCh = 0; inCh < numInCh; inCh++)    /* Loop across input channels */
        {
          /* variable declarations for input and coeff vectors */
          xb_vec2Nx8 dvecCoeffData1, dvecCoeffData2, dvecCoeffData3, dvecCoeffData4;

          MORPH_IDT_2Nx8 dvecInData11;
          MORPH_IDT_2Nx8 dvecInData21;

          MORPH_IDT_2Nx8 dvecData1, dvecData2, dvecData3, dvecData4;

          pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2);
          pdvecIn2 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2 + \
                                         stride * inDataPitch1 * enable2ndRow);

          for (ky = 0; ky < kSizeY; ky++)    /* Loop across kernel height */
          {
            /* loads 1st input row */
            valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
            MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, inDataPitch1);

            /* loads 5th(corresponding to the 2nd output row) input row */
            vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn2);
            MORPH_OP_LOAD_2Nx8(dvecInData21, vaInData, pdvecIn2, inDataPitch1);


            /* 32 elements from 1st row and 32 elements from 2nd row are concatenated here
             * If 1st input row is 0,1,2,3,4,5,6,7,8,9,...127, and the 2nd input row is
             * 128,129,130,131.........252,253,254,255, Data should be arranged  as
             *
             * dvecData1 : 0, 4, 8,...120,124,128,132,136,...248,252
             * dvecData2 : 1, 5, 9,...121,125,129,133,137,...249,253
             * dvecData3 : 2, 6,10,...122,126,130,134,138,...250,254
             * dvecData4 : 3, 7,11,...123,127,131,135,139,...251,255
             *
             * Lower half of the vectors contain data from 1st input row and
             * upper half of the vectors contain data from 2nd output row.
             *
             */

            IVP_DSEL2NX8I(dvecData2, dvecData1,
                          IVP_SEL2NX8I(dvecInData21, dvecInData21, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                          IVP_SEL2NX8I(dvecInData11, dvecInData11, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_0),
                          IVP_DSELI_8B_DEINTERLEAVE_1);
            IVP_DSEL2NX8I(dvecData4, dvecData3,
                          IVP_SEL2NX8I(dvecInData21, dvecInData21, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                          IVP_SEL2NX8I(dvecInData11, dvecInData11, IVP_SELI_8B_EXTRACT_2_OF_4_OFF_2),
                          IVP_DSELI_8B_DEINTERLEAVE_1);

            /* load 1 row of coeff for all the the 4 output channels */
            IVP_LAV2NX8_XP(dvecCoeffData1, vaCoeffData1, pdvecCoeff1, coeffPitch1);
            IVP_LAV2NX8_XP(dvecCoeffData2, vaCoeffData2, pdvecCoeff2, coeffPitch1);
            IVP_LAV2NX8_XP(dvecCoeffData3, vaCoeffData3, pdvecCoeff3, coeffPitch1);
            IVP_LAV2NX8_XP(dvecCoeffData4, vaCoeffData4, pdvecCoeff4, coeffPitch1);

            /* shuffles the coeff in desired manner */
            dvecCoeffData1 = IVP_SHFL2NX8(dvecCoeffData1, dvecIdx);
            dvecCoeffData2 = IVP_SHFL2NX8(dvecCoeffData2, dvecIdx);
            dvecCoeffData3 = IVP_SHFL2NX8(dvecCoeffData3, dvecIdx);
            dvecCoeffData4 = IVP_SHFL2NX8(dvecCoeffData4, dvecIdx);

            /* mulitples coeff c0,c4,c8,c12 with input data */
            MORPH_OP_MUL4TA(dacc1, 0, dvecData1, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 0));
            MORPH_OP_MUL4TA(dacc2, 0, dvecData1, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 0));
            MORPH_OP_MUL4TA(dacc3, 0, dvecData1, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 0));
            MORPH_OP_MUL4TA(dacc4, 0, dvecData1, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 0));

            /* mulitples coeff c1,c5,c9,c13 with input data */
            MORPH_OP_MUL4TA(dacc1, 0, dvecData2, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 1));
            MORPH_OP_MUL4TA(dacc2, 0, dvecData2, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 1));
            MORPH_OP_MUL4TA(dacc3, 0, dvecData2, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 1));
            MORPH_OP_MUL4TA(dacc4, 0, dvecData2, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 1));

            /* mulitples coeff c2,c6,c10,c14 with input data */
            MORPH_OP_MUL4TA(dacc1, 0, dvecData3, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 2));
            MORPH_OP_MUL4TA(dacc2, 0, dvecData3, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 2));
            MORPH_OP_MUL4TA(dacc3, 0, dvecData3, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 2));
            MORPH_OP_MUL4TA(dacc4, 0, dvecData3, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 2));

            /* mulitples coeff c3,c7,c11,0 with input data */
            MORPH_OP_MUL4TA(dacc1, 0, dvecData4, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData1)), 3));
            MORPH_OP_MUL4TA(dacc2, 0, dvecData4, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData2)), 3));
            MORPH_OP_MUL4TA(dacc3, 0, dvecData4, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData3)), 3));
            MORPH_OP_MUL4TA(dacc4, 0, dvecData4, IVP_EXTRN_2X32( \
                              IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData4)), 3));
          }  /* end of for (ky = 0; ky < kSizeY; ky++)*/
        }      /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

        /* Pack, Output Scale, Output Shift and clamping */
        xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
        xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      pOutScaleData[outCh + 2 * enable3rdCh], outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      pOutScaleData[outCh + 3 * enable4thCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc1, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc2, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc3, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
        PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc4, packShiftAccU, \
                                      outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
        /* variable store count */
        varLen = XT_MIN(outW - x, vectorizationWidth);

        /* store the first half of the output vectors
         * dvecOut1, dvecOut2, dvecOut3, dvecOut4
         */

        /* Storing the first row outputs, first channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput);
        valign vaOutData = IVP_ZALIGN();
        IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + enable2ndCh * outDataPitch2 * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 3rd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 2 * outDataPitch2 * enable3rdCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable3rdCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the first row outputs, 4th channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + 3 * outDataPitch2 * enable4thCh * bytesPerPixel);
        IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable4thCh);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* extract the half of the output vectors
         * dvecOut1, dvecOut2, dvecOut3, dvecOut4
         * and store in the next row
         */

        /* Storing the 2nd row outputs, first channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch1 * enable2ndRow * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut1L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * 2 * varLen * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 2nd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (outDataPitch2 * enable2ndCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut2L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable2ndCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable2ndCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 3rd channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (2 * outDataPitch2 * enable3rdCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut3L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable3rdCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable3rdCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        /* Storing the 2nd row outputs, 4th channel */
        pdvecOut = (xb_vec2Nx8 *) (pOutput + (3 * outDataPitch2 * enable4thCh + \
                                              outDataPitch1 * enable2ndRow) * bytesPerPixel);
        IVP_SAV2NX8_XP(IVP_SHFL2NX8I(dvecOut4L, IVP_SHFLI_8B_SWAP_32), vaOutData, pdvecOut, \
                       (-typeFlag + 1) * varLen * enable4thCh * enable2ndRow);
        IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * 2 * \
                       varLen * enable4thCh * enable2ndRow);
        IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

        pOutput += 4 * outDataPitch2 * bytesPerPixel;
        pCoeff  += 4 * coeffPitch3;
      }  /* end of (outCh = 0; outCh < numOutCh; outCh += 4)*/
    }    /* end of for (y = 0; y < outH; y += 2)*/
  }
  return(XAI_ERROR_STATUS());
}

/******************************************************************************************
*   xaiConvolved(VQ)3D_S_MxNj1d2I8S8IX_MOW_WHD
*  ***************************************************************************************/
/******************************************************************************/
/* Description : P6 optimized generic implementation for MxN 3D convolution   */
/*               with dilation = 2. Based on MORPH pre-processor specifiers,  */
/*               code implementation is generated during preprocessing stage. */
/*               This method can be used to generate MxN 3D dialted           */
/*               convolution function and MxN 3D VQ dialted convolution       */
/*               function for U8 bit and S8 bit input data with input stride  */
/*               equal to 1.                                                  */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                */
/*               Output scale array, CNN convolution params structure         */
/* Outputs     : XI Error Code                                                */
/* InOuts      : Output Tile                                                  */
/* Assumptions : CoeffData is S8                                              */
/*               biasArray is signed 32b, value not exceeding signed 24b      */
/*               Output scale array is U16                                    */
/*               OutData is S8 / U8 / S16                                     */
/*               Kernel Size is MxNxDxN                                       */
/*               Input and Output are in WHD format                           */
/*               Coeff is in WHDN format                                      */
/******************************************************************************/

/****************** xaiConvolvedVQ3D_S_MxNj1d2_S8S8IX_MOW_WHD ******************/
/****************** xaiConvolvedVQ3D_S_MxNj1d2_U8S8IX_MOW_WHD ******************/
/******************* xaiConvolved3D_S_MxNj1d2_S8S8IX_MOW_WHD *******************/
/******************* xaiConvolved3D_S_MxNj1d2_U8S8IX_MOW_WHD *******************/

XAI_ERR_TYPE MAKE_NAME(MAKE_NAME_VQ(xaiConvolved, 3D_S_MxNj1d2), S8IX_MOW_WHD) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Error Checks */
  XAI_ERROR_CHECKS()
  {
    MORPH_IDT_CHECK(inTile);
    XAI_CHECK_CONV_OUTPUT_TILE3D(outTile);
    XAI_CHECK_TILE4D_S8(coeffTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(outTile);
    XAI_CHECK_TILE4D_IN_DRAM_BOUNDARY(coeffTile);
    XAI_CHECK_POINTER(param);
    XAI_CHECK_ARRAY_S32(biasArray);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(inTile, outTile);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(coeffTile, outTile);
    XAI_CHECK_ERROR(XAI_TILE4D_GET_DIM1(coeffTile) <= 16, XAI_ERR_KSIZE,           \
                    "Kernel width = %d, which should be less than or equal to 16", \
                    XAI_TILE4D_GET_DIM1(coeffTile));
    XAI_CHECK_ERROR(XAI_TILE4D_GET_DIM2(coeffTile) <= 16, XAI_ERR_KSIZE,              \
                    "\nKernel height = %d, which should be less than or equal to 16", \
                    XAI_TILE4D_GET_DIM2(coeffTile));
    XAI_CHECK_EDGES_MOW_WHD(inTile, coeffTile, param);
    XAI_CHECK_TILE3D_DATA_ORDER(inTile, XAI_WHD);
    XAI_CHECK_TILE3D_DATA_ORDER(outTile, XAI_WHD);
    XAI_CHECK_TILE4D_DATA_ORDER(coeffTile, XAI_WHDN);
    XAI_CHECK_STRIDE(param, 1);
    XAI_CHECK_ERROR((XAI_CNN_CONV_GET_STRIDEX(param) == XAI_CNN_CONV_GET_STRIDEY(param)),                                           \
                    XAI_ERR_BADARG, "\nStride along width = %hhu and height = %hhu\nStride along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_DILATION(param, 2);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_DILATIONX(param) == XAI_CNN_CONV_GET_DILATIONY(param),                                             \
                    XAI_ERR_BADARG, "\nDilation along width = %hhu and height = %hhu\nDilation along width and height should be equal", \
                    XAI_CNN_CONV_GET_DILATIONX(param), XAI_CNN_CONV_GET_DILATIONY(param));
    XAI_CHECK_CONSISTENCY_MOW_WHD(inTile, coeffTile, biasArray, outTile, param);
    XAI_CHECK_COEFFTILE_CONTIGUOUS(coeffTile, param);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_ACCUM_SHIFT(param) < 24,                                     \
                    XAI_ERR_NORM, "\nThe accumulator shift = %hhu, value should be less than 24", \
                    XAI_CNN_CONV_GET_ACCUM_SHIFT(param));
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_OUTPUT_SHIFT(param) < 32,                               \
                    XAI_ERR_NORM, "\nThe output shift = %hhu, value should be less than 32", \
                    XAI_CNN_CONV_GET_OUTPUT_SHIFT(param));
    XAI_CHECK_CONV_RELU_LIMITS_IX(param, outTile);
#if DILATED_VQ_CONV == VQ_TRUE
    XAI_CHECK_ARRAY_U16(outputScaleArray);
    XAI_CHECK_ERROR(XAI_ARRAY_GET_WIDTH(outputScaleArray) >= XAI_TILE4D_GET_DIM4(coeffTile),                                                                                          \
                    XAI_ERR_DATASIZE, "\nWidth of Output Scale Array = %d, Number of Kernels = %d\nWidth of Output Scale Array should be greater than or equal to Number of Kernels", \
                    XAI_ARRAY_GET_WIDTH(outputScaleArray), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_ERROR((((uintptr_t) (XAI_ARRAY_GET_DATA_PTR(outputScaleArray)) & \
                      0x1) == 0), XAI_ERR_NORM, "The output scale array is not aligned to 2 byte boundary");
#endif
  }
#if DILATED_VQ_CONV == VQ_FALSE
  if (XAI_CNN_CONV_GET_OUTPUT_SCALE(param) == 0)
  {
    int32_t fillValue;
    int32_t reluFlag = XAI_CNN_CONV_GET_FLAG_RELU(param);
    fillValue = reluFlag ? (CLAMP(0, XAI_CNN_CONV_GET_RELU_MIN(param), XAI_CNN_CONV_GET_RELU_MAX(param))) : 0;
    return(xaiFillTile3D(outTile, fillValue, 0));
  }
#endif
  /* Getting parameters from the tile structures */
  const int32_t inW = XAI_TILE3D_GET_DIM1(inTile) + \
                      XAI_TILE3D_GET_DIM1_EDGE1(inTile) + XAI_TILE3D_GET_DIM1_EDGE2(inTile);
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeX = XAI_TILE4D_GET_DIM1(coeffTile);
  const int32_t kSizeY = XAI_TILE4D_GET_DIM2(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t dilationU     = XAI_CNN_CONV_GET_DILATION(param);

  /* Pitches of Coefficient Data (WHDN) */
  const int32_t coeffPitch1 = XAI_TILE4D_GET_DIM1_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Since the dilation value > 1 ,                                      */
  /* Effective Kernel size = dilation(KernelSize - 1) + 1                */
  /* Effective kernel size is used for calculating the min required edge */
  int32_t dilatedKSizeX = dilationU * (kSizeX - 1) + 1;
  int32_t dilatedKSizeY = dilationU * (kSizeY - 1) + 1;

  /* For dilation equal to 2 dilated width and height will always be odd */
  /* Condition check to evaluate left or right alignment of kernel based */
  /* on the edge flag is not required.                                   */

  /* Move pointer to the start of the active data (including edge) */
  pInData = &pInData[-((dilatedKSizeY / 2) * inDataPitch1 + (dilatedKSizeX / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 * restrict pdvecIn1;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1, * restrict pdvecCoeff2;

  /* Generating two select interleave pattern to apply on accumulator values just before storing
   * For 8 bit output
   *     Pattern1 = 0  64 1  65 2  66    ....  31 95
   *     Pattern2 = 32 96 33 97 34 98  ...     63 127
   * For 16 bit output
   *     Pattern1 = 0  1  64 65  2 3  66 67 .... 30 31 94  95
   *     Pattern2 = 32 33 96 97 34 35 98 99  ... 62 63 126 127
   */
  /* 0 1 2 3 .. 62 63*/
  xb_vec2Nx8 dvecPattern1 = IVP_SEQ2NX8();
  /* 64 65 66 67 ...126 127*/
  xb_vec2Nx8 dvecPattern2 = IVP_ADD2NX8(dvecPattern1, 64);

  if (!typeFlag)
  {
    MORPH_OP_DSELI(dvecPattern2, dvecPattern1, \
                   dvecPattern2, dvecPattern1, \
                   IVP_DSELI_8B_INTERLEAVE_1);
  }
  else
  {
    MORPH_OP_DSELI(dvecPattern2, dvecPattern1, \
                   dvecPattern2, dvecPattern1, \
                   IVP_DSELI_INTERLEAVE_1);
  }

  /* Variable Declarations */
  int32_t inCh, outCh, x, y, ky;
  const int32_t vectorizationWidth = 4 * XCHAL_IVPN_SIMD_WIDTH - dilatedKSizeX + 1;
  int32_t varLen;

  /* 4 * XCHAL_IVPN_SIMD_WIDTH bytes of input are loaded at a time
   * into two vectors. Also loop across output channels is unrolled twice,
   * thereby producing four output vectors in 1 iteration.
   *
   * Load 128 input bytes from row corresponding to each ky
   * dvecInData11 = a0 a1 a2 a3.... a63
   * dvecInData12 = a64 a65 a66 .... a127
   *
   * Separate odd and even indices
   * dvecInData11 = a0 a2 a4 a6.... a126
   * dvecInData12 = a1 a3 a5 a7.... a127
   *
   * Let the coefficients be
   * C11 C12 C13 ... C1kW
   * C21 C22 C23 ... C2kW
   *   .
   *   .
   * CkH1 CkH2 CkH3 ... CkHkW
   *
   * acc11 = [a0 a2 a4 a6.... a126] * C11 +
   *         [a2 a4 a6.... a126 X ] * C12 +
   *         [a4 a6.... a126 X  X ] * C13 +
   *                .
   *                .
   *         [                    ] * C1kW
   *
   * acc12 = [a1 a3 a5 a7.... a127] * C11 +
   *         [a3 a5 a7.... a127 X ] * C12 +
   *         [a5 a7.... a127 X  X ] * C13 +
   *                .
   *                .
   *         [                    ] * C1kW
   *
   * Continue the same multiplication steps for ky = 1 to kHeight -1 .
   * acc11 and acc12 contains convolved output corresponding to even and odd indices
   * respectively at the end of inchannel loop iterations.
   *
   * acc11 and acc12 are interleaved to obtain the outputs in correct order.
   *
   */

  if (kSizeX > 12)
  {
    /* 4 * XCHAL_IVPN_SIMD_WIDTH bytes of input are loaded at a time
     * into two vectors. Also loop across output channels is unrolled twice,
     * thereby producing four output vectors in 1 iteration
     */
    for (x = 0; x < outW; x += vectorizationWidth)   /* Loop across Output width */
    {
      /* out of bound flag */
      int32_t flag = XT_SALT(64, inW - x);

      for (y = 0; y < outH; y++)     /* Loop across Output height */
      {
        /* initialize output data pointer */
        int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

        /* initialize input data pointer */
        MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * (y) + (x)];

        /* initialize coeff and bias data pointer*/
        int8_t *pCoeff = &pCoeffData[0];
        int32_t *pBias = &pBiasData[0];

        for (outCh = 0; outCh < numOutCh; outCh += 2)   /* Loop across Output depth */
        {
          /* handles odd output channel */
          int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

          xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
          xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

          /* wide vectors(accumulators) initialized with bias */
          xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;

          dacc12 = dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);

          dacc22 = dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc22, hvecBias2, hvecBias2);

          /* priming of coeff load is done outside the innermost loop*/
          pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
          valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

          pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
          valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

          for (inCh = 0; inCh < numInCh; inCh++)   /* Loop across input channels */
          {
            /* variable declarations for input and coeff vectors */

            xb_vec2Nx8 dvecCoeffData11;
            xb_vec2Nx8 dvecCoeffData21;

            xb_vec2Nx8 dvecInData11, dvecInData12;

            pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2);

            for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
            {
              /* loads 128 bytes of input row */
              valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
              MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
              MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, \
                                 dilationU * inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

              MORPH_OP_DSELI(dvecInData12, dvecInData11, dvecInData12, dvecInData11, \
                             IVP_DSELI_8B_DEINTERLEAVE_1);

              /* load 1 row of coeff for 1st output channel */
              IVP_LAV2NX8_XP(dvecCoeffData11, vaCoeffData1, pdvecCoeff1, coeffPitch1);

              /* load 1 row of coeff for 2nd output channel */
              IVP_LAV2NX8_XP(dvecCoeffData21, vaCoeffData2, pdvecCoeff2, coeffPitch1);

              /* multiples loaded input data with first four coeff */
              MORPH_OP_MUL4TA(dacc11, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                0));
              MORPH_OP_MUL4TA(dacc12, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                0));

              MORPH_OP_MUL4TA(dacc21, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                0));
              MORPH_OP_MUL4TA(dacc22, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                0));

              /* right rotate the input vectors by 4
               * in order to multiply with next column of
               * coeff in the next iteration
               */
              dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);

              /* multiples input data with next four coeffs from the same row */
              MORPH_OP_MUL4TA(dacc11, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                1));
              MORPH_OP_MUL4TA(dacc12, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                1));

              MORPH_OP_MUL4TA(dacc21, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                1));
              MORPH_OP_MUL4TA(dacc22, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                1));

              /* right rotate the input vectors by 4
               * in order to multiply with next column of
               * coeff in the next iteration
               */
              dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);

              /* multiples input data with next four coeffs from the same row */
              MORPH_OP_MUL4TA(dacc11, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                2));
              MORPH_OP_MUL4TA(dacc12, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                2));

              MORPH_OP_MUL4TA(dacc21, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                2));
              MORPH_OP_MUL4TA(dacc22, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                2));

              /* right rotate the input vectors by 4
               * in order to multiply with next column of
               * coeff in the next iteration
               */
              dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);

              /* multiples input data with next four coeffs from the same row */
              MORPH_OP_MUL4TA(dacc11, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                3));
              MORPH_OP_MUL4TA(dacc12, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                3));

              MORPH_OP_MUL4TA(dacc21, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                3));
              MORPH_OP_MUL4TA(dacc22, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                3));
            } /* end of for (ky = 0; ky < kSizeY; ky++)*/
          }   /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

          /* Pack, Output Scale, Output Shift and clamping */
          xb_vec2Nx8 dvec1L, dvec2L, dvec3L, dvec4L;
          xb_vec2Nx8 dvec1H, dvec2H, dvec3H, dvec4H;
#if DILATED_VQ_CONV == VQ_TRUE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec1L, dvec1H, dacc11, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec2L, dvec2H, dacc12, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec3L, dvec3H, dacc21, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec4L, dvec4H, dacc22, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec1L, dvec1H, dacc11, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec2L, dvec2H, dacc12, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec3L, dvec3H, dacc21, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec4L, dvec4H, dacc22, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
          /* Interleave odd and even indices */
          xb_vec2Nx8 dvecOut1L = MORPH_OP_SEL(dvec2L, dvec1L, dvecPattern1);
          xb_vec2Nx8 dvecOut2L = MORPH_OP_SEL(dvec2L, dvec1L, dvecPattern2);
          xb_vec2Nx8 dvecOut1H = MORPH_OP_SEL(dvec2H, dvec1H, dvecPattern1);
          xb_vec2Nx8 dvecOut2H = MORPH_OP_SEL(dvec2H, dvec1H, dvecPattern2);
          xb_vec2Nx8 dvecOut3L = MORPH_OP_SEL(dvec4L, dvec3L, dvecPattern1);
          xb_vec2Nx8 dvecOut4L = MORPH_OP_SEL(dvec4L, dvec3L, dvecPattern2);
          xb_vec2Nx8 dvecOut3H = MORPH_OP_SEL(dvec4H, dvec3H, dvecPattern1);
          xb_vec2Nx8 dvecOut4H = MORPH_OP_SEL(dvec4H, dvec3H, dvecPattern2);

          /* variable store count */
          varLen = XT_MIN(outW - x, vectorizationWidth);

          /* Storing the first output depth, first row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput);
          valign vaOutData = IVP_ZALIGN();
          IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
          IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen - \
                         2 * XCHAL_IVPN_SIMD_WIDTH);
          IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 4 * XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 6 * XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the second output depth, first row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, ((bytesPerPixel * varLen) - \
                                                          2 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 4 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 6 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          pOutput += 2 * outDataPitch2 * bytesPerPixel;
          pCoeff  += 2 * coeffPitch3;
        } /* end of (outCh = 0; outCh < numOutCh; outCh += 2)*/
      }   /* end of for (y = 0; y < outH; y ++)*/
    }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  }
  else if (kSizeX > 8)
  {
    /* 4 * XCHAL_IVPN_SIMD_WIDTH bytes of input are loaded at a time
     * into two vectors. Also loop across output channels is unrolled twice,
     * thereby producing four output vectors in 1 iteration
     */
    for (x = 0; x < outW; x += vectorizationWidth)   /* Loop across Output width */
    {
      /* out of bound flag */
      int32_t flag = XT_SALT(64, inW - x);

      for (y = 0; y < outH; y++)     /* Loop across Output height */
      {
        /* initialize output data pointer */
        int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

        /* initialize input data pointer */
        MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * (y) + (x)];

        /* initialize coeff and bias data pointer*/
        int8_t *pCoeff = &pCoeffData[0];
        int32_t *pBias = &pBiasData[0];

        for (outCh = 0; outCh < numOutCh; outCh += 2)   /* Loop across Output depth */
        {
          /* handles odd output channel*/
          int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

          xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
          xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

          /* wide vectors(accumulators) initialized with bias */
          xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;

          dacc12 = dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);

          dacc22 = dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc22, hvecBias2, hvecBias2);

          /* priming of coeff load is done outside the innermost loop*/
          pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
          valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

          pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
          valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

          for (inCh = 0; inCh < numInCh; inCh++)   /* Loop across input channels */
          {
            /* variable declarations for input and coeff vectors */

            xb_vec2Nx8 dvecCoeffData11;
            xb_vec2Nx8 dvecCoeffData21;

            xb_vec2Nx8 dvecInData11, dvecInData12;

            pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2);

            for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
            {
              /* loads 128 bytes of input row */
              valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
              MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
              MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, \
                                 dilationU * inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

              MORPH_OP_DSELI(dvecInData12, dvecInData11, dvecInData12, dvecInData11, \
                             IVP_DSELI_8B_DEINTERLEAVE_1);

              /* load 1 row of coeff for 1st output channel */
              IVP_LAV2NX8_XP(dvecCoeffData11, vaCoeffData1, pdvecCoeff1, coeffPitch1);

              /* load 1 row of coeff for 2nd output channel */
              IVP_LAV2NX8_XP(dvecCoeffData21, vaCoeffData2, pdvecCoeff2, coeffPitch1);

              /* multiples loaded input data with first four coeff */
              MORPH_OP_MUL4TA(dacc11, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                0));
              MORPH_OP_MUL4TA(dacc12, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                0));

              MORPH_OP_MUL4TA(dacc21, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                0));
              MORPH_OP_MUL4TA(dacc22, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                0));

              /* right rotate the input vectors by 4
               * in order to multiply with next column of
               * coeff in the next iteration
               */
              dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);

              /* multiples input data with next four coeffs from the same row */
              MORPH_OP_MUL4TA(dacc11, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                1));
              MORPH_OP_MUL4TA(dacc12, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                1));

              MORPH_OP_MUL4TA(dacc21, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                1));
              MORPH_OP_MUL4TA(dacc22, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                1));

              /* right rotate the input vectors by 4
               * in order to multiply with next column of
               * coeff in the next iteration
               */
              dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);

              /* multiples input data with next four coeffs from the same row */
              MORPH_OP_MUL4TA(dacc11, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                2));
              MORPH_OP_MUL4TA(dacc12, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                2));

              MORPH_OP_MUL4TA(dacc21, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                2));
              MORPH_OP_MUL4TA(dacc22, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                2));
            } /* end of for (ky = 0; ky < kSizeY; ky++)*/
          }   /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

          /* Pack, Output Scale, Output Shift and clamping */
          xb_vec2Nx8 dvec1L, dvec2L, dvec3L, dvec4L;
          xb_vec2Nx8 dvec1H, dvec2H, dvec3H, dvec4H;
#if DILATED_VQ_CONV == VQ_TRUE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec1L, dvec1H, dacc11, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec2L, dvec2H, dacc12, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec3L, dvec3H, dacc21, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec4L, dvec4H, dacc22, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec1L, dvec1H, dacc11, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec2L, dvec2H, dacc12, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec3L, dvec3H, dacc21, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec4L, dvec4H, dacc22, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
          /* Interleave odd and even indices */
          xb_vec2Nx8 dvecOut1L = MORPH_OP_SEL(dvec2L, dvec1L, dvecPattern1);
          xb_vec2Nx8 dvecOut2L = MORPH_OP_SEL(dvec2L, dvec1L, dvecPattern2);
          xb_vec2Nx8 dvecOut1H = MORPH_OP_SEL(dvec2H, dvec1H, dvecPattern1);
          xb_vec2Nx8 dvecOut2H = MORPH_OP_SEL(dvec2H, dvec1H, dvecPattern2);
          xb_vec2Nx8 dvecOut3L = MORPH_OP_SEL(dvec4L, dvec3L, dvecPattern1);
          xb_vec2Nx8 dvecOut4L = MORPH_OP_SEL(dvec4L, dvec3L, dvecPattern2);
          xb_vec2Nx8 dvecOut3H = MORPH_OP_SEL(dvec4H, dvec3H, dvecPattern1);
          xb_vec2Nx8 dvecOut4H = MORPH_OP_SEL(dvec4H, dvec3H, dvecPattern2);

          /* variable store count */
          varLen = XT_MIN(outW - x, vectorizationWidth);

          /* Storing the first output depth, first row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput);
          valign vaOutData = IVP_ZALIGN();
          IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
          IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen - \
                         2 * XCHAL_IVPN_SIMD_WIDTH);
          IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 4 * XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 6 * XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the second output depth, first row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, ((bytesPerPixel * varLen) - \
                                                          2 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 4 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 6 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          pOutput += 2 * outDataPitch2 * bytesPerPixel;
          pCoeff  += 2 * coeffPitch3;
        } /* end of (outCh = 0; outCh < numOutCh; outCh += 2)*/
      }   /* end of for (y = 0; y < outH; y ++)*/
    }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  }
  else if (kSizeX > 4)
  {
    /* 4 * XCHAL_IVPN_SIMD_WIDTH bytes of input are loaded at a time
     * into two vectors. Also loop across output channels is unrolled twice,
     * thereby producing four output vectors in 1 iteration
     */
    for (x = 0; x < outW; x += vectorizationWidth)   /* Loop across Output width */
    {
      /* out of bound flag */
      int32_t flag = XT_SALT(64, inW - x);

      for (y = 0; y < outH; y++)     /* Loop across Output height */
      {
        /* initialize output data pointer */
        int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

        /* initialize input data pointer */
        MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * (y) + (x)];

        /* initialize coeff and bias data pointer*/
        int8_t *pCoeff = &pCoeffData[0];
        int32_t *pBias = &pBiasData[0];

        for (outCh = 0; outCh < numOutCh; outCh += 2)   /* Loop across Output depth */
        {
          /* handles odd output channel */
          int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

          xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
          xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

          /* wide vectors(accumulators) initialized with bias */
          xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;

          dacc12 = dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);

          dacc22 = dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc22, hvecBias2, hvecBias2);

          /* priming of coeff load is done outside the innermost loop*/
          pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
          valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

          pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
          valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

          for (inCh = 0; inCh < numInCh; inCh++)   /* Loop across input channels */
          {
            /* variable declarations for input and coeff vectors */

            xb_vec2Nx8 dvecCoeffData11;
            xb_vec2Nx8 dvecCoeffData21;

            xb_vec2Nx8 dvecInData11, dvecInData12;

            pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2);

            for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
            {
              /* loads 128 bytes of input row */
              valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
              MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
              MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, \
                                 dilationU * inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

              MORPH_OP_DSELI(dvecInData12, dvecInData11, dvecInData12, dvecInData11, \
                             IVP_DSELI_8B_DEINTERLEAVE_1);

              /* load 1 row of coeff for 1st output channel */
              IVP_LAV2NX8_XP(dvecCoeffData11, vaCoeffData1, pdvecCoeff1, coeffPitch1);

              /* load 1 row of coeff for 2nd output channel */
              IVP_LAV2NX8_XP(dvecCoeffData21, vaCoeffData2, pdvecCoeff2, coeffPitch1);

              /* multiples loaded input data with first four coeff */
              MORPH_OP_MUL4TA(dacc11, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                0));
              MORPH_OP_MUL4TA(dacc12, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                0));

              MORPH_OP_MUL4TA(dacc21, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                0));
              MORPH_OP_MUL4TA(dacc22, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                0));

              /* right rotate the input vectors by 4
               * in order to multiply with next column of
               * coeff in the next iteration
               */
              dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);

              /* multiples input data with next four coeffs from the same row */
              MORPH_OP_MUL4TA(dacc11, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                1));
              MORPH_OP_MUL4TA(dacc12, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                1));

              MORPH_OP_MUL4TA(dacc21, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                1));
              MORPH_OP_MUL4TA(dacc22, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                1));
            } /* end of for (ky = 0; ky < kSizeY; ky++)*/
          }   /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

          /* Pack, Output Scale, Output Shift and clamping */
          xb_vec2Nx8 dvec1L, dvec2L, dvec3L, dvec4L;
          xb_vec2Nx8 dvec1H, dvec2H, dvec3H, dvec4H;
#if DILATED_VQ_CONV == VQ_TRUE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec1L, dvec1H, dacc11, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec2L, dvec2H, dacc12, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec3L, dvec3H, dacc21, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec4L, dvec4H, dacc22, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec1L, dvec1H, dacc11, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec2L, dvec2H, dacc12, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec3L, dvec3H, dacc21, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec4L, dvec4H, dacc22, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
          /* Interleave odd and even indices */
          xb_vec2Nx8 dvecOut1L = MORPH_OP_SEL(dvec2L, dvec1L, dvecPattern1);
          xb_vec2Nx8 dvecOut2L = MORPH_OP_SEL(dvec2L, dvec1L, dvecPattern2);
          xb_vec2Nx8 dvecOut1H = MORPH_OP_SEL(dvec2H, dvec1H, dvecPattern1);
          xb_vec2Nx8 dvecOut2H = MORPH_OP_SEL(dvec2H, dvec1H, dvecPattern2);
          xb_vec2Nx8 dvecOut3L = MORPH_OP_SEL(dvec4L, dvec3L, dvecPattern1);
          xb_vec2Nx8 dvecOut4L = MORPH_OP_SEL(dvec4L, dvec3L, dvecPattern2);
          xb_vec2Nx8 dvecOut3H = MORPH_OP_SEL(dvec4H, dvec3H, dvecPattern1);
          xb_vec2Nx8 dvecOut4H = MORPH_OP_SEL(dvec4H, dvec3H, dvecPattern2);

          /* variable store count */
          varLen = XT_MIN(outW - x, vectorizationWidth);

          /* Storing the first output depth, first row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput);
          valign vaOutData = IVP_ZALIGN();
          IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
          IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen - \
                         2 * XCHAL_IVPN_SIMD_WIDTH);
          IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 4 * XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 6 * XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the second output depth, first row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, ((bytesPerPixel * varLen) - \
                                                          2 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 4 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 6 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          pOutput += 2 * outDataPitch2 * bytesPerPixel;
          pCoeff  += 2 * coeffPitch3;
        } /* end of (outCh = 0; outCh < numOutCh; outCh += 2)*/
      }   /* end of for (y = 0; y < outH; y ++)*/
    }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  }
  else
  {
    /* 4 * XCHAL_IVPN_SIMD_WIDTH bytes of input are loaded at a time
     * into two vectors. Also loop across output channels is unrolled twice,
     * thereby producing four output vectors in 1 iteration
     */

    for (x = 0; x < outW; x += vectorizationWidth)   /* Loop across Output width */
    {
      /* out of bound flag */
      int32_t flag = XT_SALT(64, inW - x);

      for (y = 0; y < outH; y++)     /* Loop across Output height */
      {
        /* initialize output data pointer */
        int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

        /* initialize input data pointer */
        MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * (y) + (x)];

        /* initialize coeff and bias data pointer*/
        int8_t *pCoeff = &pCoeffData[0];
        int32_t *pBias = &pBiasData[0];

        for (outCh = 0; outCh < numOutCh; outCh += 2)   /* Loop across Output depth */
        {
          /* handles odd output channel */
          int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

          xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
          xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);


          /* wide vectors(accumulators) initialized with bias */
          xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;

          dacc12 = dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);

          dacc22 = dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc22, hvecBias2, hvecBias2);

          /* priming of coeff load is done outside the innermost loop*/
          pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
          valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

          pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
          valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);


          for (inCh = 0; inCh < numInCh; inCh++)   /* Loop across input channels */
          {
            /* variable declarations for input and coeff vectors */

            xb_vec2Nx8 dvecCoeffData11;
            xb_vec2Nx8 dvecCoeffData21;

            xb_vec2Nx8 dvecInData11, dvecInData12;

            pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2);

            for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
            {
              /* loads 128 bytes of input row */
              valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
              MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
              MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, \
                                 dilationU * inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

              MORPH_OP_DSELI(dvecInData12, dvecInData11, dvecInData12, dvecInData11, \
                             IVP_DSELI_8B_DEINTERLEAVE_1);

              /* load 1 row of coeff for 1st output channel */
              IVP_LAV2NX8_XP(dvecCoeffData11, vaCoeffData1, pdvecCoeff1, coeffPitch1);

              /* load 1 row of coeff for 2nd output channel */
              IVP_LAV2NX8_XP(dvecCoeffData21, vaCoeffData2, pdvecCoeff2, coeffPitch1);

              /* multiples loaded input data with first four coeff */
              MORPH_OP_MUL4TA(dacc11, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                0));
              MORPH_OP_MUL4TA(dacc12, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                0));

              MORPH_OP_MUL4TA(dacc21, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                0));
              MORPH_OP_MUL4TA(dacc22, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                0));
            } /* end of for (ky = 0; ky < kSizeY; ky++)*/
          }   /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

          /* Pack, Output Scale, Output Shift and clamping */
          xb_vec2Nx8 dvec1L, dvec2L, dvec3L, dvec4L;
          xb_vec2Nx8 dvec1H, dvec2H, dvec3H, dvec4H;
#if DILATED_VQ_CONV == VQ_TRUE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec1L, dvec1H, dacc11, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec2L, dvec2H, dacc12, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec3L, dvec3H, dacc21, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec4L, dvec4H, dacc22, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec1L, dvec1H, dacc11, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec2L, dvec2H, dacc12, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec3L, dvec3H, dacc21, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvec4L, dvec4H, dacc22, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
          /* Interleave odd and even indices */
          xb_vec2Nx8 dvecOut1L = MORPH_OP_SEL(dvec2L, dvec1L, dvecPattern1);
          xb_vec2Nx8 dvecOut2L = MORPH_OP_SEL(dvec2L, dvec1L, dvecPattern2);
          xb_vec2Nx8 dvecOut1H = MORPH_OP_SEL(dvec2H, dvec1H, dvecPattern1);
          xb_vec2Nx8 dvecOut2H = MORPH_OP_SEL(dvec2H, dvec1H, dvecPattern2);
          xb_vec2Nx8 dvecOut3L = MORPH_OP_SEL(dvec4L, dvec3L, dvecPattern1);
          xb_vec2Nx8 dvecOut4L = MORPH_OP_SEL(dvec4L, dvec3L, dvecPattern2);
          xb_vec2Nx8 dvecOut3H = MORPH_OP_SEL(dvec4H, dvec3H, dvecPattern1);
          xb_vec2Nx8 dvecOut4H = MORPH_OP_SEL(dvec4H, dvec3H, dvecPattern2);

          /* variable store count */
          varLen = XT_MIN(outW - x, vectorizationWidth);

          /* Storing the first output depth, first row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput);
          valign vaOutData = IVP_ZALIGN();
          IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
          IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen - \
                         2 * XCHAL_IVPN_SIMD_WIDTH);
          IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 4 * XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 6 * XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the second output depth, first row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, ((bytesPerPixel * varLen) - \
                                                          2 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 4 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 6 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          pOutput += 2 * outDataPitch2 * bytesPerPixel;
          pCoeff  += 2 * coeffPitch3;
        } /* end of (outCh = 0; outCh < numOutCh; outCh += 2)*/
      }   /* end of for (y = 0; y < outH; y ++)*/
    }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  }

  return(XAI_ERROR_STATUS());
}

/******************************************************************************************
*   xaiConvolved(VQ)3D_S_MxNj1d4I8S8IX_MOW_WHD
*  ***************************************************************************************/
/******************************************************************************/
/* Description : P6 optimized generic implementation for MxN 3D convolution   */
/*               with dilation = 4. Based on MORPH pre-processor specifiers,  */
/*               code implementation is generated during preprocessing stage. */
/*               This method can be used to generate MxN 3D dialted           */
/*               convolution function and MxN 3D VQ dialted convolution       */
/*               function for U8 bit and S8 bit input data with input stride  */
/*               equal to 1.                                                  */
/* Inputs      : Input Data Tile, Coeff Data Tile, Bias Array,                */
/*               Output scale array, CNN convolution params structure         */
/* Outputs     : XI Error Code                                                */
/* InOuts      : Output Tile                                                  */
/* Assumptions : CoeffData is S8                                              */
/*               biasArray is signed 32b, value not exceeding signed 24b      */
/*               Output scale array is U16                                    */
/*               OutData is S8 / U8 / S16                                     */
/*               Kernel Size is MxNxDxN                                       */
/*               Input and Output are in WHD format                           */
/*               Coeff is in WHDN format                                      */
/******************************************************************************/

/****************** xaiConvolvedVQ3D_S_MxNj1d4_S8S8IX_MOW_WHD ******************/
/****************** xaiConvolvedVQ3D_S_MxNj1d4_U8S8IX_MOW_WHD ******************/
/******************* xaiConvolved3D_S_MxNj1d4_S8S8IX_MOW_WHD *******************/
/******************* xaiConvolved3D_S_MxNj1d4_U8S8IX_MOW_WHD *******************/

XAI_ERR_TYPE MAKE_NAME(MAKE_NAME_VQ(xaiConvolved, 3D_S_MxNj1d4), S8IX_MOW_WHD) MAKE_ARGUMENTS(inTile, coeffTile, biasArray, outTile, param)
{
  /* Error Checks */
  XAI_ERROR_CHECKS()
  {
    MORPH_IDT_CHECK(inTile);
    XAI_CHECK_CONV_OUTPUT_TILE3D(outTile);
    XAI_CHECK_TILE4D_S8(coeffTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(inTile);
    XAI_CHECK_TILE3D_IN_DRAM_BOUNDARY(outTile);
    XAI_CHECK_TILE4D_IN_DRAM_BOUNDARY(coeffTile);
    XAI_CHECK_POINTER(param);
    XAI_CHECK_ARRAY_S32(biasArray);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(inTile, outTile);
    XAI_CHECK_TILES3D_ARE_NOT_OVERLAP(coeffTile, outTile);
    XAI_CHECK_ERROR(XAI_TILE4D_GET_DIM1(coeffTile) <= 16, XAI_ERR_KSIZE,           \
                    "Kernel width = %d, which should be less than or equal to 16", \
                    XAI_TILE4D_GET_DIM1(coeffTile));
    XAI_CHECK_ERROR(XAI_TILE4D_GET_DIM2(coeffTile) <= 16, XAI_ERR_KSIZE,               \
                    "\nKernel height = %d,  which should be less than or equal to 16", \
                    XAI_TILE4D_GET_DIM2(coeffTile));
    XAI_CHECK_EDGES_MOW_WHD(inTile, coeffTile, param);
    XAI_CHECK_TILE3D_DATA_ORDER(inTile, XAI_WHD);
    XAI_CHECK_TILE3D_DATA_ORDER(outTile, XAI_WHD);
    XAI_CHECK_TILE4D_DATA_ORDER(coeffTile, XAI_WHDN);
    XAI_CHECK_STRIDE(param, 1);
    XAI_CHECK_ERROR((XAI_CNN_CONV_GET_STRIDEX(param) == XAI_CNN_CONV_GET_STRIDEY(param)),                                           \
                    XAI_ERR_BADARG, "\nStride along width = %hhu and height = %hhu\nStride along width and height should be equal", \
                    XAI_CNN_CONV_GET_STRIDEX(param), XAI_CNN_CONV_GET_STRIDEY(param));
    XAI_CHECK_DILATION(param, 4);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_DILATIONX(param) == XAI_CNN_CONV_GET_DILATIONY(param),                                             \
                    XAI_ERR_BADARG, "\nDilation along width = %hhu and height = %hhu\nDilation along width and height should be equal", \
                    XAI_CNN_CONV_GET_DILATIONX(param), XAI_CNN_CONV_GET_DILATIONY(param));
    XAI_CHECK_CONSISTENCY_MOW_WHD(inTile, coeffTile, biasArray, outTile, param);
    XAI_CHECK_COEFFTILE_CONTIGUOUS(coeffTile, param);
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_ACCUM_SHIFT(param) < 24,                                     \
                    XAI_ERR_NORM, "\nThe accumulator shift = %hhu, value should be less than 24", \
                    XAI_CNN_CONV_GET_ACCUM_SHIFT(param));
    XAI_CHECK_ERROR(XAI_CNN_CONV_GET_OUTPUT_SHIFT(param) < 32,                               \
                    XAI_ERR_NORM, "\nThe output shift = %hhu, value should be less than 32", \
                    XAI_CNN_CONV_GET_OUTPUT_SHIFT(param));
    XAI_CHECK_CONV_RELU_LIMITS_IX(param, outTile);
#if DILATED_VQ_CONV == VQ_TRUE
    XAI_CHECK_ARRAY_U16(outputScaleArray);
    XAI_CHECK_ERROR(XAI_ARRAY_GET_WIDTH(outputScaleArray) >= XAI_TILE4D_GET_DIM4(coeffTile),                                                                                          \
                    XAI_ERR_DATASIZE, "\nWidth of Output Scale Array = %d, Number of Kernels = %d\nWidth of Output Scale Array should be greater than or equal to Number of Kernels", \
                    XAI_ARRAY_GET_WIDTH(outputScaleArray), XAI_TILE4D_GET_DIM4(coeffTile));
    XAI_CHECK_ERROR((((uintptr_t) (XAI_ARRAY_GET_DATA_PTR(outputScaleArray)) & \
                      0x1) == 0), XAI_ERR_NORM, "The output scale array is not aligned to 2 byte boundary");
#endif
  }
#if DILATED_VQ_CONV == VQ_FALSE
  if (XAI_CNN_CONV_GET_OUTPUT_SCALE(param) == 0)
  {
    int32_t fillValue;
    int32_t reluFlag = XAI_CNN_CONV_GET_FLAG_RELU(param);
    fillValue = reluFlag ? (CLAMP(0, XAI_CNN_CONV_GET_RELU_MIN(param), XAI_CNN_CONV_GET_RELU_MAX(param))) : 0;
    return(xaiFillTile3D(outTile, fillValue, 0));
  }
#endif
  /* Getting parameters from the tile structures */
  const int32_t inW = XAI_TILE3D_GET_DIM1(inTile) + \
                      XAI_TILE3D_GET_DIM1_EDGE1(inTile) + XAI_TILE3D_GET_DIM1_EDGE2(inTile);
  const int32_t outW     = XAI_TILE3D_GET_DIM1(outTile);
  const int32_t outH     = XAI_TILE3D_GET_DIM2(outTile);
  const int32_t numInCh  = XAI_TILE3D_GET_DIM3(inTile);
  const int32_t numOutCh = XAI_TILE3D_GET_DIM3(outTile);

  /* Kernel Size (WHDN)*/
  const int32_t kSizeX = XAI_TILE4D_GET_DIM1(coeffTile);
  const int32_t kSizeY = XAI_TILE4D_GET_DIM2(coeffTile);

  /* CNN convolution parameters */
  const uint8_t packShiftAccU = XAI_CNN_CONV_GET_ACCUM_SHIFT(param);
  const uint8_t outShiftU     = XAI_CNN_CONV_GET_OUTPUT_SHIFT(param);
  const uint8_t enableReLu    = XAI_CNN_CONV_GET_FLAG_RELU(param);
  const uint8_t dilationU     = XAI_CNN_CONV_GET_DILATION(param);

  /* Pitches of Coefficient Data (WHDN) */
  const int32_t coeffPitch1 = XAI_TILE4D_GET_DIM1_PITCH(coeffTile);
  const int32_t coeffPitch3 = XAI_TILE4D_GET_DIM3_PITCH(coeffTile);

  /* Pitches of Input Data (WHD) in dim1 and dim2 */
  const int32_t inDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(inTile);
  const int32_t inDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(inTile);

  /* Pitch of Output Data (WHD) in dim1 and dim2 */
  const int32_t outDataPitch1 = XAI_TILE3D_GET_DIM1_PITCH(outTile);
  const int32_t outDataPitch2 = XAI_TILE3D_GET_DIM2_PITCH(outTile);

  /* Data Pointers of input, output, coefficient and bias data */
  MORPH_IDT_SCALAR* pInData = (MORPH_IDT_SCALAR *) XAI_TILE3D_GET_DATA_PTR(inTile);
  int8_t* pOutData          = (int8_t *) XAI_TILE3D_GET_DATA_PTR(outTile);
  int32_t* pBiasData        = (int32_t *) XAI_ARRAY_GET_DATA_PTR(biasArray);
  int8_t* pCoeffData        = (int8_t *) XAI_TILE4D_GET_DATA_PTR(coeffTile);
#if DILATED_VQ_CONV == VQ_TRUE
  uint16_t* restrict pOutScaleData = (uint16_t *) XAI_ARRAY_GET_DATA_PTR(outputScaleArray);
#elif DILATED_VQ_CONV == VQ_FALSE
  const uint16_t outScale = XAI_CNN_CONV_GET_OUTPUT_SCALE(param);
#endif
  /* Since the dilation value > 1 ,                                      */
  /* Effective Kernel size = dilation(KernelSize - 1) + 1                */
  /* Effective kernel size is used for calculating the min required edge */
  int32_t dilatedKSizeX = dilationU * (kSizeX - 1) + 1;
  int32_t dilatedKSizeY = dilationU * (kSizeY - 1) + 1;

  /* For dilation equal to 4 dilated width and height will always be odd */
  /* Condition check to evaluate left or right alignment of kernel based */
  /* on the edge flag is not required.                                   */

  /* Move pointer to the start of the active data (including edge) */
  pInData = &pInData[-((dilatedKSizeY / 2) * inDataPitch1 + (dilatedKSizeX / 2))];

  /* Setting the limits for output data according to ReLu Flag and outTileType */
  int32_t minLim, maxLim;
  if (enableReLu)
  {
    minLim = XAI_CNN_CONV_GET_RELU_MIN(param);
    maxLim = XAI_CNN_CONV_GET_RELU_MAX(param);
  }
  else
  {
    minLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? \
             SHRT_MIN : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MIN : 0);
    maxLim = XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16) ? SHRT_MAX \
             : (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S8) ? SCHAR_MAX : UCHAR_MAX);
  }
  const int8_t typeFlag       = (XAI_TILE3D_CHECK_TYPE(outTile, XAI_S16)) ? 1 : 0;
  const uint8_t bytesPerPixel = XAI_TILE3D_GET_ELEMENT_SIZE(outTile);

  MORPH_IDT_2Nx8 * restrict pdvecIn1;
  xb_vec2Nx8* restrict pdvecOut;
  xb_vec2Nx8* restrict pdvecCoeff1, * restrict pdvecCoeff2;


  /* Variable Declarations */
  int32_t inCh, outCh, x, y, ky;
  const int32_t vectorizationWidth = 4 * XCHAL_IVPN_SIMD_WIDTH - dilatedKSizeX + 1;
  int32_t varLen;

  /* 4 * XCHAL_IVPN_SIMD_WIDTH bytes of input are loaded at a time
   * into two vectors. Also loop across output channels is unrolled twice,
   * thereby producing four output vectors in 1 iteration.
   *
   * Load 128 bytes from row corresponding to each ky
   * dvecInData11 = a0 a1 a2 a3      ...                   a63
   * dvecInData12 = a64 a65 a66      ...                   a127
   *
   * Deinterleave the indices
   * dvecInData11 = a0 a2 a4 a6      ...                   a126
   * dvecInData12 = a1 a3 a5 a7      ...                   a127
   *
   * Deinterleave the indices
   * dvecInData11 = a0 a4 a8   ...   a124 ... a1 a5  ...   a125
   * dvecInData12 = a2 a6 a10   ...  a126 ... a3 a7  ...   a127
   *
   * Let the coefficients be
   * C11 C12 C13 ... C1kW
   * C21 C22 C23 ... C2kW
   *   .
   *   .
   * CkH1 CkH2 CkH3 ... CkHkW
   *
   * dacc11 = [a0 a4 a8   ...   a124 ... a1 a5  ...   a125] * C11 +
   *         [a4 a8   ...   a124 ... a1 a5  ...   a125 X ] * C12 +
   *         [a8   ...   a124 ... a1 a5  ...   a125 X  X ] * C13
   *                      .
   *                      .
   *         [                                           ] * C1kW
   *
   * dacc12 = [a2 a6 a10   ...  a126 ... a3 a7  ...   a127] * C0 +
   *         [a6 a10   ...  a126 ... a3 a7  ...   a127 X ] * C1 +
   *         [a10   ...  a126 ... a3 a7  ...   a127 X  X ] * C2 +
   *                      .
   *                      .
   *         [                                           ] * C1kW
   *
   *
   * Continue the same multiplication steps for ky = 1 to kHeight -1 .
   * dacc11 and dacc12 contains convolved output corresponding to even and odd indices
   * respectively at the end of inchannel loop iterations.
   *
   * acc11 and acc12 are interleaved to obtain the outputs in correct order.
   * Pack, Shift scale and clamp dacc11 and dacc12 to obtain dvecOut1L , dvecOut1H, dvecOut2L and dvecOut2H
   *
   * For 8bit output, dvecOutL contains the required output elements
   * dvecOut1L = [A0 A4 A8 ... A116 X X A1 A5 ... A117 X X] - 64 elements
   * dvecOut2L = [A2 A6 A10 ...A118 X X A3 A7 ... A119 X X] - 64 elements
   * Interleave the elements
   * dvecOut1L = [A0 A2 A4       ...    A116 A117 X X X X ] - 64 elements
   * dvecOut2L = [A1 A3 A7       ...    A118 A119 X X X X ] - 64 elements
   * Interleave the elements
   * dvecOut1L = [A0 A1 A2 A3                   ...                 ]- 64 elements
   * dvecOut2L = [  ...         A116 A117 A118 A119 X X X X X X X X ]- 64 elements
   *
   *
   * For 16bit output
   * dvecOut1L = [A0 A4 A8  ... A116 X X] - 32 16b elements
   * dvecOut1H = [A1 A5 A9  ... A117 X X] - 32 16b elements
   * dvecOut2L = [A2 A6 A10 ... A118 X X] - 32 16b elements
   * dvecOut2H = [A3 A7 A11 ... A119 X X] - 32 16b elements
   * Interleave the elements of dvecOut1L and dvecOut1H
   * dvecOut1L = [A0 A1 A4 A5         ...      ]
   * dvecOut1H = [ ...            A116 A117 X X]
   * Interleave the elements of dvecOut2L and dvecOut2H
   * dvecOut2L = [A2 A3 A6 A7               ...]
   * dvecOut2H = [ ...            A118 A119 X X]
   * Interleave2 the elements of dvecOut2L and dvecOut1L
   * dvecOut1L = [A0  A1  A2  A3                        ...          ]
   * dvecOut2L = [A32 A33 A34 A35                        ...         ]
   * Interleave2 the elements of dvecOut2H and dvecOut1H
   * dvecOut1H = [A64 A65 A66 A67                  ...               ]
   * dvecOut2H = [ ...            A116 A117 A118 A119 X X X X X X X X]
   *
   */

  if (kSizeX > 12)
  {
    /* 4 * XCHAL_IVPN_SIMD_WIDTH bytes of input are loaded at a time
     * into two vectors. Also loop across output channels is unrolled twice,
     * thereby producing four output vectors in 1 iteration
     */
    for (x = 0; x < outW; x += vectorizationWidth)   /* Loop across Output width */
    {
      /* out of bound flag */
      int32_t flag = XT_SALT(64, inW - x);

      for (y = 0; y < outH; y++)     /* Loop across Output height */
      {
        /* initialize output data pointer */
        int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

        /* initialize input data pointer */
        MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * (y) + (x)];

        /* initialize coeff and bias data pointer*/
        int8_t *pCoeff = &pCoeffData[0];
        int32_t *pBias = &pBiasData[0];

        for (outCh = 0; outCh < numOutCh; outCh += 2)   /* Loop across Output depth */
        {
          /* handles odd output channel */
          int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

          xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
          xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

          /* wide vectors(accumulators) initialized with bias */
          xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;

          dacc12 = dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);

          dacc22 = dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc22, hvecBias2, hvecBias2);

          /* priming of coeff load is done outside the innermost loop*/
          pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
          valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

          pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
          valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

          for (inCh = 0; inCh < numInCh; inCh++)   /* Loop across input channels */
          {
            /* variable declarations for input and coeff vectors */

            xb_vec2Nx8 dvecCoeffData11;
            xb_vec2Nx8 dvecCoeffData21;

            xb_vec2Nx8 dvecInData11, dvecInData12;

            pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2);

            for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
            {
              /* loads 128 bytes of input row */
              valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
              MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
              MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, \
                                 dilationU * inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

              MORPH_OP_DSELI(dvecInData12, dvecInData11, dvecInData12, dvecInData11, \
                             IVP_DSELI_8B_DEINTERLEAVE_1);
              MORPH_OP_DSELI(dvecInData12, dvecInData11, dvecInData12, dvecInData11, \
                             IVP_DSELI_8B_DEINTERLEAVE_1);

              /* load 1 row of coeff for 1st output channel */
              IVP_LAV2NX8_XP(dvecCoeffData11, vaCoeffData1, pdvecCoeff1, coeffPitch1);

              /* load 1 row of coeff for 2nd output channel */
              IVP_LAV2NX8_XP(dvecCoeffData21, vaCoeffData2, pdvecCoeff2, coeffPitch1);

              /* multiples loaded input data with first four coeff */
              MORPH_OP_MUL4TA(dacc11, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                0));
              MORPH_OP_MUL4TA(dacc12, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                0));

              MORPH_OP_MUL4TA(dacc21, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                0));
              MORPH_OP_MUL4TA(dacc22, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                0));

              /* right rotate the input vectors by 4
               * in order to multiply with next column of
               * coeff in the next iteration
               */
              dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);

              /* multiples input data with next four coeffs from the same row */
              MORPH_OP_MUL4TA(dacc11, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                1));
              MORPH_OP_MUL4TA(dacc12, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                1));

              MORPH_OP_MUL4TA(dacc21, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                1));
              MORPH_OP_MUL4TA(dacc22, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                1));

              /* right rotate the input vectors by 4
               * in order to multiply with next column of
               * coeff in the next iteration
               */
              dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);

              /* multiples input data with next four coeffs from the same row */
              MORPH_OP_MUL4TA(dacc11, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                2));
              MORPH_OP_MUL4TA(dacc12, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                2));

              MORPH_OP_MUL4TA(dacc21, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                2));
              MORPH_OP_MUL4TA(dacc22, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                2));

              /* right rotate the input vectors by 4
               * in order to multiply with next column of
               * coeff in the next iteration
               */
              dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);

              /* multiples input data with next four coeffs from the same row */
              MORPH_OP_MUL4TA(dacc11, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                3));
              MORPH_OP_MUL4TA(dacc12, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                3));

              MORPH_OP_MUL4TA(dacc21, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                3));
              MORPH_OP_MUL4TA(dacc22, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                3));
            } /* end of for (ky = 0; ky < kSizeY; ky++)*/
          }   /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

          /* Pack, Output Scale, Output Shift and clamping */
          xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
          xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
          /* 8 bit output */
          if (!typeFlag)
          {
            MORPH_OP_DSELI(dvecOut2L, dvecOut1L, dvecOut2L, dvecOut1L, \
                           IVP_DSELI_8B_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut2L, dvecOut1L, dvecOut2L, dvecOut1L, \
                           IVP_DSELI_8B_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut4L, dvecOut3L, dvecOut4L, dvecOut3L, \
                           IVP_DSELI_8B_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut4L, dvecOut3L, dvecOut4L, dvecOut3L, \
                           IVP_DSELI_8B_INTERLEAVE_1);
          }
          else /* 16bit output */
          {
            MORPH_OP_DSELI(dvecOut1H, dvecOut1L, dvecOut1H, dvecOut1L, \
                           IVP_DSELI_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut2H, dvecOut2L, dvecOut2H, dvecOut2L, \
                           IVP_DSELI_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut2L, dvecOut1L, dvecOut2L, dvecOut1L, \
                           IVP_DSELI_INTERLEAVE_2);
            MORPH_OP_DSELI(dvecOut2H, dvecOut1H, dvecOut2H, dvecOut1H, \
                           IVP_DSELI_INTERLEAVE_2);
            MORPH_OP_DSELI(dvecOut3H, dvecOut3L, dvecOut3H, dvecOut3L, \
                           IVP_DSELI_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut4H, dvecOut4L, dvecOut4H, dvecOut4L, \
                           IVP_DSELI_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut4L, dvecOut3L, dvecOut4L, dvecOut3L, \
                           IVP_DSELI_INTERLEAVE_2);
            MORPH_OP_DSELI(dvecOut4H, dvecOut3H, dvecOut4H, dvecOut3H, \
                           IVP_DSELI_INTERLEAVE_2);
          }

          /* variable store count */
          varLen = XT_MIN(outW - x, vectorizationWidth);

          /* Storing the first output depth, first row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput);
          valign vaOutData = IVP_ZALIGN();
          IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
          IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen - \
                         2 * XCHAL_IVPN_SIMD_WIDTH);
          IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 4 * XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 6 * XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the second output depth, first row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, ((bytesPerPixel * varLen) - \
                                                          2 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 4 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 6 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          pOutput += 2 * outDataPitch2 * bytesPerPixel;
          pCoeff  += 2 * coeffPitch3;
        } /* end of (outCh = 0; outCh < numOutCh; outCh += 2)*/
      }   /* end of for (y = 0; y < outH; y ++)*/
    }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  }
  else if (kSizeX > 8)
  {
    /* 4 * XCHAL_IVPN_SIMD_WIDTH bytes of input are loaded at a time
     * into two vectors. Also loop across output channels is unrolled twice,
     * thereby producing four output vectors in 1 iteration
     */
    for (x = 0; x < outW; x += vectorizationWidth)   /* Loop across Output width */
    {
      /* out of bound flag */
      int32_t flag = XT_SALT(64, inW - x);

      for (y = 0; y < outH; y++)     /* Loop across Output height */
      {
        /* initialize output data pointer */
        int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

        /* initialize input data pointer */
        MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * (y) + (x)];

        /* initialize coeff and bias data pointer*/
        int8_t *pCoeff = &pCoeffData[0];
        int32_t *pBias = &pBiasData[0];

        for (outCh = 0; outCh < numOutCh; outCh += 2)   /* Loop across Output depth */
        {
          /* handles odd output channel*/
          int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

          xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
          xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

          /* wide vectors(accumulators) initialized with bias */
          xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;

          dacc12 = dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);

          dacc22 = dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc22, hvecBias2, hvecBias2);

          /* priming of coeff load is done outside the innermost loop*/
          pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
          valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

          pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
          valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

          for (inCh = 0; inCh < numInCh; inCh++)   /* Loop across input channels */
          {
            /* variable declarations for input and coeff vectors */

            xb_vec2Nx8 dvecCoeffData11;
            xb_vec2Nx8 dvecCoeffData21;

            xb_vec2Nx8 dvecInData11, dvecInData12;

            pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2);

            for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
            {
              /* loads 128 bytes of input row */
              valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
              MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
              MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, \
                                 dilationU * inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

              MORPH_OP_DSELI(dvecInData12, dvecInData11, dvecInData12, dvecInData11, \
                             IVP_DSELI_8B_DEINTERLEAVE_1);
              MORPH_OP_DSELI(dvecInData12, dvecInData11, dvecInData12, dvecInData11, \
                             IVP_DSELI_8B_DEINTERLEAVE_1);

              /* load 1 row of coeff for 1st output channel */
              IVP_LAV2NX8_XP(dvecCoeffData11, vaCoeffData1, pdvecCoeff1, coeffPitch1);

              /* load 1 row of coeff for 2nd output channel */
              IVP_LAV2NX8_XP(dvecCoeffData21, vaCoeffData2, pdvecCoeff2, coeffPitch1);

              /* multiples loaded input data with first four coeff */
              MORPH_OP_MUL4TA(dacc11, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                0));
              MORPH_OP_MUL4TA(dacc12, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                0));

              MORPH_OP_MUL4TA(dacc21, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                0));
              MORPH_OP_MUL4TA(dacc22, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                0));

              /* right rotate the input vectors by 4
               * in order to multiply with next column of
               * coeff in the next iteration
               */
              dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);

              /* multiples input data with next four coeffs from the same row */
              MORPH_OP_MUL4TA(dacc11, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                1));
              MORPH_OP_MUL4TA(dacc12, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                1));

              MORPH_OP_MUL4TA(dacc21, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                1));
              MORPH_OP_MUL4TA(dacc22, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                1));

              /* right rotate the input vectors by 4
               * in order to multiply with next column of
               * coeff in the next iteration
               */
              dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);

              /* multiples input data with next four coeffs from the same row */
              MORPH_OP_MUL4TA(dacc11, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                2));
              MORPH_OP_MUL4TA(dacc12, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                2));

              MORPH_OP_MUL4TA(dacc21, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                2));
              MORPH_OP_MUL4TA(dacc22, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                2));
            } /* end of for (ky = 0; ky < kSizeY; ky++)*/
          }   /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

          /* Pack, Output Scale, Output Shift and clamping */
          xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
          xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
          /* 8 bit output */
          if (!typeFlag)
          {
            MORPH_OP_DSELI(dvecOut2L, dvecOut1L, dvecOut2L, dvecOut1L, \
                           IVP_DSELI_8B_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut2L, dvecOut1L, dvecOut2L, dvecOut1L, \
                           IVP_DSELI_8B_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut4L, dvecOut3L, dvecOut4L, dvecOut3L, \
                           IVP_DSELI_8B_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut4L, dvecOut3L, dvecOut4L, dvecOut3L, \
                           IVP_DSELI_8B_INTERLEAVE_1);
          }
          else /* 16bit output */
          {
            MORPH_OP_DSELI(dvecOut1H, dvecOut1L, dvecOut1H, dvecOut1L, \
                           IVP_DSELI_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut2H, dvecOut2L, dvecOut2H, dvecOut2L, \
                           IVP_DSELI_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut2L, dvecOut1L, dvecOut2L, dvecOut1L, \
                           IVP_DSELI_INTERLEAVE_2);
            MORPH_OP_DSELI(dvecOut2H, dvecOut1H, dvecOut2H, dvecOut1H, \
                           IVP_DSELI_INTERLEAVE_2);
            MORPH_OP_DSELI(dvecOut3H, dvecOut3L, dvecOut3H, dvecOut3L, \
                           IVP_DSELI_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut4H, dvecOut4L, dvecOut4H, dvecOut4L, \
                           IVP_DSELI_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut4L, dvecOut3L, dvecOut4L, dvecOut3L, \
                           IVP_DSELI_INTERLEAVE_2);
            MORPH_OP_DSELI(dvecOut4H, dvecOut3H, dvecOut4H, dvecOut3H, \
                           IVP_DSELI_INTERLEAVE_2);
          }

          /* variable store count */
          varLen = XT_MIN(outW - x, vectorizationWidth);

          /* Storing the first output depth, first row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput);
          valign vaOutData = IVP_ZALIGN();
          IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
          IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen - \
                         2 * XCHAL_IVPN_SIMD_WIDTH);
          IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 4 * XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 6 * XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the second output depth, first row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, ((bytesPerPixel * varLen) - \
                                                          2 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 4 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 6 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          pOutput += 2 * outDataPitch2 * bytesPerPixel;
          pCoeff  += 2 * coeffPitch3;
        } /* end of (outCh = 0; outCh < numOutCh; outCh += 2)*/
      }   /* end of for (y = 0; y < outH; y ++)*/
    }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  }
  else if (kSizeX > 4)
  {
    /* 4 * XCHAL_IVPN_SIMD_WIDTH bytes of input are loaded at a time
     * into two vectors. Also loop across output channels is unrolled twice,
     * thereby producing four output vectors in 1 iteration
     */
    for (x = 0; x < outW; x += vectorizationWidth)   /* Loop across Output width */
    {
      /* out of bound flag */
      int32_t flag = XT_SALT(64, inW - x);

      for (y = 0; y < outH; y++)     /* Loop across Output height */
      {
        /* initialize output data pointer */
        int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

        /* initialize input data pointer */
        MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * (y) + (x)];

        /* initialize coeff and bias data pointer*/
        int8_t *pCoeff = &pCoeffData[0];
        int32_t *pBias = &pBiasData[0];

        for (outCh = 0; outCh < numOutCh; outCh += 2)   /* Loop across Output depth */
        {
          /* handles odd output channel */
          int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

          xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
          xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);

          /* wide vectors(accumulators) initialized with bias */
          xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;

          dacc12 = dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);

          dacc22 = dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc22, hvecBias2, hvecBias2);

          /* priming of coeff load is done outside the innermost loop*/
          pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
          valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

          pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
          valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);

          for (inCh = 0; inCh < numInCh; inCh++)   /* Loop across input channels */
          {
            /* variable declarations for input and coeff vectors */

            xb_vec2Nx8 dvecCoeffData11;
            xb_vec2Nx8 dvecCoeffData21;

            xb_vec2Nx8 dvecInData11, dvecInData12;

            pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2);

            for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
            {
              /* loads 128 bytes of input row */
              valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
              MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
              MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, \
                                 dilationU * inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

              MORPH_OP_DSELI(dvecInData12, dvecInData11, dvecInData12, dvecInData11, \
                             IVP_DSELI_8B_DEINTERLEAVE_1);
              MORPH_OP_DSELI(dvecInData12, dvecInData11, dvecInData12, dvecInData11, \
                             IVP_DSELI_8B_DEINTERLEAVE_1);

              /* load 1 row of coeff for 1st output channel */
              IVP_LAV2NX8_XP(dvecCoeffData11, vaCoeffData1, pdvecCoeff1, coeffPitch1);

              /* load 1 row of coeff for 2nd output channel */
              IVP_LAV2NX8_XP(dvecCoeffData21, vaCoeffData2, pdvecCoeff2, coeffPitch1);

              /* multiples loaded input data with first four coeff */
              MORPH_OP_MUL4TA(dacc11, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                0));
              MORPH_OP_MUL4TA(dacc12, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                0));

              MORPH_OP_MUL4TA(dacc21, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                0));
              MORPH_OP_MUL4TA(dacc22, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                0));

              /* right rotate the input vectors by 4
               * in order to multiply with next column of
               * coeff in the next iteration
               */
              dvecInData11 = IVP_SEL2NX8I(dvecInData12, dvecInData11, IVP_SELI_8B_ROTATE_RIGHT_4);
              dvecInData12 = IVP_SEL2NX8I((xb_vec2Nx8) 0, dvecInData12, IVP_SELI_8B_ROTATE_RIGHT_4);

              /* multiples input data with next four coeffs from the same row */
              MORPH_OP_MUL4TA(dacc11, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                1));
              MORPH_OP_MUL4TA(dacc12, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                1));

              MORPH_OP_MUL4TA(dacc21, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                1));
              MORPH_OP_MUL4TA(dacc22, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                1));
            } /* end of for (ky = 0; ky < kSizeY; ky++)*/
          }   /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

          /* Pack, Output Scale, Output Shift and clamping */
          xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
          xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
          /* 8 bit output */
          if (!typeFlag)
          {
            MORPH_OP_DSELI(dvecOut2L, dvecOut1L, dvecOut2L, dvecOut1L, \
                           IVP_DSELI_8B_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut2L, dvecOut1L, dvecOut2L, dvecOut1L, \
                           IVP_DSELI_8B_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut4L, dvecOut3L, dvecOut4L, dvecOut3L, \
                           IVP_DSELI_8B_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut4L, dvecOut3L, dvecOut4L, dvecOut3L, \
                           IVP_DSELI_8B_INTERLEAVE_1);
          }
          else /* 16bit output */
          {
            MORPH_OP_DSELI(dvecOut1H, dvecOut1L, dvecOut1H, dvecOut1L, \
                           IVP_DSELI_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut2H, dvecOut2L, dvecOut2H, dvecOut2L, \
                           IVP_DSELI_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut2L, dvecOut1L, dvecOut2L, dvecOut1L, \
                           IVP_DSELI_INTERLEAVE_2);
            MORPH_OP_DSELI(dvecOut2H, dvecOut1H, dvecOut2H, dvecOut1H, \
                           IVP_DSELI_INTERLEAVE_2);
            MORPH_OP_DSELI(dvecOut3H, dvecOut3L, dvecOut3H, dvecOut3L, \
                           IVP_DSELI_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut4H, dvecOut4L, dvecOut4H, dvecOut4L, \
                           IVP_DSELI_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut4L, dvecOut3L, dvecOut4L, dvecOut3L, \
                           IVP_DSELI_INTERLEAVE_2);
            MORPH_OP_DSELI(dvecOut4H, dvecOut3H, dvecOut4H, dvecOut3H, \
                           IVP_DSELI_INTERLEAVE_2);
          }

          /* variable store count */
          varLen = XT_MIN(outW - x, vectorizationWidth);

          /* Storing the first output depth, first row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput);
          valign vaOutData = IVP_ZALIGN();
          IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
          IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen - \
                         2 * XCHAL_IVPN_SIMD_WIDTH);
          IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 4 * XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 6 * XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the second output depth, first row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, ((bytesPerPixel * varLen) - \
                                                          2 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 4 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 6 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          pOutput += 2 * outDataPitch2 * bytesPerPixel;
          pCoeff  += 2 * coeffPitch3;
        } /* end of (outCh = 0; outCh < numOutCh; outCh += 2)*/
      }   /* end of for (y = 0; y < outH; y ++)*/
    }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  }
  else
  {
    /* 4 * XCHAL_IVPN_SIMD_WIDTH bytes of input are loaded at a time
     * into two vectors. Also loop across output channels is unrolled twice,
     * thereby producing four output vectors in 1 iteration
     */

    for (x = 0; x < outW; x += vectorizationWidth)   /* Loop across Output width */
    {
      /* out of bound flag */
      int32_t flag = XT_SALT(64, inW - x);

      for (y = 0; y < outH; y++)     /* Loop across Output height */
      {
        /* initialize output data pointer */
        int8_t *pOutput = &pOutData[(y * outDataPitch1 + x) * bytesPerPixel];

        /* initialize input data pointer */
        MORPH_IDT_SCALAR *pInput = &pInData[inDataPitch1 * (y) + (x)];

        /* initialize coeff and bias data pointer*/
        int8_t *pCoeff = &pCoeffData[0];
        int32_t *pBias = &pBiasData[0];

        for (outCh = 0; outCh < numOutCh; outCh += 2)   /* Loop across Output depth */
        {
          /* handles odd output channel */
          int32_t enable2ndCh = XT_SALT(outCh, numOutCh - 1);

          xb_vecN_2x32v hvecBias1; IVP_LSRN_2X32_XP(hvecBias1, pBias, 4 * enable2ndCh);
          xb_vecN_2x32v hvecBias2; IVP_LSRN_2X32_XP(hvecBias2, pBias, 4);


          /* wide vectors(accumulators) initialized with bias */
          xb_vec2Nx24 dacc11, dacc12, dacc21, dacc22;

          dacc12 = dacc11 = IVP_CVT24UNX32L(hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc11, hvecBias1, hvecBias1);
          IVP_CVT24UNX32H(dacc12, hvecBias1, hvecBias1);

          dacc22 = dacc21 = IVP_CVT24UNX32L(hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc21, hvecBias2, hvecBias2);
          IVP_CVT24UNX32H(dacc22, hvecBias2, hvecBias2);

          /* priming of coeff load is done outside the innermost loop*/
          pdvecCoeff1 = (xb_vec2Nx8 *) (pCoeff);
          valign vaCoeffData1; vaCoeffData1 = IVP_LA2NX8_PP(pdvecCoeff1);

          pdvecCoeff2 = (xb_vec2Nx8 *) (pCoeff + coeffPitch3 * enable2ndCh);
          valign vaCoeffData2; vaCoeffData2 = IVP_LA2NX8_PP(pdvecCoeff2);


          for (inCh = 0; inCh < numInCh; inCh++)   /* Loop across input channels */
          {
            /* variable declarations for input and coeff vectors */

            xb_vec2Nx8 dvecCoeffData11;
            xb_vec2Nx8 dvecCoeffData21;

            xb_vec2Nx8 dvecInData11, dvecInData12;

            pdvecIn1 = (MORPH_IDT_2Nx8 *) (pInput + inCh * inDataPitch2);

            for (ky = 0; ky < kSizeY; ky++)   /* Loop across kernel height */
            {
              /* loads 128 bytes of input row */
              valign vaInData = MORPH_OP_PRIME_2Nx8(pdvecIn1);
              MORPH_OP_LOAD_2Nx8(dvecInData11, vaInData, pdvecIn1, 2 * XCHAL_IVPN_SIMD_WIDTH * flag);
              MORPH_OP_LOAD_2Nx8(dvecInData12, vaInData, pdvecIn1, \
                                 dilationU * inDataPitch1 - 2 * XCHAL_IVPN_SIMD_WIDTH * flag);

              MORPH_OP_DSELI(dvecInData12, dvecInData11, dvecInData12, dvecInData11, \
                             IVP_DSELI_8B_DEINTERLEAVE_1);
              MORPH_OP_DSELI(dvecInData12, dvecInData11, dvecInData12, dvecInData11, \
                             IVP_DSELI_8B_DEINTERLEAVE_1);

              /* load 1 row of coeff for 1st output channel */
              IVP_LAV2NX8_XP(dvecCoeffData11, vaCoeffData1, pdvecCoeff1, coeffPitch1);

              /* load 1 row of coeff for 2nd output channel */
              IVP_LAV2NX8_XP(dvecCoeffData21, vaCoeffData2, pdvecCoeff2, coeffPitch1);

              /* multiples loaded input data with first four coeff */
              MORPH_OP_MUL4TA(dacc11, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                0));
              MORPH_OP_MUL4TA(dacc12, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData11)), \
                                0));

              MORPH_OP_MUL4TA(dacc21, dvecInData11, dvecInData11, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                0));
              MORPH_OP_MUL4TA(dacc22, dvecInData12, dvecInData12, IVP_EXTRN_2X32                \
                                (IVP_MOVN_2X32_FROMNX16(IVP_MOVNX16_FROM2NX8(dvecCoeffData21)), \
                                0));
            } /* end of for (ky = 0; ky < kSizeY; ky++)*/
          }   /* end of for (inCh = 0; inCh < numInCh; inCh++)*/

          /* Pack, Output Scale, Output Shift and clamping */
          xb_vec2Nx8 dvecOut1L, dvecOut2L, dvecOut3L, dvecOut4L;
          xb_vec2Nx8 dvecOut1H, dvecOut2H, dvecOut3H, dvecOut4H;
#if DILATED_VQ_CONV == VQ_TRUE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                        pOutScaleData[outCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                        pOutScaleData[outCh + enable2ndCh], outShiftU, minLim, maxLim, typeFlag);
#elif DILATED_VQ_CONV == VQ_FALSE
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut1L, dvecOut1H, dacc11, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut2L, dvecOut2H, dacc12, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut3L, dvecOut3H, dacc21, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
          PACK_SCALE_SHIFT_CLAMP_LIMITS(dvecOut4L, dvecOut4H, dacc22, packShiftAccU, \
                                        outScale, outShiftU, minLim, maxLim, typeFlag);
#endif
          /* 8 bit output */
          if (!typeFlag)
          {
            MORPH_OP_DSELI(dvecOut2L, dvecOut1L, dvecOut2L, dvecOut1L, \
                           IVP_DSELI_8B_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut2L, dvecOut1L, dvecOut2L, dvecOut1L, \
                           IVP_DSELI_8B_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut4L, dvecOut3L, dvecOut4L, dvecOut3L, \
                           IVP_DSELI_8B_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut4L, dvecOut3L, dvecOut4L, dvecOut3L, \
                           IVP_DSELI_8B_INTERLEAVE_1);
          }
          else /* 16bit output */
          {
            MORPH_OP_DSELI(dvecOut1H, dvecOut1L, dvecOut1H, dvecOut1L, \
                           IVP_DSELI_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut2H, dvecOut2L, dvecOut2H, dvecOut2L, \
                           IVP_DSELI_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut2L, dvecOut1L, dvecOut2L, dvecOut1L, \
                           IVP_DSELI_INTERLEAVE_2);
            MORPH_OP_DSELI(dvecOut2H, dvecOut1H, dvecOut2H, dvecOut1H, \
                           IVP_DSELI_INTERLEAVE_2);
            MORPH_OP_DSELI(dvecOut3H, dvecOut3L, dvecOut3H, dvecOut3L, \
                           IVP_DSELI_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut4H, dvecOut4L, dvecOut4H, dvecOut4L, \
                           IVP_DSELI_INTERLEAVE_1);
            MORPH_OP_DSELI(dvecOut4L, dvecOut3L, dvecOut4L, dvecOut3L, \
                           IVP_DSELI_INTERLEAVE_2);
            MORPH_OP_DSELI(dvecOut4H, dvecOut3H, dvecOut4H, dvecOut3H, \
                           IVP_DSELI_INTERLEAVE_2);
          }

          /* variable store count */
          varLen = XT_MIN(outW - x, vectorizationWidth);

          /* Storing the first output depth, first row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput);
          valign vaOutData = IVP_ZALIGN();
          IVP_SAV2NX8_XP(dvecOut1L, vaOutData, pdvecOut, bytesPerPixel * varLen);
          IVP_SAV2NX8_XP(dvecOut2L, vaOutData, pdvecOut, bytesPerPixel * varLen - \
                         2 * XCHAL_IVPN_SIMD_WIDTH);
          IVP_SAV2NX8_XP(dvecOut1H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 4 * XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAV2NX8_XP(dvecOut2H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 6 * XCHAL_IVPN_SIMD_WIDTH));
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          /* Storing the second output depth, first row */
          pdvecOut = (xb_vec2Nx8 *) (pOutput + outDataPitch2 * enable2ndCh * bytesPerPixel);
          IVP_SAV2NX8_XP(dvecOut3L, vaOutData, pdvecOut, bytesPerPixel * varLen * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut4L, vaOutData, pdvecOut, ((bytesPerPixel * varLen) - \
                                                          2 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut3H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 4 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAV2NX8_XP(dvecOut4H, vaOutData, pdvecOut, typeFlag * \
                         (2 * varLen - 6 * XCHAL_IVPN_SIMD_WIDTH) * enable2ndCh);
          IVP_SAPOS2NX8_FP(vaOutData, pdvecOut);

          pOutput += 2 * outDataPitch2 * bytesPerPixel;
          pCoeff  += 2 * coeffPitch3;
        } /* end of (outCh = 0; outCh < numOutCh; outCh += 2)*/
      }   /* end of for (y = 0; y < outH; y ++)*/
    }     /* end of for (x = 0; x < outW; x += vectorizationWidth)*/
  }

  return(XAI_ERROR_STATUS());
}

//#endif
#endif /*if ((XCHAL_VISION_TYPE >= 6))*/


