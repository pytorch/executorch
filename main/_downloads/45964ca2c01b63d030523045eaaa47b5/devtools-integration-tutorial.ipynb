{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Using the ExecuTorch Developer Tools to Profile a Model\n\n**Author:** [Jack Khuu](https://github.com/Jack-Khuu)_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The [ExecuTorch Developer Tools](../devtools-overview.html)_ is a set of tools designed to\nprovide users with the ability to profile, debug, and visualize ExecuTorch\nmodels.\n\nThis tutorial will show a full end-to-end flow of how to utilize the Developer Tools to profile a model.\nSpecifically, it will:\n\n1. Generate the artifacts consumed by the Developer Tools ([ETRecord](../etrecord.html)_, [ETDump](../etdump.html)_).\n2. Create an Inspector class consuming these artifacts.\n3. Utilize the Inspector class to analyze the model profiling result.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n\nTo run this tutorial, you\u2019ll first need to\n[Set up your ExecuTorch environment](../getting-started-setup.html)_.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate ETRecord (Optional)\n\nThe first step is to generate an ``ETRecord``. ``ETRecord`` contains model\ngraphs and metadata for linking runtime results (such as profiling) to\nthe eager model. This is generated via ``executorch.devtools.generate_etrecord``.\n\n``executorch.devtools.generate_etrecord`` takes in an output file path (str), the\nedge dialect model (``EdgeProgramManager``), the ExecuTorch dialect model\n(``ExecutorchProgramManager``), and an optional dictionary of additional models.\n\nIn this tutorial, an example model (shown below) is used to demonstrate.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import copy\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom executorch.devtools import generate_etrecord\n\nfrom executorch.exir import (\n    EdgeCompileConfig,\n    EdgeProgramManager,\n    ExecutorchProgramManager,\n    to_edge,\n)\nfrom torch.export import export, ExportedProgram\n\n\n# Generate Model\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        # 1 input image channel, 6 output channels, 5x5 square convolution\n        # kernel\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        # an affine operation: y = Wx + b\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        # Max pooling over a (2, 2) window\n        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n        # If the size is a square, you can specify with a single number\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n        x = torch.flatten(x, 1)  # flatten all dimensions except the batch dimension\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n\nmodel = Net()\n\naten_model: ExportedProgram = export(model, (torch.randn(1, 1, 32, 32),), strict=True)\n\nedge_program_manager: EdgeProgramManager = to_edge(\n    aten_model, compile_config=EdgeCompileConfig(_check_ir_validity=True)\n)\nedge_program_manager_copy = copy.deepcopy(edge_program_manager)\net_program_manager: ExecutorchProgramManager = edge_program_manager.to_executorch()\n\n\n# Generate ETRecord\netrecord_path = \"etrecord.bin\"\ngenerate_etrecord(etrecord_path, edge_program_manager_copy, et_program_manager)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-danger\"><h4>Warning</h4><p>Users should do a deepcopy of the output of ``to_edge()`` and pass in the\n   deepcopy to the ``generate_etrecord`` API. This is needed because the\n   subsequent call, ``to_executorch()``, does an in-place mutation and will\n   lose debug data in the process.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate ETDump\n\nNext step is to generate an ``ETDump``. ``ETDump`` contains runtime results\nfrom executing a [Bundled Program Model](../bundled-io.html)_.\n\nIn this tutorial, a `Bundled Program` is created from the example model above.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom executorch.devtools import BundledProgram\n\nfrom executorch.devtools.bundled_program.config import MethodTestCase, MethodTestSuite\nfrom executorch.devtools.bundled_program.serialize import (\n    serialize_from_bundled_program_to_flatbuffer,\n)\n\nfrom executorch.exir import to_edge\nfrom torch.export import export\n\n# Step 1: ExecuTorch Program Export\nm_name = \"forward\"\nmethod_graphs = {m_name: export(model, (torch.randn(1, 1, 32, 32),), strict=True)}\n\n# Step 2: Construct Method Test Suites\ninputs = [[torch.randn(1, 1, 32, 32)] for _ in range(2)]\n\nmethod_test_suites = [\n    MethodTestSuite(\n        method_name=m_name,\n        test_cases=[\n            MethodTestCase(inputs=inp, expected_outputs=getattr(model, m_name)(*inp))\n            for inp in inputs\n        ],\n    )\n]\n\n# Step 3: Generate BundledProgram\nexecutorch_program = to_edge(method_graphs).to_executorch()\nbundled_program = BundledProgram(executorch_program, method_test_suites)\n\n# Step 4: Serialize BundledProgram to flatbuffer.\nserialized_bundled_program = serialize_from_bundled_program_to_flatbuffer(\n    bundled_program\n)\nsave_path = \"bundled_program.bp\"\nwith open(save_path, \"wb\") as f:\n    f.write(serialized_bundled_program)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use CMake (follow [these instructions](../runtime-build-and-cross-compilation.html#configure-the-cmake-build)_ to set up cmake) to execute the Bundled Program to generate the ``ETDump``::\n\n      cd executorch\n      ./examples/devtools/build_example_runner.sh\n      cmake-out/examples/devtools/example_runner --bundled_program_path=\"bundled_program.bp\"\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating an Inspector\n\nFinal step is to create the ``Inspector`` by passing in the artifact paths.\nInspector takes the runtime results from ``ETDump`` and correlates them to\nthe operators of the Edge Dialect Graph.\n\nRecall: An ``ETRecord`` is not required. If an ``ETRecord`` is not provided,\nthe Inspector will show runtime results without operator correlation.\n\nTo visualize all runtime events, call Inspector's ``print_data_tabular``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from executorch.devtools import Inspector\n\n\netrecord_path = \"etrecord.bin\"\netdump_path = \"etdump.etdp\"\ninspector = Inspector(etdump_path=etdump_path, etrecord=etrecord_path)\ninspector.print_data_tabular()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is an example output:\n\n<img src=\"file://../_static/img/inspector_tabular_output.png\">\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyzing with an Inspector\n\n``Inspector`` provides 2 ways of accessing ingested information: [EventBlocks](../model-inspector#eventblock-class)_\nand ``DataFrames``. These mediums give users the ability to perform custom\nanalysis about their model performance.\n\nBelow are examples usages, with both ``EventBlock`` and ``DataFrame`` approaches.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set Up\nimport pprint as pp\n\nimport pandas as pd\n\npd.set_option(\"display.max_colwidth\", None)\npd.set_option(\"display.max_columns\", None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If a user wants the raw profiling results, they would do something similar to\nfinding the raw runtime data of an ``addmm.out`` event.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for event_block in inspector.event_blocks:\n    # Via EventBlocks\n    for event in event_block.events:\n        if event.name == \"native_call_addmm.out\":\n            print(event.name, event.perf_data.raw if event.perf_data else \"\")\n\n    print()\n    # Via Dataframe\n    df = event_block.to_dataframe()\n    df = df[df.event_name == \"native_call_addmm.out\"]\n    if len(df) > 0:\n        print(df[[\"event_name\", \"raw\"]])\n        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If a user wants to trace an operator back to their model code, they would do\nsomething similar to finding the module hierarchy and stack trace of the\nslowest ``convolution.out`` call.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for event_block in inspector.event_blocks:\n    # Via EventBlocks\n    slowest = None\n    for event in event_block.events:\n        if event.name == \"native_call_convolution.out\":\n            if slowest is None or event.perf_data.p50 > slowest.perf_data.p50:\n                slowest = event\n    if slowest is not None:\n        print(slowest.name)\n        print()\n        pp.pprint(slowest.stack_traces)\n        print()\n        pp.pprint(slowest.module_hierarchy)\n\n    # Via Dataframe\n    df = event_block.to_dataframe()\n    df = df[df.event_name == \"native_call_convolution.out\"]\n    if len(df) > 0:\n        slowest = df.loc[df[\"p50\"].idxmax()]\n        assert slowest is not None\n        print(slowest.name)\n        print()\n        pp.pprint(slowest.stack_traces if slowest.stack_traces else \"\")\n        print()\n        pp.pprint(slowest.module_hierarchy if slowest.module_hierarchy else \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If a user wants the total runtime of a module, they can use\n``find_total_for_module``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(inspector.find_total_for_module(\"L__self__\"))\nprint(inspector.find_total_for_module(\"L__self___conv2\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: ``find_total_for_module`` is a special first class method of\n[Inspector](../model-inspector.html)_\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n\nIn this tutorial, we learned about the steps required to consume an ExecuTorch\nmodel with the ExecuTorch Developer Tools. It also showed how to use the Inspector APIs\nto analyze the model run results.\n\n### Links Mentioned\n\n- [ExecuTorch Developer Tools Overview](../devtools-overview.html)_\n- [ETRecord](../etrecord.html)_\n- [ETDump](../etdump.html)_\n- [Inspector](../model-inspector.html)_\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}