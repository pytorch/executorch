
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Managing Tensor Memory in C++ &#8212; ExecuTorch main documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=047068a3" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=a8da1a53"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'extension-tensor';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.15.4';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://docs.pytorch.org/executorch/executorch-versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'main';
        DOCUMENTATION_OPTIONS.show_version_warning_banner = true;
        </script>
    <link rel="canonical" href="https://docs.pytorch.org/executorch/extension-tensor.html" />
    <link rel="icon" href="_static/executorch-chip-logo.svg"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Backends" href="embedded-backends.html" />
    <link rel="prev" title="Running an ExecuTorch Model Using the Module Extension in C++" href="extension-module.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->


<link rel="stylesheet" type="text/css" href="_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="_static/js/theme.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="https://docs.pytorch.org/docs/stable/_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy"
  content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" height="0" width="0"
    style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'GTM-T8XT4PS');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'main');
</script>
<noscript>
  <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1" />
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Repository configuration for tutorials -->

<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>

  </head>

<body data-feedback-url="https://github.com/pytorch/executorch" class="pytorch-body">
  
    <div class="container-fluid header-holder tutorials-header" id="header-holder">
   <div class="header-container-wrapper">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                <span>Learn</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started/locally">
                  <span class=dropdown-title>Get Started</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/webinars/">
                  <span class="dropdown-title">Webinars</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Community</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Landscape</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/join-ecosystem">
                  <span class="dropdown-title">Join the Ecosystem</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-hub/">
                  <span class="dropdown-title">Community Hub</span>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/">
                  <span class="dropdown-title">Forums</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contributor-awards/">
                  <span class="dropdown-title">Contributor Awards</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-events/">
                  <span class="dropdown-title">Community Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/programs/ambassadors/">
                  <span class="dropdown-title">PyTorch Ambassadors</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Projects</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/pytorch/">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/vllm/">
                  <span class="dropdown-title">vLLM</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/deepspeed/">
                  <span class="dropdown-title">DeepSpeed</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/host-your-project/">
                  <span class="dropdown-title">Host Your Project</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/ray/">
                  <span class="dropdown-title">RAY</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span> Docs</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/domains">
                  <span class="dropdown-title">Domains</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Blogs & News</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">Blog</span>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/announcements">
                  <span class="dropdown-title">Announcements</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/case-studies/">
                  <span class="dropdown-title">Case Studies</span>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                </a>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>About</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/members">
                  <span class="dropdown-title">Members</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact">
                  <span class="dropdown-title">Contact</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/wp-content/uploads/2025/09/pytorch_brand_guide_091925a.pdf">
                  <span class="dropdown-title">Brand Guidelines</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown main-menu-button">
              <a href="https://pytorch.org/join" data-cta="join">
                JOIN
              </a>
            </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu">
        <i class="fa-solid fa-ellipsis"></i>
      </a>
    </div>
  </div>
 </div>

 <!-- Begin Mobile Menu -->

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="header-container-wrapper">
      <div class="mobile-main-menu-header-container">
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu">
        </a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">
    <div class="main-menu">
      <ul>
         <li class="resources-mobile-menu-title">
           <a>Learn</a>
         </li>
         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/get-started/locally">Get Started</a>
           </li>
           <li>
             <a href="https://docs.pytorch.org/tutorials">Tutorials</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
           </li>
           <li>
            <a href="https://pytorch.org/webinars/">Webinars</a>
          </li>
        </ul>
         <li class="resources-mobile-menu-title">
           <a>Community</a>
         </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://landscape.pytorch.org/">Landscape</a>
          </li>
          <li>
             <a href="https://pytorch.org/join-ecosystem">Join the Ecosystem</a>
           </li>
           <li>
             <a href="https://pytorch.org/community-hub/">Community Hub</a>
           </li>
           <li>
             <a href="https://discuss.pytorch.org/">Forums</a>
           </li>
           <li>
             <a href="https://pytorch.org/resources">Developer Resources</a>
           </li>
           <li>
             <a href="https://pytorch.org/contributor-awards/">Contributor Awards</a>
           </li>
           <li>
            <a href="https://pytorch.org/community-events/">Community Events</a>
          </li>
          <li>
            <a href="https://pytorch.org/programs/ambassadors/">PyTorch Ambassadors</a>
          </li>
       </ul>

         <li class="resources-mobile-menu-title">
           <a>Projects</a>
         </li>

         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/projects/pytorch/">PyTorch</a>
           </li>

           <li>
             <a href="https://pytorch.org/projects/vllm/">vLLM</a>
           </li>
           <li>
            <a href="https://pytorch.org/projects/deepspeed/">DeepSpeed</a>
          </li>
          <li>
             <a href="https://pytorch.org/projects/host-your-project/">Host Your Project</a>
           </li>
         </ul>

         <li class="resources-mobile-menu-title">
           <a>Docs</a>
         </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://docs.pytorch.org/docs/stable/index.html">PyTorch</a>
          </li>

          <li>
            <a href="https://pytorch.org/domains">Domains</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>Blog & News</a>
        </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>
          <li>
            <a href="https://pytorch.org/announcements">Announcements</a>
          </li>

          <li>
            <a href="https://pytorch.org/case-studies/">Case Studies</a>
          </li>
          <li>
            <a href="https://pytorch.org/events">Events</a>
          </li>
          <li>
             <a href="https://pytorch.org/newsletter">Newsletter</a>
           </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>About</a>
        </li>

        <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
          </li>
          <li>
            <a href="https://pytorch.org/members">Members</a>
          </li>
          <li>
            <a href="https://pytorch.org/governing-board">Governing Board</a>
          </li>
          <li>
            <a href="https://pytorch.org/tac">Technical Advisory Council</a>
         </li>
         <li>
             <a href="https://pytorch.org/credits">Cloud Credit Program</a>
          </li>
          <li>
             <a href="https://pytorch.org/staff">Staff</a>
          </li>
          <li>
             <a href="https://pytorch.org/contact">Contact</a>
          </li>
        </ul>
      </ul>
    </div>
  </div>
</div>

<!-- End Mobile Menu -->
  
  
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/et-logo.png" class="logo__image only-light" alt="ExecuTorch main documentation - Home"/>
    <script>document.write(`<img src="_static/et-logo.png" class="logo__image only-dark" alt="ExecuTorch main documentation - Home"/>`);</script>
  
  
</a></div>
    
      <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-2"
      type="button"
      class="version-switcher__button btn btn-sm dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-2"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-2"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-2">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="intro-section.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="quick-start-section.html">
    Quick Start
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="edge-platforms-section.html">
    Edge
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="backends-section.html">
    Backends
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="llm/working-with-llms.html">
    LLMs
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="advanced-topics-section.html">
    Advanced
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="tools-section.html">
    Tools
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="api-section.html">
    API
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="support-section.html">
    Support
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/executorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/executorch" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="intro-section.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="quick-start-section.html">
    Quick Start
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="edge-platforms-section.html">
    Edge
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="backends-section.html">
    Backends
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="llm/working-with-llms.html">
    LLMs
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="advanced-topics-section.html">
    Advanced
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="tools-section.html">
    Tools
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="api-section.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="support-section.html">
    Support
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/executorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/executorch" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"></div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="edge-platforms-section.html" class="nav-link">Edge</a></li>
    
    
    <li class="breadcrumb-item"><a href="embedded-section.html" class="nav-link">Embedded Systems</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Managing...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
  
<div id="searchbox"></div>
  <article class="bd-article" id="pytorch-article">
    <!-- Hidden breadcrumb schema for SEO only -->
    <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <link itemprop="item" href="edge-platforms-section.html">
        <meta itemprop="name" content="Edge">
        <meta itemprop="position" content="1">
      </div>
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <link itemprop="item" href="embedded-section.html">
        <meta itemprop="name" content="Embedded Systems">
        <meta itemprop="position" content="2">
      </div>
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <meta itemprop="name" content="Managing Tensor Memory in C++">
        <meta itemprop="position" content="3">
      </div>
    </div>

    
    

    
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="managing-tensor-memory-in-c">
<h1>Managing Tensor Memory in C++<a class="headerlink" href="#managing-tensor-memory-in-c" title="Link to this heading">#</a></h1>
<p><strong>Author:</strong> <a class="reference external" href="https://github.com/shoumikhin">Anthony Shoumikhin</a></p>
<p>Tensors are fundamental data structures in ExecuTorch, representing multi-dimensional arrays used in computations for neural networks and other numerical algorithms. In ExecuTorch, the <a class="reference external" href="https://github.com/pytorch/executorch/blob/main/runtime/core/portable_type/tensor.h">Tensor</a> class doesn’t own its metadata (sizes, strides, dim_order) or data, keeping the runtime lightweight. Users are responsible for supplying all these memory buffers and ensuring that the metadata and data outlive the <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> instance. While this design is lightweight and flexible, especially for tiny embedded systems, it places a significant burden on the user. If your environment requires minimal dynamic allocations, a small binary footprint, or limited C++ standard library support, you’ll need to accept that trade-off and stick with the regular <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> type.</p>
<p>Imagine you’re working with a <a class="reference internal" href="extension-module.html"><span class="std std-doc"><code class="docutils literal notranslate"><span class="pre">Module</span></code></span></a> interface, and you need to pass a <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> to the <code class="docutils literal notranslate"><span class="pre">forward()</span></code> method. You would need to declare and maintain at least the sizes array and data separately, sometimes the strides too, often leading to the following pattern:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;executorch/extension/module/module.h&gt;</span>

<span class="k">using</span><span class="w"> </span><span class="k">namespace</span><span class="w"> </span><span class="nn">executorch</span><span class="o">::</span><span class="nn">aten</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="k">namespace</span><span class="w"> </span><span class="nn">executorch</span><span class="o">::</span><span class="nn">extension</span><span class="p">;</span>

<span class="n">SizesType</span><span class="w"> </span><span class="n">sizes</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">};</span>
<span class="n">DimOrderType</span><span class="w"> </span><span class="n">dim_order</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">};</span>
<span class="n">StridesType</span><span class="w"> </span><span class="n">strides</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">};</span>
<span class="kt">float</span><span class="w"> </span><span class="n">data</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mf">1.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">2.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">3.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">4.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">5.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">6.0f</span><span class="p">};</span>
<span class="n">TensorImpl</span><span class="w"> </span><span class="nf">tensor_impl</span><span class="p">(</span>
<span class="w">    </span><span class="n">ScalarType</span><span class="o">::</span><span class="n">Float</span><span class="p">,</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">size</span><span class="p">(</span><span class="n">sizes</span><span class="p">),</span>
<span class="w">    </span><span class="n">sizes</span><span class="p">,</span>
<span class="w">    </span><span class="n">data</span><span class="p">,</span>
<span class="w">    </span><span class="n">dim_order</span><span class="p">,</span>
<span class="w">    </span><span class="n">strides</span><span class="p">);</span>
<span class="c1">// ...</span>
<span class="k">module</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tensor_impl</span><span class="p">));</span>
</pre></div>
</div>
<p>You must ensure <code class="docutils literal notranslate"><span class="pre">sizes</span></code>, <code class="docutils literal notranslate"><span class="pre">dim_order</span></code>, <code class="docutils literal notranslate"><span class="pre">strides</span></code>, and <code class="docutils literal notranslate"><span class="pre">data</span></code> stay valid. This makes code maintenance difficult and error-prone. Users have struggled to manage lifetimes, and many have created their own ad-hoc managed tensor abstractions to hold all the pieces together, leading to a fragmented and inconsistent ecosystem.</p>
<section id="introducing-tensorptr">
<h2>Introducing TensorPtr<a class="headerlink" href="#introducing-tensorptr" title="Link to this heading">#</a></h2>
<p>To alleviate these issues, ExecuTorch provides <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code>, a smart pointer that manages the lifecycle of both the tensor’s data and its dynamic metadata.</p>
<p>With <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code>, users no longer need to worry about metadata lifetimes separately. Data ownership is determined based on whether it is passed by pointer or moved into the <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> as an <code class="docutils literal notranslate"><span class="pre">std::vector</span></code>. Everything is bundled in one place and managed automatically, enabling you to focus on actual computations.</p>
<p>Here’s how you can use it:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;executorch/extension/module/module.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;executorch/extension/tensor/tensor.h&gt;</span>

<span class="k">using</span><span class="w"> </span><span class="k">namespace</span><span class="w"> </span><span class="nn">executorch</span><span class="o">::</span><span class="nn">extension</span><span class="p">;</span>

<span class="k">auto</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">make_tensor_ptr</span><span class="p">(</span>
<span class="w">    </span><span class="p">{</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">},</span><span class="w">                                </span><span class="c1">// sizes</span>
<span class="w">    </span><span class="p">{</span><span class="mf">1.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">2.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">3.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">4.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">5.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">6.0f</span><span class="p">});</span><span class="w"> </span><span class="c1">// data</span>
<span class="c1">// ...</span>
<span class="k">module</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">tensor</span><span class="p">);</span>
</pre></div>
</div>
<p>The data is now owned by the tensor instance because it’s provided as a vector. To create a non-owning <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code>, just pass the data by pointer. The <code class="docutils literal notranslate"><span class="pre">type</span></code> is deduced automatically based on the data vector (<code class="docutils literal notranslate"><span class="pre">float</span></code>). <code class="docutils literal notranslate"><span class="pre">strides</span></code> and <code class="docutils literal notranslate"><span class="pre">dim_order</span></code> are computed automatically to default values based on the <code class="docutils literal notranslate"><span class="pre">sizes</span></code> if not specified explicitly as additional arguments.</p>
<p><code class="docutils literal notranslate"><span class="pre">EValue</span></code> in <code class="docutils literal notranslate"><span class="pre">Module::forward()</span></code> accepts <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> directly, ensuring seamless integration. <code class="docutils literal notranslate"><span class="pre">EValue</span></code> can now be constructed implicitly with a smart pointer to any type that it can hold. This allows <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> to be dereferenced implicitly when passed to <code class="docutils literal notranslate"><span class="pre">forward()</span></code>, and <code class="docutils literal notranslate"><span class="pre">EValue</span></code> will hold the <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> that the <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> points to.</p>
</section>
<section id="api-overview">
<h2>API Overview<a class="headerlink" href="#api-overview" title="Link to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> is literally an alias for <code class="docutils literal notranslate"><span class="pre">std::shared_ptr&lt;Tensor&gt;</span></code>, so you can work with it easily without duplicating the data and metadata. Each <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> instance may either own its data or reference external data.</p>
<section id="creating-tensors">
<h3>Creating Tensors<a class="headerlink" href="#creating-tensors" title="Link to this heading">#</a></h3>
<p>There are several ways to create a <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code>.</p>
<section id="creating-scalar-tensors">
<h4>Creating Scalar Tensors<a class="headerlink" href="#creating-scalar-tensors" title="Link to this heading">#</a></h4>
<p>You can create a scalar tensor, i.e. a tensor with zero dimensions or with one of the sizes being zero.</p>
<p><em>Providing A Single Data Value</em></p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">make_tensor_ptr</span><span class="p">(</span><span class="mf">3.14</span><span class="p">);</span>
</pre></div>
</div>
<p>The resulting tensor will contain a single value <code class="docutils literal notranslate"><span class="pre">3.14</span></code> of type double, which is deduced automatically.</p>
<p><em>Providing A Single Data Value with a Type</em></p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">make_tensor_ptr</span><span class="p">(</span><span class="mi">42</span><span class="p">,</span><span class="w"> </span><span class="n">ScalarType</span><span class="o">::</span><span class="n">Float</span><span class="p">);</span>
</pre></div>
</div>
<p>Now the integer <code class="docutils literal notranslate"><span class="pre">42</span></code> will be cast to float and the tensor will contain a single value <code class="docutils literal notranslate"><span class="pre">42</span></code> of type float.</p>
</section>
<section id="owning-data-from-a-vector">
<h4>Owning Data from a Vector<a class="headerlink" href="#owning-data-from-a-vector" title="Link to this heading">#</a></h4>
<p>When you provide sizes and data vectors, <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> takes ownership of both the data and the sizes.</p>
<p><em>Providing Data Vector</em></p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">make_tensor_ptr</span><span class="p">(</span>
<span class="w">    </span><span class="p">{</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">},</span><span class="w">                                 </span><span class="c1">// sizes</span>
<span class="w">    </span><span class="p">{</span><span class="mf">1.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">2.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">3.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">4.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">5.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">6.0f</span><span class="p">});</span><span class="w">  </span><span class="c1">// data (float)</span>
</pre></div>
</div>
<p>The type is deduced automatically as <code class="docutils literal notranslate"><span class="pre">ScalarType::Float</span></code> from the data vector.</p>
<p><em>Providing Data Vector with a Type</em></p>
<p>If you provide data of one type but specify a different scalar type, the data will be cast to the given type.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">make_tensor_ptr</span><span class="p">(</span>
<span class="w">    </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="mi">6</span><span class="p">},</span><span class="w">          </span><span class="c1">// data (int)</span>
<span class="w">    </span><span class="n">ScalarType</span><span class="o">::</span><span class="n">Double</span><span class="p">);</span><span class="w">         </span><span class="c1">// double scalar type</span>
</pre></div>
</div>
<p>In this example, even though the data vector contains integers, we specify the scalar type as <code class="docutils literal notranslate"><span class="pre">Double</span></code>. The integers are cast to double, and the new data vector is owned by the <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code>. Since the <code class="docutils literal notranslate"><span class="pre">sizes</span></code> argument is skipped in this example, the tensor is one-dimensional with a size equal to the length of the data vector. Note that the reverse cast, from a floating-point type to an integral type, is not allowed because that loses precision. Similarly, casting other types to <code class="docutils literal notranslate"><span class="pre">Bool</span></code> is disallowed.</p>
<p><em>Providing Data Vector as <code class="docutils literal notranslate"><span class="pre">std::vector&lt;uint8_t&gt;</span></code></em></p>
<p>You can also provide raw data in the form of a <code class="docutils literal notranslate"><span class="pre">std::vector&lt;uint8_t&gt;</span></code>, specifying the sizes and scalar type. The data will be reinterpreted according to the provided type.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="cm">/* raw data */</span><span class="p">;</span>
<span class="k">auto</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">make_tensor_ptr</span><span class="p">(</span>
<span class="w">    </span><span class="p">{</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">},</span><span class="w">                 </span><span class="c1">// sizes</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">data</span><span class="p">),</span><span class="w">        </span><span class="c1">// data as uint8_t vector</span>
<span class="w">    </span><span class="n">ScalarType</span><span class="o">::</span><span class="n">Int</span><span class="p">);</span><span class="w">       </span><span class="c1">// int scalar type</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">data</span></code> vector must be large enough to accommodate all the elements according to the provided sizes and scalar type.</p>
</section>
<section id="non-owning-data-from-raw-pointer">
<h4>Non-Owning Data from Raw Pointer<a class="headerlink" href="#non-owning-data-from-raw-pointer" title="Link to this heading">#</a></h4>
<p>You can create a <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> that references existing data without taking ownership.</p>
<p><em>Providing Raw Data</em></p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">float</span><span class="w"> </span><span class="n">data</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mf">1.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">2.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">3.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">4.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">5.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">6.0f</span><span class="p">};</span>
<span class="k">auto</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">make_tensor_ptr</span><span class="p">(</span>
<span class="w">    </span><span class="p">{</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">},</span><span class="w">              </span><span class="c1">// sizes</span>
<span class="w">    </span><span class="n">data</span><span class="p">,</span><span class="w">                </span><span class="c1">// raw data pointer</span>
<span class="w">    </span><span class="n">ScalarType</span><span class="o">::</span><span class="n">Float</span><span class="p">);</span><span class="w">  </span><span class="c1">// float scalar type</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> does not own the data, so you must ensure the <code class="docutils literal notranslate"><span class="pre">data</span></code> remains valid.</p>
<p><em>Providing Raw Data with Custom Deleter</em></p>
<p>If you want the <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> to manage the lifetime of the data, you can provide a custom deleter.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="o">*</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="kt">double</span><span class="p">[</span><span class="mi">6</span><span class="p">]{</span><span class="mf">1.0</span><span class="p">,</span><span class="w"> </span><span class="mf">2.0</span><span class="p">,</span><span class="w"> </span><span class="mf">3.0</span><span class="p">,</span><span class="w"> </span><span class="mf">4.0</span><span class="p">,</span><span class="w"> </span><span class="mf">5.0</span><span class="p">,</span><span class="w"> </span><span class="mf">6.0</span><span class="p">};</span>
<span class="k">auto</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">make_tensor_ptr</span><span class="p">(</span>
<span class="w">    </span><span class="p">{</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">},</span><span class="w">                               </span><span class="c1">// sizes</span>
<span class="w">    </span><span class="n">data</span><span class="p">,</span><span class="w">                                 </span><span class="c1">// data pointer</span>
<span class="w">    </span><span class="n">ScalarType</span><span class="o">::</span><span class="n">Double</span><span class="p">,</span><span class="w">                   </span><span class="c1">// double scalar type</span>
<span class="w">    </span><span class="n">TensorShapeDynamism</span><span class="o">::</span><span class="n">DYNAMIC_BOUND</span><span class="p">,</span><span class="w">   </span><span class="c1">// default dynamism</span>
<span class="w">    </span><span class="p">[](</span><span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">ptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">delete</span><span class="p">[]</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">ptr</span><span class="p">);</span><span class="w"> </span><span class="p">});</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> will call the custom deleter when it is destroyed, i.e., when the smart pointer is reset and no more references to the underlying <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> exist.</p>
</section>
<section id="sharing-existing-tensor">
<h4>Sharing Existing Tensor<a class="headerlink" href="#sharing-existing-tensor" title="Link to this heading">#</a></h4>
<p>Since <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> is a <code class="docutils literal notranslate"><span class="pre">std::shared_ptr&lt;Tensor&gt;</span></code>, you can easily create a <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> that shares an existing <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>. Any changes made to the shared data are reflected across all instances sharing the same data.</p>
<p><em>Sharing Existing TensorPtr</em></p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">make_tensor_ptr</span><span class="p">({</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mf">1.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">2.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">3.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">4.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">5.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">6.0f</span><span class="p">});</span>
<span class="k">auto</span><span class="w"> </span><span class="n">tensor_copy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tensor</span><span class="p">;</span>
</pre></div>
</div>
<p>Now <code class="docutils literal notranslate"><span class="pre">tensor</span></code> and <code class="docutils literal notranslate"><span class="pre">tensor_copy</span></code> point to the same data and metadata.</p>
</section>
<section id="viewing-existing-tensor">
<h4>Viewing Existing Tensor<a class="headerlink" href="#viewing-existing-tensor" title="Link to this heading">#</a></h4>
<p>You can create a <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> from an existing <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, copying its properties and referencing the same data.</p>
<p><em>Viewing Existing Tensor</em></p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Tensor</span><span class="w"> </span><span class="n">original_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="cm">/* some existing tensor */</span><span class="p">;</span>
<span class="k">auto</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">make_tensor_ptr</span><span class="p">(</span><span class="n">original_tensor</span><span class="p">);</span>
</pre></div>
</div>
<p>Now the newly created <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> references the same data as the original tensor, but has its own metadata copy, so it can interpret or “view” the data differently, but any modifications to the data will be reflected in the original <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> as well.</p>
</section>
</section>
<section id="cloning-tensors">
<h3>Cloning Tensors<a class="headerlink" href="#cloning-tensors" title="Link to this heading">#</a></h3>
<p>To create a new <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> that owns a copy of the data from an existing tensor:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">Tensor</span><span class="w"> </span><span class="n">original_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="cm">/* some existing tensor */</span><span class="p">;</span>
<span class="k">auto</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clone_tensor_ptr</span><span class="p">(</span><span class="n">original_tensor</span><span class="p">);</span>
</pre></div>
</div>
<p>The newly created <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> has its own copy of the data, so it can modify and manage it independently.
Likewise, you can create a clone of an existing <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code>.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">original_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">make_tensor_ptr</span><span class="p">(</span><span class="cm">/* ... */</span><span class="p">);</span>
<span class="k">auto</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clone_tensor_ptr</span><span class="p">(</span><span class="n">original_tensor</span><span class="p">);</span>
</pre></div>
</div>
<p>Note that, regardless of whether the original <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> owns the data or not, the newly created <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> will own a copy of the data.</p>
</section>
<section id="resizing-tensors">
<h3>Resizing Tensors<a class="headerlink" href="#resizing-tensors" title="Link to this heading">#</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">TensorShapeDynamism</span></code> enum specifies the mutability of a tensor’s shape:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">STATIC</span></code>: The tensor’s shape cannot be changed.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DYNAMIC_BOUND</span></code>: The tensor’s shape can be changed but cannot contain more elements than it originally had at creation based on the initial sizes.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DYNAMIC</span></code>: The tensor’s shape can be changed arbitrarily. Currently, <code class="docutils literal notranslate"><span class="pre">DYNAMIC</span></code> is an alias for <code class="docutils literal notranslate"><span class="pre">DYNAMIC_BOUND</span></code>.</p></li>
</ul>
<p>When resizing a tensor, you must respect its dynamism setting. Resizing is only allowed for tensors with <code class="docutils literal notranslate"><span class="pre">DYNAMIC</span></code> or <code class="docutils literal notranslate"><span class="pre">DYNAMIC_BOUND</span></code> shapes, and you cannot resize <code class="docutils literal notranslate"><span class="pre">DYNAMIC_BOUND</span></code> tensors to contain more elements than they had initially.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">make_tensor_ptr</span><span class="p">(</span>
<span class="w">    </span><span class="p">{</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">},</span><span class="w">                      </span><span class="c1">// sizes</span>
<span class="w">    </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="mi">6</span><span class="p">},</span><span class="w">          </span><span class="c1">// data</span>
<span class="w">    </span><span class="n">ScalarType</span><span class="o">::</span><span class="n">Int</span><span class="p">,</span>
<span class="w">    </span><span class="n">TensorShapeDynamism</span><span class="o">::</span><span class="n">DYNAMIC_BOUND</span><span class="p">);</span>
<span class="c1">// Initial sizes: {2, 3}</span>
<span class="c1">// Number of elements: 6</span>

<span class="n">resize_tensor_ptr</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">});</span>
<span class="c1">// The tensor sizes are now {2, 2}</span>
<span class="c1">// Number of elements is 4 &lt; initial 6</span>

<span class="n">resize_tensor_ptr</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">});</span>
<span class="c1">// The tensor sizes are now {1, 3}</span>
<span class="c1">// Number of elements is 3 &lt; initial 6</span>

<span class="n">resize_tensor_ptr</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">});</span>
<span class="c1">// The tensor sizes are now {3, 2}</span>
<span class="c1">// Number of elements is 6 == initial 6</span>

<span class="n">resize_tensor_ptr</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="mi">6</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">});</span>
<span class="c1">// The tensor sizes are now {6, 1}</span>
<span class="c1">// Number of elements is 6 == initial 6</span>
</pre></div>
</div>
</section>
</section>
<section id="convenience-helpers">
<h2>Convenience Helpers<a class="headerlink" href="#convenience-helpers" title="Link to this heading">#</a></h2>
<p>ExecuTorch provides several helper functions to create tensors conveniently.</p>
<section id="creating-non-owning-tensors-with-for-blob-and-from-blob">
<h3>Creating Non-Owning Tensors with <code class="docutils literal notranslate"><span class="pre">for_blob</span></code> and <code class="docutils literal notranslate"><span class="pre">from_blob</span></code><a class="headerlink" href="#creating-non-owning-tensors-with-for-blob-and-from-blob" title="Link to this heading">#</a></h3>
<p>These helpers allow you to create tensors that do not own the data.</p>
<p><em>Using <code class="docutils literal notranslate"><span class="pre">from_blob()</span></code></em></p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">float</span><span class="w"> </span><span class="n">data</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mf">1.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">2.0f</span><span class="p">,</span><span class="w"> </span><span class="mf">3.0f</span><span class="p">};</span>
<span class="k">auto</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">from_blob</span><span class="p">(</span>
<span class="w">    </span><span class="n">data</span><span class="p">,</span><span class="w">                </span><span class="c1">// data pointer</span>
<span class="w">    </span><span class="p">{</span><span class="mi">3</span><span class="p">},</span><span class="w">                 </span><span class="c1">// sizes</span>
<span class="w">    </span><span class="n">ScalarType</span><span class="o">::</span><span class="n">Float</span><span class="p">);</span><span class="w">  </span><span class="c1">// float scalar type</span>
</pre></div>
</div>
<p><em>Using <code class="docutils literal notranslate"><span class="pre">for_blob()</span></code> with Fluent Syntax</em></p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">double</span><span class="w"> </span><span class="n">data</span><span class="p">[]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mf">1.0</span><span class="p">,</span><span class="w"> </span><span class="mf">2.0</span><span class="p">,</span><span class="w"> </span><span class="mf">3.0</span><span class="p">,</span><span class="w"> </span><span class="mf">4.0</span><span class="p">,</span><span class="w"> </span><span class="mf">5.0</span><span class="p">,</span><span class="w"> </span><span class="mf">6.0</span><span class="p">};</span>
<span class="k">auto</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">for_blob</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">},</span><span class="w"> </span><span class="n">ScalarType</span><span class="o">::</span><span class="n">Double</span><span class="p">)</span>
<span class="w">                  </span><span class="p">.</span><span class="n">strides</span><span class="p">({</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">})</span>
<span class="w">                  </span><span class="p">.</span><span class="n">dynamism</span><span class="p">(</span><span class="n">TensorShapeDynamism</span><span class="o">::</span><span class="n">STATIC</span><span class="p">)</span>
<span class="w">                  </span><span class="p">.</span><span class="n">make_tensor_ptr</span><span class="p">();</span>
</pre></div>
</div>
<p><em>Using Custom Deleter with <code class="docutils literal notranslate"><span class="pre">from_blob()</span></code></em></p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="kt">int</span><span class="p">[</span><span class="mi">3</span><span class="p">]{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">};</span>
<span class="k">auto</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">from_blob</span><span class="p">(</span>
<span class="w">    </span><span class="n">data</span><span class="p">,</span><span class="w">             </span><span class="c1">// data pointer</span>
<span class="w">    </span><span class="p">{</span><span class="mi">3</span><span class="p">},</span><span class="w">              </span><span class="c1">// sizes</span>
<span class="w">    </span><span class="n">ScalarType</span><span class="o">::</span><span class="n">Int</span><span class="p">,</span><span class="w">  </span><span class="c1">// int scalar type</span>
<span class="w">    </span><span class="p">[](</span><span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">ptr</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">delete</span><span class="p">[]</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">ptr</span><span class="p">);</span><span class="w"> </span><span class="p">});</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> will call the custom deleter when it is destroyed.</p>
</section>
<section id="creating-empty-tensors">
<h3>Creating Empty Tensors<a class="headerlink" href="#creating-empty-tensors" title="Link to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">empty()</span></code> creates an uninitialized tensor with sizes specified.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">empty</span><span class="p">({</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">});</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">empty_like()</span></code> creates an uninitialized tensor with the same sizes as an existing <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code>.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">TensorPtr</span><span class="w"> </span><span class="n">original_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="cm">/* some existing tensor */</span><span class="p">;</span>
<span class="k">auto</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">empty_like</span><span class="p">(</span><span class="n">original_tensor</span><span class="p">);</span>
</pre></div>
</div>
<p>And <code class="docutils literal notranslate"><span class="pre">empty_strided()</span></code> creates an uninitialized tensor with sizes and strides specified.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">empty_strided</span><span class="p">({</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">});</span>
</pre></div>
</div>
</section>
<section id="creating-tensors-filled-with-specific-values">
<h3>Creating Tensors Filled with Specific Values<a class="headerlink" href="#creating-tensors-filled-with-specific-values" title="Link to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">full()</span></code>, <code class="docutils literal notranslate"><span class="pre">zeros()</span></code> and <code class="docutils literal notranslate"><span class="pre">ones()</span></code> create a tensor filled with a provided value, zeros or ones respectively.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">tensor_full</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">full</span><span class="p">({</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">},</span><span class="w"> </span><span class="mf">42.0f</span><span class="p">);</span>
<span class="k">auto</span><span class="w"> </span><span class="n">tensor_zeros</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">zeros</span><span class="p">({</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">});</span>
<span class="k">auto</span><span class="w"> </span><span class="n">tensor_ones</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ones</span><span class="p">({</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">});</span>
</pre></div>
</div>
<p>Similarly to <code class="docutils literal notranslate"><span class="pre">empty()</span></code>, there are extra helper functions <code class="docutils literal notranslate"><span class="pre">full_like()</span></code>, <code class="docutils literal notranslate"><span class="pre">full_strided()</span></code>, <code class="docutils literal notranslate"><span class="pre">zeros_like()</span></code>, <code class="docutils literal notranslate"><span class="pre">zeros_strided()</span></code>, <code class="docutils literal notranslate"><span class="pre">ones_like()</span></code> and <code class="docutils literal notranslate"><span class="pre">ones_strided()</span></code> to create filled tensors with the same properties as an existing <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> or with custom strides.</p>
</section>
<section id="creating-random-tensors">
<h3>Creating Random Tensors<a class="headerlink" href="#creating-random-tensors" title="Link to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">rand()</span></code> creates a tensor filled with random values between 0 and 1.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">tensor_rand</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rand</span><span class="p">({</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">});</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">randn()</span></code> creates a tensor filled with random values from a normal distribution.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">tensor_randn</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">randn</span><span class="p">({</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">});</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">randint()</span></code> creates a tensor filled with random integers between min (inclusive) and max (exclusive) integers specified.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">tensor_randint</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">});</span>
</pre></div>
</div>
</section>
<section id="id1">
<h3>Creating Scalar Tensors<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<p>In addition to <code class="docutils literal notranslate"><span class="pre">make_tensor_ptr()</span></code> with a single data value, you can create a scalar tensor with <code class="docutils literal notranslate"><span class="pre">scalar_tensor()</span></code>.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">scalar_tensor</span><span class="p">(</span><span class="mf">3.14f</span><span class="p">);</span>
</pre></div>
</div>
<p>Note that the <code class="docutils literal notranslate"><span class="pre">scalar_tensor()</span></code> function expects a value of type <code class="docutils literal notranslate"><span class="pre">Scalar</span></code>. In ExecuTorch, <code class="docutils literal notranslate"><span class="pre">Scalar</span></code> can represent <code class="docutils literal notranslate"><span class="pre">bool</span></code>, <code class="docutils literal notranslate"><span class="pre">int</span></code>, or floating-point types, but not types like <code class="docutils literal notranslate"><span class="pre">Half</span></code> or <code class="docutils literal notranslate"><span class="pre">BFloat16</span></code>, etc. for which you’d need to use <code class="docutils literal notranslate"><span class="pre">make_tensor_ptr()</span></code> to skip the <code class="docutils literal notranslate"><span class="pre">Scalar</span></code> type.</p>
</section>
</section>
<section id="notes-on-evalue-and-lifetime-management">
<h2>Notes on EValue and Lifetime Management<a class="headerlink" href="#notes-on-evalue-and-lifetime-management" title="Link to this heading">#</a></h2>
<p>The <a class="reference internal" href="extension-module.html"><span class="std std-doc"><code class="docutils literal notranslate"><span class="pre">Module</span></code></span></a> interface expects data in the form of <code class="docutils literal notranslate"><span class="pre">EValue</span></code>, a variant type that can hold a <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> or other scalar types. When you pass a <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> to a function expecting an <code class="docutils literal notranslate"><span class="pre">EValue</span></code>, you can dereference the <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> to get the underlying <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">TensorPtr</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="cm">/* create a TensorPtr */</span>
<span class="c1">//...</span>
<span class="k">module</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">tensor</span><span class="p">);</span>
</pre></div>
</div>
<p>Or even a vector of <code class="docutils literal notranslate"><span class="pre">EValues</span></code> for multiple parameters.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">TensorPtr</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="cm">/* create a TensorPtr */</span>
<span class="n">TensorPtr</span><span class="w"> </span><span class="n">tensor2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="cm">/* create another TensorPtr */</span>
<span class="c1">//...</span>
<span class="k">module</span><span class="p">.</span><span class="n">forward</span><span class="p">({</span><span class="n">tensor</span><span class="p">,</span><span class="w"> </span><span class="n">tensor2</span><span class="p">});</span>
</pre></div>
</div>
<p>However, be cautious: <code class="docutils literal notranslate"><span class="pre">EValue</span></code> will not hold onto the dynamic data and metadata from the <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code>. It merely holds a regular <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, which does not own the data or metadata but refers to them using raw pointers. You need to ensure that the <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> remains valid for as long as the <code class="docutils literal notranslate"><span class="pre">EValue</span></code> is in use.</p>
<p>This also applies when using functions like <code class="docutils literal notranslate"><span class="pre">set_input()</span></code> or <code class="docutils literal notranslate"><span class="pre">set_output()</span></code> that expect <code class="docutils literal notranslate"><span class="pre">EValue</span></code>.</p>
</section>
<section id="interoperability-with-aten">
<h2>Interoperability with ATen<a class="headerlink" href="#interoperability-with-aten" title="Link to this heading">#</a></h2>
<p>If your code is compiled with the preprocessor flag <code class="docutils literal notranslate"><span class="pre">USE_ATEN_LIB</span></code> enabled, all the <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> APIs will use <code class="docutils literal notranslate"><span class="pre">at::</span></code> APIs under the hood. E.g. <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> becomes a <code class="docutils literal notranslate"><span class="pre">std::shared_ptr&lt;at::Tensor&gt;</span></code>. This allows for seamless integration with <a class="reference external" href="https://pytorch.org/cppdocs">PyTorch ATen</a> library.</p>
<section id="api-equivalence-table">
<h3>API Equivalence Table<a class="headerlink" href="#api-equivalence-table" title="Link to this heading">#</a></h3>
<p>Here’s a table matching <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> creation functions with their corresponding ATen APIs:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>ATen</p></th>
<th class="head"><p>ExecuTorch</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">at::tensor(data,</span> <span class="pre">type)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">make_tensor_ptr(data,</span> <span class="pre">type)</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">at::tensor(data,</span> <span class="pre">type).reshape(sizes)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">make_tensor_ptr(sizes,</span> <span class="pre">data,</span> <span class="pre">type)</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">tensor.clone()</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">clone_tensor_ptr(tensor)</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">tensor.resize_(new_sizes)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">resize_tensor_ptr(tensor,</span> <span class="pre">new_sizes)</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">at::scalar_tensor(value)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">scalar_tensor(value)</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">at::from_blob(data,</span> <span class="pre">sizes,</span> <span class="pre">type)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">from_blob(data,</span> <span class="pre">sizes,</span> <span class="pre">type)</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">at::empty(sizes)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">empty(sizes)</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">at::empty_like(tensor)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">empty_like(tensor)</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">at::empty_strided(sizes,</span> <span class="pre">strides)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">empty_strided(sizes,</span> <span class="pre">strides)</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">at::full(sizes,</span> <span class="pre">value)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">full(sizes,</span> <span class="pre">value)</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">at::full_like(tensor,</span> <span class="pre">value)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">full_like(tensor,</span> <span class="pre">value)</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">at::full_strided(sizes,</span> <span class="pre">strides,</span> <span class="pre">value)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">full_strided(sizes,</span> <span class="pre">strides,</span> <span class="pre">value)</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">at::zeros(sizes)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">zeros(sizes)</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">at::zeros_like(tensor)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">zeros_like(tensor)</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">at::zeros_strided(sizes,</span> <span class="pre">strides)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">zeros_strided(sizes,</span> <span class="pre">strides)</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">at::ones(sizes)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ones(sizes)</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">at::ones_like(tensor)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ones_like(tensor)</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">at::ones_strided(sizes,</span> <span class="pre">strides)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ones_strided(sizes,</span> <span class="pre">strides)</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">at::rand(sizes)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">rand(sizes)</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">at::rand_like(tensor)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">rand_like(tensor)</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">at::randn(sizes)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">randn(sizes)</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">at::randn_like(tensor)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">randn_like(tensor)</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">at::randint(low,</span> <span class="pre">high,</span> <span class="pre">sizes)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">randint(low,</span> <span class="pre">high,</span> <span class="pre">sizes)</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">at::randint_like(tensor,</span> <span class="pre">low,</span> <span class="pre">high)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">randint_like(tensor,</span> <span class="pre">low,</span> <span class="pre">high)</span></code></p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section id="best-practices">
<h2>Best Practices<a class="headerlink" href="#best-practices" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><em>Manage Lifetimes Carefully</em>: Even though <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> handles memory management, ensure that any non-owned data (e.g., when using <code class="docutils literal notranslate"><span class="pre">from_blob()</span></code>) remains valid while the tensor is in use.</p></li>
<li><p><em>Use Convenience Functions</em>: Utilize helper functions for common tensor creation patterns to write cleaner and more readable code.</p></li>
<li><p><em>Be Aware of Data Ownership</em>: Know whether your tensor owns its data or references external data to avoid unintended side effects or memory leaks.</p></li>
<li><p><em>Ensure <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> Outlives <code class="docutils literal notranslate"><span class="pre">EValue</span></code></em>: When passing tensors to modules that expect <code class="docutils literal notranslate"><span class="pre">EValue</span></code>, ensure that the <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> remains valid as long as the <code class="docutils literal notranslate"><span class="pre">EValue</span></code> is in use.</p></li>
</ul>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">TensorPtr</span></code> in ExecuTorch simplifies tensor memory management by bundling the data and dynamic metadata into a smart pointer. This design eliminates the need for users to manage multiple pieces of data and ensures safer and more maintainable code.</p>
<p>By providing interfaces similar to PyTorch’s ATen library, ExecuTorch simplifies the adoption of the new API, allowing developers to transition without a steep learning curve.</p>
</section>
</section>


                </article>
              
  </article>
  
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
    <a class="left-prev"
       href="extension-module.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Running an ExecuTorch Model Using the Module Extension in C++</p>
      </div>
    </a>
    <a class="right-next"
       href="embedded-backends.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Backends</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>

<div class="footer-info">
  <p class="copyright">
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="extension-module.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Running an ExecuTorch Model Using the Module Extension in C++</p>
      </div>
    </a>
    <a class="right-next"
       href="embedded-backends.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Backends</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introducing-tensorptr">Introducing TensorPtr</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#api-overview">API Overview</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-tensors">Creating Tensors</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-scalar-tensors">Creating Scalar Tensors</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#owning-data-from-a-vector">Owning Data from a Vector</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#non-owning-data-from-raw-pointer">Non-Owning Data from Raw Pointer</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sharing-existing-tensor">Sharing Existing Tensor</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#viewing-existing-tensor">Viewing Existing Tensor</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cloning-tensors">Cloning Tensors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#resizing-tensors">Resizing Tensors</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#convenience-helpers">Convenience Helpers</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-non-owning-tensors-with-for-blob-and-from-blob">Creating Non-Owning Tensors with <code class="docutils literal notranslate"><span class="pre">for_blob</span></code> and <code class="docutils literal notranslate"><span class="pre">from_blob</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-empty-tensors">Creating Empty Tensors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-tensors-filled-with-specific-values">Creating Tensors Filled with Specific Values</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-random-tensors">Creating Random Tensors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Creating Scalar Tensors</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#notes-on-evalue-and-lifetime-management">Notes on EValue and Lifetime Management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interoperability-with-aten">Interoperability with ATen</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#api-equivalence-table">API Equivalence Table</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#best-practices">Best Practices</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
  </nav></div>
    
       <div class="sidebar-secondary-item">

  
  <div class="tocsection editthispage">
    <a href="https://github.com/pytorch/executorch/edit/main/docs/source/extension-tensor.md">
      <i class="fa-solid fa-pencil"></i>
      
      
        
          Edit on GitHub
        
      
    </a>
  </div>
</div>
    
       <div class="sidebar-secondary-item">
    <div class="tocsection sourcelink">
      <a href="_sources/extension-tensor.md.txt">
        <i class="fa-solid fa-file-lines"></i> Show Source
      </a>
    </div>
</div>
    




</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  

<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4">
        <h2>Docs</h2>
        <p>Access comprehensive developer documentation for PyTorch</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/docs/stable/index.html">View Docs</a>
      </div>

      <div class="col-md-4">
        <h2>Tutorials</h2>
        <p>Get in-depth tutorials for beginners and advanced developers</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/tutorials">View Tutorials</a>
      </div>

      <div class="col-md-4">
        <h2>Resources</h2>
        <p>Find development resources and get your questions answered</p>
        <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
      </div>
    </div>
  </div>
</div>




<footer class="site-footer">

  <div class="container footer-container">

    <div class="newsletter" id="newsletter">

      <p class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and
        the latest news</p>


      <script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/embed/v2.js"></script>
      <script>
        hbspt.forms.create({
          region: "na1",
          portalId: "8112310",
          formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
        });
      </script>


      <p class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its
        projects regarding their events, training, research, developments, and related announcements. I understand that
        I can unsubscribe at any time using the links in the footers of the emails I receive. <a
          href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>

    </div>

    <div class="lf-grid">
      <ul class="social-links">
        <li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-0.51 -0.26 26.45 26.45" aria-label="Facebook">
              <path fill="currentColor"
                d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z" />
            </svg>
          </a></li>
        <li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 300 300" aria-label="X">
              <path fill="currentColor"
                d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66" />
            </svg>
          </a></li>
        <li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0.21 0.27 34.45 25.07" aria-label="YouTube">
              <path fill="currentColor"
                d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z" />
            </svg>
          </a></li>
        <li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-10.23 -10.23 531.96 531.96" aria-label="LinkedIn">
              <rect width="512" height="512" rx="0" fill="currentColor" />
              <circle fill="#000" cx="142" cy="138" r="37" />
              <path stroke="#000" stroke-width="66" d="M244 194v198M142 194v198" />
              <path fill="#000"
                d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32" />
            </svg>
          </a></li>
        <li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.16 -0.03 21.19 21.19" aria-label="Slack">
              <path fill="currentColor"
                d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z">
              </path>
            </svg>
          </a></li>
        <li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.14 -0.17 38.02 33.02" aria-label="WeChat">
              <path fill="currentColor"
                d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z">
              </path>
              <path fill="currentColor"
                d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z">
              </path>
            </svg>
          </a></li>
      </ul>
    </div>
    
    <div class="privacy-policy">
      <div class="copyright">
      
        <p>
          &copy; PyTorch. Copyright © The Linux Foundation®. All rights reserved. The Linux Foundation has registered
          trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark
          usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a
            href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a
            href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
        </p>
        
      </div>
    </div>


  </div>
</footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/img/pytorch-x.svg">
  </div>
</div>
  
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2024, ExecuTorch.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  <script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "Managing Tensor Memory in C++",
       "headline": "Managing Tensor Memory in C++",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/extension-tensor.html",
       "articleBody": "Managing Tensor Memory in C++# Author: Anthony Shoumikhin Tensors are fundamental data structures in ExecuTorch, representing multi-dimensional arrays used in computations for neural networks and other numerical algorithms. In ExecuTorch, the Tensor class doesn\u2019t own its metadata (sizes, strides, dim_order) or data, keeping the runtime lightweight. Users are responsible for supplying all these memory buffers and ensuring that the metadata and data outlive the Tensor instance. While this design is lightweight and flexible, especially for tiny embedded systems, it places a significant burden on the user. If your environment requires minimal dynamic allocations, a small binary footprint, or limited C++ standard library support, you\u2019ll need to accept that trade-off and stick with the regular Tensor type. Imagine you\u2019re working with a Module interface, and you need to pass a Tensor to the forward() method. You would need to declare and maintain at least the sizes array and data separately, sometimes the strides too, often leading to the following pattern: #include \u003cexecutorch/extension/module/module.h\u003e using namespace executorch::aten; using namespace executorch::extension; SizesType sizes[] = {2, 3}; DimOrderType dim_order[] = {0, 1}; StridesType strides[] = {3, 1}; float data[] = {1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 6.0f}; TensorImpl tensor_impl( ScalarType::Float, std::size(sizes), sizes, data, dim_order, strides); // ... module.forward(Tensor(\u0026tensor_impl)); You must ensure sizes, dim_order, strides, and data stay valid. This makes code maintenance difficult and error-prone. Users have struggled to manage lifetimes, and many have created their own ad-hoc managed tensor abstractions to hold all the pieces together, leading to a fragmented and inconsistent ecosystem. Introducing TensorPtr# To alleviate these issues, ExecuTorch provides TensorPtr, a smart pointer that manages the lifecycle of both the tensor\u2019s data and its dynamic metadata. With TensorPtr, users no longer need to worry about metadata lifetimes separately. Data ownership is determined based on whether it is passed by pointer or moved into the TensorPtr as an std::vector. Everything is bundled in one place and managed automatically, enabling you to focus on actual computations. Here\u2019s how you can use it: #include \u003cexecutorch/extension/module/module.h\u003e #include \u003cexecutorch/extension/tensor/tensor.h\u003e using namespace executorch::extension; auto tensor = make_tensor_ptr( {2, 3}, // sizes {1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 6.0f}); // data // ... module.forward(tensor); The data is now owned by the tensor instance because it\u2019s provided as a vector. To create a non-owning TensorPtr, just pass the data by pointer. The type is deduced automatically based on the data vector (float). strides and dim_order are computed automatically to default values based on the sizes if not specified explicitly as additional arguments. EValue in Module::forward() accepts TensorPtr directly, ensuring seamless integration. EValue can now be constructed implicitly with a smart pointer to any type that it can hold. This allows TensorPtr to be dereferenced implicitly when passed to forward(), and EValue will hold the Tensor that the TensorPtr points to. API Overview# TensorPtr is literally an alias for std::shared_ptr\u003cTensor\u003e, so you can work with it easily without duplicating the data and metadata. Each Tensor instance may either own its data or reference external data. Creating Tensors# There are several ways to create a TensorPtr. Creating Scalar Tensors# You can create a scalar tensor, i.e. a tensor with zero dimensions or with one of the sizes being zero. Providing A Single Data Value auto tensor = make_tensor_ptr(3.14); The resulting tensor will contain a single value 3.14 of type double, which is deduced automatically. Providing A Single Data Value with a Type auto tensor = make_tensor_ptr(42, ScalarType::Float); Now the integer 42 will be cast to float and the tensor will contain a single value 42 of type float. Owning Data from a Vector# When you provide sizes and data vectors, TensorPtr takes ownership of both the data and the sizes. Providing Data Vector auto tensor = make_tensor_ptr( {2, 3}, // sizes {1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 6.0f}); // data (float) The type is deduced automatically as ScalarType::Float from the data vector. Providing Data Vector with a Type If you provide data of one type but specify a different scalar type, the data will be cast to the given type. auto tensor = make_tensor_ptr( {1, 2, 3, 4, 5, 6}, // data (int) ScalarType::Double); // double scalar type In this example, even though the data vector contains integers, we specify the scalar type as Double. The integers are cast to double, and the new data vector is owned by the TensorPtr. Since the sizes argument is skipped in this example, the tensor is one-dimensional with a size equal to the length of the data vector. Note that the reverse cast, from a floating-point type to an integral type, is not allowed because that loses precision. Similarly, casting other types to Bool is disallowed. Providing Data Vector as std::vector\u003cuint8_t\u003e You can also provide raw data in the form of a std::vector\u003cuint8_t\u003e, specifying the sizes and scalar type. The data will be reinterpreted according to the provided type. std::vector\u003cuint8_t\u003e data = /* raw data */; auto tensor = make_tensor_ptr( {2, 3}, // sizes std::move(data), // data as uint8_t vector ScalarType::Int); // int scalar type The data vector must be large enough to accommodate all the elements according to the provided sizes and scalar type. Non-Owning Data from Raw Pointer# You can create a TensorPtr that references existing data without taking ownership. Providing Raw Data float data[] = {1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 6.0f}; auto tensor = make_tensor_ptr( {2, 3}, // sizes data, // raw data pointer ScalarType::Float); // float scalar type The TensorPtr does not own the data, so you must ensure the data remains valid. Providing Raw Data with Custom Deleter If you want the TensorPtr to manage the lifetime of the data, you can provide a custom deleter. auto* data = new double[6]{1.0, 2.0, 3.0, 4.0, 5.0, 6.0}; auto tensor = make_tensor_ptr( {2, 3}, // sizes data, // data pointer ScalarType::Double, // double scalar type TensorShapeDynamism::DYNAMIC_BOUND, // default dynamism [](void* ptr) { delete[] static_cast\u003cdouble*\u003e(ptr); }); The TensorPtr will call the custom deleter when it is destroyed, i.e., when the smart pointer is reset and no more references to the underlying Tensor exist. Sharing Existing Tensor# Since TensorPtr is a std::shared_ptr\u003cTensor\u003e, you can easily create a TensorPtr that shares an existing Tensor. Any changes made to the shared data are reflected across all instances sharing the same data. Sharing Existing TensorPtr auto tensor = make_tensor_ptr({2, 3}, {1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 6.0f}); auto tensor_copy = tensor; Now tensor and tensor_copy point to the same data and metadata. Viewing Existing Tensor# You can create a TensorPtr from an existing Tensor, copying its properties and referencing the same data. Viewing Existing Tensor Tensor original_tensor = /* some existing tensor */; auto tensor = make_tensor_ptr(original_tensor); Now the newly created TensorPtr references the same data as the original tensor, but has its own metadata copy, so it can interpret or \u201cview\u201d the data differently, but any modifications to the data will be reflected in the original Tensor as well. Cloning Tensors# To create a new TensorPtr that owns a copy of the data from an existing tensor: Tensor original_tensor = /* some existing tensor */; auto tensor = clone_tensor_ptr(original_tensor); The newly created TensorPtr has its own copy of the data, so it can modify and manage it independently. Likewise, you can create a clone of an existing TensorPtr. auto original_tensor = make_tensor_ptr(/* ... */); auto tensor = clone_tensor_ptr(original_tensor); Note that, regardless of whether the original TensorPtr owns the data or not, the newly created TensorPtr will own a copy of the data. Resizing Tensors# The TensorShapeDynamism enum specifies the mutability of a tensor\u2019s shape: STATIC: The tensor\u2019s shape cannot be changed. DYNAMIC_BOUND: The tensor\u2019s shape can be changed but cannot contain more elements than it originally had at creation based on the initial sizes. DYNAMIC: The tensor\u2019s shape can be changed arbitrarily. Currently, DYNAMIC is an alias for DYNAMIC_BOUND. When resizing a tensor, you must respect its dynamism setting. Resizing is only allowed for tensors with DYNAMIC or DYNAMIC_BOUND shapes, and you cannot resize DYNAMIC_BOUND tensors to contain more elements than they had initially. auto tensor = make_tensor_ptr( {2, 3}, // sizes {1, 2, 3, 4, 5, 6}, // data ScalarType::Int, TensorShapeDynamism::DYNAMIC_BOUND); // Initial sizes: {2, 3} // Number of elements: 6 resize_tensor_ptr(tensor, {2, 2}); // The tensor sizes are now {2, 2} // Number of elements is 4 \u003c initial 6 resize_tensor_ptr(tensor, {1, 3}); // The tensor sizes are now {1, 3} // Number of elements is 3 \u003c initial 6 resize_tensor_ptr(tensor, {3, 2}); // The tensor sizes are now {3, 2} // Number of elements is 6 == initial 6 resize_tensor_ptr(tensor, {6, 1}); // The tensor sizes are now {6, 1} // Number of elements is 6 == initial 6 Convenience Helpers# ExecuTorch provides several helper functions to create tensors conveniently. Creating Non-Owning Tensors with for_blob and from_blob# These helpers allow you to create tensors that do not own the data. Using from_blob() float data[] = {1.0f, 2.0f, 3.0f}; auto tensor = from_blob( data, // data pointer {3}, // sizes ScalarType::Float); // float scalar type Using for_blob() with Fluent Syntax double data[] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0}; auto tensor = for_blob(data, {2, 3}, ScalarType::Double) .strides({3, 1}) .dynamism(TensorShapeDynamism::STATIC) .make_tensor_ptr(); Using Custom Deleter with from_blob() int* data = new int[3]{1, 2, 3}; auto tensor = from_blob( data, // data pointer {3}, // sizes ScalarType::Int, // int scalar type [](void* ptr) { delete[] static_cast\u003cint*\u003e(ptr); }); The TensorPtr will call the custom deleter when it is destroyed. Creating Empty Tensors# empty() creates an uninitialized tensor with sizes specified. auto tensor = empty({2, 3}); empty_like() creates an uninitialized tensor with the same sizes as an existing TensorPtr. TensorPtr original_tensor = /* some existing tensor */; auto tensor = empty_like(original_tensor); And empty_strided() creates an uninitialized tensor with sizes and strides specified. auto tensor = empty_strided({2, 3}, {3, 1}); Creating Tensors Filled with Specific Values# full(), zeros() and ones() create a tensor filled with a provided value, zeros or ones respectively. auto tensor_full = full({2, 3}, 42.0f); auto tensor_zeros = zeros({2, 3}); auto tensor_ones = ones({3, 4}); Similarly to empty(), there are extra helper functions full_like(), full_strided(), zeros_like(), zeros_strided(), ones_like() and ones_strided() to create filled tensors with the same properties as an existing TensorPtr or with custom strides. Creating Random Tensors# rand() creates a tensor filled with random values between 0 and 1. auto tensor_rand = rand({2, 3}); randn() creates a tensor filled with random values from a normal distribution. auto tensor_randn = randn({2, 3}); randint() creates a tensor filled with random integers between min (inclusive) and max (exclusive) integers specified. auto tensor_randint = randint(0, 10, {2, 3}); Creating Scalar Tensors# In addition to make_tensor_ptr() with a single data value, you can create a scalar tensor with scalar_tensor(). auto tensor = scalar_tensor(3.14f); Note that the scalar_tensor() function expects a value of type Scalar. In ExecuTorch, Scalar can represent bool, int, or floating-point types, but not types like Half or BFloat16, etc. for which you\u2019d need to use make_tensor_ptr() to skip the Scalar type. Notes on EValue and Lifetime Management# The Module interface expects data in the form of EValue, a variant type that can hold a Tensor or other scalar types. When you pass a TensorPtr to a function expecting an EValue, you can dereference the TensorPtr to get the underlying Tensor. TensorPtr tensor = /* create a TensorPtr */ //... module.forward(tensor); Or even a vector of EValues for multiple parameters. TensorPtr tensor = /* create a TensorPtr */ TensorPtr tensor2 = /* create another TensorPtr */ //... module.forward({tensor, tensor2}); However, be cautious: EValue will not hold onto the dynamic data and metadata from the TensorPtr. It merely holds a regular Tensor, which does not own the data or metadata but refers to them using raw pointers. You need to ensure that the TensorPtr remains valid for as long as the EValue is in use. This also applies when using functions like set_input() or set_output() that expect EValue. Interoperability with ATen# If your code is compiled with the preprocessor flag USE_ATEN_LIB enabled, all the TensorPtr APIs will use at:: APIs under the hood. E.g. TensorPtr becomes a std::shared_ptr\u003cat::Tensor\u003e. This allows for seamless integration with PyTorch ATen library. API Equivalence Table# Here\u2019s a table matching TensorPtr creation functions with their corresponding ATen APIs: ATen ExecuTorch at::tensor(data, type) make_tensor_ptr(data, type) at::tensor(data, type).reshape(sizes) make_tensor_ptr(sizes, data, type) tensor.clone() clone_tensor_ptr(tensor) tensor.resize_(new_sizes) resize_tensor_ptr(tensor, new_sizes) at::scalar_tensor(value) scalar_tensor(value) at::from_blob(data, sizes, type) from_blob(data, sizes, type) at::empty(sizes) empty(sizes) at::empty_like(tensor) empty_like(tensor) at::empty_strided(sizes, strides) empty_strided(sizes, strides) at::full(sizes, value) full(sizes, value) at::full_like(tensor, value) full_like(tensor, value) at::full_strided(sizes, strides, value) full_strided(sizes, strides, value) at::zeros(sizes) zeros(sizes) at::zeros_like(tensor) zeros_like(tensor) at::zeros_strided(sizes, strides) zeros_strided(sizes, strides) at::ones(sizes) ones(sizes) at::ones_like(tensor) ones_like(tensor) at::ones_strided(sizes, strides) ones_strided(sizes, strides) at::rand(sizes) rand(sizes) at::rand_like(tensor) rand_like(tensor) at::randn(sizes) randn(sizes) at::randn_like(tensor) randn_like(tensor) at::randint(low, high, sizes) randint(low, high, sizes) at::randint_like(tensor, low, high) randint_like(tensor, low, high) Best Practices# Manage Lifetimes Carefully: Even though TensorPtr handles memory management, ensure that any non-owned data (e.g., when using from_blob()) remains valid while the tensor is in use. Use Convenience Functions: Utilize helper functions for common tensor creation patterns to write cleaner and more readable code. Be Aware of Data Ownership: Know whether your tensor owns its data or references external data to avoid unintended side effects or memory leaks. Ensure TensorPtr Outlives EValue: When passing tensors to modules that expect EValue, ensure that the TensorPtr remains valid as long as the EValue is in use. Conclusion# The TensorPtr in ExecuTorch simplifies tensor memory management by bundling the data and dynamic metadata into a smart pointer. This design eliminates the need for users to manage multiple pieces of data and ensures safer and more maintainable code. By providing interfaces similar to PyTorch\u2019s ATen library, ExecuTorch simplifies the adoption of the new API, allowing developers to transition without a steep learning curve.",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "https://pytorch.org/docs/stable/_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/extension-tensor.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
  <script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
  
  </body>
</html>