
<!DOCTYPE html>


<html lang="en" data-content_root="../../../../" >

  <head>
  <meta name="robots" content="noindex">
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>executorch.exir.program._program &#8212; ExecuTorch main documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/theme.css?v=047068a3" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../../../_static/documentation_options.js?v=a8da1a53"></script>
    <script src="../../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/mermaid@11.2.0/dist/mermaid.esm.min.mjs"></script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/@mermaid-js/layout-elk@0.1.4/dist/mermaid-layout-elk.esm.min.mjs"></script>
    <script type="module">import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@11.2.0/dist/mermaid.esm.min.mjs";import elkLayouts from "https://cdn.jsdelivr.net/npm/@mermaid-js/layout-elk@0.1.4/dist/mermaid-layout-elk.esm.min.mjs";mermaid.registerLayoutLoaders(elkLayouts);mermaid.initialize({startOnLoad:false});</script>
    <script src="https://cdn.jsdelivr.net/npm/d3@7.9.0/dist/d3.min.js"></script>
    <script type="module">
import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@11.2.0/dist/mermaid.esm.min.mjs";
window.addEventListener("load", () => mermaid.run());
</script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/executorch/exir/program/_program';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.15.4';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://docs.pytorch.org/executorch/executorch-versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'main';
        DOCUMENTATION_OPTIONS.show_version_warning_banner = true;
        </script>
    <link rel="canonical" href="https://docs.pytorch.org/executorch/_modules/executorch/exir/program/_program.html" />
    <link rel="icon" href="../../../../_static/executorch-chip-logo.svg"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->


<link rel="stylesheet" type="text/css" href="../../../../_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="../../../../_static/js/theme.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="https://docs.pytorch.org/docs/stable/_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="../../../../_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy"
  content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" height="0" width="0"
    style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'GTM-T8XT4PS');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'main');
</script>
<noscript>
  <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1" />
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Repository configuration for tutorials -->

<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>

  </head>

<body data-feedback-url="https://github.com/pytorch/executorch" class="pytorch-body">
  
    <div class="container-fluid header-holder tutorials-header" id="header-holder">
   <div class="header-container-wrapper">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                <span>Learn</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started/locally">
                  <span class=dropdown-title>Get Started</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/webinars/">
                  <span class="dropdown-title">Webinars</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Community</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Landscape</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/join-ecosystem">
                  <span class="dropdown-title">Join the Ecosystem</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-hub/">
                  <span class="dropdown-title">Community Hub</span>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/">
                  <span class="dropdown-title">Forums</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contributor-awards/">
                  <span class="dropdown-title">Contributor Awards</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-events/">
                  <span class="dropdown-title">Community Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/programs/ambassadors/">
                  <span class="dropdown-title">PyTorch Ambassadors</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Projects</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/pytorch/">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/vllm/">
                  <span class="dropdown-title">vLLM</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/deepspeed/">
                  <span class="dropdown-title">DeepSpeed</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/host-your-project/">
                  <span class="dropdown-title">Host Your Project</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/ray/">
                  <span class="dropdown-title">RAY</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span> Docs</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/domains">
                  <span class="dropdown-title">Domains</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Blogs & News</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">Blog</span>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/announcements">
                  <span class="dropdown-title">Announcements</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/case-studies/">
                  <span class="dropdown-title">Case Studies</span>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                </a>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>About</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/members">
                  <span class="dropdown-title">Members</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact">
                  <span class="dropdown-title">Contact</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/wp-content/uploads/2025/09/pytorch_brand_guide_091925a.pdf">
                  <span class="dropdown-title">Brand Guidelines</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown main-menu-button">
              <a href="https://pytorch.org/join" data-cta="join">
                JOIN
              </a>
            </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu">
        <i class="fa-solid fa-ellipsis"></i>
      </a>
    </div>
  </div>
 </div>

 <!-- Begin Mobile Menu -->

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="header-container-wrapper">
      <div class="mobile-main-menu-header-container">
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu">
        </a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">
    <div class="main-menu">
      <ul>
         <li class="resources-mobile-menu-title">
           <a>Learn</a>
         </li>
         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/get-started/locally">Get Started</a>
           </li>
           <li>
             <a href="https://docs.pytorch.org/tutorials">Tutorials</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
           </li>
           <li>
            <a href="https://pytorch.org/webinars/">Webinars</a>
          </li>
        </ul>
         <li class="resources-mobile-menu-title">
           <a>Community</a>
         </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://landscape.pytorch.org/">Landscape</a>
          </li>
          <li>
             <a href="https://pytorch.org/join-ecosystem">Join the Ecosystem</a>
           </li>
           <li>
             <a href="https://pytorch.org/community-hub/">Community Hub</a>
           </li>
           <li>
             <a href="https://discuss.pytorch.org/">Forums</a>
           </li>
           <li>
             <a href="https://pytorch.org/resources">Developer Resources</a>
           </li>
           <li>
             <a href="https://pytorch.org/contributor-awards/">Contributor Awards</a>
           </li>
           <li>
            <a href="https://pytorch.org/community-events/">Community Events</a>
          </li>
          <li>
            <a href="https://pytorch.org/programs/ambassadors/">PyTorch Ambassadors</a>
          </li>
       </ul>

         <li class="resources-mobile-menu-title">
           <a>Projects</a>
         </li>

         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/projects/pytorch/">PyTorch</a>
           </li>

           <li>
             <a href="https://pytorch.org/projects/vllm/">vLLM</a>
           </li>
           <li>
            <a href="https://pytorch.org/projects/deepspeed/">DeepSpeed</a>
          </li>
          <li>
             <a href="https://pytorch.org/projects/host-your-project/">Host Your Project</a>
           </li>
         </ul>

         <li class="resources-mobile-menu-title">
           <a>Docs</a>
         </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://docs.pytorch.org/docs/stable/index.html">PyTorch</a>
          </li>

          <li>
            <a href="https://pytorch.org/domains">Domains</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>Blog & News</a>
        </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>
          <li>
            <a href="https://pytorch.org/announcements">Announcements</a>
          </li>

          <li>
            <a href="https://pytorch.org/case-studies/">Case Studies</a>
          </li>
          <li>
            <a href="https://pytorch.org/events">Events</a>
          </li>
          <li>
             <a href="https://pytorch.org/newsletter">Newsletter</a>
           </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>About</a>
        </li>

        <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
          </li>
          <li>
            <a href="https://pytorch.org/members">Members</a>
          </li>
          <li>
            <a href="https://pytorch.org/governing-board">Governing Board</a>
          </li>
          <li>
            <a href="https://pytorch.org/tac">Technical Advisory Council</a>
         </li>
         <li>
             <a href="https://pytorch.org/credits">Cloud Credit Program</a>
          </li>
          <li>
             <a href="https://pytorch.org/staff">Staff</a>
          </li>
          <li>
             <a href="https://pytorch.org/contact">Contact</a>
          </li>
        </ul>
      </ul>
    </div>
  </div>
</div>

<!-- End Mobile Menu -->
  
  
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../../_static/et-logo.png" class="logo__image only-light" alt="ExecuTorch main documentation - Home"/>
    <script>document.write(`<img src="../../../../_static/et-logo.png" class="logo__image only-dark" alt="ExecuTorch main documentation - Home"/>`);</script>
  
  
</a></div>
    
      <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-2"
      type="button"
      class="version-switcher__button btn btn-sm dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-2"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-2"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-2">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../intro-section.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../quick-start-section.html">
    Quick Start
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../edge-platforms-section.html">
    Edge
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../backends-section.html">
    Backends
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../llm/working-with-llms.html">
    LLMs
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../advanced-topics-section.html">
    Advanced
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../tools-section.html">
    Tools
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../api-section.html">
    API
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../../../support-section.html">
    Support
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/executorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/executorch" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../intro-section.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../quick-start-section.html">
    Quick Start
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../edge-platforms-section.html">
    Edge
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../backends-section.html">
    Backends
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../llm/working-with-llms.html">
    LLMs
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../advanced-topics-section.html">
    Advanced
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../tools-section.html">
    Tools
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../api-section.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../support-section.html">
    Support
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/executorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/executorch" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../../index.html" class="nav-link">Module code</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">executorch.e...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
  
<div id="searchbox"></div>
  <article class="bd-article" id="pytorch-article">
    <!-- Hidden breadcrumb schema for SEO only -->
    <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <link itemprop="item" href="../../../index.html">
        <meta itemprop="name" content="Module code">
        <meta itemprop="position" content="1">
      </div>
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <meta itemprop="name" content="executorch.exir.program._program">
        <meta itemprop="position" content="2">
      </div>
    </div>

    
    

    
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for executorch.exir.program._program</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1"># All rights reserved.</span>
<span class="c1"># Copyright 2025 Arm Limited and/or its affiliates.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the BSD-style license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>

<span class="c1"># pyre-unsafe</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">copy</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">io</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Set</span><span class="p">,</span> <span class="n">TextIO</span><span class="p">,</span> <span class="n">Type</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch._export</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir._serialize._cord</span><span class="w"> </span><span class="kn">import</span> <span class="n">Cord</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir._serialize._named_data_store</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">NamedDataStore</span><span class="p">,</span>
    <span class="n">NamedDataStoreOutput</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir._serialize._serialize</span><span class="w"> </span><span class="kn">import</span> <span class="n">serialize_for_executorch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir._serialize.data_serializer</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataSerializer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir._warnings</span><span class="w"> </span><span class="kn">import</span> <span class="n">experimental</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.backend.backend_api</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">MethodProgramsPartitionerSpec</span><span class="p">,</span>
    <span class="n">to_backend</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.backend.partitioner</span><span class="w"> </span><span class="kn">import</span> <span class="n">Partitioner</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.capture._config</span><span class="w"> </span><span class="kn">import</span> <span class="n">EdgeCompileConfig</span><span class="p">,</span> <span class="n">ExecutorchBackendConfig</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.delegate</span><span class="w"> </span><span class="kn">import</span> <span class="n">executorch_call_delegate</span><span class="p">,</span> <span class="n">is_lowered_module</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.emit</span><span class="w"> </span><span class="kn">import</span> <span class="n">emit_program</span><span class="p">,</span> <span class="n">EmitterOutput</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.emit._emitter</span><span class="w"> </span><span class="kn">import</span> <span class="n">_DelegateDebugIdentifierMap</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.error</span><span class="w"> </span><span class="kn">import</span> <span class="n">ExportError</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.graph_module</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_control_flow_submodules</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.operator.convert</span><span class="w"> </span><span class="kn">import</span> <span class="n">_pybind_schema_to_native_schema</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.operator.util</span><span class="w"> </span><span class="kn">import</span> <span class="n">_QUANT_PRIMITIVES</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.pass_base</span><span class="w"> </span><span class="kn">import</span> <span class="n">PassBase</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.pass_manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">PassType</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.passes</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">base_post_op_replace_passes</span><span class="p">,</span>
    <span class="n">base_pre_op_replace_passes</span><span class="p">,</span>
    <span class="n">dead_code_elimination_pass</span><span class="p">,</span>
    <span class="n">EdgeToBackendOpsPass</span><span class="p">,</span>
    <span class="n">MemoryFormatOpsPass</span><span class="p">,</span>
    <span class="n">OpReplacePass</span><span class="p">,</span>
    <span class="n">remove_unused_parameters_pass</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.passes.external_constants_pass</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">external_constants_pass</span><span class="p">,</span>
    <span class="n">external_mutable_weights_pass</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.passes.insert_write_back_for_buffers_pass</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">insert_write_back_for_buffers_pass</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.passes.normalize_view_copy_base_pass</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">NormalizeViewCopyBasePass</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.passes.quant_fusion_pass</span><span class="w"> </span><span class="kn">import</span> <span class="n">quant_fusion_and_const_prop_pass</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.passes.reinplace</span><span class="w"> </span><span class="kn">import</span> <span class="n">reinplace_pass</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.passes.remove_graph_asserts_pass</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">RemoveGraphAssertsPass</span><span class="p">,</span>
    <span class="n">RemoveNonCoreAtenOpGraphAssertsPass</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.passes.remove_mixed_type_operators</span><span class="w"> </span><span class="kn">import</span> <span class="n">RemoveMixedTypeOperators</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.passes.replace_aten_with_edge_pass</span><span class="w"> </span><span class="kn">import</span> <span class="n">aten_to_edge</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.passes.replace_view_copy_with_view_pass</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">ReplaceViewCopyWithViewPass</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.passes.spec_prop_pass</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpecPropPass</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.passes.weights_to_outputs_pass</span><span class="w"> </span><span class="kn">import</span> <span class="n">weights_to_outputs_pass</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.print_program</span><span class="w"> </span><span class="kn">import</span> <span class="n">pretty_print</span><span class="p">,</span> <span class="n">print_program</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.schema</span><span class="w"> </span><span class="kn">import</span> <span class="n">Program</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.tracer</span><span class="w"> </span><span class="kn">import</span> <span class="n">_default_decomposition_table</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.verification.verifier</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">EXIRATenDialectVerifier</span><span class="p">,</span>
    <span class="n">EXIREdgeDialectVerifier</span><span class="p">,</span>
    <span class="n">get_aten_verifier</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch._export.passes</span><span class="w"> </span><span class="kn">import</span> <span class="n">ReplaceViewOpsWithViewCopyOpsPass</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch._export.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">_detect_fake_mode_from_gm</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch._export.verifier</span><span class="w"> </span><span class="kn">import</span> <span class="n">Verifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.export</span><span class="w"> </span><span class="kn">import</span> <span class="n">ExportedProgram</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.export._remove_auto_functionalized_pass</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">unsafe_remove_auto_functionalized_pass</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.export.exported_program</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">ConstantArgument</span><span class="p">,</span>
    <span class="n">ExportGraphSignature</span><span class="p">,</span>
    <span class="n">InputKind</span><span class="p">,</span>
    <span class="n">InputSpec</span><span class="p">,</span>
    <span class="n">OutputSpec</span><span class="p">,</span>
    <span class="n">TensorArgument</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.fx</span><span class="w"> </span><span class="kn">import</span> <span class="n">_pytree</span> <span class="k">as</span> <span class="n">fx_pytree</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.fx._compatibility</span><span class="w"> </span><span class="kn">import</span> <span class="n">compatibility</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.fx.passes.infra.pass_manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">PassManager</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">_pytree</span> <span class="k">as</span> <span class="n">pytree</span>

<span class="n">Val</span> <span class="o">=</span> <span class="n">Any</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">torch.library</span><span class="w"> </span><span class="kn">import</span> <span class="n">Library</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">executorch.exir.program.fb.logger</span><span class="w"> </span><span class="kn">import</span> <span class="n">et_logger</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="c1"># Define a stub decorator that does nothing</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">et_logger</span><span class="p">(</span><span class="n">api_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">],</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">decorator</span><span class="p">(</span><span class="n">func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
            <span class="k">def</span><span class="w"> </span><span class="nf">wrapper</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">wrapper</span>

        <span class="k">return</span> <span class="n">decorator</span>


<span class="c1"># This is the reserved namespace that is used to register ops to that will</span>
<span class="c1"># be prevented from being decomposed during to_edge_transform_and_lower.</span>
<span class="n">edge_no_decomp_namespace</span> <span class="o">=</span> <span class="s2">&quot;EDGE_DO_NOT_DECOMP&quot;</span>
<span class="n">lib</span> <span class="o">=</span> <span class="n">Library</span><span class="p">(</span><span class="n">edge_no_decomp_namespace</span><span class="p">,</span> <span class="s2">&quot;DEF&quot;</span><span class="p">)</span>
<span class="c1"># Map from aten ops to the transformed ops registered in the edge_no_decomp_namespace.</span>
<span class="n">aten_op_to_transform_op</span> <span class="o">=</span> <span class="p">{}</span>
<span class="c1"># Map from the transformed ops registered in the edge_no_decomp_namespace to aten ops.</span>
<span class="n">transform_op_to_aten_op</span> <span class="o">=</span> <span class="p">{}</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_get_updated_range_constraints</span><span class="p">(</span><span class="n">gm</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_shape_env</span><span class="p">(</span><span class="n">gm</span><span class="p">):</span>
        <span class="n">vals</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">node</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s2">&quot;val&quot;</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">gm</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span>
            <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">meta</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;val&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">]</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torch._guards</span><span class="w"> </span><span class="kn">import</span> <span class="n">detect_fake_mode</span>  <span class="c1"># type: ignore[21]</span>

        <span class="n">fake_mode</span> <span class="o">=</span> <span class="n">detect_fake_mode</span><span class="p">(</span><span class="n">vals</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">fake_mode</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">fake_mode</span><span class="o">.</span><span class="n">shape_env</span>
        <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">vals</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">SymInt</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">v</span><span class="o">.</span><span class="n">node</span><span class="o">.</span><span class="n">shape_env</span>

    <span class="n">shape_env</span> <span class="o">=</span> <span class="n">get_shape_env</span><span class="p">(</span><span class="n">gm</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">shape_env</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{}</span>
    <span class="n">range_constraints</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">k</span><span class="p">:</span> <span class="n">v</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">shape_env</span><span class="o">.</span><span class="n">var_to_range</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">shape_env</span><span class="o">.</span><span class="n">replacements</span>
    <span class="p">}</span>
    <span class="c1"># Only when we have an unbacked symint, and it&#39;s used as constructor inputs,</span>
    <span class="c1"># runtime_var_to_range will make a difference compated to var_to_range.</span>
    <span class="c1"># e.g. [2, oo) -&gt; [0, oo)</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">shape_env</span><span class="o">.</span><span class="n">var_to_range</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">shape_env</span><span class="o">.</span><span class="n">replacements</span><span class="p">:</span>
            <span class="n">range_constraints</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
    <span class="k">return</span> <span class="n">range_constraints</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_get_updated_graph_signature</span><span class="p">(</span>
    <span class="n">old_signature</span><span class="p">:</span> <span class="n">ExportGraphSignature</span><span class="p">,</span>
    <span class="n">new_gm</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ExportGraphSignature</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Update the graph signature&#39;s user_input/user_outputs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">new_input_specs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">new_gm</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">!=</span> <span class="s2">&quot;placeholder&quot;</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="k">assert</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span>
            <span class="n">old_signature</span><span class="o">.</span><span class="n">input_specs</span>
        <span class="p">),</span> <span class="s2">&quot;Number of inputs changed after transformation&quot;</span>
        <span class="n">old_input_spec</span> <span class="o">=</span> <span class="n">old_signature</span><span class="o">.</span><span class="n">input_specs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">arg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">old_input_spec</span><span class="o">.</span><span class="n">arg</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">old_input_spec</span><span class="o">.</span><span class="n">arg</span><span class="p">,</span> <span class="n">ConstantArgument</span><span class="p">)</span>
            <span class="c1"># pyre-fixme[20]: Argument `class_fqn` expected.</span>
            <span class="k">else</span> <span class="nb">type</span><span class="p">(</span><span class="n">old_input_spec</span><span class="o">.</span><span class="n">arg</span><span class="p">)(</span><span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">new_input_specs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">InputSpec</span><span class="p">(</span>
                <span class="n">old_input_spec</span><span class="o">.</span><span class="n">kind</span><span class="p">,</span>
                <span class="n">arg</span><span class="p">,</span>
                <span class="n">old_input_spec</span><span class="o">.</span><span class="n">target</span><span class="p">,</span>
                <span class="n">persistent</span><span class="o">=</span><span class="n">old_input_spec</span><span class="o">.</span><span class="n">persistent</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">output_node</span> <span class="o">=</span> <span class="n">new_gm</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">output_node</span><span class="p">()</span>
    <span class="k">assert</span> <span class="n">output_node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;output&quot;</span>

    <span class="n">new_output_specs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">output_node</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">assert</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span>
            <span class="n">old_signature</span><span class="o">.</span><span class="n">output_specs</span>
        <span class="p">),</span> <span class="s2">&quot;Number of outputs changed after transformation&quot;</span>
        <span class="n">old_output_spec</span> <span class="o">=</span> <span class="n">old_signature</span><span class="o">.</span><span class="n">output_specs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">arg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">old_output_spec</span><span class="o">.</span><span class="n">arg</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">old_output_spec</span><span class="o">.</span><span class="n">arg</span><span class="p">,</span> <span class="n">ConstantArgument</span><span class="p">)</span>
            <span class="c1"># pyre-fixme[20]: Argument `class_fqn` expected.</span>
            <span class="k">else</span> <span class="nb">type</span><span class="p">(</span><span class="n">old_output_spec</span><span class="o">.</span><span class="n">arg</span><span class="p">)(</span><span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">new_output_specs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">OutputSpec</span><span class="p">(</span><span class="n">old_output_spec</span><span class="o">.</span><span class="n">kind</span><span class="p">,</span> <span class="n">arg</span><span class="p">,</span> <span class="n">old_output_spec</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="n">new_signature</span> <span class="o">=</span> <span class="n">ExportGraphSignature</span><span class="p">(</span>
        <span class="n">input_specs</span><span class="o">=</span><span class="n">new_input_specs</span><span class="p">,</span> <span class="n">output_specs</span><span class="o">=</span><span class="n">new_output_specs</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">new_signature</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_transform</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">*</span><span class="n">passes</span><span class="p">:</span> <span class="n">PassType</span><span class="p">,</span>
    <span class="n">override_verifiers</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span><span class="n">Verifier</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ExportedProgram&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transforms the program according to the provided passes.</span>

<span class="sd">    Args:</span>
<span class="sd">        self: The ExportedProgram instance to transform</span>
<span class="sd">        *passes: A sequence of passes to apply to the program</span>
<span class="sd">        override_verifiers: Optional list of verifier classes to use instead of the default verifiers.</span>
<span class="sd">            This is needed if the transforms yields illegal graph that the default verifier cannot handle.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ExportedProgram: A new ExportedProgram with the transformations applied, or self if no changes were made</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># A user friendly check to avoid vararg surprises, PEP 3102</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="nb">any</span><span class="p">(</span>
        <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">Verifier</span><span class="p">))</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">passes</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Expected all passes to be of PassType, not list or Verifier. Use override_verifiers kwarg instead. Got: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">passes</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="k">return</span> <span class="n">_transform_with_pass_manager</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">PassManager</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">passes</span><span class="p">)),</span> <span class="n">override_verifiers</span>
    <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_transform_with_pass_manager</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">pass_manager</span><span class="p">:</span> <span class="n">PassManager</span><span class="p">,</span>
    <span class="n">override_verifiers</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span><span class="n">Verifier</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ExportedProgram&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transforms the program using the provided pass_manager.</span>

<span class="sd">    Args:</span>
<span class="sd">        self: The ExportedProgram instance to transform</span>
<span class="sd">        pass_manager: An instance of PassManager to apply transformations.</span>
<span class="sd">        override_verifiers: Optional list of verifier classes to use instead of the default verifiers.</span>
<span class="sd">            This is needed if the transforms yields illegal graph that the default verifier cannot handle.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ExportedProgram: A new ExportedProgram with the transformations applied, or self if no changes were made</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">pass_manager</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">graph_module</span><span class="p">)</span>
    <span class="n">transformed_gm</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">graph_module</span> <span class="k">if</span> <span class="n">res</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_module</span>
    <span class="k">assert</span> <span class="n">transformed_gm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">transformed_gm</span> <span class="ow">is</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_module</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">res</span><span class="o">.</span><span class="n">modified</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">return</span> <span class="n">_update_exported_program_graph_module</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">transformed_gm</span><span class="p">,</span> <span class="n">override_verifiers</span>
    <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_update_exported_program_graph_module</span><span class="p">(</span>
    <span class="n">exported_program</span><span class="p">:</span> <span class="n">ExportedProgram</span><span class="p">,</span>
    <span class="n">gm</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">,</span>
    <span class="n">override_verifiers</span><span class="p">:</span> <span class="kc">None</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span><span class="n">Verifier</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ExportedProgram&quot;</span><span class="p">:</span>
    <span class="n">transformed_ep</span> <span class="o">=</span> <span class="n">ExportedProgram</span><span class="p">(</span>
        <span class="n">root</span><span class="o">=</span><span class="n">gm</span><span class="p">,</span>
        <span class="n">graph</span><span class="o">=</span><span class="n">gm</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span>
        <span class="n">graph_signature</span><span class="o">=</span><span class="n">_get_updated_graph_signature</span><span class="p">(</span>
            <span class="n">exported_program</span><span class="o">.</span><span class="n">graph_signature</span><span class="p">,</span> <span class="n">gm</span>
        <span class="p">),</span>
        <span class="n">state_dict</span><span class="o">=</span><span class="n">exported_program</span><span class="o">.</span><span class="n">state_dict</span><span class="p">,</span>
        <span class="n">range_constraints</span><span class="o">=</span><span class="n">_get_updated_range_constraints</span><span class="p">(</span><span class="n">gm</span><span class="p">),</span>
        <span class="n">module_call_graph</span><span class="o">=</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">exported_program</span><span class="o">.</span><span class="n">_module_call_graph</span><span class="p">),</span>
        <span class="n">example_inputs</span><span class="o">=</span><span class="n">exported_program</span><span class="o">.</span><span class="n">example_inputs</span><span class="p">,</span>
        <span class="n">constants</span><span class="o">=</span><span class="n">exported_program</span><span class="o">.</span><span class="n">constants</span><span class="p">,</span>
        <span class="n">verifiers</span><span class="o">=</span><span class="n">override_verifiers</span> <span class="ow">or</span> <span class="p">[</span><span class="n">exported_program</span><span class="o">.</span><span class="n">verifier</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="n">transformed_ep</span><span class="o">.</span><span class="n">graph_module</span><span class="o">.</span><span class="n">meta</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">exported_program</span><span class="o">.</span><span class="n">graph_module</span><span class="o">.</span><span class="n">meta</span><span class="p">)</span>
    <span class="n">transformed_ep</span><span class="o">.</span><span class="n">graph_module</span><span class="o">.</span><span class="n">meta</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">gm</span><span class="o">.</span><span class="n">meta</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">transformed_ep</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_copy_module</span><span class="p">(</span><span class="n">new_prog</span><span class="p">,</span> <span class="n">new_gm</span><span class="p">):</span>
    <span class="n">new_prog</span><span class="o">.</span><span class="n">meta</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">new_gm</span><span class="o">.</span><span class="n">meta</span><span class="p">)</span>
    <span class="n">new_prog</span><span class="o">.</span><span class="n">graph</span> <span class="o">=</span> <span class="n">new_gm</span><span class="o">.</span><span class="n">graph</span>
    <span class="n">submodules</span> <span class="o">=</span> <span class="p">[</span><span class="n">name</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">new_prog</span><span class="o">.</span><span class="n">named_children</span><span class="p">()]</span>
    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">submodules</span><span class="p">:</span>
        <span class="nb">delattr</span><span class="p">(</span><span class="n">new_prog</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">mod</span> <span class="ow">in</span> <span class="n">new_gm</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="n">new_prog</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">mod</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">new_gm</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;get_attr&quot;</span><span class="p">:</span>
            <span class="n">t</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">new_gm</span><span class="p">,</span> <span class="n">node</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="n">new_prog</span><span class="p">,</span> <span class="n">node</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_create_empty_etrecord</span><span class="p">():</span>
    <span class="c1"># Import etrecord at runtime to resolve cyclic dependencies (program -&gt; etrecord -&gt; program).</span>
    <span class="c1"># This also ensures that etrecord-related packages do not affect the export flow.</span>
    <span class="c1"># @manual</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">executorch.devtools.etrecord</span><span class="w"> </span><span class="kn">import</span> <span class="n">ETRecord</span>

    <span class="k">return</span> <span class="n">ETRecord</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">lift_constant_tensor_pass</span><span class="p">(</span><span class="n">ep</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Takes an ExportedProgram and returns the ExportedProgram modified in-place,</span>
<span class="sd">    with the constant tensors as buffers.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">([</span><span class="n">node</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">ep</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span> <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;placeholder&quot;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ep</span>

    <span class="n">graph_signature</span> <span class="o">=</span> <span class="n">ep</span><span class="o">.</span><span class="n">graph_signature</span>
    <span class="n">buffers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">graph_signature</span><span class="o">.</span><span class="n">buffers</span><span class="p">)</span>

    <span class="n">fake_mode</span> <span class="o">=</span> <span class="n">_detect_fake_mode_from_gm</span><span class="p">(</span><span class="n">ep</span><span class="o">.</span><span class="n">graph_module</span><span class="p">)</span>

    <span class="n">first_user_input</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">lifted_constants</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">ep</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;placeholder&quot;</span> <span class="ow">and</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">graph_signature</span><span class="o">.</span><span class="n">user_inputs</span><span class="p">:</span>
            <span class="n">first_user_input</span> <span class="o">=</span> <span class="n">node</span>
            <span class="k">break</span>

    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">ep</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;get_attr&quot;</span><span class="p">:</span>
            <span class="n">constant_tensor</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">ep</span><span class="o">.</span><span class="n">graph_module</span><span class="p">,</span> <span class="n">node</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">constant_tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="k">continue</span>

            <span class="n">constant_tensor_fqn</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;_lifted_tensor_constant</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">buffers</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

            <span class="k">with</span> <span class="n">ep</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">inserting_before</span><span class="p">(</span><span class="n">first_user_input</span><span class="p">):</span>
                <span class="c1"># Insert the constant node before the first user input</span>
                <span class="n">const_placeholder_node</span> <span class="o">=</span> <span class="n">ep</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">constant_tensor_fqn</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">meta</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="n">const_placeholder_node</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
                <span class="k">if</span> <span class="n">fake_mode</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">const_placeholder_node</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s2">&quot;val&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fake_mode</span><span class="o">.</span><span class="n">from_tensor</span><span class="p">(</span>
                        <span class="n">constant_tensor</span><span class="p">,</span> <span class="n">static_shapes</span><span class="o">=</span><span class="kc">True</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">const_placeholder_node</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s2">&quot;val&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">constant_tensor</span>
                <span class="n">const_placeholder_node</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s2">&quot;val&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">constant</span> <span class="o">=</span> <span class="n">constant_tensor</span>
                <span class="n">node</span><span class="o">.</span><span class="n">replace_all_uses_with</span><span class="p">(</span><span class="n">const_placeholder_node</span><span class="p">)</span>
                <span class="n">ep</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">erase_node</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

                <span class="c1"># Add the constant as a buffer to the graph signature</span>
                <span class="n">lifted_constants</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">InputSpec</span><span class="p">(</span>
                        <span class="n">kind</span><span class="o">=</span><span class="n">InputKind</span><span class="o">.</span><span class="n">BUFFER</span><span class="p">,</span>
                        <span class="n">arg</span><span class="o">=</span><span class="n">TensorArgument</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">const_placeholder_node</span><span class="o">.</span><span class="n">name</span><span class="p">),</span>
                        <span class="n">target</span><span class="o">=</span><span class="n">constant_tensor_fqn</span><span class="p">,</span>
                        <span class="n">persistent</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>
                <span class="n">buffers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">constant_tensor_fqn</span><span class="p">)</span>
                <span class="n">ep</span><span class="o">.</span><span class="n">state_dict</span><span class="p">[</span><span class="n">constant_tensor_fqn</span><span class="p">]</span> <span class="o">=</span> <span class="n">constant_tensor</span>

    <span class="n">new_input_specs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">graph_signature</span><span class="o">.</span><span class="n">input_specs</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">s</span><span class="o">.</span><span class="n">kind</span> <span class="o">==</span> <span class="n">InputKind</span><span class="o">.</span><span class="n">USER_INPUT</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">lifted_constants</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">new_input_specs</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">lifted_constants</span><span class="p">)</span>
            <span class="n">lifted_constants</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
        <span class="n">new_input_specs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lifted_constants</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">new_input_specs</span> <span class="o">=</span> <span class="n">lifted_constants</span> <span class="o">+</span> <span class="n">new_input_specs</span>
    <span class="n">ep</span><span class="o">.</span><span class="n">graph_signature</span><span class="o">.</span><span class="n">input_specs</span> <span class="o">=</span> <span class="n">new_input_specs</span>
    <span class="n">ep</span><span class="o">.</span><span class="n">graph_module</span><span class="o">.</span><span class="n">recompile</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">ep</span>


<span class="c1"># Stub to ease migration from `transform` to private `_transform`</span>
<span class="k">def</span><span class="w"> </span><span class="nf">transform_exported_program</span><span class="p">(</span><span class="n">ep</span><span class="p">,</span> <span class="o">*</span><span class="n">passes</span><span class="p">:</span> <span class="n">PassType</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ExportedProgram</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ep</span><span class="p">,</span> <span class="s2">&quot;_transform&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">ep</span><span class="o">.</span><span class="n">_transform</span><span class="p">(</span><span class="o">*</span><span class="n">passes</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ep</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="o">*</span><span class="n">passes</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">HackedUpExportedProgramDONOTUSE</span><span class="p">(</span><span class="n">ExportedProgram</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">root</span><span class="p">,</span>
        <span class="n">graph</span><span class="p">,</span>
        <span class="n">graph_signature</span><span class="p">,</span>
        <span class="n">call_spec</span><span class="p">,</span>
        <span class="n">state_dict</span><span class="p">,</span>
        <span class="n">range_constraints</span><span class="p">,</span>
        <span class="n">module_call_graph</span><span class="p">,</span>
        <span class="n">example_inputs</span><span class="p">,</span>
        <span class="n">verifier</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">root</span><span class="o">=</span><span class="n">root</span><span class="p">,</span>
            <span class="n">graph</span><span class="o">=</span><span class="n">graph</span><span class="p">,</span>
            <span class="n">graph_signature</span><span class="o">=</span><span class="n">graph_signature</span><span class="p">,</span>
            <span class="n">state_dict</span><span class="o">=</span><span class="n">state_dict</span><span class="p">,</span>
            <span class="n">range_constraints</span><span class="o">=</span><span class="n">range_constraints</span><span class="p">,</span>
            <span class="n">module_call_graph</span><span class="o">=</span><span class="n">module_call_graph</span><span class="p">,</span>
            <span class="n">example_inputs</span><span class="o">=</span><span class="n">example_inputs</span><span class="p">,</span>
            <span class="n">verifier</span><span class="o">=</span><span class="n">verifier</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">torch._export.error</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">error</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_spec</span><span class="o">.</span><span class="n">in_spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">user_args</span> <span class="o">=</span> <span class="n">args</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">args</span> <span class="o">=</span> <span class="n">fx_pytree</span><span class="o">.</span><span class="n">tree_flatten_spec</span><span class="p">(</span><span class="n">user_args</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_spec</span><span class="o">.</span><span class="n">in_spec</span><span class="p">)</span>  <span class="c1"># type: ignore[assignment]</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">received_spec</span> <span class="o">=</span> <span class="n">pytree</span><span class="o">.</span><span class="n">tree_flatten</span><span class="p">(</span><span class="n">user_args</span><span class="p">)</span>
                <span class="k">raise</span> <span class="n">error</span><span class="o">.</span><span class="n">InternalError</span><span class="p">(</span>
                    <span class="s2">&quot;Trying to flatten user inputs with exported input tree spec: </span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">call_spec</span><span class="o">.</span><span class="n">in_spec</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="s2">&quot;but actually got inputs with tree spec of: </span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">received_spec</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

        <span class="n">ordered_params</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_signature</span><span class="o">.</span><span class="n">parameters</span>
        <span class="p">)</span>
        <span class="n">ordered_buffers</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_signature</span><span class="o">.</span><span class="n">buffers</span>
        <span class="p">)</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="c1"># NOTE: calling convention is first params, then buffers, then args as user supplied them.</span>
            <span class="c1"># See: torch/_functorch/aot_autograd.py#L1034</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">Interpreter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">graph_module</span><span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="o">*</span><span class="n">ordered_params</span><span class="p">,</span> <span class="o">*</span><span class="n">ordered_buffers</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">enable_io_processing</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_spec</span><span class="o">.</span><span class="n">out_spec</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">mutation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_signature</span><span class="o">.</span><span class="n">buffers_to_mutate</span>
            <span class="n">num_mutated</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">mutation</span><span class="p">)</span>
            <span class="n">mutated_buffers</span> <span class="o">=</span> <span class="n">res</span><span class="p">[:</span><span class="n">num_mutated</span><span class="p">]</span>

            <span class="c1"># Exclude dependency token from final result.</span>
            <span class="n">assertion_dep_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_signature</span><span class="o">.</span><span class="n">assertion_dep_token</span>
            <span class="k">if</span> <span class="n">assertion_dep_token</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">assertion_dep_token_index</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">assertion_dep_token</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="p">[:</span><span class="n">assertion_dep_token_index</span><span class="p">]</span>

            <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="n">num_mutated</span><span class="p">:]</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">res</span> <span class="o">=</span> <span class="n">pytree</span><span class="o">.</span><span class="n">tree_unflatten</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_spec</span><span class="o">.</span><span class="n">out_spec</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">received_spec</span> <span class="o">=</span> <span class="n">pytree</span><span class="o">.</span><span class="n">tree_flatten</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
                <span class="k">raise</span> <span class="n">error</span><span class="o">.</span><span class="n">InternalError</span><span class="p">(</span>
                    <span class="s2">&quot;Trying to flatten user outputs with exported output tree spec: </span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">call_spec</span><span class="o">.</span><span class="n">out_spec</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="s2">&quot;but actually got outputs with tree spec of: </span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">received_spec</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">finally</span><span class="p">:</span>
                <span class="n">ix</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">for</span> <span class="n">buffer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_signature</span><span class="o">.</span><span class="n">buffers_to_mutate</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">[</span><span class="n">buffer</span><span class="p">]</span> <span class="o">=</span> <span class="n">mutated_buffers</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span>
                    <span class="n">ix</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">res</span>


<span class="nd">@compatibility</span><span class="p">(</span><span class="n">is_backward_compatible</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">ExirExportedProgram</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">exported_program</span><span class="p">:</span> <span class="n">ExportedProgram</span><span class="p">,</span>
        <span class="n">after_to_edge_passes</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exported_program</span> <span class="o">=</span> <span class="n">exported_program</span>

        <span class="c1"># Add a flag to denote whehter to_edge is called on this program</span>
        <span class="c1"># to detect misusage of directly calling to_executorch without to_edge</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">after_to_edge_passes</span> <span class="o">=</span> <span class="n">after_to_edge_passes</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">passes</span><span class="p">:</span> <span class="n">PassType</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ExirExportedProgram&quot;</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exported_program</span> <span class="o">=</span> <span class="n">_transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">exported_program</span><span class="p">,</span> <span class="o">*</span><span class="n">passes</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">module</span><span class="p">()(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>

    <span class="c1"># TODO(ycao): Change this to a composable function.</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">to_edge</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">EdgeCompileConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ExirExportedProgram&quot;</span><span class="p">:</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">config</span> <span class="ow">or</span> <span class="n">EdgeCompileConfig</span><span class="p">()</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">graph_module</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;type is instead: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">graph_module</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="k">return</span> <span class="n">_to_edge</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">dump</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">graph_module</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">to_executorch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ExecutorchBackendConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ExecutorchProgram&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">after_to_edge_passes</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Must run to_edge before to_executorch.&quot;</span><span class="p">)</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">config</span> <span class="ow">or</span> <span class="n">ExecutorchBackendConfig</span><span class="p">()</span>
        <span class="n">new_gm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">graph_module</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">edge_to_executorch_passes</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>
            <span class="n">new_gm_res</span> <span class="o">=</span> <span class="n">p</span><span class="p">(</span><span class="n">new_gm</span><span class="p">)</span>
            <span class="k">assert</span> <span class="n">new_gm_res</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="n">new_gm</span> <span class="o">=</span> <span class="n">new_gm_res</span><span class="o">.</span><span class="n">graph_module</span>

        <span class="c1"># This is tech debt on tech debt. memory planning pass inherits from some pass infra for GMs.</span>
        <span class="c1"># This isnt enough info now so i cant use call I have to use some new function &#39;run&#39;.</span>
        <span class="c1"># Existing user passes dont use run so Im just cheating here because they dont need to work on mutable buffers yet.</span>
        <span class="c1"># After exir.capture is gone I will clean up the memory planning infra to be consistent.</span>
        <span class="c1"># Frankly all of exir has big code quality issues because of the migrations that need to be addressed.</span>
        <span class="n">new_gm_res</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">memory_planning_pass</span><span class="p">(</span><span class="n">new_gm</span><span class="p">)</span>  <span class="c1"># pyre-ignore[29]</span>
        <span class="k">assert</span> <span class="n">new_gm_res</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="n">new_gm</span> <span class="o">=</span> <span class="n">new_gm_res</span><span class="o">.</span><span class="n">graph_module</span>
        <span class="n">new_prog</span> <span class="o">=</span> <span class="n">ExirExportedProgram</span><span class="p">(</span>
            <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">exported_program</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">after_to_edge_passes</span>
        <span class="p">)</span>
        <span class="n">_copy_module</span><span class="p">(</span><span class="n">new_prog</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">graph_module</span><span class="p">,</span> <span class="n">new_gm</span><span class="p">)</span>
        <span class="n">executorch_prog</span> <span class="o">=</span> <span class="n">ExecutorchProgram</span><span class="p">(</span>
            <span class="n">new_prog</span><span class="p">,</span>
            <span class="n">emit_stacktrace</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">emit_stacktrace</span><span class="p">,</span>
            <span class="n">extract_delegate_segments</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">extract_delegate_segments</span><span class="p">,</span>
            <span class="n">segment_alignment</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">segment_alignment</span><span class="p">,</span>
            <span class="n">constant_tensor_alignment</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">constant_tensor_alignment</span><span class="p">,</span>
            <span class="n">delegate_alignment</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">delegate_alignment</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">executorch_prog</span><span class="o">.</span><span class="n">graph_module</span><span class="o">.</span><span class="n">meta</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">new_gm</span><span class="o">.</span><span class="n">meta</span><span class="p">)</span>
        <span class="n">executorch_prog</span><span class="o">.</span><span class="n">graph_module</span><span class="o">.</span><span class="n">meta</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">graph_module</span><span class="o">.</span><span class="n">meta</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">executorch_prog</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">__deepcopy__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">memo</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ExirExportedProgram&quot;</span><span class="p">:</span>
        <span class="n">new_eep</span> <span class="o">=</span> <span class="n">ExirExportedProgram</span><span class="p">(</span>
            <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">exported_program</span><span class="p">,</span> <span class="n">memo</span><span class="p">),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">after_to_edge_passes</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">new_eep</span>


<span class="nd">@compatibility</span><span class="p">(</span><span class="n">is_backward_compatible</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">ExecutorchProgram</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">exir_exported_program</span><span class="p">:</span> <span class="n">ExirExportedProgram</span><span class="p">,</span>
        <span class="n">emit_stacktrace</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">extract_delegate_segments</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">segment_alignment</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">constant_tensor_alignment</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">delegate_alignment</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">exir_exported_program</span><span class="o">.</span><span class="n">after_to_edge_passes</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Need to call prog.to_edge prior to constructing ExecutorchProgram.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exported_program</span> <span class="o">=</span> <span class="n">exir_exported_program</span><span class="o">.</span><span class="n">exported_program</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pte_data</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Cord</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tensor_data</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Cord</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_buffer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bytes</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_emitter_output</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">EmitterOutput</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_emit_stacktrace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">emit_stacktrace</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_extract_delegate_segments</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">extract_delegate_segments</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_segment_alignment</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">segment_alignment</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_constant_tensor_alignment</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">constant_tensor_alignment</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_delegate_alignment</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">delegate_alignment</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">executorch.extension.flat_tensor.serialize.serialize</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
            <span class="n">FlatTensorConfig</span><span class="p">,</span>
            <span class="n">FlatTensorSerializer</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_data_serializer</span><span class="p">:</span> <span class="n">DataSerializer</span> <span class="o">=</span> <span class="n">FlatTensorSerializer</span><span class="p">(</span>
            <span class="n">FlatTensorConfig</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_segment_alignment</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_emitter_output</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">EmitterOutput</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_emitter_output</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_emitter_output</span> <span class="o">=</span> <span class="n">emit_program</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">exported_program</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_emit_stacktrace</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_emitter_output</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_pte_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Cord</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pte_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_pte_data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor_data</span> <span class="o">=</span> <span class="n">serialize_for_executorch</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_get_emitter_output</span><span class="p">(),</span>
                <span class="n">ExecutorchBackendConfig</span><span class="p">(</span>
                    <span class="n">extract_delegate_segments</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_extract_delegate_segments</span><span class="p">,</span>
                    <span class="n">segment_alignment</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_segment_alignment</span><span class="p">,</span>
                    <span class="n">constant_tensor_alignment</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_constant_tensor_alignment</span><span class="p">,</span>
                    <span class="n">delegate_alignment</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_delegate_alignment</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_data_serializer</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pte_data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pte_data</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">buffer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bytes</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the serialized ExecuTorch binary as a byte string.</span>

<span class="sd">        Note that the call to `buffer` may allocate a very large amount of</span>
<span class="sd">        contiguous memory, depending on the model size. If writing to a file,</span>
<span class="sd">        use `write_to_file` which won&#39;t incur additional copies.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO(T181494963): update pybinding to remove buffer cache, which can consume large</span>
        <span class="c1"># amounts of memory longer than necessary.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_buffer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_buffer</span> <span class="o">=</span> <span class="nb">bytes</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_pte_data</span><span class="p">())</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_buffer</span>

    <span class="nd">@property</span>
    <span class="nd">@experimental</span><span class="p">(</span><span class="s2">&quot;This API is experimental and subject to change without notice.&quot;</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">data_files</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the data files as a dictionary of filename to byte data.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dict[str, bytes]: Dictionary mapping data filenames (e.g., .ptd files) to</span>
<span class="sd">                their serialized byte content.</span>
<span class="sd">            Returns empty dict if no data files are available.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pte_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_get_pte_data</span><span class="p">()</span>  <span class="c1"># This populates _tensor_data</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{}</span>

        <span class="k">return</span> <span class="p">{</span><span class="n">filename</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">(</span><span class="n">cord</span><span class="p">)</span> <span class="k">for</span> <span class="n">filename</span><span class="p">,</span> <span class="n">cord</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor_data</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">program</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Program</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_emitter_output</span><span class="p">()</span><span class="o">.</span><span class="n">program</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">debug_handle_map</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_emitter_output</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_emitter_output</span><span class="o">.</span><span class="n">debug_handle_map</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_emitter_output</span><span class="p">()</span><span class="o">.</span><span class="n">debug_handle_map</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">delegate_map</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">_DelegateDebugIdentifierMap</span><span class="p">]]]]:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_emitter_output</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_emitter_output</span><span class="o">.</span><span class="n">method_to_delegate_debug_id_map</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_emitter_output</span><span class="p">()</span><span class="o">.</span><span class="n">method_to_delegate_debug_id_map</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">instruction_id_to_num_outs_map</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]]:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_emitter_output</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_emitter_output</span><span class="o">.</span><span class="n">instruction_id_to_num_outs_map</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_emitter_output</span><span class="p">()</span><span class="o">.</span><span class="n">instruction_id_to_num_outs_map</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">graph_module</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">graph_module</span>

    <span class="c1"># TODO (zhxchen17) Change this to property.</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">dump_graph_module</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">graph_module</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">dump_exported_program</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ExportedProgram</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">exported_program</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">write_to_file</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">open_file</span><span class="p">:</span> <span class="n">io</span><span class="o">.</span><span class="n">BufferedIOBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Writes the serialized ExecuTorch binary to the file at `open_file`. Prefer to use this over</span>
<span class="sd">        `buffer`, as it writes to file without copying into a contiguous block of memory first,</span>
<span class="sd">        reducing the peak memory usage.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_pte_data</span><span class="p">()</span><span class="o">.</span><span class="n">write_to_file</span><span class="p">(</span><span class="n">open_file</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">write_tensor_data_to_file</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outdir</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Writes the serialized ExecuTorch data files to the directory at `outdir`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor_data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="c1"># pyre-ignore[16]: `Optional` has no attribute `items`.</span>
        <span class="k">for</span> <span class="n">filename</span><span class="p">,</span> <span class="n">cord</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor_data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">outdir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">.ptd&quot;</span><span class="p">),</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Writing data file to </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">.ptd&quot;</span><span class="p">)</span>
                <span class="n">cord</span><span class="o">.</span><span class="n">write_to_file</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_get_aten_to_edge_passes</span><span class="p">(</span><span class="n">config</span><span class="p">:</span> <span class="n">EdgeCompileConfig</span><span class="p">):</span>
    <span class="c1"># TODO: the last two passes for aten_to_edge need to be eliminated_dead_code -&gt; debug_handle_generator. After enable</span>
    <span class="c1"># use_edge_op it can be moved to aten_to_edge_passes before eliminated_dead_code pass. Also ExportPass doesn&#39;t play</span>
    <span class="c1"># well with node.meta, meaning after some passes permuting operators, we may lose some information in node.meta.</span>
    <span class="c1"># It might be regenerated in SpecPropPass so it may not be visiable. However debug handle will be lost.</span>

    <span class="n">pre_op_replace_passes</span> <span class="o">=</span> <span class="n">base_pre_op_replace_passes</span> <span class="o">+</span> <span class="p">[</span><span class="n">RemoveMixedTypeOperators</span><span class="p">()]</span>

    <span class="n">post_op_replace_passes</span> <span class="o">=</span> <span class="n">base_post_op_replace_passes</span>

    <span class="k">return</span> <span class="n">pre_op_replace_passes</span><span class="p">,</span> <span class="n">post_op_replace_passes</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_to_edge</span><span class="p">(</span><span class="n">ep</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">EdgeCompileConfig</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ExirExportedProgram&quot;</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">_check_ir_validity</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">EXIRATenDialectVerifier</span><span class="p">()(</span><span class="n">ep</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">graph_module</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">ExportError</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;If a particular operator failed core ATen IR check, please consider adding it to the exception list. &quot;</span>
                <span class="s2">&quot;Add the operator to _core_aten_ops_exception_list in EdgeCompileConfig. This is the recommended way &quot;</span>
                <span class="s2">&quot;to resolve this type of failure, so that the rest of the IR validation check can still be performed.</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;If you&#39;d like to disable IR validation checking, please set _check_ir_validity in EdgeCompileConfig, &quot;</span>
                <span class="s2">&quot;like *.to_edge(exir.EdgeCompileConfig(_check_ir_validity=False)).&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span>

    <span class="n">dialect</span> <span class="o">=</span> <span class="n">ep</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">dialect</span>
    <span class="k">if</span> <span class="n">dialect</span> <span class="o">==</span> <span class="s2">&quot;ATEN&quot;</span><span class="p">:</span>
        <span class="n">ep</span> <span class="o">=</span> <span class="n">ExirExportedProgram</span><span class="p">(</span>
            <span class="n">ExportedProgram</span><span class="p">(</span>
                <span class="n">root</span><span class="o">=</span><span class="n">ep</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">graph_module</span><span class="p">,</span>
                <span class="n">graph</span><span class="o">=</span><span class="n">ep</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">graph_module</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span>
                <span class="n">graph_signature</span><span class="o">=</span><span class="n">ep</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">graph_signature</span><span class="p">,</span>
                <span class="n">state_dict</span><span class="o">=</span><span class="n">ep</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">state_dict</span><span class="p">,</span>
                <span class="n">range_constraints</span><span class="o">=</span><span class="n">ep</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">range_constraints</span><span class="p">,</span>
                <span class="n">module_call_graph</span><span class="o">=</span><span class="n">ep</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">module_call_graph</span><span class="p">,</span>
                <span class="n">example_inputs</span><span class="o">=</span><span class="n">ep</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">example_inputs</span><span class="p">,</span>
                <span class="n">constants</span><span class="o">=</span><span class="n">ep</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">constants</span><span class="p">,</span>
                <span class="n">verifiers</span><span class="o">=</span><span class="p">[</span>
                    <span class="n">get_aten_verifier</span><span class="p">(</span>
                        <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">],</span>
            <span class="p">),</span>
            <span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="n">pre_op_replace_passes</span><span class="p">,</span> <span class="n">post_op_replace_passes</span> <span class="o">=</span> <span class="n">_get_aten_to_edge_passes</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

    <span class="n">new_ep</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">ep</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="o">*</span><span class="n">pre_op_replace_passes</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dialect</span> <span class="o">==</span> <span class="s2">&quot;ATEN&quot;</span><span class="p">:</span>
        <span class="n">new_ep</span><span class="o">.</span><span class="n">exported_program</span> <span class="o">=</span> <span class="n">lift_constant_tensor_pass</span><span class="p">(</span><span class="n">new_ep</span><span class="o">.</span><span class="n">exported_program</span><span class="p">)</span>

    <span class="n">new_gm</span> <span class="o">=</span> <span class="n">new_ep</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">graph_module</span>
    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">_use_edge_ops</span><span class="p">:</span>
        <span class="n">new_gm_res</span> <span class="o">=</span> <span class="n">OpReplacePass</span><span class="p">()(</span><span class="n">new_gm</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">new_gm_res</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="n">new_gm</span> <span class="o">=</span> <span class="n">new_gm_res</span><span class="o">.</span><span class="n">graph_module</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">_skip_dim_order</span><span class="p">:</span>
            <span class="n">new_gm_res</span> <span class="o">=</span> <span class="n">MemoryFormatOpsPass</span><span class="p">()(</span><span class="n">new_gm</span><span class="p">)</span>
            <span class="k">assert</span> <span class="n">new_gm_res</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="n">new_gm</span> <span class="o">=</span> <span class="n">new_gm_res</span><span class="o">.</span><span class="n">graph_module</span>

    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">post_op_replace_passes</span><span class="p">:</span>
        <span class="n">new_gm_res</span> <span class="o">=</span> <span class="n">p</span><span class="p">(</span><span class="n">new_gm</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">new_gm_res</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="n">new_gm</span> <span class="o">=</span> <span class="n">new_gm_res</span><span class="o">.</span><span class="n">graph_module</span>

    <span class="n">new_ep</span><span class="o">.</span><span class="n">exported_program</span> <span class="o">=</span> <span class="n">ExportedProgram</span><span class="p">(</span>
        <span class="n">root</span><span class="o">=</span><span class="n">new_gm</span><span class="p">,</span>
        <span class="n">graph</span><span class="o">=</span><span class="n">new_gm</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span>
        <span class="n">graph_signature</span><span class="o">=</span><span class="n">_get_updated_graph_signature</span><span class="p">(</span>
            <span class="n">new_ep</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">graph_signature</span><span class="p">,</span> <span class="n">new_gm</span>
        <span class="p">),</span>
        <span class="n">state_dict</span><span class="o">=</span><span class="n">new_ep</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">state_dict</span><span class="p">,</span>
        <span class="n">range_constraints</span><span class="o">=</span><span class="n">new_ep</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">range_constraints</span><span class="p">,</span>
        <span class="n">module_call_graph</span><span class="o">=</span><span class="n">new_ep</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">module_call_graph</span><span class="p">,</span>
        <span class="n">example_inputs</span><span class="o">=</span><span class="n">new_ep</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">example_inputs</span><span class="p">,</span>
        <span class="n">constants</span><span class="o">=</span><span class="n">new_ep</span><span class="o">.</span><span class="n">exported_program</span><span class="o">.</span><span class="n">constants</span><span class="p">,</span>
        <span class="n">verifiers</span><span class="o">=</span><span class="p">[</span>
            <span class="n">EXIREdgeDialectVerifier</span><span class="p">(</span>
                <span class="n">edge_compile_config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
                <span class="n">class_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">],</span>
    <span class="p">)</span>
    <span class="n">new_ep</span><span class="o">.</span><span class="n">after_to_edge_passes</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">return</span> <span class="n">new_ep</span>


<span class="k">def</span><span class="w"> </span><span class="nf">pre_memory_planning_passes</span><span class="p">(</span>
    <span class="n">config</span><span class="p">:</span> <span class="n">ExecutorchBackendConfig</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">PassType</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a list of passes to run before memory planning.</span>
<span class="sd">    Get the sym shape eval pass based on the method name, if the pass is not in the dict, use the default pass.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Handle symbolic shape eval pass</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">sym_shape_eval_pass</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="n">default_pass</span> <span class="o">=</span> <span class="n">ExecutorchBackendConfig</span><span class="p">()</span><span class="o">.</span><span class="n">sym_shape_eval_pass</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">name</span><span class="p">:</span>
            <span class="n">sym_shape_eval_pass</span> <span class="o">=</span> <span class="n">default_pass</span>
        <span class="c1"># pyre-ignore: Undefined attribute [16]</span>
        <span class="n">sym_shape_eval_pass</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">sym_shape_eval_pass</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">default_pass</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">sym_shape_eval_pass</span><span class="p">,</span> <span class="n">PassBase</span><span class="p">):</span>
        <span class="n">sym_shape_eval_pass</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">sym_shape_eval_pass</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;sym_shape_eval_pass must be a dict or a PassBase, got </span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">sym_shape_eval_pass</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">remove_view_copy</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="n">NormalizeViewCopyBasePass</span><span class="p">(),</span>
            <span class="n">dead_code_elimination_pass</span><span class="p">,</span>
            <span class="n">ReplaceViewCopyWithViewPass</span><span class="p">(),</span>
            <span class="n">sym_shape_eval_pass</span><span class="p">,</span>
            <span class="n">config</span><span class="o">.</span><span class="n">to_out_var_pass</span><span class="p">,</span>
        <span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="n">sym_shape_eval_pass</span><span class="p">,</span>
            <span class="n">config</span><span class="o">.</span><span class="n">to_out_var_pass</span><span class="p">,</span>
        <span class="p">]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">edge_to_executorch_passes</span><span class="p">(</span>
    <span class="n">config</span><span class="p">:</span> <span class="n">ExecutorchBackendConfig</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">PassType</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a list of passes to lower from edge to executorch.</span>
<span class="sd">    Get the pre memory planning passes based on the method name, if the pass is not in the dict, use the default pass.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">passes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">PassType</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
        <span class="c1"># ExecuTorch backend ops are unable to handle unbacked symints. So after</span>
        <span class="c1"># this pass, passes cannot be Interpreter-based, because it will fail if</span>
        <span class="c1"># there exists an unbacked symint operation.</span>
        <span class="o">*</span><span class="n">config</span><span class="o">.</span><span class="n">passes</span><span class="p">,</span>
        <span class="n">SpecPropPass</span><span class="p">(),</span>
        <span class="n">EdgeToBackendOpsPass</span><span class="p">(),</span>
        <span class="n">RemoveGraphAssertsPass</span><span class="p">(),</span>
    <span class="p">]</span> <span class="o">+</span> <span class="n">pre_memory_planning_passes</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">passes</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_generate_edge_program</span><span class="p">(</span>
    <span class="n">config</span><span class="p">:</span> <span class="n">EdgeCompileConfig</span><span class="p">,</span>
    <span class="n">program</span><span class="p">:</span> <span class="n">ExportedProgram</span><span class="p">,</span>
    <span class="n">core_aten_ops_exception_list</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">_ops</span><span class="o">.</span><span class="n">OpOverload</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">preserve_ops</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">_ops</span><span class="o">.</span><span class="n">OpOverload</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ExportedProgram</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">        config: The configuration for the edge program.</span>
<span class="sd">        program: The exported program to be converted to an edge program.</span>
<span class="sd">        core_aten_ops_exception_list: A list of aten ops that are missing decompositions to core aten.</span>
<span class="sd">        preserve_ops: A list of aten ops that should not be decomposed.</span>
<span class="sd">    Returns:</span>
<span class="sd">        An ExportedProgram in edge dialect.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Remove unused parameters</span>
    <span class="n">program</span> <span class="o">=</span> <span class="n">remove_unused_parameters_pass</span><span class="p">(</span><span class="n">program</span><span class="p">)</span>

    <span class="n">pre_op_replace_passes</span><span class="p">,</span> <span class="n">post_op_replace_passes</span> <span class="o">=</span> <span class="n">_get_aten_to_edge_passes</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

    <span class="n">passes</span> <span class="o">=</span> <span class="p">[</span>
        <span class="c1"># Remove invalid assert ops, such as _assert_tensor_metadata</span>
        <span class="n">RemoveNonCoreAtenOpGraphAssertsPass</span><span class="p">(),</span>
        <span class="c1"># TODO move inside aten_to_edge passes after all users are migrated off v1 capture</span>
        <span class="n">ReplaceViewOpsWithViewCopyOpsPass</span><span class="p">(),</span>
    <span class="p">]</span>
    <span class="n">passes</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">pre_op_replace_passes</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">_use_edge_ops</span><span class="p">:</span>
        <span class="n">passes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">OpReplacePass</span><span class="p">())</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="o">.</span><span class="n">_skip_dim_order</span><span class="p">:</span>
            <span class="n">passes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">MemoryFormatOpsPass</span><span class="p">())</span>

    <span class="n">gm</span> <span class="o">=</span> <span class="n">program</span><span class="o">.</span><span class="n">graph_module</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">passes</span><span class="p">:</span>
        <span class="n">gm_res</span> <span class="o">=</span> <span class="n">p</span><span class="p">(</span><span class="n">gm</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">gm_res</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="n">gm</span> <span class="o">=</span> <span class="n">gm_res</span><span class="o">.</span><span class="n">graph_module</span>

    <span class="n">edge_program</span> <span class="o">=</span> <span class="n">ExportedProgram</span><span class="p">(</span>
        <span class="n">root</span><span class="o">=</span><span class="n">gm</span><span class="p">,</span>
        <span class="n">graph</span><span class="o">=</span><span class="n">gm</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span>
        <span class="n">graph_signature</span><span class="o">=</span><span class="n">_get_updated_graph_signature</span><span class="p">(</span><span class="n">program</span><span class="o">.</span><span class="n">graph_signature</span><span class="p">,</span> <span class="n">gm</span><span class="p">),</span>
        <span class="n">state_dict</span><span class="o">=</span><span class="n">program</span><span class="o">.</span><span class="n">state_dict</span><span class="p">,</span>
        <span class="n">range_constraints</span><span class="o">=</span><span class="n">program</span><span class="o">.</span><span class="n">range_constraints</span><span class="p">,</span>
        <span class="n">module_call_graph</span><span class="o">=</span><span class="n">program</span><span class="o">.</span><span class="n">module_call_graph</span><span class="p">,</span>
        <span class="n">example_inputs</span><span class="o">=</span><span class="n">program</span><span class="o">.</span><span class="n">example_inputs</span><span class="p">,</span>
        <span class="n">constants</span><span class="o">=</span><span class="n">program</span><span class="o">.</span><span class="n">constants</span><span class="p">,</span>
        <span class="n">verifiers</span><span class="o">=</span><span class="p">[</span>
            <span class="n">EXIREdgeDialectVerifier</span><span class="p">(</span>
                <span class="n">edge_compile_config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
                <span class="n">class_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">core_aten_ops_exception_list</span><span class="o">=</span><span class="n">core_aten_ops_exception_list</span><span class="p">,</span>
                <span class="n">preserve_ops</span><span class="o">=</span><span class="n">preserve_ops</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">],</span>
    <span class="p">)</span>
    <span class="c1"># Lift the tensor constants created in ScalarToTensorPass</span>
    <span class="n">edge_program</span> <span class="o">=</span> <span class="n">lift_constant_tensor_pass</span><span class="p">(</span><span class="n">edge_program</span><span class="p">)</span>
    <span class="n">edge_program</span> <span class="o">=</span> <span class="n">_transform</span><span class="p">(</span><span class="n">edge_program</span><span class="p">,</span> <span class="o">*</span><span class="n">post_op_replace_passes</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">edge_program</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_replace_aten_ops_with_transformed_ops</span><span class="p">(</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">program</span><span class="p">:</span> <span class="n">ExportedProgram</span><span class="p">,</span>
    <span class="n">partitioner</span><span class="p">,</span>
<span class="p">):</span>
    <span class="n">preserve_ops</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="n">partitioners</span> <span class="o">=</span> <span class="n">partitioner</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">partitioners</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span>

    <span class="c1"># Iterate through the graph and replace the aten ops with the corresponding</span>
    <span class="c1"># transformed ops.</span>
    <span class="k">for</span> <span class="n">partitioner</span> <span class="ow">in</span> <span class="n">partitioners</span><span class="p">:</span>
        <span class="n">ops_set_to_not_decompose</span><span class="p">,</span> <span class="n">check_op_support</span> <span class="o">=</span> <span class="n">partitioner</span><span class="o">.</span><span class="n">ops_to_not_decompose</span><span class="p">(</span>
            <span class="n">program</span>
        <span class="p">)</span>
        <span class="n">ops_set_to_not_decompose</span> <span class="o">=</span> <span class="n">_remove_invalid_ops_for_not_decompose</span><span class="p">(</span>
            <span class="n">ops_set_to_not_decompose</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">op_aten</span> <span class="ow">in</span> <span class="n">ops_set_to_not_decompose</span><span class="p">:</span>
            <span class="n">_register_no_decomp_op</span><span class="p">(</span><span class="n">op_aten</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">program</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
            <span class="n">is_op_supported</span> <span class="o">=</span> <span class="n">check_op_support</span><span class="p">(</span><span class="n">node</span><span class="p">)</span> <span class="k">if</span> <span class="n">check_op_support</span> <span class="k">else</span> <span class="kc">True</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;call_function&quot;</span>
                <span class="ow">and</span> <span class="n">node</span><span class="o">.</span><span class="n">target</span> <span class="ow">in</span> <span class="n">ops_set_to_not_decompose</span>
                <span class="ow">and</span> <span class="n">is_op_supported</span>
            <span class="p">):</span>
                <span class="n">preserve_ops</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
                <span class="n">node</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">aten_op_to_transform_op</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">target</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">submod</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">get_control_flow_submodules</span><span class="p">(</span><span class="n">program</span><span class="o">.</span><span class="n">graph_module</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">submod</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
                <span class="n">is_op_supported</span> <span class="o">=</span> <span class="n">check_op_support</span><span class="p">(</span><span class="n">node</span><span class="p">)</span> <span class="k">if</span> <span class="n">check_op_support</span> <span class="k">else</span> <span class="kc">True</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;call_function&quot;</span>
                    <span class="ow">and</span> <span class="n">node</span><span class="o">.</span><span class="n">target</span> <span class="ow">in</span> <span class="n">ops_set_to_not_decompose</span>
                    <span class="ow">and</span> <span class="n">is_op_supported</span>
                <span class="p">):</span>
                    <span class="n">preserve_ops</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
                    <span class="n">node</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">aten_op_to_transform_op</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">target</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">preserve_ops</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_restore_transformed_ops_to_aten_ops</span><span class="p">(</span><span class="n">program</span><span class="p">:</span> <span class="n">ExportedProgram</span><span class="p">):</span>
    <span class="c1"># Iterate through the graph and replace back the transformed ops with their</span>
    <span class="c1"># corresponding aten ops.</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">program</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;call_function&quot;</span> <span class="ow">and</span> <span class="nb">str</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="n">transform_op_to_aten_op</span><span class="p">:</span>
            <span class="n">node</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">transform_op_to_aten_op</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">target</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">submod</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">get_control_flow_submodules</span><span class="p">(</span><span class="n">program</span><span class="o">.</span><span class="n">graph_module</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">submod</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;call_function&quot;</span>
                <span class="ow">and</span> <span class="nb">str</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="n">transform_op_to_aten_op</span>
            <span class="p">):</span>
                <span class="n">node</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">transform_op_to_aten_op</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">target</span><span class="p">)]</span>


<span class="c1"># Returns the op in edge_no_decomp_namespace namespace for the aten</span>
<span class="c1"># op that is passed in.</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_get_transformed_op</span><span class="p">(</span><span class="n">op_aten</span><span class="p">):</span>
    <span class="n">op_name</span> <span class="o">=</span> <span class="n">op_aten</span><span class="o">.</span><span class="n">_schema</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;::&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">overload_name</span> <span class="o">=</span> <span class="n">op_aten</span><span class="o">.</span><span class="n">_schema</span><span class="o">.</span><span class="n">overload_name</span>
    <span class="k">assert</span> <span class="nb">hasattr</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="p">,</span> <span class="n">edge_no_decomp_namespace</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Couldn&#39;t find </span><span class="si">{</span><span class="n">edge_no_decomp_namespace</span><span class="si">}</span><span class="s2"> in torch.ops. Please make sure the Library has been registered.&quot;</span>
    <span class="n">op_namespace</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="p">,</span> <span class="n">edge_no_decomp_namespace</span><span class="p">)</span>
    <span class="n">op</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">op_namespace</span><span class="p">,</span> <span class="n">op_name</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">overload_name</span><span class="p">)</span>


<span class="c1"># Registers the op in edge_no_decomp_namespace namespace for the aten</span>
<span class="c1"># op that is passed in if it is not already cached in the table.</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_register_no_decomp_op</span><span class="p">(</span><span class="n">op_aten</span><span class="p">):</span>
    <span class="c1"># Check if the op is already cached in the table. If not, then we need to</span>
    <span class="c1"># create a new op in the edge_no_decomp_namespace namespace.</span>
    <span class="k">if</span> <span class="n">aten_op_to_transform_op</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">op_aten</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span>
        <span class="n">op_aten</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">_ops</span><span class="o">.</span><span class="n">OpOverload</span>
    <span class="p">):</span>
        <span class="c1"># Extract the schema from the aten op.</span>
        <span class="n">op_schema</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">op_aten</span><span class="o">.</span><span class="n">_schema</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;::&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">op_name</span> <span class="o">=</span> <span class="n">op_aten</span><span class="o">.</span><span class="n">_schema</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;::&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># Define an op in the edge_no_decomp_namespace namespace with the aten schema.</span>
        <span class="n">lib</span><span class="o">.</span><span class="n">define</span><span class="p">(</span><span class="n">op_schema</span><span class="p">)</span>
        <span class="c1"># Define the implementation of the op in the edge_no_decomp_namespace namespace.</span>
        <span class="c1"># Important to note that the implementation of the op is the same as the aten op.</span>

        <span class="n">overload_name</span> <span class="o">=</span> <span class="n">op_aten</span><span class="o">.</span><span class="n">_schema</span><span class="o">.</span><span class="n">overload_name</span>
        <span class="k">if</span> <span class="n">overload_name</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="n">op_name</span> <span class="o">+=</span> <span class="s2">&quot;.&quot;</span> <span class="o">+</span> <span class="n">overload_name</span>
        <span class="n">lib</span><span class="o">.</span><span class="n">impl</span><span class="p">(</span><span class="n">op_name</span><span class="p">,</span> <span class="n">op_aten</span><span class="p">,</span> <span class="s2">&quot;CompositeExplicitAutograd&quot;</span><span class="p">)</span>

        <span class="c1"># Cache the aten op and transformed op in their corresponding tables for future use.</span>
        <span class="n">aten_op_to_transform_op</span><span class="p">[</span><span class="n">op_aten</span><span class="p">]</span> <span class="o">=</span> <span class="n">_get_transformed_op</span><span class="p">(</span><span class="n">op_aten</span><span class="p">)</span>
        <span class="n">transform_op_to_aten_op</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">aten_op_to_transform_op</span><span class="p">[</span><span class="n">op_aten</span><span class="p">])]</span> <span class="o">=</span> <span class="n">op_aten</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_sanity_check_graph_for_non_decomp_ops</span><span class="p">(</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">program</span><span class="p">:</span> <span class="n">ExportedProgram</span><span class="p">,</span>
    <span class="n">ops_set_to_not_decompose</span><span class="p">,</span>
    <span class="n">check_op_support</span><span class="p">,</span>
    <span class="n">generate_error</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">partitioner_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
    <span class="n">warning_str_end</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
    <span class="k">if</span> <span class="n">partitioner_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">warning_str_end</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;This op was registered by the partitioner </span><span class="si">{</span><span class="n">partitioner_name</span><span class="si">}</span><span class="s2"> to not be decomposed.</span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="n">warning_str_end</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;The following ops: </span><span class="si">{</span><span class="n">ops_set_to_not_decompose</span><span class="si">}</span><span class="s2"> were specified to not be decomposed in </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.&quot;</span>

    <span class="c1"># Check that the ops that were registered to not be decomposed are not present in the</span>
    <span class="c1"># graph anymore as the transform passes and backends should have consumed them by now.</span>
    <span class="n">ops_set_to_not_decompose</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">aten_to_edge</span><span class="p">(</span><span class="n">op</span><span class="p">)</span> <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">ops_set_to_not_decompose</span>
    <span class="p">}</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">ops_set_to_not_decompose</span><span class="p">)</span>

    <span class="n">quant_primitives</span> <span class="o">=</span> <span class="p">{</span><span class="n">aten_to_edge</span><span class="p">(</span><span class="n">op</span><span class="p">)</span> <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">_QUANT_PRIMITIVES</span><span class="p">}</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">program</span><span class="o">.</span><span class="n">graph_module</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
        <span class="n">is_op_supported</span> <span class="o">=</span> <span class="n">check_op_support</span><span class="p">(</span><span class="n">node</span><span class="p">)</span> <span class="k">if</span> <span class="n">check_op_support</span> <span class="k">else</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;call_function&quot;</span>
            <span class="ow">and</span> <span class="n">node</span><span class="o">.</span><span class="n">target</span> <span class="ow">in</span> <span class="n">ops_set_to_not_decompose</span>
            <span class="ow">and</span> <span class="n">node</span><span class="o">.</span><span class="n">target</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">quant_primitives</span>
        <span class="p">)</span> <span class="ow">and</span> <span class="n">is_op_supported</span><span class="p">:</span>
            <span class="n">warning_str</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Node </span><span class="si">{</span><span class="n">node</span><span class="si">}</span><span class="s2"> with op </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">target</span><span class="si">}</span><span class="s2"> was not decomposed or delegated.</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="o">+</span> <span class="n">warning_str_end</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">generate_error</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">warning_str</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="n">warning_str</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">submod</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">get_control_flow_submodules</span><span class="p">(</span><span class="n">program</span><span class="o">.</span><span class="n">graph_module</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">submod</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
            <span class="n">is_op_supported</span> <span class="o">=</span> <span class="n">check_op_support</span><span class="p">(</span><span class="n">node</span><span class="p">)</span> <span class="k">if</span> <span class="n">check_op_support</span> <span class="k">else</span> <span class="kc">True</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;call_function&quot;</span>
                <span class="ow">and</span> <span class="n">node</span><span class="o">.</span><span class="n">target</span> <span class="ow">in</span> <span class="n">ops_set_to_not_decompose</span>
                <span class="ow">and</span> <span class="n">node</span><span class="o">.</span><span class="n">target</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">quant_primitives</span>
            <span class="p">)</span> <span class="ow">and</span> <span class="n">is_op_supported</span><span class="p">:</span>
                <span class="n">warning_str</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Node </span><span class="si">{</span><span class="n">node</span><span class="si">}</span><span class="s2"> with op </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">target</span><span class="si">}</span><span class="s2"> was not decomposed or delegated.</span><span class="se">\n</span><span class="s2">&quot;</span>
                    <span class="o">+</span> <span class="n">warning_str_end</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">generate_error</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">warning_str</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="n">warning_str</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_remove_invalid_ops_for_not_decompose</span><span class="p">(</span>
    <span class="n">preserve_ops</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">_ops</span><span class="o">.</span><span class="n">OpOverload</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">_ops</span><span class="o">.</span><span class="n">OpOverload</span><span class="p">]:</span>
    <span class="n">_logged_warnings</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">log_warning</span><span class="p">(</span><span class="n">warn_str</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">warn_str</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_logged_warnings</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">warn_str</span><span class="p">)</span>
            <span class="n">_logged_warnings</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">warn_str</span><span class="p">)</span>

    <span class="c1"># To address https://github.com/pytorch/executorch/issues/8781</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">keep</span><span class="p">(</span><span class="n">op</span><span class="p">):</span>
        <span class="c1"># Explicit allow list</span>
        <span class="n">allow_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Ops in torch.ops.quant are not always loaded, so we use try/except</span>
            <span class="c1"># Aliases output, but we need to allow it for XNNPACK</span>
            <span class="n">allow_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">torchao</span><span class="o">.</span><span class="n">choose_qparams_affine</span><span class="o">.</span><span class="n">default</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">pass</span>

        <span class="k">if</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">allow_list</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="n">schema</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">_schema</span>
        <span class="n">native_schema</span> <span class="o">=</span> <span class="n">_pybind_schema_to_native_schema</span><span class="p">(</span><span class="n">schema</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">native_schema</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">log_warning</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Torchgen is not able to parse the schema of </span><span class="si">{</span><span class="n">op</span><span class="o">.</span><span class="n">_schema</span><span class="si">}</span><span class="s2">.  This is not fatal.&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">native_schema</span><span class="o">.</span><span class="n">is_mutable</span><span class="p">:</span>
                <span class="n">log_warning</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Op </span><span class="si">{</span><span class="n">op</span><span class="si">}</span><span class="s2"> was requested for preservation by partitioner.  This request is ignored because it is mutable.&quot;</span>
                <span class="p">)</span>
                <span class="k">return</span> <span class="kc">False</span>

            <span class="k">if</span> <span class="n">native_schema</span><span class="o">.</span><span class="n">aliased_return_names</span><span class="p">()</span> <span class="o">!=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]:</span>
                <span class="n">log_warning</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Op </span><span class="si">{</span><span class="n">op</span><span class="si">}</span><span class="s2"> was requested for preservation by partitioner.  This request is ignored because it aliases output.&quot;</span>
                <span class="p">)</span>
                <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># Explicit block list of ops that don&#39;t work if asked for</span>
        <span class="c1"># preservation</span>
        <span class="k">if</span> <span class="n">op</span> <span class="ow">in</span> <span class="p">[</span>
            <span class="c1"># Hits infinte recursion error when op is in</span>
            <span class="c1"># EDGE_DO_NOT_DECOMP namespace</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">_to_copy</span><span class="o">.</span><span class="n">default</span><span class="p">,</span>
            <span class="c1"># scalar to tensor type promotion does not work on ops</span>
            <span class="c1"># in EDGE_DO_NOT_DECOMP namespace</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">mul</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">add</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">sub</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">div</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">item</span><span class="o">.</span><span class="n">default</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">_local_scalar_dense</span><span class="o">.</span><span class="n">default</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">unbind</span><span class="o">.</span><span class="n">int</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">split_with_sizes</span><span class="o">.</span><span class="n">default</span><span class="p">,</span>
        <span class="p">]:</span>
            <span class="n">log_warning</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Op </span><span class="si">{</span><span class="n">op</span><span class="si">}</span><span class="s2"> was requested for preservation by partitioner.  This request is ignored because it is in a blocklist.&quot;</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="n">keep</span><span class="p">,</span> <span class="n">preserve_ops</span><span class="p">))</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_can_skip_using_EDGE_DO_NOT_DECOMP</span><span class="p">(</span>
    <span class="n">partitioner</span><span class="p">:</span> <span class="n">Partitioner</span><span class="p">,</span> <span class="n">program</span><span class="p">:</span> <span class="n">ExportedProgram</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="c1"># THe current design of using EDGE_DO_NOT_DECOMP to prevent decomposition</span>
    <span class="c1"># has long standing issues.  _remove_invalid_ops_for_not_decompose was a band-aid to</span>
    <span class="c1"># fix some of the issues, but more issues are coming up over time, including a new issue with SDPA</span>
    <span class="c1"># and contiguous views: https://fb.workplace.com/groups/pytorch.edge.users/permalink/1796069037930048/</span>
    <span class="c1"># EDGE_DO_NOT_DECOMP is only needed by partitioners that specify check_op_support</span>
    <span class="c1"># As a temp fix, we give a more reliable path for backends that do not specify check_op_support</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">check_op_support</span> <span class="o">=</span> <span class="n">partitioner</span><span class="o">.</span><span class="n">ops_to_not_decompose</span><span class="p">(</span><span class="n">program</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">check_op_support</span> <span class="ow">is</span> <span class="kc">None</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_gen_edge_manager_for_partitioners</span><span class="p">(</span>
    <span class="n">partitioner</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Partitioner</span><span class="p">]],</span>
    <span class="n">aten_programs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ExportedProgram</span><span class="p">],</span>
    <span class="n">config</span><span class="p">:</span> <span class="n">EdgeCompileConfig</span><span class="p">,</span>
    <span class="n">constant_methods</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">generate_etrecord</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;EdgeProgramManager&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generates EdgeProgramManager for subsequent lowering to the</span>
<span class="sd">    partitioners specified by partitioner. The EdgeProgramManager is generated from</span>
<span class="sd">    aten_programs.</span>

<span class="sd">    Partitioners specify what nodes should not be decomposed from the original aten programs.</span>
<span class="sd">    This is done through two passes of run_decompositions.</span>
<span class="sd">        - First pass preserves all aten_targets specified by partitioners to preserve</span>
<span class="sd">          them from nested decompositions</span>
<span class="sd">        - Second pass uses check_op fn provided by partitioners to perform additional checks</span>
<span class="sd">          on nodes with preserved aten targets. They are then replaces with transformed ops to</span>
<span class="sd">          keep them through the second pass of decompositions</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ops_set_to_not_decompose_by_program</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
    <span class="n">edge_programs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ExportedProgram</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">program</span> <span class="ow">in</span> <span class="n">aten_programs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="c1"># Functionalize program before asking partitioners to preserve ops</span>
        <span class="n">program</span> <span class="o">=</span> <span class="n">program</span><span class="o">.</span><span class="n">run_decompositions</span><span class="p">({})</span>

        <span class="k">if</span> <span class="n">partitioner</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">partitioners_for_program</span> <span class="o">=</span> <span class="n">partitioner</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[])</span>
            <span class="n">final_ops_to_preserve</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

            <span class="c1"># Decompose by default if there are no partitioners for the method</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">partitioners_for_program</span><span class="p">:</span>
                <span class="n">program</span> <span class="o">=</span> <span class="n">program</span><span class="o">.</span><span class="n">run_decompositions</span><span class="p">(</span><span class="n">_default_decomposition_table</span><span class="p">())</span>

            <span class="c1"># Process each partitioner individually using their specific requirements</span>
            <span class="k">for</span> <span class="n">curr_partitioner</span> <span class="ow">in</span> <span class="n">partitioners_for_program</span><span class="p">:</span>
                <span class="n">curr_ops_no_decomp</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">curr_partitioner</span><span class="o">.</span><span class="n">ops_to_not_decompose</span><span class="p">(</span><span class="n">program</span><span class="p">)</span>

                <span class="c1"># Check if this partitioner can skip using EDGE_DO_NOT_DECOMP</span>
                <span class="n">can_skip_using_edge_do_not_decomp</span> <span class="o">=</span> <span class="n">_can_skip_using_EDGE_DO_NOT_DECOMP</span><span class="p">(</span>
                    <span class="n">curr_partitioner</span><span class="p">,</span> <span class="n">program</span>
                <span class="p">)</span>

                <span class="k">if</span> <span class="n">can_skip_using_edge_do_not_decomp</span><span class="p">:</span>
                    <span class="c1"># Preserve all ops in curr_ops_no_decomp from decomposition</span>
                    <span class="n">table</span> <span class="o">=</span> <span class="n">_default_decomposition_table</span><span class="p">()</span>
                    <span class="n">ops_needing_preservation</span> <span class="o">=</span> <span class="p">[]</span>

                    <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">curr_ops_no_decomp</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">table</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="n">ops_needing_preservation</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

                    <span class="n">program</span> <span class="o">=</span> <span class="n">program</span><span class="o">.</span><span class="n">run_decompositions</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
                    <span class="n">final_ops_to_preserve</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">ops_needing_preservation</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># EDGE_DO_NOT_DECOMP path for the partitioner</span>
                    <span class="n">curr_ops_no_decomp</span> <span class="o">=</span> <span class="n">_remove_invalid_ops_for_not_decompose</span><span class="p">(</span>
                        <span class="n">curr_ops_no_decomp</span>
                    <span class="p">)</span>

                    <span class="c1"># Apply decompositions with this partitioner&#39;s preserved ops</span>
                    <span class="n">table</span> <span class="o">=</span> <span class="n">_default_decomposition_table</span><span class="p">()</span>
                    <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">curr_ops_no_decomp</span><span class="p">:</span>
                        <span class="n">table</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

                    <span class="c1"># First pass of decompositions with this partitioner&#39;s preserved ops</span>
                    <span class="n">program</span> <span class="o">=</span> <span class="n">program</span><span class="o">.</span><span class="n">run_decompositions</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>

                    <span class="c1"># Filter ops using EDGE_DO_NOT_DECOMP</span>
                    <span class="n">temp_partitioner_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="p">[</span><span class="n">curr_partitioner</span><span class="p">]}</span>
                    <span class="n">preserved_ops</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">_replace_aten_ops_with_transformed_ops</span><span class="p">(</span>
                            <span class="n">name</span><span class="p">,</span> <span class="n">program</span><span class="p">,</span> <span class="n">temp_partitioner_dict</span>
                        <span class="p">)</span>
                        <span class="ow">or</span> <span class="p">[]</span>
                    <span class="p">)</span>
                    <span class="n">final_ops_to_preserve</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">preserved_ops</span><span class="p">)</span>

                    <span class="c1"># Second pass of decompositions with this partitioner&#39;s preserved ops after filtering</span>
                    <span class="n">program</span> <span class="o">=</span> <span class="n">program</span><span class="o">.</span><span class="n">run_decompositions</span><span class="p">(</span><span class="n">_default_decomposition_table</span><span class="p">())</span>

                    <span class="c1"># Restore ops from edge_no_decomp_namespace to aten ops</span>
                    <span class="n">_restore_transformed_ops_to_aten_ops</span><span class="p">(</span><span class="n">program</span><span class="p">)</span>
            <span class="n">ops_set_to_not_decompose_by_program</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">final_ops_to_preserve</span><span class="p">)</span>

        <span class="n">edge_programs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">_generate_edge_program</span><span class="p">(</span>
            <span class="n">config</span><span class="p">,</span>
            <span class="n">program</span><span class="p">,</span>
            <span class="n">preserve_ops</span><span class="o">=</span><span class="n">ops_set_to_not_decompose_by_program</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[]),</span>
        <span class="p">)</span>

    <span class="n">edge_manager</span> <span class="o">=</span> <span class="n">EdgeProgramManager</span><span class="p">(</span>
        <span class="n">edge_programs</span><span class="p">,</span>
        <span class="n">constant_methods</span><span class="p">,</span>
        <span class="n">config</span><span class="p">,</span>
        <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">()</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="o">*</span><span class="n">ops_set_to_not_decompose_by_program</span><span class="o">.</span><span class="n">values</span><span class="p">())),</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">generate_etrecord</span><span class="p">:</span>
        <span class="n">etrecord</span> <span class="o">=</span> <span class="n">_create_empty_etrecord</span><span class="p">()</span>
        <span class="n">etrecord</span><span class="o">.</span><span class="n">add_exported_program</span><span class="p">(</span><span class="n">aten_programs</span><span class="p">)</span>
        <span class="n">etrecord</span><span class="o">.</span><span class="n">add_edge_dialect_program</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">edge_manager</span><span class="p">))</span>
        <span class="n">edge_manager</span><span class="o">.</span><span class="n">_etrecord</span> <span class="o">=</span> <span class="n">etrecord</span>

    <span class="k">return</span> <span class="n">edge_manager</span>


<span class="k">def</span><span class="w"> </span><span class="nf">collect_named_data_store_from_exported_program</span><span class="p">(</span>
    <span class="n">exported_program</span><span class="p">:</span> <span class="n">ExportedProgram</span><span class="p">,</span>
    <span class="n">named_data_store</span><span class="p">:</span> <span class="n">NamedDataStore</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Collects all the named data store outputs found within the exported program</span>
<span class="sd">    and adds them to named_data_store.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># collected all the named data into the named data store for deduplication</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">collect_named_data_store_outputs</span><span class="p">(</span>
        <span class="n">graph_module</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">graph_module</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">target</span> <span class="o">==</span> <span class="n">executorch_call_delegate</span><span class="p">:</span>
                <span class="n">lbm</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">graph_module</span><span class="p">,</span> <span class="n">node</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
                <span class="k">assert</span> <span class="n">is_lowered_module</span><span class="p">(</span><span class="n">lbm</span><span class="p">)</span>
                <span class="n">data_store_output</span> <span class="o">=</span> <span class="n">lbm</span><span class="o">.</span><span class="n">named_data_store_output</span>
                <span class="k">if</span> <span class="n">data_store_output</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">named_data_store</span><span class="o">.</span><span class="n">merge_named_data_store</span><span class="p">(</span><span class="n">data_store_output</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">submod</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">get_control_flow_submodules</span><span class="p">(</span><span class="n">graph_module</span><span class="p">):</span>
            <span class="n">collect_named_data_store_outputs</span><span class="p">(</span><span class="n">submod</span><span class="p">)</span>

    <span class="n">collect_named_data_store_outputs</span><span class="p">(</span><span class="n">exported_program</span><span class="o">.</span><span class="n">graph_module</span><span class="p">)</span>


<div class="viewcode-block" id="to_edge_transform_and_lower">
<a class="viewcode-back" href="../../../../export-to-executorch-api-reference.html#executorch.exir.to_edge_transform_and_lower">[docs]</a>
<span class="nd">@et_logger</span><span class="p">(</span><span class="s2">&quot;to_edge_transform_and_lower&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">to_edge_transform_and_lower</span><span class="p">(</span>  <span class="c1"># noqa: C901</span>
    <span class="n">programs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ExportedProgram</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ExportedProgram</span><span class="p">]],</span>
    <span class="n">transform_passes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
        <span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">PassType</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">PassType</span><span class="p">]],</span> <span class="n">PassManager</span><span class="p">]</span>
    <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">partitioner</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
        <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Partitioner</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Partitioner</span><span class="p">]]]</span>
    <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">constant_methods</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">compile_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">EdgeCompileConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">generate_etrecord</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;EdgeProgramManager&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    :func:`to_edge_transform_and_lower` constructs an EdgeProgramManager from a set of</span>
<span class="sd">    exported programs in ATen dialect. It differs fundamentally from to_edge in that it</span>
<span class="sd">    combines the conversion of the ATen dialect to the edge dialect program, then running</span>
<span class="sd">    the transformation passes and then subsequently lowering the programs to their</span>
<span class="sd">    corresponding backends all into a single API.</span>

<span class="sd">    This is fundamentally useful for lowering to backends that have ops registered that they</span>
<span class="sd">    do not want to be decomposed and thus rely on matching with these non-decomposed ops. For</span>
<span class="sd">    these sorts of backends this is the *only* API that should be used to lower to the edge</span>
<span class="sd">    dialect. Using a combination of to_edge(...) and to_backend(...) will result in inconsistent</span>
<span class="sd">    or wrong behavior.</span>

<span class="sd">    This API is the primary recommended way to lower to the CPU based XNNPack backend.</span>

<span class="sd">    Args:</span>
<span class="sd">        programs: Can be a single ExportedProgram or a dictionary mapping function names</span>
<span class="sd">            to their corresponding ExportedPrograms. If only a single ExportedProgram is</span>
<span class="sd">            provided it will be assigned the name &quot;forward&quot;.</span>

<span class="sd">        transform_passes: The transform_passes can be one of:</span>
<span class="sd">            1) a list of passes -</span>
<span class="sd">                all methods in the given EdgeProgramManager will be transformed with the provided passes.</span>
<span class="sd">            2) a dictionary -</span>
<span class="sd">                only method names specified in the dictionary will be transformed</span>
<span class="sd">                with their corresponding passes</span>
<span class="sd">            3) an instance of a PassManager -</span>
<span class="sd">                all methods in the given EdgeProgramManager will be</span>
<span class="sd">                transformed with the given PassManager instance.</span>

<span class="sd">        partitioner: The partitioner can either be a Partitioner subclass instance, or a</span>
<span class="sd">            dictionary mapping method names to Partitioner subclass instance. If it is a</span>
<span class="sd">            Partitioner subclass, all programs in the given EdgeProgramManager will be lowered</span>
<span class="sd">            using the given partitioner. If it is a dictionary, only method names specified in</span>
<span class="sd">            the dictionary will be lowered with the given partitioner.</span>

<span class="sd">        constant_methods: An optional dictionary of method name to the constant value</span>
<span class="sd">            returned by that method in eager mode. Often used to store config information on</span>
<span class="sd">            Edge models.</span>

<span class="sd">        compile_config: An optional argument used to provide greater control over the</span>
<span class="sd">            transformation to edge dialect process.</span>

<span class="sd">        generate_etrecord: An optional argument used to generate an etrecord for debugging purposes.</span>

<span class="sd">    Returns:</span>
<span class="sd">        EdgeProgramManager</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">constant_methods</span><span class="p">,</span> <span class="n">EdgeCompileConfig</span><span class="p">)</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">compile_config</span> <span class="ow">or</span> <span class="n">EdgeCompileConfig</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">programs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="n">aten_programs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;forward&quot;</span><span class="p">:</span> <span class="n">programs</span><span class="p">}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">aten_programs</span> <span class="o">=</span> <span class="n">programs</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">partitioner</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">and</span> <span class="n">partitioner</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">partitioner</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">partitioner</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">aten_programs</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>
    <span class="k">elif</span> <span class="n">partitioner</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">partitioner</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">aten_programs</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>

    <span class="n">edge_manager</span> <span class="o">=</span> <span class="n">_gen_edge_manager_for_partitioners</span><span class="p">(</span>
        <span class="n">partitioner</span><span class="p">,</span> <span class="n">aten_programs</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">constant_methods</span><span class="p">,</span> <span class="n">generate_etrecord</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">transform_passes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">edge_manager</span> <span class="o">=</span> <span class="n">edge_manager</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">transform_passes</span><span class="p">)</span>

    <span class="n">max_num_partitioners</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">partitioner_list</span> <span class="ow">in</span> <span class="n">partitioner</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
        <span class="n">max_num_partitioners</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">max_num_partitioners</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">partitioner_list</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_num_partitioners</span><span class="p">):</span>
        <span class="n">method_to_partitioner</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">partitioner_list</span> <span class="ow">in</span> <span class="n">partitioner</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">partitioner_list</span><span class="p">):</span>
                <span class="n">method_to_partitioner</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">partitioner_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">edge_manager</span> <span class="o">=</span> <span class="n">edge_manager</span><span class="o">.</span><span class="n">to_backend</span><span class="p">(</span><span class="n">method_to_partitioner</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">program</span> <span class="ow">in</span> <span class="n">edge_manager</span><span class="o">.</span><span class="n">_edge_programs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">ops_set_to_not_decompose</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">_ops</span><span class="o">.</span><span class="n">OpOverload</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="n">partitioners</span> <span class="o">=</span> <span class="n">partitioner</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[])</span>
        <span class="k">for</span> <span class="n">curr_partitioner</span> <span class="ow">in</span> <span class="n">partitioners</span><span class="p">:</span>
            <span class="n">curr_op_set</span><span class="p">,</span> <span class="n">check_op_support</span> <span class="o">=</span> <span class="n">curr_partitioner</span><span class="o">.</span><span class="n">ops_to_not_decompose</span><span class="p">(</span>
                <span class="n">program</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">_can_skip_using_EDGE_DO_NOT_DECOMP</span><span class="p">(</span><span class="n">curr_partitioner</span><span class="p">,</span> <span class="n">program</span><span class="p">):</span>
                <span class="n">curr_op_set</span> <span class="o">=</span> <span class="n">_remove_invalid_ops_for_not_decompose</span><span class="p">(</span><span class="n">curr_op_set</span><span class="p">)</span>
            <span class="n">ops_set_to_not_decompose</span> <span class="o">=</span> <span class="n">ops_set_to_not_decompose</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">curr_op_set</span><span class="p">)</span>
            <span class="n">_sanity_check_graph_for_non_decomp_ops</span><span class="p">(</span>
                <span class="n">name</span><span class="p">,</span>
                <span class="n">program</span><span class="p">,</span>
                <span class="n">ops_set_to_not_decompose</span><span class="p">,</span>
                <span class="n">check_op_support</span><span class="p">,</span>
                <span class="n">partitioner_name</span><span class="o">=</span><span class="n">curr_partitioner</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="n">generate_error</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">preserve_ops</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">preserve_ops</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">ops_set_to_not_decompose</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">_check_ir_validity</span><span class="p">:</span>
            <span class="n">EXIREdgeDialectVerifier</span><span class="p">(</span>
                <span class="n">edge_compile_config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
                <span class="n">class_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">preserve_ops</span><span class="o">=</span><span class="n">preserve_ops</span><span class="p">,</span>
            <span class="p">)()(</span><span class="n">program</span><span class="o">.</span><span class="n">graph_module</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">edge_manager</span></div>



<div class="viewcode-block" id="to_edge">
<a class="viewcode-back" href="../../../../export-to-executorch-api-reference.html#executorch.exir.to_edge">[docs]</a>
<span class="nd">@et_logger</span><span class="p">(</span><span class="s2">&quot;to_edge&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">to_edge</span><span class="p">(</span>
    <span class="n">programs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ExportedProgram</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ExportedProgram</span><span class="p">]],</span>
    <span class="n">constant_methods</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">compile_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">EdgeCompileConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">generate_etrecord</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;EdgeProgramManager&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    :func:`to_edge` constructs an EdgeProgramManager from a set of exported programs in</span>
<span class="sd">    ATen dialect. Upon construction those programs are transformed into edge dialect.</span>

<span class="sd">    Args:</span>
<span class="sd">        programs: Can be a single ExportedProgram or a dictionary mapping function names to their corresponding ExportedPrograms. If only a single ExportedProgram is provided it will be assigned the name &quot;forward&quot;.</span>

<span class="sd">        constant_methods: An optional dictionary of method name to the constant value returned by that method in eager mode. Often used to store config information on Edge models.</span>

<span class="sd">        compile_config: An optional argument used to provide greater control over the transformation to edge dialect process.</span>

<span class="sd">        generate_etrecord: An optional argument used to generate an etrecord for debugging purposes. Default is False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        EdgeProgramManager</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">constant_methods</span><span class="p">,</span> <span class="n">EdgeCompileConfig</span><span class="p">)</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">compile_config</span> <span class="ow">or</span> <span class="n">EdgeCompileConfig</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">programs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="n">aten_programs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;forward&quot;</span><span class="p">:</span> <span class="n">programs</span><span class="p">}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">aten_programs</span> <span class="o">=</span> <span class="n">programs</span>

    <span class="n">edge_programs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ExportedProgram</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">program</span> <span class="ow">in</span> <span class="n">aten_programs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="c1"># Decompose to Core ATen</span>
        <span class="n">table</span> <span class="o">=</span> <span class="n">_default_decomposition_table</span><span class="p">()</span>
        <span class="n">preserve_ops</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">compile_config</span><span class="p">:</span>
            <span class="n">preserve_ops</span> <span class="o">=</span> <span class="n">compile_config</span><span class="o">.</span><span class="n">preserve_ops</span>
            <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">compile_config</span><span class="o">.</span><span class="n">preserve_ops</span><span class="p">:</span>
                <span class="n">table</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">program</span> <span class="o">=</span> <span class="n">program</span><span class="o">.</span><span class="n">run_decompositions</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">_check_ir_validity</span><span class="p">:</span>
            <span class="c1"># Remove invalid assert ops, such as _assert_tensor_metadata.</span>
            <span class="c1"># This pass is run in _generate_edge_program; it is required here to</span>
            <span class="c1"># ensure the graph is in ATen dialect before verification.</span>
            <span class="n">gm</span> <span class="o">=</span> <span class="n">program</span><span class="o">.</span><span class="n">graph_module</span>
            <span class="n">gm_res</span> <span class="o">=</span> <span class="n">RemoveNonCoreAtenOpGraphAssertsPass</span><span class="p">()(</span><span class="n">gm</span><span class="p">)</span>
            <span class="k">assert</span> <span class="n">gm_res</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="n">gm</span> <span class="o">=</span> <span class="n">gm_res</span><span class="o">.</span><span class="n">graph_module</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">EXIRATenDialectVerifier</span><span class="p">(</span>
                    <span class="n">edge_compile_config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
                    <span class="n">class_only</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="p">)(</span><span class="n">gm</span><span class="p">)</span>
            <span class="k">except</span> <span class="n">ExportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input program </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> is not in ATen dialect.&quot;</span><span class="p">)</span>
                <span class="k">raise</span> <span class="n">e</span>

        <span class="n">edge_programs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">_generate_edge_program</span><span class="p">(</span>
            <span class="n">config</span><span class="p">,</span> <span class="n">program</span><span class="p">,</span> <span class="n">preserve_ops</span><span class="o">=</span><span class="n">preserve_ops</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">_check_ir_validity</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">EXIREdgeDialectVerifier</span><span class="p">(</span>
                    <span class="n">edge_compile_config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
                    <span class="n">class_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">preserve_ops</span><span class="o">=</span><span class="n">preserve_ops</span><span class="p">,</span>
                <span class="p">)()(</span><span class="n">edge_programs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">graph_module</span><span class="p">)</span>
            <span class="k">except</span> <span class="n">ExportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input program </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> is not in Edge dialect.&quot;</span><span class="p">)</span>
                <span class="k">raise</span> <span class="n">e</span>

    <span class="n">epm</span> <span class="o">=</span> <span class="n">EdgeProgramManager</span><span class="p">(</span><span class="n">edge_programs</span><span class="p">,</span> <span class="n">constant_methods</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">generate_etrecord</span><span class="p">:</span>
        <span class="n">etrecord</span> <span class="o">=</span> <span class="n">_create_empty_etrecord</span><span class="p">()</span>
        <span class="n">etrecord</span><span class="o">.</span><span class="n">add_exported_program</span><span class="p">(</span><span class="n">aten_programs</span><span class="p">)</span>
        <span class="n">etrecord</span><span class="o">.</span><span class="n">add_edge_dialect_program</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">epm</span><span class="p">))</span>
        <span class="n">epm</span><span class="o">.</span><span class="n">_etrecord</span> <span class="o">=</span> <span class="n">etrecord</span>

    <span class="k">return</span> <span class="n">epm</span></div>



<div class="viewcode-block" id="EdgeProgramManager">
<a class="viewcode-back" href="../../../../export-to-executorch-api-reference.html#executorch.exir.EdgeProgramManager">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">EdgeProgramManager</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Package of one or more `ExportedPrograms` in Edge dialect. Designed to simplify</span>
<span class="sd">    lowering to ExecuTorch. See: https://pytorch.org/executorch/main/ir-exir</span>

<span class="sd">    Allows easy applications of transforms across a collection of exported programs</span>
<span class="sd">    including the delegation of subgraphs.</span>

<span class="sd">    Manages the second link in the lowering chain of ATen -&gt; Edge -&gt; ExecuTorch.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">edge_programs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ExportedProgram</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ExportedProgram</span><span class="p">]],</span>
        <span class="n">constant_methods</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">compile_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">EdgeCompileConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">core_aten_ops_exception_list</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">_ops</span><span class="o">.</span><span class="n">OpOverload</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">preserve_ops</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">_ops</span><span class="o">.</span><span class="n">OpOverload</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Should not be called directly by users. User should use :func:&#39;to_edge&#39; instead.</span>

<span class="sd">        Constructs an EdgeProgramManager from an existing set of exported programs in edge dialect.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compile_config</span> <span class="o">=</span> <span class="n">compile_config</span> <span class="ow">or</span> <span class="n">EdgeCompileConfig</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge_programs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">edge_programs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;forward&quot;</span><span class="p">:</span> <span class="n">edge_programs</span><span class="p">}</span>

        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">program</span> <span class="ow">in</span> <span class="n">edge_programs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">EXIREdgeDialectVerifier</span><span class="p">(</span>
                    <span class="n">edge_compile_config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">compile_config</span><span class="p">,</span>
                    <span class="n">core_aten_ops_exception_list</span><span class="o">=</span><span class="n">core_aten_ops_exception_list</span><span class="p">,</span>
                    <span class="n">preserve_ops</span><span class="o">=</span><span class="n">preserve_ops</span><span class="p">,</span>
                <span class="p">)(</span><span class="n">program</span><span class="o">.</span><span class="n">graph_module</span><span class="p">)</span>
            <span class="k">except</span> <span class="n">ExportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input program </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> is not in aten dialect.&quot;</span><span class="p">)</span>
                <span class="k">raise</span> <span class="n">e</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_edge_programs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ExportedProgram</span><span class="p">]</span> <span class="o">=</span> <span class="n">edge_programs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_config_methods</span> <span class="o">=</span> <span class="n">constant_methods</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_named_data_store</span> <span class="o">=</span> <span class="n">NamedDataStore</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">program</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edge_programs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">collect_named_data_store_from_exported_program</span><span class="p">(</span>
                <span class="n">program</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_named_data_store</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_etrecord</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">methods</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the set of methods in this EdgeProgramManager.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_edge_programs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">config_methods</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the set of config methods in this EdgeProgramManager.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_config_methods</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_config_methods</span> <span class="k">else</span> <span class="nb">set</span><span class="p">()</span>

<div class="viewcode-block" id="EdgeProgramManager.exported_program">
<a class="viewcode-back" href="../../../../export-to-executorch-api-reference.html#executorch.exir.EdgeProgramManager.exported_program">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">exported_program</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">method_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;forward&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ExportedProgram</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the ExportedProgram specified by &#39;method_name&#39;.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edge_programs</span><span class="p">[</span><span class="n">method_name</span><span class="p">]</span></div>


    <span class="nd">@et_logger</span><span class="p">(</span><span class="s2">&quot;transform&quot;</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">transform</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">passes</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">PassType</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">PassType</span><span class="p">]],</span> <span class="n">PassManager</span><span class="p">],</span>
        <span class="n">compile_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">EdgeCompileConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;EdgeProgramManager&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Transforms the program according to the provided passes.</span>

<span class="sd">        Args:</span>
<span class="sd">            passes: This param can be one of:</span>
<span class="sd">                1) a list of passes -</span>
<span class="sd">                    all methods in the given EdgeProgramManager</span>
<span class="sd">                    will be transformed with the provided passes.</span>
<span class="sd">                2) a dictionary mapping method names to lists of passes -</span>
<span class="sd">                    only method names specified in the dictionary will be</span>
<span class="sd">                    transformed with their corresponding passes.</span>
<span class="sd">                3) a PassManager instance -</span>
<span class="sd">                    all methods in the given EdgeProgramManager will be</span>
<span class="sd">                    transformed with the given PassManager instance.</span>
<span class="sd">            compile_config: Compile config to use for veriy the correctness of model</span>
<span class="sd">                graph after each pass. If not specified, the compile config of the</span>
<span class="sd">                calling EdgeProgramManager will be used. It will be used in as compile</span>
<span class="sd">                config of returned EdgeProgramManager.</span>

<span class="sd">        Returns:</span>
<span class="sd">            EdgeProgramManager: A copy of the calling EdgeProgramManager with the</span>
<span class="sd">            transformations applied.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">compile_config</span> <span class="o">=</span> <span class="n">compile_config</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">compile_config</span>
        <span class="n">new_programs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ExportedProgram</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># Cast passes parameter upfront.</span>
        <span class="n">passes_seq</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">PassType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">passes_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">PassType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">pass_manager</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PassManager</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">passes</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">):</span>
            <span class="n">passes_seq</span> <span class="o">=</span> <span class="n">passes</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">passes</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">passes_dict</span> <span class="o">=</span> <span class="n">passes</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">passes</span><span class="p">,</span> <span class="n">PassManager</span><span class="p">):</span>
            <span class="n">pass_manager</span> <span class="o">=</span> <span class="n">passes</span>

        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">program</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edge_programs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># If the method name is enforced, but not matched, we skip transformation.</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">passes</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
                <span class="ow">and</span> <span class="n">passes_dict</span>
                <span class="ow">and</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">passes_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
            <span class="p">):</span>
                <span class="n">new_programs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">program</span><span class="p">)</span>
                <span class="k">continue</span>

            <span class="c1"># Depending on the passes parameter, call the corresponding transform function.</span>
            <span class="k">if</span> <span class="n">passes_seq</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">new_programs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">_transform</span><span class="p">(</span><span class="n">program</span><span class="p">,</span> <span class="o">*</span><span class="n">passes_seq</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">passes_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">new_programs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">_transform</span><span class="p">(</span><span class="n">program</span><span class="p">,</span> <span class="o">*</span><span class="n">passes_dict</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
            <span class="k">elif</span> <span class="n">pass_manager</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">new_programs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">_transform_with_pass_manager</span><span class="p">(</span><span class="n">program</span><span class="p">,</span> <span class="n">pass_manager</span><span class="p">)</span>

            <span class="c1"># Verify the correctness of model graph after each transformation.</span>
            <span class="n">EXIREdgeDialectVerifier</span><span class="p">(</span><span class="n">edge_compile_config</span><span class="o">=</span><span class="n">compile_config</span><span class="p">)(</span>
                <span class="n">new_programs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">graph_module</span>
            <span class="p">)</span>

        <span class="n">epm</span> <span class="o">=</span> <span class="n">EdgeProgramManager</span><span class="p">(</span>
            <span class="n">new_programs</span><span class="p">,</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_config_methods</span><span class="p">),</span> <span class="n">compile_config</span>
        <span class="p">)</span>

        <span class="n">epm</span><span class="o">.</span><span class="n">_etrecord</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_etrecord</span>
        <span class="k">return</span> <span class="n">epm</span>

    <span class="nd">@et_logger</span><span class="p">(</span><span class="s2">&quot;to_backend&quot;</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">to_backend</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">partitioner</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Partitioner</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Partitioner</span><span class="p">]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;EdgeProgramManager&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a semantically-equivalent program to the one given as input,</span>
<span class="sd">        but with portions of each program in the EdgeProgramManager targeted</span>
<span class="sd">        for delegation as determined by the partitioner.</span>

<span class="sd">        Args:</span>
<span class="sd">            partitioner: The partitioner can either be a Partitioner subclass instance, or a</span>
<span class="sd">                dictionary mapping method names to Partitioner subclass instance. If it is a</span>
<span class="sd">                Partitioner subclass, all programs in the given EdgeProgramManager</span>
<span class="sd">                will be lowered using the given partitioner. If it is a</span>
<span class="sd">                dictionary, only method names specified in the dictionary will be</span>
<span class="sd">                lowered with the given partitioner.</span>

<span class="sd">                The Partitioner subclass instance is in charge with tagging portions of the</span>
<span class="sd">                input program for delegation. A valid partitioner must return PartitionerResult including valid</span>
<span class="sd">                partition_tags: Dict[str, DelegationSpec], where each key is a tag</span>
<span class="sd">                name and the nodes with same tag will be fused a one subgraph and</span>
<span class="sd">                delegated to backend specififed in delegation spec.</span>

<span class="sd">        Returns:</span>
<span class="sd">            EdgeProgramManager: A copy of the calling EdgeProgramManager with the</span>
<span class="sd">            specified subgraphs lowered.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_edge_programs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ExportedProgram</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">method_to_partitioner</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Partitioner</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">partitioner</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">method_to_partitioner</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">partitioner</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edge_programs</span><span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">method_to_partitioner</span> <span class="o">=</span> <span class="n">partitioner</span>

        <span class="n">method_to_programs_and_partitioners</span> <span class="o">=</span> <span class="n">MethodProgramsPartitionerSpec</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_edge_programs</span><span class="p">,</span>
            <span class="n">method_to_partitioner</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">new_edge_programs</span> <span class="o">=</span> <span class="n">to_backend</span><span class="p">(</span><span class="n">method_to_programs_and_partitioners</span><span class="p">)</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">EdgeCompileConfig</span><span class="p">(</span><span class="n">_check_ir_validity</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">epm</span> <span class="o">=</span> <span class="n">EdgeProgramManager</span><span class="p">(</span>
            <span class="n">new_edge_programs</span><span class="p">,</span>
            <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_config_methods</span><span class="p">),</span>
            <span class="n">config</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">epm</span><span class="o">.</span><span class="n">_etrecord</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_etrecord</span>
        <span class="k">return</span> <span class="n">epm</span>

    <span class="nd">@et_logger</span><span class="p">(</span><span class="s2">&quot;to_executorch&quot;</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">to_executorch</span><span class="p">(</span>  <span class="c1"># noqa (FLAKE8) C901</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ExecutorchBackendConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ExecutorchProgramManager&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Transforms the program to the ExecuTorch backend.</span>

<span class="sd">        Args:</span>
<span class="sd">            config: An optional argument used to provide greater control over</span>
<span class="sd">                the transformation to the ExecuTorch backend.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ExecutorchProgramManager: A manager representing the state of the EdgeProgramManager</span>
<span class="sd">            after it has been transformed to the ExecuTorch backend.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">config</span> <span class="k">if</span> <span class="n">config</span> <span class="k">else</span> <span class="n">ExecutorchBackendConfig</span><span class="p">()</span>
        <span class="n">execution_programs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ExportedProgram</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">program</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edge_programs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">do_quant_fusion_and_const_prop</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">program</span><span class="o">.</span><span class="n">graph_signature</span><span class="o">.</span><span class="n">backward_signature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
                        <span class="s2">&quot;Cannot run do_quant_fusion_and_const_prop on a graph with a backward signature intended for on-device training.&quot;</span>
                        <span class="s2">&quot; Please set do_quant_fusion_and_const_prop to False in the ExecutorchBackendConfig.&quot;</span>
                    <span class="p">)</span>
                <span class="n">program</span> <span class="o">=</span> <span class="n">quant_fusion_and_const_prop_pass</span><span class="p">(</span><span class="n">program</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">run_reinplace_pass</span><span class="p">:</span>
                <span class="n">program</span> <span class="o">=</span> <span class="n">reinplace_pass</span><span class="p">(</span><span class="n">program</span><span class="p">)</span>
            <span class="n">program</span> <span class="o">=</span> <span class="n">weights_to_outputs_pass</span><span class="p">(</span><span class="n">program</span><span class="p">)</span>
            <span class="n">program</span> <span class="o">=</span> <span class="n">unsafe_remove_auto_functionalized_pass</span><span class="p">(</span><span class="n">program</span><span class="p">)</span>
            <span class="n">gm</span><span class="p">,</span> <span class="n">new_signature</span> <span class="o">=</span> <span class="n">insert_write_back_for_buffers_pass</span><span class="p">(</span><span class="n">program</span><span class="p">)</span>
            <span class="n">new_gm</span> <span class="o">=</span> <span class="n">program</span><span class="o">.</span><span class="n">graph_module</span>
            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">edge_to_executorch_passes</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
                <span class="n">new_gm_res</span> <span class="o">=</span> <span class="n">p</span><span class="p">(</span><span class="n">new_gm</span><span class="p">)</span>
                <span class="k">assert</span> <span class="n">new_gm_res</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="n">new_gm</span> <span class="o">=</span> <span class="n">new_gm_res</span><span class="o">.</span><span class="n">graph_module</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">SpecPropPass</span><span class="p">):</span>
                    <span class="c1"># Note that this is a hacky way to get around the fact that</span>
                    <span class="c1"># placeholder nodes corresponding to the parameters of the graph module</span>
                    <span class="c1"># shall not participate in memory planning. It increases runtime memory</span>
                    <span class="c1"># footprint.</span>
                    <span class="c1"># Proper way would be to have ExportPass work with ExportedProgram</span>
                    <span class="c1"># instead of GraphModule. This is because ExportPass should work</span>
                    <span class="c1"># on top of the export artifact of torch.export whichi s ExportedProgram.</span>
                    <span class="c1"># Working with GraphModule does not provide all the information contained</span>
                    <span class="c1"># in the ExportedProgram</span>
                    <span class="c1"># TODO(who?)</span>
                    <span class="n">p</span><span class="o">.</span><span class="n">update_placeholder_tensor_specs</span><span class="p">(</span><span class="n">program</span><span class="p">,</span> <span class="n">new_gm</span><span class="p">)</span>

            <span class="c1"># Tag constant weights.</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">external_constants</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span>
                <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">external_constants</span>
            <span class="p">):</span>
                <span class="n">new_gm_res</span> <span class="o">=</span> <span class="n">external_constants_pass</span><span class="p">(</span><span class="n">new_gm</span><span class="p">)</span>
                <span class="n">new_gm</span> <span class="o">=</span> <span class="n">new_gm_res</span><span class="o">.</span><span class="n">graph_module</span>
            <span class="k">elif</span> <span class="nb">callable</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">external_constants</span><span class="p">):</span>
                <span class="n">new_gm_res</span> <span class="o">=</span> <span class="n">external_constants_pass</span><span class="p">(</span><span class="n">new_gm</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">external_constants</span><span class="p">)</span>
                <span class="n">new_gm</span> <span class="o">=</span> <span class="n">new_gm_res</span><span class="o">.</span><span class="n">graph_module</span>

            <span class="c1"># Tag mutable weights.</span>
            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">external_mutable_weights</span><span class="p">:</span>
                <span class="n">new_gm_res</span> <span class="o">=</span> <span class="n">external_mutable_weights_pass</span><span class="p">(</span><span class="n">new_gm</span><span class="p">,</span> <span class="n">program</span><span class="p">)</span>
                <span class="n">new_gm</span> <span class="o">=</span> <span class="n">new_gm_res</span><span class="o">.</span><span class="n">graph_module</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">memory_planning_pass</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="n">memory_planning_pass</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">memory_planning_pass</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                    <span class="n">name</span><span class="p">,</span> <span class="n">ExecutorchBackendConfig</span><span class="p">()</span><span class="o">.</span><span class="n">memory_planning_pass</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">memory_planning_pass</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">memory_planning_pass</span>
            <span class="c1"># TODO(jakeszwe): Follow up with compiler on if the deepcopy is necessary and if so how to make it work</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">memory_planning_pass</span><span class="p">,</span> <span class="s2">&quot;run&quot;</span><span class="p">):</span>
                <span class="n">new_gm_res</span> <span class="o">=</span> <span class="n">memory_planning_pass</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">new_gm</span><span class="p">,</span> <span class="n">new_signature</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">new_gm_res</span> <span class="o">=</span> <span class="n">memory_planning_pass</span><span class="p">(</span><span class="n">new_gm</span><span class="p">)</span>

            <span class="c1"># WARNING: DO NOT ADD ANY MORE PASSES AFTER MEMORY PLANNING PASS.</span>
            <span class="c1"># THERE ARE A LOT OF ASSUMPTIONS IN THE STACK THAT MEMORY PLANNING IS THE LAST PASS BEFORE THE EMITTER.</span>
            <span class="k">assert</span> <span class="n">new_gm_res</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="n">new_gm</span> <span class="o">=</span> <span class="n">new_gm_res</span><span class="o">.</span><span class="n">graph_module</span>

            <span class="n">_copy_module</span><span class="p">(</span><span class="n">program</span><span class="o">.</span><span class="n">graph_module</span><span class="p">,</span> <span class="n">new_gm</span><span class="p">)</span>
            <span class="n">execution_programs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">program</span>
        <span class="c1"># After running memory planning on all entry points we can run the cross entry point memory planning</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">memory_planning_pass</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">memory_planning_pass</span> <span class="ow">in</span> <span class="n">config</span><span class="o">.</span><span class="n">memory_planning_pass</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">memory_planning_pass</span><span class="p">,</span> <span class="s2">&quot;run_multimethod&quot;</span><span class="p">):</span>
                    <span class="n">memory_planning_pass</span><span class="o">.</span><span class="n">run_multimethod</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">memory_planning_pass</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">memory_planning_pass</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">memory_planning_pass</span><span class="p">,</span> <span class="s2">&quot;run_multimethod&quot;</span><span class="p">):</span>
                <span class="n">memory_planning_pass</span><span class="o">.</span><span class="n">run_multimethod</span><span class="p">()</span>

        <span class="n">et_pm</span> <span class="o">=</span> <span class="n">ExecutorchProgramManager</span><span class="p">(</span>
            <span class="n">execution_programs</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_config_methods</span><span class="p">,</span>
            <span class="n">config</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_named_data_store</span><span class="o">.</span><span class="n">get_named_data_store_output</span><span class="p">(),</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_etrecord</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_etrecord</span><span class="o">.</span><span class="n">add_executorch_program</span><span class="p">(</span><span class="n">et_pm</span><span class="p">)</span>
            <span class="n">et_pm</span><span class="o">.</span><span class="n">_etrecord</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_etrecord</span>

        <span class="k">return</span> <span class="n">et_pm</span></div>



<div class="viewcode-block" id="ExecutorchProgramManager">
<a class="viewcode-back" href="../../../../export-to-executorch-api-reference.html#executorch.exir.ExecutorchProgramManager">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">ExecutorchProgramManager</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Package of one or more `ExportedPrograms` in Execution dialect. Designed to simplify</span>
<span class="sd">    lowering to ExecuTorch. See: https://pytorch.org/executorch/main/ir-exir</span>

<span class="sd">    When the ExecutorchProgramManager is constructed the ExportedPrograms in execution dialect</span>
<span class="sd">    are used to form the executorch binary (in a process called emission) and then serialized</span>
<span class="sd">    to a buffer.</span>

<span class="sd">    Manages the final link in the lowering chain of ATen -&gt; Edge -&gt; ExecuTorch.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">execution_programs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ExportedProgram</span><span class="p">],</span>
        <span class="n">config_methods</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">backend_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ExecutorchBackendConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">named_data</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NamedDataStoreOutput</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        End users should not call this constructor directly. Instead, they should use</span>
<span class="sd">        :func:&#39;to_executorch&#39; to construct an ExecutorchProgramManager.</span>

<span class="sd">        Constructs an ExecutorchProgramManager from a set of exported programs in</span>
<span class="sd">        execution dialect.</span>

<span class="sd">        Args:</span>
<span class="sd">            execution_programs: A dictionary of method name to the corresponding</span>
<span class="sd">            ExportedProgram.</span>

<span class="sd">            config_methods: A dictionary of method name to the config value returned</span>
<span class="sd">            by that method in eager mode.</span>

<span class="sd">            backend_config: An optional argument used to provide greater control over</span>
<span class="sd">            the emission and serialization.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Set up methods</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_execution_programs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ExportedProgram</span><span class="p">]</span> <span class="o">=</span> <span class="n">execution_programs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_config_methods</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="n">config_methods</span>

        <span class="c1"># Named data from EdgeProgramManager</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_named_data</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">NamedDataStoreOutput</span><span class="p">]</span> <span class="o">=</span> <span class="n">named_data</span>

        <span class="n">backend_config</span> <span class="o">=</span> <span class="n">backend_config</span> <span class="ow">or</span> <span class="n">ExecutorchBackendConfig</span><span class="p">()</span>

        <span class="c1"># Emit methods</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_emitter_output</span><span class="p">:</span> <span class="n">EmitterOutput</span> <span class="o">=</span> <span class="n">emit_program</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_execution_programs</span><span class="p">,</span>
            <span class="n">backend_config</span><span class="o">.</span><span class="n">emit_stacktrace</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_config_methods</span><span class="p">,</span>
            <span class="n">backend_config</span><span class="o">.</span><span class="n">emit_mutable_buffer_names</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Serialize emitter output, ready to be written to a file.</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">executorch.extension.flat_tensor.serialize.serialize</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
            <span class="n">FlatTensorConfig</span><span class="p">,</span>
            <span class="n">FlatTensorSerializer</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_data_serializer</span> <span class="o">=</span> <span class="n">FlatTensorSerializer</span><span class="p">(</span>
            <span class="n">FlatTensorConfig</span><span class="p">(</span><span class="n">segment_alignment</span><span class="o">=</span><span class="n">backend_config</span><span class="o">.</span><span class="n">segment_alignment</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pte_data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor_data</span> <span class="o">=</span> <span class="n">serialize_for_executorch</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_emitter_output</span><span class="p">,</span>
            <span class="n">backend_config</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_data_serializer</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_named_data</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_buffer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bytes</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_etrecord</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">methods</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the set of methods in this ExecutorchProgramManager.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_execution_programs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">config_methods</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the set of config methods in this ExecutorchProgramManager.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_config_methods</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_config_methods</span> <span class="k">else</span> <span class="nb">set</span><span class="p">()</span>

<div class="viewcode-block" id="ExecutorchProgramManager.exported_program">
<a class="viewcode-back" href="../../../../export-to-executorch-api-reference.html#executorch.exir.ExecutorchProgramManager.exported_program">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">exported_program</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">method_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;forward&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ExportedProgram</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the ExportedProgram specified by &#39;method_name&#39;.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execution_programs</span><span class="p">[</span><span class="n">method_name</span><span class="p">]</span></div>


<div class="viewcode-block" id="ExecutorchProgramManager.dump_executorch_program">
<a class="viewcode-back" href="../../../../export-to-executorch-api-reference.html#executorch.exir.ExecutorchProgramManager.dump_executorch_program">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">dump_executorch_program</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TextIO</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prints the ExecuTorch binary in a human readable format.</span>

<span class="sd">        Args:</span>
<span class="sd">            verbose (bool):</span>
<span class="sd">                If False prints the binary in a condensed format.</span>
<span class="sd">                If True prints the binary 1-1 with the specification in the schema.</span>
<span class="sd">            out:</span>
<span class="sd">                If None, prints to stdout.</span>
<span class="sd">                If non-None, writes the string to that stream object. It can be</span>
<span class="sd">                    a file object, a StringIO object, or any other TextIO subclass.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="n">pretty_print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_emitter_output</span><span class="o">.</span><span class="n">program</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">print_program</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_emitter_output</span><span class="o">.</span><span class="n">program</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">)</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">debug_handle_map</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_emitter_output</span><span class="o">.</span><span class="n">debug_handle_map</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">delegate_map</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">_DelegateDebugIdentifierMap</span><span class="p">]]]]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_emitter_output</span><span class="o">.</span><span class="n">method_to_delegate_debug_id_map</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">instruction_id_to_num_outs_map</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_emitter_output</span><span class="o">.</span><span class="n">instruction_id_to_num_outs_map</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">executorch_program</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Program</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the object that represents the ExecuTorch binary before serialization.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_emitter_output</span><span class="o">.</span><span class="n">program</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">buffer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bytes</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the serialized ExecuTorch binary as a byte string.</span>

<span class="sd">        Note that the call to `buffer` may allocate a very large amount of</span>
<span class="sd">        contiguous memory, depending on the model size. If writing to a file,</span>
<span class="sd">        use `write_to_file` which won&#39;t incur additional copies.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO(T181494963): update pybinding to remove buffer cache, which can consume large</span>
        <span class="c1"># amounts of memory longer than necessary.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_buffer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_buffer</span> <span class="o">=</span> <span class="nb">bytes</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_pte_data</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_buffer</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_etrecord</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the generated ETRecord if etrecord generation was enabled.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ETRecord object if generation was enabled, None otherwise</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: if ETRecord object was not generated.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_etrecord</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;ETRecord was not generated&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_etrecord</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">write_to_file</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">open_file</span><span class="p">:</span> <span class="n">io</span><span class="o">.</span><span class="n">BufferedIOBase</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Writes the serialized ExecuTorch binary to the file at `open_file`. Prefer to use this over</span>
<span class="sd">        `buffer`, as it writes to file without copying into a contiguous block of memory first,</span>
<span class="sd">        reducing the peak memory usage.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pte_data</span><span class="o">.</span><span class="n">write_to_file</span><span class="p">(</span><span class="n">open_file</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">write_tensor_data_to_file</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outdir</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Writes the serialized ExecuTorch data files to the directory at `outdir`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor_data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">filename</span><span class="p">,</span> <span class="n">cord</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor_data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">filename</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.ptd&quot;</span><span class="p">):</span>
                <span class="n">filename</span> <span class="o">+=</span> <span class="s2">&quot;.ptd&quot;</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">outdir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">),</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Writing data file to </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">cord</span><span class="o">.</span><span class="n">write_to_file</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Saves the serialized ExecuTorch binary to the file at `path`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">path</span><span class="p">[</span><span class="o">-</span><span class="mi">4</span><span class="p">:]</span> <span class="o">!=</span> <span class="s2">&quot;.pte&quot;</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Path </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2"> does not end with .pte&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Path </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2"> does not end with .pte&quot;</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">write_to_file</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saved exported program to </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error while saving to </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>

</pre></div>

                </article>
              
  </article>
  
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
</div>

<div class="footer-info">
  <p class="copyright">
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  

<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4">
        <h2>Docs</h2>
        <p>Access comprehensive developer documentation for PyTorch</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/docs/stable/index.html">View Docs</a>
      </div>

      <div class="col-md-4">
        <h2>Tutorials</h2>
        <p>Get in-depth tutorials for beginners and advanced developers</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/tutorials">View Tutorials</a>
      </div>

      <div class="col-md-4">
        <h2>Resources</h2>
        <p>Find development resources and get your questions answered</p>
        <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
      </div>
    </div>
  </div>
</div>




<footer class="site-footer">

  <div class="container footer-container">

    <div class="newsletter" id="newsletter">

      <p class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and
        the latest news</p>


      <script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/embed/v2.js"></script>
      <script>
        hbspt.forms.create({
          region: "na1",
          portalId: "8112310",
          formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
        });
      </script>


      <p class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its
        projects regarding their events, training, research, developments, and related announcements. I understand that
        I can unsubscribe at any time using the links in the footers of the emails I receive. <a
          href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>

    </div>

    <div class="lf-grid">
      <ul class="social-links">
        <li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-0.51 -0.26 26.45 26.45" aria-label="Facebook">
              <path fill="currentColor"
                d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z" />
            </svg>
          </a></li>
        <li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 300 300" aria-label="X">
              <path fill="currentColor"
                d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66" />
            </svg>
          </a></li>
        <li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0.21 0.27 34.45 25.07" aria-label="YouTube">
              <path fill="currentColor"
                d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z" />
            </svg>
          </a></li>
        <li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-10.23 -10.23 531.96 531.96" aria-label="LinkedIn">
              <rect width="512" height="512" rx="0" fill="currentColor" />
              <circle fill="#000" cx="142" cy="138" r="37" />
              <path stroke="#000" stroke-width="66" d="M244 194v198M142 194v198" />
              <path fill="#000"
                d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32" />
            </svg>
          </a></li>
        <li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.16 -0.03 21.19 21.19" aria-label="Slack">
              <path fill="currentColor"
                d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z">
              </path>
            </svg>
          </a></li>
        <li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.14 -0.17 38.02 33.02" aria-label="WeChat">
              <path fill="currentColor"
                d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z">
              </path>
              <path fill="currentColor"
                d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z">
              </path>
            </svg>
          </a></li>
      </ul>
    </div>
    
    <div class="privacy-policy">
      <div class="copyright">
      
        <p>
          &copy; PyTorch. Copyright © The Linux Foundation®. All rights reserved. The Linux Foundation has registered
          trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark
          usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a
            href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a
            href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
        </p>
        
      </div>
    </div>


  </div>
</footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../_static/img/pytorch-x.svg">
  </div>
</div>
  
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2024, ExecuTorch.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  <script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "executorch.exir.program._program",
       "headline": "executorch.exir.program._program",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/_modules/executorch/exir/program/_program.html",
       "articleBody": "Source code for executorch.exir.program._program # Copyright (c) Meta Platforms, Inc. and affiliates. # All rights reserved. # Copyright 2025 Arm Limited and/or its affiliates. # # This source code is licensed under the BSD-style license found in the # LICENSE file in the root directory of this source tree. # pyre-unsafe import copy import io import logging import os from collections import defaultdict from typing import Any, Dict, List, Optional, Sequence, Set, TextIO, Type, Union import torch import torch._export from executorch.exir._serialize._cord import Cord from executorch.exir._serialize._named_data_store import ( NamedDataStore, NamedDataStoreOutput, ) from executorch.exir._serialize._serialize import serialize_for_executorch from executorch.exir._serialize.data_serializer import DataSerializer from executorch.exir._warnings import experimental from executorch.exir.backend.backend_api import ( MethodProgramsPartitionerSpec, to_backend, ) from executorch.exir.backend.partitioner import Partitioner from executorch.exir.capture._config import EdgeCompileConfig, ExecutorchBackendConfig from executorch.exir.delegate import executorch_call_delegate, is_lowered_module from executorch.exir.emit import emit_program, EmitterOutput from executorch.exir.emit._emitter import _DelegateDebugIdentifierMap from executorch.exir.error import ExportError from executorch.exir.graph_module import get_control_flow_submodules from executorch.exir.operator.convert import _pybind_schema_to_native_schema from executorch.exir.operator.util import _QUANT_PRIMITIVES from executorch.exir.pass_base import PassBase from executorch.exir.pass_manager import PassType from executorch.exir.passes import ( base_post_op_replace_passes, base_pre_op_replace_passes, dead_code_elimination_pass, EdgeToBackendOpsPass, MemoryFormatOpsPass, OpReplacePass, remove_unused_parameters_pass, ) from executorch.exir.passes.external_constants_pass import ( external_constants_pass, external_mutable_weights_pass, ) from executorch.exir.passes.insert_write_back_for_buffers_pass import ( insert_write_back_for_buffers_pass, ) from executorch.exir.passes.normalize_view_copy_base_pass import ( NormalizeViewCopyBasePass, ) from executorch.exir.passes.quant_fusion_pass import quant_fusion_and_const_prop_pass from executorch.exir.passes.reinplace import reinplace_pass from executorch.exir.passes.remove_graph_asserts_pass import ( RemoveGraphAssertsPass, RemoveNonCoreAtenOpGraphAssertsPass, ) from executorch.exir.passes.remove_mixed_type_operators import RemoveMixedTypeOperators from executorch.exir.passes.replace_aten_with_edge_pass import aten_to_edge from executorch.exir.passes.replace_view_copy_with_view_pass import ( ReplaceViewCopyWithViewPass, ) from executorch.exir.passes.spec_prop_pass import SpecPropPass from executorch.exir.passes.weights_to_outputs_pass import weights_to_outputs_pass from executorch.exir.print_program import pretty_print, print_program from executorch.exir.schema import Program from executorch.exir.tracer import _default_decomposition_table from executorch.exir.verification.verifier import ( EXIRATenDialectVerifier, EXIREdgeDialectVerifier, get_aten_verifier, ) from torch._export.passes import ReplaceViewOpsWithViewCopyOpsPass from torch._export.utils import _detect_fake_mode_from_gm from torch._export.verifier import Verifier from torch.export import ExportedProgram from torch.export._remove_auto_functionalized_pass import ( unsafe_remove_auto_functionalized_pass, ) from torch.export.exported_program import ( ConstantArgument, ExportGraphSignature, InputKind, InputSpec, OutputSpec, TensorArgument, ) from torch.fx import _pytree as fx_pytree from torch.fx._compatibility import compatibility from torch.fx.passes.infra.pass_manager import PassManager from torch.utils import _pytree as pytree Val = Any from typing import Any, Callable from torch.library import Library try: from executorch.exir.program.fb.logger import et_logger except ImportError: # Define a stub decorator that does nothing def et_logger(api_name: str) -\u003e Callable[[Any], Any]: def decorator(func: Callable[..., Any]) -\u003e Callable[..., Any]: def wrapper(*args: Any, **kwargs: Any) -\u003e Any: return func(*args, **kwargs) return wrapper return decorator # This is the reserved namespace that is used to register ops to that will # be prevented from being decomposed during to_edge_transform_and_lower. edge_no_decomp_namespace = \"EDGE_DO_NOT_DECOMP\" lib = Library(edge_no_decomp_namespace, \"DEF\") # Map from aten ops to the transformed ops registered in the edge_no_decomp_namespace. aten_op_to_transform_op = {} # Map from the transformed ops registered in the edge_no_decomp_namespace to aten ops. transform_op_to_aten_op = {} def _get_updated_range_constraints(gm): def get_shape_env(gm): vals = [ node.meta[\"val\"] for node in gm.graph.nodes if node.meta.get(\"val\", None) is not None ] from torch._guards import detect_fake_mode # type: ignore[21] fake_mode = detect_fake_mode(vals) if fake_mode is not None: return fake_mode.shape_env for v in vals: if isinstance(v, torch.SymInt): return v.node.shape_env shape_env = get_shape_env(gm) if shape_env is None: return {} range_constraints = { k: v for k, v in shape_env.var_to_range.items() if k not in shape_env.replacements } # Only when we have an unbacked symint, and it\u0027s used as constructor inputs, # runtime_var_to_range will make a difference compated to var_to_range. # e.g. [2, oo) -\u003e [0, oo) for k, v in shape_env.var_to_range.items(): if k not in shape_env.replacements: range_constraints[k] = v return range_constraints def _get_updated_graph_signature( old_signature: ExportGraphSignature, new_gm: torch.fx.GraphModule, ) -\u003e ExportGraphSignature: \"\"\" Update the graph signature\u0027s user_input/user_outputs. \"\"\" new_input_specs = [] i = 0 for node in new_gm.graph.nodes: if node.op != \"placeholder\": continue assert i \u003c len( old_signature.input_specs ), \"Number of inputs changed after transformation\" old_input_spec = old_signature.input_specs[i] arg = ( old_input_spec.arg if isinstance(old_input_spec.arg, ConstantArgument) # pyre-fixme[20]: Argument `class_fqn` expected. else type(old_input_spec.arg)(node.name) ) new_input_specs.append( InputSpec( old_input_spec.kind, arg, old_input_spec.target, persistent=old_input_spec.persistent, ) ) i += 1 output_node = new_gm.graph.output_node() assert output_node.op == \"output\" new_output_specs = [] for i, node in enumerate(output_node.args[0]): assert i \u003c len( old_signature.output_specs ), \"Number of outputs changed after transformation\" old_output_spec = old_signature.output_specs[i] arg = ( old_output_spec.arg if isinstance(old_output_spec.arg, ConstantArgument) # pyre-fixme[20]: Argument `class_fqn` expected. else type(old_output_spec.arg)(node.name) ) new_output_specs.append( OutputSpec(old_output_spec.kind, arg, old_output_spec.target) ) new_signature = ExportGraphSignature( input_specs=new_input_specs, output_specs=new_output_specs ) return new_signature def _transform( self, *passes: PassType, override_verifiers: None | list[Type[Verifier]] = None, ) -\u003e \"ExportedProgram\": \"\"\" Transforms the program according to the provided passes. Args: self: The ExportedProgram instance to transform *passes: A sequence of passes to apply to the program override_verifiers: Optional list of verifier classes to use instead of the default verifiers. This is needed if the transforms yields illegal graph that the default verifier cannot handle. Returns: ExportedProgram: A new ExportedProgram with the transformations applied, or self if no changes were made \"\"\" # A user friendly check to avoid vararg surprises, PEP 3102 assert not any( isinstance(p, (list, Verifier)) for p in passes ), f\"Expected all passes to be of PassType, not list or Verifier. Use override_verifiers kwarg instead. Got: {list(passes)}\" return _transform_with_pass_manager( self, PassManager(list(passes)), override_verifiers ) def _transform_with_pass_manager( self, pass_manager: PassManager, override_verifiers: None | list[Type[Verifier]] = None, ) -\u003e \"ExportedProgram\": \"\"\" Transforms the program using the provided pass_manager. Args: self: The ExportedProgram instance to transform pass_manager: An instance of PassManager to apply transformations. override_verifiers: Optional list of verifier classes to use instead of the default verifiers. This is needed if the transforms yields illegal graph that the default verifier cannot handle. Returns: ExportedProgram: A new ExportedProgram with the transformations applied, or self if no changes were made \"\"\" res = pass_manager(self.graph_module) transformed_gm = res.graph_module if res is not None else self.graph_module assert transformed_gm is not None if transformed_gm is self.graph_module and not res.modified: return self return _update_exported_program_graph_module( self, transformed_gm, override_verifiers ) def _update_exported_program_graph_module( exported_program: ExportedProgram, gm: torch.fx.GraphModule, override_verifiers: None | list[Type[Verifier]] = None, ) -\u003e \"ExportedProgram\": transformed_ep = ExportedProgram( root=gm, graph=gm.graph, graph_signature=_get_updated_graph_signature( exported_program.graph_signature, gm ), state_dict=exported_program.state_dict, range_constraints=_get_updated_range_constraints(gm), module_call_graph=copy.deepcopy(exported_program._module_call_graph), example_inputs=exported_program.example_inputs, constants=exported_program.constants, verifiers=override_verifiers or [exported_program.verifier], ) transformed_ep.graph_module.meta.update(exported_program.graph_module.meta) transformed_ep.graph_module.meta.update(gm.meta) return transformed_ep def _copy_module(new_prog, new_gm): new_prog.meta.update(new_gm.meta) new_prog.graph = new_gm.graph submodules = [name for name, _ in new_prog.named_children()] for name in submodules: delattr(new_prog, name) for name, mod in new_gm.named_children(): setattr(new_prog, name, mod) for node in new_gm.graph.nodes: if node.op == \"get_attr\": t = getattr(new_gm, node.target, None) if isinstance(t, torch.Tensor): setattr(new_prog, node.target, t) def _create_empty_etrecord(): # Import etrecord at runtime to resolve cyclic dependencies (program -\u003e etrecord -\u003e program). # This also ensures that etrecord-related packages do not affect the export flow. # @manual from executorch.devtools.etrecord import ETRecord return ETRecord() def lift_constant_tensor_pass(ep): \"\"\" Takes an ExportedProgram and returns the ExportedProgram modified in-place, with the constant tensors as buffers. \"\"\" if len([node for node in ep.graph.nodes if node.op == \"placeholder\"]) == 0: return ep graph_signature = ep.graph_signature buffers = list(graph_signature.buffers) fake_mode = _detect_fake_mode_from_gm(ep.graph_module) first_user_input = None lifted_constants = [] for node in ep.graph.nodes: if node.op == \"placeholder\" and node.name in graph_signature.user_inputs: first_user_input = node break for node in ep.graph.nodes: if node.op == \"get_attr\": constant_tensor = getattr(ep.graph_module, node.target) if not isinstance(constant_tensor, torch.Tensor): continue constant_tensor_fqn = f\"_lifted_tensor_constant{len(buffers)}\" with ep.graph.inserting_before(first_user_input): # Insert the constant node before the first user input const_placeholder_node = ep.graph.placeholder(constant_tensor_fqn) for k, v in node.meta.items(): const_placeholder_node.meta[k] = v if fake_mode is not None: const_placeholder_node.meta[\"val\"] = fake_mode.from_tensor( constant_tensor, static_shapes=True ) else: const_placeholder_node.meta[\"val\"] = constant_tensor const_placeholder_node.meta[\"val\"].constant = constant_tensor node.replace_all_uses_with(const_placeholder_node) ep.graph.erase_node(node) # Add the constant as a buffer to the graph signature lifted_constants.append( InputSpec( kind=InputKind.BUFFER, arg=TensorArgument(name=const_placeholder_node.name), target=constant_tensor_fqn, persistent=True, ) ) buffers.append(constant_tensor_fqn) ep.state_dict[constant_tensor_fqn] = constant_tensor new_input_specs = [] for s in graph_signature.input_specs: if s.kind == InputKind.USER_INPUT and len(lifted_constants) \u003e 0: new_input_specs.extend(lifted_constants) lifted_constants.clear() new_input_specs.append(s) if len(lifted_constants) \u003e 0: new_input_specs = lifted_constants + new_input_specs ep.graph_signature.input_specs = new_input_specs ep.graph_module.recompile() return ep # Stub to ease migration from `transform` to private `_transform` def transform_exported_program(ep, *passes: PassType) -\u003e ExportedProgram: if hasattr(ep, \"_transform\"): return ep._transform(*passes) else: return ep.transform(*passes) class HackedUpExportedProgramDONOTUSE(ExportedProgram): def __init__( self, root, graph, graph_signature, call_spec, state_dict, range_constraints, module_call_graph, example_inputs, verifier, ): super().__init__( root=root, graph=graph, graph_signature=graph_signature, state_dict=state_dict, range_constraints=range_constraints, module_call_graph=module_call_graph, example_inputs=example_inputs, verifier=verifier, ) def __call__(self, *args: Any, **kwargs: Any) -\u003e Any: import torch._export.error as error if self.call_spec.in_spec is not None: user_args = args try: args = fx_pytree.tree_flatten_spec(user_args, self.call_spec.in_spec) # type: ignore[assignment] except Exception: _, received_spec = pytree.tree_flatten(user_args) raise error.InternalError( \"Trying to flatten user inputs with exported input tree spec: \\n\" f\"{self.call_spec.in_spec}\\n\" \"but actually got inputs with tree spec of: \\n\" f\"{received_spec}\" ) ordered_params = tuple( self.state_dict[name] for name in self.graph_signature.parameters ) ordered_buffers = tuple( self.state_dict[name] for name in self.graph_signature.buffers ) with torch.no_grad(): # NOTE: calling convention is first params, then buffers, then args as user supplied them. # See: torch/_functorch/aot_autograd.py#L1034 res = torch.fx.Interpreter(self.graph_module).run( *ordered_params, *ordered_buffers, *args, enable_io_processing=False ) if self.call_spec.out_spec is not None: mutation = self.graph_signature.buffers_to_mutate num_mutated = len(mutation) mutated_buffers = res[:num_mutated] # Exclude dependency token from final result. assertion_dep_token = self.graph_signature.assertion_dep_token if assertion_dep_token is not None: assertion_dep_token_index = list(assertion_dep_token.keys())[0] res = res[:assertion_dep_token_index] res = res[num_mutated:] try: res = pytree.tree_unflatten(res, self.call_spec.out_spec) except Exception: _, received_spec = pytree.tree_flatten(res) raise error.InternalError( \"Trying to flatten user outputs with exported output tree spec: \\n\" f\"{self.call_spec.out_spec}\\n\" \"but actually got outputs with tree spec of: \\n\" f\"{received_spec}\" ) finally: ix = 0 for buffer in self.graph_signature.buffers_to_mutate.values(): self.state_dict[buffer] = mutated_buffers[ix] ix += 1 return res @compatibility(is_backward_compatible=False) class ExirExportedProgram: def __init__( self, exported_program: ExportedProgram, after_to_edge_passes: bool, ): self.exported_program = exported_program # Add a flag to denote whehter to_edge is called on this program # to detect misusage of directly calling to_executorch without to_edge self.after_to_edge_passes = after_to_edge_passes def transform(self, *passes: PassType) -\u003e \"ExirExportedProgram\": self.exported_program = _transform(self.exported_program, *passes) return self def __call__(self, *args: Any) -\u003e Any: return self.exported_program.module()(*args) # TODO(ycao): Change this to a composable function. def to_edge( self, config: Optional[EdgeCompileConfig] = None ) -\u003e \"ExirExportedProgram\": config = config or EdgeCompileConfig() assert isinstance( self.exported_program.graph_module, torch.fx.GraphModule ), f\"type is instead: {type(self.exported_program.graph_module).__name__}\" return _to_edge(self, config) def dump(self) -\u003e None: print(self.exported_program.graph_module.graph) def to_executorch( self, config: Optional[ExecutorchBackendConfig] = None, ) -\u003e \"ExecutorchProgram\": if not self.after_to_edge_passes: raise RuntimeError(\"Must run to_edge before to_executorch.\") config = config or ExecutorchBackendConfig() new_gm = self.exported_program.graph_module for p in edge_to_executorch_passes(config): new_gm_res = p(new_gm) assert new_gm_res is not None new_gm = new_gm_res.graph_module # This is tech debt on tech debt. memory planning pass inherits from some pass infra for GMs. # This isnt enough info now so i cant use call I have to use some new function \u0027run\u0027. # Existing user passes dont use run so Im just cheating here because they dont need to work on mutable buffers yet. # After exir.capture is gone I will clean up the memory planning infra to be consistent. # Frankly all of exir has big code quality issues because of the migrations that need to be addressed. new_gm_res = config.memory_planning_pass(new_gm) # pyre-ignore[29] assert new_gm_res is not None new_gm = new_gm_res.graph_module new_prog = ExirExportedProgram( copy.deepcopy(self.exported_program), self.after_to_edge_passes ) _copy_module(new_prog.exported_program.graph_module, new_gm) executorch_prog = ExecutorchProgram( new_prog, emit_stacktrace=config.emit_stacktrace, extract_delegate_segments=config.extract_delegate_segments, segment_alignment=config.segment_alignment, constant_tensor_alignment=config.constant_tensor_alignment, delegate_alignment=config.delegate_alignment, ) executorch_prog.graph_module.meta.update(new_gm.meta) executorch_prog.graph_module.meta.update( self.exported_program.graph_module.meta ) return executorch_prog def __deepcopy__( self, memo: Optional[Dict[int, Any]] = None ) -\u003e \"ExirExportedProgram\": new_eep = ExirExportedProgram( copy.deepcopy(self.exported_program, memo), self.after_to_edge_passes, ) return new_eep @compatibility(is_backward_compatible=False) class ExecutorchProgram: def __init__( self, exir_exported_program: ExirExportedProgram, emit_stacktrace: bool, extract_delegate_segments: bool, segment_alignment: int, constant_tensor_alignment: Optional[int] = None, delegate_alignment: Optional[int] = None, ) -\u003e None: if not exir_exported_program.after_to_edge_passes: raise RuntimeError( \"Need to call prog.to_edge prior to constructing ExecutorchProgram.\" ) self.exported_program = exir_exported_program.exported_program self._pte_data: Optional[Cord] = None self._tensor_data: Optional[Dict[str, Cord]] = None self._buffer: Optional[bytes] = None self._emitter_output: Optional[EmitterOutput] = None self._emit_stacktrace: bool = emit_stacktrace self._extract_delegate_segments: bool = extract_delegate_segments self._segment_alignment: int = segment_alignment self._constant_tensor_alignment: Optional[int] = constant_tensor_alignment self._delegate_alignment: Optional[int] = delegate_alignment from executorch.extension.flat_tensor.serialize.serialize import ( FlatTensorConfig, FlatTensorSerializer, ) self._data_serializer: DataSerializer = FlatTensorSerializer( FlatTensorConfig(self._segment_alignment) ) def _get_emitter_output(self) -\u003e EmitterOutput: if self._emitter_output is None: self._emitter_output = emit_program( self.exported_program, self._emit_stacktrace ) return self._emitter_output def _get_pte_data(self) -\u003e Cord: if self._pte_data is None: self._pte_data, self._tensor_data = serialize_for_executorch( self._get_emitter_output(), ExecutorchBackendConfig( extract_delegate_segments=self._extract_delegate_segments, segment_alignment=self._segment_alignment, constant_tensor_alignment=self._constant_tensor_alignment, delegate_alignment=self._delegate_alignment, ), self._data_serializer, ) assert self._pte_data is not None return self._pte_data @property def buffer(self) -\u003e bytes: \"\"\"Returns the serialized ExecuTorch binary as a byte string. Note that the call to `buffer` may allocate a very large amount of contiguous memory, depending on the model size. If writing to a file, use `write_to_file` which won\u0027t incur additional copies. \"\"\" # TODO(T181494963): update pybinding to remove buffer cache, which can consume large # amounts of memory longer than necessary. if self._buffer is None: self._buffer = bytes(self._get_pte_data()) return self._buffer @property @experimental(\"This API is experimental and subject to change without notice.\") def data_files(self) -\u003e Dict[str, bytes]: \"\"\"Returns the data files as a dictionary of filename to byte data. Returns: Dict[str, bytes]: Dictionary mapping data filenames (e.g., .ptd files) to their serialized byte content. Returns empty dict if no data files are available. \"\"\" if self._pte_data is None: self._get_pte_data() # This populates _tensor_data if self._tensor_data is None: return {} return {filename: bytes(cord) for filename, cord in self._tensor_data.items()} @property def program(self) -\u003e Program: return self._get_emitter_output().program @property def debug_handle_map(self) -\u003e Dict[int, Union[int, List[int]]]: if self._emitter_output: return self._emitter_output.debug_handle_map return self._get_emitter_output().debug_handle_map @property def delegate_map( self, ) -\u003e Dict[str, Dict[int, Dict[str, Union[str, _DelegateDebugIdentifierMap]]]]: if self._emitter_output: return self._emitter_output.method_to_delegate_debug_id_map return self._get_emitter_output().method_to_delegate_debug_id_map @property def instruction_id_to_num_outs_map( self, ) -\u003e Dict[str, Dict[int, Union[int, List[int]]]]: if self._emitter_output: return self._emitter_output.instruction_id_to_num_outs_map return self._get_emitter_output().instruction_id_to_num_outs_map @property def graph_module(self) -\u003e torch.fx.GraphModule: return self.exported_program.graph_module # TODO (zhxchen17) Change this to property. def dump_graph_module(self) -\u003e torch.fx.GraphModule: return self.exported_program.graph_module def dump_exported_program(self) -\u003e ExportedProgram: return self.exported_program def write_to_file(self, open_file: io.BufferedIOBase) -\u003e None: \"\"\" Writes the serialized ExecuTorch binary to the file at `open_file`. Prefer to use this over `buffer`, as it writes to file without copying into a contiguous block of memory first, reducing the peak memory usage. \"\"\" self._get_pte_data().write_to_file(open_file) def write_tensor_data_to_file(self, outdir) -\u003e None: \"\"\" Writes the serialized ExecuTorch data files to the directory at `outdir`. \"\"\" assert self._tensor_data is not None # pyre-ignore[16]: `Optional` has no attribute `items`. for filename, cord in self._tensor_data.items(): with open(os.path.join(outdir, f\"{filename}.ptd\"), \"wb\") as f: logging.info(f\"Writing data file to {filename}.ptd\") cord.write_to_file(f) def _get_aten_to_edge_passes(config: EdgeCompileConfig): # TODO: the last two passes for aten_to_edge need to be eliminated_dead_code -\u003e debug_handle_generator. After enable # use_edge_op it can be moved to aten_to_edge_passes before eliminated_dead_code pass. Also ExportPass doesn\u0027t play # well with node.meta, meaning after some passes permuting operators, we may lose some information in node.meta. # It might be regenerated in SpecPropPass so it may not be visiable. However debug handle will be lost. pre_op_replace_passes = base_pre_op_replace_passes + [RemoveMixedTypeOperators()] post_op_replace_passes = base_post_op_replace_passes return pre_op_replace_passes, post_op_replace_passes def _to_edge(ep, config: EdgeCompileConfig) -\u003e \"ExirExportedProgram\": if config._check_ir_validity: try: EXIRATenDialectVerifier()(ep.exported_program.graph_module) except ExportError: logging.info( \"If a particular operator failed core ATen IR check, please consider adding it to the exception list. \" \"Add the operator to _core_aten_ops_exception_list in EdgeCompileConfig. This is the recommended way \" \"to resolve this type of failure, so that the rest of the IR validation check can still be performed.\\n\" \"If you\u0027d like to disable IR validation checking, please set _check_ir_validity in EdgeCompileConfig, \" \"like *.to_edge(exir.EdgeCompileConfig(_check_ir_validity=False)).\" ) raise dialect = ep.exported_program.dialect if dialect == \"ATEN\": ep = ExirExportedProgram( ExportedProgram( root=ep.exported_program.graph_module, graph=ep.exported_program.graph_module.graph, graph_signature=ep.exported_program.graph_signature, state_dict=ep.exported_program.state_dict, range_constraints=ep.exported_program.range_constraints, module_call_graph=ep.exported_program.module_call_graph, example_inputs=ep.exported_program.example_inputs, constants=ep.exported_program.constants, verifiers=[ get_aten_verifier( config=config, ) ], ), False, ) pre_op_replace_passes, post_op_replace_passes = _get_aten_to_edge_passes(config) new_ep = copy.deepcopy(ep).transform(*pre_op_replace_passes) if dialect == \"ATEN\": new_ep.exported_program = lift_constant_tensor_pass(new_ep.exported_program) new_gm = new_ep.exported_program.graph_module if config._use_edge_ops: new_gm_res = OpReplacePass()(new_gm) assert new_gm_res is not None new_gm = new_gm_res.graph_module if not config._skip_dim_order: new_gm_res = MemoryFormatOpsPass()(new_gm) assert new_gm_res is not None new_gm = new_gm_res.graph_module for p in post_op_replace_passes: new_gm_res = p(new_gm) assert new_gm_res is not None new_gm = new_gm_res.graph_module new_ep.exported_program = ExportedProgram( root=new_gm, graph=new_gm.graph, graph_signature=_get_updated_graph_signature( new_ep.exported_program.graph_signature, new_gm ), state_dict=new_ep.exported_program.state_dict, range_constraints=new_ep.exported_program.range_constraints, module_call_graph=new_ep.exported_program.module_call_graph, example_inputs=new_ep.exported_program.example_inputs, constants=new_ep.exported_program.constants, verifiers=[ EXIREdgeDialectVerifier( edge_compile_config=config, class_only=True, ) ], ) new_ep.after_to_edge_passes = True return new_ep def pre_memory_planning_passes( config: ExecutorchBackendConfig, name: Optional[str] = None ) -\u003e List[PassType]: \"\"\" Returns a list of passes to run before memory planning. Get the sym shape eval pass based on the method name, if the pass is not in the dict, use the default pass. \"\"\" # Handle symbolic shape eval pass if isinstance(config.sym_shape_eval_pass, dict): default_pass = ExecutorchBackendConfig().sym_shape_eval_pass if not name: sym_shape_eval_pass = default_pass # pyre-ignore: Undefined attribute [16] sym_shape_eval_pass = config.sym_shape_eval_pass.get(name, default_pass) elif isinstance(config.sym_shape_eval_pass, PassBase): sym_shape_eval_pass = config.sym_shape_eval_pass else: raise RuntimeError( f\"sym_shape_eval_pass must be a dict or a PassBase, got {config.sym_shape_eval_pass}\" ) if config.remove_view_copy: return [ NormalizeViewCopyBasePass(), dead_code_elimination_pass, ReplaceViewCopyWithViewPass(), sym_shape_eval_pass, config.to_out_var_pass, ] else: return [ sym_shape_eval_pass, config.to_out_var_pass, ] def edge_to_executorch_passes( config: ExecutorchBackendConfig, name: Optional[str] = None ) -\u003e List[PassType]: \"\"\" Returns a list of passes to lower from edge to executorch. Get the pre memory planning passes based on the method name, if the pass is not in the dict, use the default pass. \"\"\" passes: List[PassType] = [ # ExecuTorch backend ops are unable to handle unbacked symints. So after # this pass, passes cannot be Interpreter-based, because it will fail if # there exists an unbacked symint operation. *config.passes, SpecPropPass(), EdgeToBackendOpsPass(), RemoveGraphAssertsPass(), ] + pre_memory_planning_passes(config, name) return passes def _generate_edge_program( config: EdgeCompileConfig, program: ExportedProgram, core_aten_ops_exception_list: Optional[List[torch._ops.OpOverload]] = None, preserve_ops: Optional[List[torch._ops.OpOverload]] = None, ) -\u003e ExportedProgram: \"\"\" Args: config: The configuration for the edge program. program: The exported program to be converted to an edge program. core_aten_ops_exception_list: A list of aten ops that are missing decompositions to core aten. preserve_ops: A list of aten ops that should not be decomposed. Returns: An ExportedProgram in edge dialect. \"\"\" # Remove unused parameters program = remove_unused_parameters_pass(program) pre_op_replace_passes, post_op_replace_passes = _get_aten_to_edge_passes(config) passes = [ # Remove invalid assert ops, such as _assert_tensor_metadata RemoveNonCoreAtenOpGraphAssertsPass(), # TODO move inside aten_to_edge passes after all users are migrated off v1 capture ReplaceViewOpsWithViewCopyOpsPass(), ] passes.extend(pre_op_replace_passes) if config._use_edge_ops: passes.append(OpReplacePass()) if not config._skip_dim_order: passes.append(MemoryFormatOpsPass()) gm = program.graph_module for p in passes: gm_res = p(gm) assert gm_res is not None gm = gm_res.graph_module edge_program = ExportedProgram( root=gm, graph=gm.graph, graph_signature=_get_updated_graph_signature(program.graph_signature, gm), state_dict=program.state_dict, range_constraints=program.range_constraints, module_call_graph=program.module_call_graph, example_inputs=program.example_inputs, constants=program.constants, verifiers=[ EXIREdgeDialectVerifier( edge_compile_config=config, class_only=True, core_aten_ops_exception_list=core_aten_ops_exception_list, preserve_ops=preserve_ops, ) ], ) # Lift the tensor constants created in ScalarToTensorPass edge_program = lift_constant_tensor_pass(edge_program) edge_program = _transform(edge_program, *post_op_replace_passes) return edge_program def _replace_aten_ops_with_transformed_ops( name: str, program: ExportedProgram, partitioner, ): preserve_ops = set() partitioners = partitioner.get(name) if partitioners is None: return # Iterate through the graph and replace the aten ops with the corresponding # transformed ops. for partitioner in partitioners: ops_set_to_not_decompose, check_op_support = partitioner.ops_to_not_decompose( program ) ops_set_to_not_decompose = _remove_invalid_ops_for_not_decompose( ops_set_to_not_decompose ) for op_aten in ops_set_to_not_decompose: _register_no_decomp_op(op_aten) for node in program.graph.nodes: is_op_supported = check_op_support(node) if check_op_support else True if ( node.op == \"call_function\" and node.target in ops_set_to_not_decompose and is_op_supported ): preserve_ops.add(node.target) node.target = aten_op_to_transform_op[node.target] for _, submod, _ in get_control_flow_submodules(program.graph_module): for node in submod.graph.nodes: is_op_supported = check_op_support(node) if check_op_support else True if ( node.op == \"call_function\" and node.target in ops_set_to_not_decompose and is_op_supported ): preserve_ops.add(node.target) node.target = aten_op_to_transform_op[node.target] return preserve_ops def _restore_transformed_ops_to_aten_ops(program: ExportedProgram): # Iterate through the graph and replace back the transformed ops with their # corresponding aten ops. for node in program.graph.nodes: if node.op == \"call_function\" and str(node.target) in transform_op_to_aten_op: node.target = transform_op_to_aten_op[str(node.target)] for _, submod, _ in get_control_flow_submodules(program.graph_module): for node in submod.graph.nodes: if ( node.op == \"call_function\" and str(node.target) in transform_op_to_aten_op ): node.target = transform_op_to_aten_op[str(node.target)] # Returns the op in edge_no_decomp_namespace namespace for the aten # op that is passed in. def _get_transformed_op(op_aten): op_name = op_aten._schema.name.split(\"::\")[1] overload_name = op_aten._schema.overload_name assert hasattr( torch.ops, edge_no_decomp_namespace ), f\"Couldn\u0027t find {edge_no_decomp_namespace} in torch.ops. Please make sure the Library has been registered.\" op_namespace = getattr(torch.ops, edge_no_decomp_namespace) op = getattr(op_namespace, op_name) return getattr(op, overload_name) # Registers the op in edge_no_decomp_namespace namespace for the aten # op that is passed in if it is not already cached in the table. def _register_no_decomp_op(op_aten): # Check if the op is already cached in the table. If not, then we need to # create a new op in the edge_no_decomp_namespace namespace. if aten_op_to_transform_op.get(op_aten) is None and isinstance( op_aten, torch._ops.OpOverload ): # Extract the schema from the aten op. op_schema = str(op_aten._schema).split(\"::\")[1] op_name = op_aten._schema.name.split(\"::\")[1] # Define an op in the edge_no_decomp_namespace namespace with the aten schema. lib.define(op_schema) # Define the implementation of the op in the edge_no_decomp_namespace namespace. # Important to note that the implementation of the op is the same as the aten op. overload_name = op_aten._schema.overload_name if overload_name != \"\": op_name += \".\" + overload_name lib.impl(op_name, op_aten, \"CompositeExplicitAutograd\") # Cache the aten op and transformed op in their corresponding tables for future use. aten_op_to_transform_op[op_aten] = _get_transformed_op(op_aten) transform_op_to_aten_op[str(aten_op_to_transform_op[op_aten])] = op_aten def _sanity_check_graph_for_non_decomp_ops( name: str, program: ExportedProgram, ops_set_to_not_decompose, check_op_support, generate_error=False, partitioner_name=None, ): warning_str_end = \"\" if partitioner_name is not None: warning_str_end += f\"This op was registered by the partitioner {partitioner_name} to not be decomposed.\\n\" warning_str_end += f\"The following ops: {ops_set_to_not_decompose} were specified to not be decomposed in {name}.\" # Check that the ops that were registered to not be decomposed are not present in the # graph anymore as the transform passes and backends should have consumed them by now. ops_set_to_not_decompose = { aten_to_edge(op) for op in ops_set_to_not_decompose }.union(ops_set_to_not_decompose) quant_primitives = {aten_to_edge(op) for op in _QUANT_PRIMITIVES} for node in program.graph_module.graph.nodes: is_op_supported = check_op_support(node) if check_op_support else True if ( node.op == \"call_function\" and node.target in ops_set_to_not_decompose and node.target not in quant_primitives ) and is_op_supported: warning_str = ( f\"Node {node} with op {node.target} was not decomposed or delegated.\\n\" + warning_str_end ) if generate_error: raise RuntimeError(warning_str) else: logging.warning(warning_str) for _, submod, _ in get_control_flow_submodules(program.graph_module): for node in submod.graph.nodes: is_op_supported = check_op_support(node) if check_op_support else True if ( node.op == \"call_function\" and node.target in ops_set_to_not_decompose and node.target not in quant_primitives ) and is_op_supported: warning_str = ( f\"Node {node} with op {node.target} was not decomposed or delegated.\\n\" + warning_str_end ) if generate_error: raise RuntimeError(warning_str) else: logging.warning(warning_str) def _remove_invalid_ops_for_not_decompose( preserve_ops: List[torch._ops.OpOverload], ) -\u003e List[torch._ops.OpOverload]: _logged_warnings = set() def log_warning(warn_str): if warn_str not in _logged_warnings: logging.warn(warn_str) _logged_warnings.add(warn_str) # To address https://github.com/pytorch/executorch/issues/8781 def keep(op): # Explicit allow list allow_list = [] try: # Ops in torch.ops.quant are not always loaded, so we use try/except # Aliases output, but we need to allow it for XNNPACK allow_list.append(torch.ops.torchao.choose_qparams_affine.default) except: pass if op in allow_list: return True schema = op._schema native_schema = _pybind_schema_to_native_schema(schema) if native_schema is None: log_warning( f\"Torchgen is not able to parse the schema of {op._schema}. This is not fatal.\" ) else: if native_schema.is_mutable: log_warning( f\"Op {op} was requested for preservation by partitioner. This request is ignored because it is mutable.\" ) return False if native_schema.aliased_return_names() != [None]: log_warning( f\"Op {op} was requested for preservation by partitioner. This request is ignored because it aliases output.\" ) return False # Explicit block list of ops that don\u0027t work if asked for # preservation if op in [ # Hits infinte recursion error when op is in # EDGE_DO_NOT_DECOMP namespace torch.ops.aten._to_copy.default, # scalar to tensor type promotion does not work on ops # in EDGE_DO_NOT_DECOMP namespace torch.ops.aten.mul.Tensor, torch.ops.aten.add.Tensor, torch.ops.aten.sub.Tensor, torch.ops.aten.div.Tensor, torch.ops.aten.item.default, torch.ops.aten._local_scalar_dense.default, torch.ops.aten.unbind.int, torch.ops.aten.split_with_sizes.default, ]: log_warning( f\"Op {op} was requested for preservation by partitioner. This request is ignored because it is in a blocklist.\" ) return False return True return list(filter(keep, preserve_ops)) def _can_skip_using_EDGE_DO_NOT_DECOMP( partitioner: Partitioner, program: ExportedProgram ) -\u003e bool: # THe current design of using EDGE_DO_NOT_DECOMP to prevent decomposition # has long standing issues. _remove_invalid_ops_for_not_decompose was a band-aid to # fix some of the issues, but more issues are coming up over time, including a new issue with SDPA # and contiguous views: https://fb.workplace.com/groups/pytorch.edge.users/permalink/1796069037930048/ # EDGE_DO_NOT_DECOMP is only needed by partitioners that specify check_op_support # As a temp fix, we give a more reliable path for backends that do not specify check_op_support _, check_op_support = partitioner.ops_to_not_decompose(program) return check_op_support is None def _gen_edge_manager_for_partitioners( partitioner: Dict[str, List[Partitioner]], aten_programs: Dict[str, ExportedProgram], config: EdgeCompileConfig, constant_methods: Optional[Dict[str, Any]], generate_etrecord: Optional[bool] = False, ) -\u003e \"EdgeProgramManager\": \"\"\" Generates EdgeProgramManager for subsequent lowering to the partitioners specified by partitioner. The EdgeProgramManager is generated from aten_programs. Partitioners specify what nodes should not be decomposed from the original aten programs. This is done through two passes of run_decompositions. - First pass preserves all aten_targets specified by partitioners to preserve them from nested decompositions - Second pass uses check_op fn provided by partitioners to perform additional checks on nodes with preserved aten targets. They are then replaces with transformed ops to keep them through the second pass of decompositions \"\"\" ops_set_to_not_decompose_by_program = defaultdict(list) edge_programs: Dict[str, ExportedProgram] = {} for name, program in aten_programs.items(): # Functionalize program before asking partitioners to preserve ops program = program.run_decompositions({}) if partitioner is not None: partitioners_for_program = partitioner.get(name, []) final_ops_to_preserve = set() # Decompose by default if there are no partitioners for the method if not partitioners_for_program: program = program.run_decompositions(_default_decomposition_table()) # Process each partitioner individually using their specific requirements for curr_partitioner in partitioners_for_program: curr_ops_no_decomp, _ = curr_partitioner.ops_to_not_decompose(program) # Check if this partitioner can skip using EDGE_DO_NOT_DECOMP can_skip_using_edge_do_not_decomp = _can_skip_using_EDGE_DO_NOT_DECOMP( curr_partitioner, program ) if can_skip_using_edge_do_not_decomp: # Preserve all ops in curr_ops_no_decomp from decomposition table = _default_decomposition_table() ops_needing_preservation = [] for op in curr_ops_no_decomp: if table.pop(op, None) is not None: ops_needing_preservation.append(op) program = program.run_decompositions(table) final_ops_to_preserve.update(ops_needing_preservation) else: # EDGE_DO_NOT_DECOMP path for the partitioner curr_ops_no_decomp = _remove_invalid_ops_for_not_decompose( curr_ops_no_decomp ) # Apply decompositions with this partitioner\u0027s preserved ops table = _default_decomposition_table() for op in curr_ops_no_decomp: table.pop(op, None) # First pass of decompositions with this partitioner\u0027s preserved ops program = program.run_decompositions(table) # Filter ops using EDGE_DO_NOT_DECOMP temp_partitioner_dict = {name: [curr_partitioner]} preserved_ops = ( _replace_aten_ops_with_transformed_ops( name, program, temp_partitioner_dict ) or [] ) final_ops_to_preserve.update(preserved_ops) # Second pass of decompositions with this partitioner\u0027s preserved ops after filtering program = program.run_decompositions(_default_decomposition_table()) # Restore ops from edge_no_decomp_namespace to aten ops _restore_transformed_ops_to_aten_ops(program) ops_set_to_not_decompose_by_program[name].extend(final_ops_to_preserve) edge_programs[name] = _generate_edge_program( config, program, preserve_ops=ops_set_to_not_decompose_by_program.get(name, []), ) edge_manager = EdgeProgramManager( edge_programs, constant_methods, config, list(set().union(*ops_set_to_not_decompose_by_program.values())), ) if generate_etrecord: etrecord = _create_empty_etrecord() etrecord.add_exported_program(aten_programs) etrecord.add_edge_dialect_program(copy.deepcopy(edge_manager)) edge_manager._etrecord = etrecord return edge_manager def collect_named_data_store_from_exported_program( exported_program: ExportedProgram, named_data_store: NamedDataStore, ) -\u003e None: \"\"\" Collects all the named data store outputs found within the exported program and adds them to named_data_store. \"\"\" # collected all the named data into the named data store for deduplication def collect_named_data_store_outputs( graph_module: torch.fx.GraphModule, ) -\u003e None: for node in graph_module.graph.nodes: if node.target == executorch_call_delegate: lbm = getattr(graph_module, node.args[0].target) assert is_lowered_module(lbm) data_store_output = lbm.named_data_store_output if data_store_output is not None: named_data_store.merge_named_data_store(data_store_output) for _, submod, _ in get_control_flow_submodules(graph_module): collect_named_data_store_outputs(submod) collect_named_data_store_outputs(exported_program.graph_module) [docs] @et_logger(\"to_edge_transform_and_lower\") def to_edge_transform_and_lower( # noqa: C901 programs: Union[ExportedProgram, Dict[str, ExportedProgram]], transform_passes: Optional[ Union[Sequence[PassType], Dict[str, Sequence[PassType]], PassManager] ] = None, partitioner: Optional[ Union[List[Partitioner], Dict[str, List[Partitioner]]] ] = None, constant_methods: Optional[Dict[str, Any]] = None, compile_config: Optional[EdgeCompileConfig] = None, generate_etrecord: bool = False, ) -\u003e \"EdgeProgramManager\": \"\"\" :func:`to_edge_transform_and_lower` constructs an EdgeProgramManager from a set of exported programs in ATen dialect. It differs fundamentally from to_edge in that it combines the conversion of the ATen dialect to the edge dialect program, then running the transformation passes and then subsequently lowering the programs to their corresponding backends all into a single API. This is fundamentally useful for lowering to backends that have ops registered that they do not want to be decomposed and thus rely on matching with these non-decomposed ops. For these sorts of backends this is the *only* API that should be used to lower to the edge dialect. Using a combination of to_edge(...) and to_backend(...) will result in inconsistent or wrong behavior. This API is the primary recommended way to lower to the CPU based XNNPack backend. Args: programs: Can be a single ExportedProgram or a dictionary mapping function names to their corresponding ExportedPrograms. If only a single ExportedProgram is provided it will be assigned the name \"forward\". transform_passes: The transform_passes can be one of: 1) a list of passes - all methods in the given EdgeProgramManager will be transformed with the provided passes. 2) a dictionary - only method names specified in the dictionary will be transformed with their corresponding passes 3) an instance of a PassManager - all methods in the given EdgeProgramManager will be transformed with the given PassManager instance. partitioner: The partitioner can either be a Partitioner subclass instance, or a dictionary mapping method names to Partitioner subclass instance. If it is a Partitioner subclass, all programs in the given EdgeProgramManager will be lowered using the given partitioner. If it is a dictionary, only method names specified in the dictionary will be lowered with the given partitioner. constant_methods: An optional dictionary of method name to the constant value returned by that method in eager mode. Often used to store config information on Edge models. compile_config: An optional argument used to provide greater control over the transformation to edge dialect process. generate_etrecord: An optional argument used to generate an etrecord for debugging purposes. Returns: EdgeProgramManager \"\"\" assert not isinstance(constant_methods, EdgeCompileConfig) config = compile_config or EdgeCompileConfig() if not isinstance(programs, dict): aten_programs = {\"forward\": programs} else: aten_programs = programs if not isinstance(partitioner, dict) and partitioner is not None: partitioner = {name: partitioner for name in aten_programs.keys()} elif partitioner is None: partitioner = {name: [] for name in aten_programs.keys()} edge_manager = _gen_edge_manager_for_partitioners( partitioner, aten_programs, config, constant_methods, generate_etrecord ) if transform_passes is not None: edge_manager = edge_manager.transform(transform_passes) max_num_partitioners = 0 for partitioner_list in partitioner.values(): max_num_partitioners = max(max_num_partitioners, len(partitioner_list)) for i in range(max_num_partitioners): method_to_partitioner = {} for name, partitioner_list in partitioner.items(): if i \u003c len(partitioner_list): method_to_partitioner[name] = partitioner_list[i] edge_manager = edge_manager.to_backend(method_to_partitioner) for name, program in edge_manager._edge_programs.items(): ops_set_to_not_decompose: Set[torch._ops.OpOverload] = set() partitioners = partitioner.get(name, []) for curr_partitioner in partitioners: curr_op_set, check_op_support = curr_partitioner.ops_to_not_decompose( program ) if not _can_skip_using_EDGE_DO_NOT_DECOMP(curr_partitioner, program): curr_op_set = _remove_invalid_ops_for_not_decompose(curr_op_set) ops_set_to_not_decompose = ops_set_to_not_decompose.union(curr_op_set) _sanity_check_graph_for_non_decomp_ops( name, program, ops_set_to_not_decompose, check_op_support, partitioner_name=curr_partitioner.__class__.__name__, generate_error=True, ) preserve_ops = config.preserve_ops + list(ops_set_to_not_decompose) if config._check_ir_validity: EXIREdgeDialectVerifier( edge_compile_config=config, class_only=True, preserve_ops=preserve_ops, )()(program.graph_module) return edge_manager [docs] @et_logger(\"to_edge\") def to_edge( programs: Union[ExportedProgram, Dict[str, ExportedProgram]], constant_methods: Optional[Dict[str, Any]] = None, compile_config: Optional[EdgeCompileConfig] = None, generate_etrecord: bool = False, ) -\u003e \"EdgeProgramManager\": \"\"\" :func:`to_edge` constructs an EdgeProgramManager from a set of exported programs in ATen dialect. Upon construction those programs are transformed into edge dialect. Args: programs: Can be a single ExportedProgram or a dictionary mapping function names to their corresponding ExportedPrograms. If only a single ExportedProgram is provided it will be assigned the name \"forward\". constant_methods: An optional dictionary of method name to the constant value returned by that method in eager mode. Often used to store config information on Edge models. compile_config: An optional argument used to provide greater control over the transformation to edge dialect process. generate_etrecord: An optional argument used to generate an etrecord for debugging purposes. Default is False. Returns: EdgeProgramManager \"\"\" assert not isinstance(constant_methods, EdgeCompileConfig) config = compile_config or EdgeCompileConfig() if not isinstance(programs, dict): aten_programs = {\"forward\": programs} else: aten_programs = programs edge_programs: Dict[str, ExportedProgram] = {} for name, program in aten_programs.items(): # Decompose to Core ATen table = _default_decomposition_table() preserve_ops = [] if compile_config: preserve_ops = compile_config.preserve_ops for op in compile_config.preserve_ops: table.pop(op, None) program = program.run_decompositions(table) if config._check_ir_validity: # Remove invalid assert ops, such as _assert_tensor_metadata. # This pass is run in _generate_edge_program; it is required here to # ensure the graph is in ATen dialect before verification. gm = program.graph_module gm_res = RemoveNonCoreAtenOpGraphAssertsPass()(gm) assert gm_res is not None gm = gm_res.graph_module try: EXIRATenDialectVerifier( edge_compile_config=config, class_only=False, )(gm) except ExportError as e: logging.info(f\"Input program {name} is not in ATen dialect.\") raise e edge_programs[name] = _generate_edge_program( config, program, preserve_ops=preserve_ops ) if config._check_ir_validity: try: EXIREdgeDialectVerifier( edge_compile_config=config, class_only=True, preserve_ops=preserve_ops, )()(edge_programs[name].graph_module) except ExportError as e: logging.info(f\"Input program {name} is not in Edge dialect.\") raise e epm = EdgeProgramManager(edge_programs, constant_methods, config) if generate_etrecord: etrecord = _create_empty_etrecord() etrecord.add_exported_program(aten_programs) etrecord.add_edge_dialect_program(copy.deepcopy(epm)) epm._etrecord = etrecord return epm [docs] class EdgeProgramManager: \"\"\" Package of one or more `ExportedPrograms` in Edge dialect. Designed to simplify lowering to ExecuTorch. See: https://pytorch.org/executorch/main/ir-exir Allows easy applications of transforms across a collection of exported programs including the delegation of subgraphs. Manages the second link in the lowering chain of ATen -\u003e Edge -\u003e ExecuTorch. \"\"\" def __init__( self, edge_programs: Union[ExportedProgram, Dict[str, ExportedProgram]], constant_methods: Optional[Dict[str, Any]] = None, compile_config: Optional[EdgeCompileConfig] = None, core_aten_ops_exception_list: Optional[List[torch._ops.OpOverload]] = None, preserve_ops: Optional[List[torch._ops.OpOverload]] = None, ): \"\"\" Should not be called directly by users. User should use :func:\u0027to_edge\u0027 instead. Constructs an EdgeProgramManager from an existing set of exported programs in edge dialect. \"\"\" self.compile_config = compile_config or EdgeCompileConfig() if not isinstance(edge_programs, dict): edge_programs = {\"forward\": edge_programs} for name, program in edge_programs.items(): try: EXIREdgeDialectVerifier( edge_compile_config=self.compile_config, core_aten_ops_exception_list=core_aten_ops_exception_list, preserve_ops=preserve_ops, )(program.graph_module) except ExportError as e: logging.info(f\"Input program {name} is not in aten dialect.\") raise e self._edge_programs: Dict[str, ExportedProgram] = edge_programs self._config_methods = constant_methods self._named_data_store = NamedDataStore() for _, program in self._edge_programs.items(): collect_named_data_store_from_exported_program( program, self._named_data_store ) self._etrecord = None @property def methods(self) -\u003e Set[str]: \"\"\" Returns the set of methods in this EdgeProgramManager. \"\"\" return set(self._edge_programs.keys()) @property def config_methods(self) -\u003e Set[str]: \"\"\" Returns the set of config methods in this EdgeProgramManager. \"\"\" return set(self._config_methods.keys()) if self._config_methods else set() [docs] def exported_program(self, method_name: str = \"forward\") -\u003e ExportedProgram: \"\"\" Returns the ExportedProgram specified by \u0027method_name\u0027. \"\"\" return self._edge_programs[method_name] @et_logger(\"transform\") def transform( self, passes: Union[Sequence[PassType], Dict[str, Sequence[PassType]], PassManager], compile_config: Optional[EdgeCompileConfig] = None, ) -\u003e \"EdgeProgramManager\": \"\"\" Transforms the program according to the provided passes. Args: passes: This param can be one of: 1) a list of passes - all methods in the given EdgeProgramManager will be transformed with the provided passes. 2) a dictionary mapping method names to lists of passes - only method names specified in the dictionary will be transformed with their corresponding passes. 3) a PassManager instance - all methods in the given EdgeProgramManager will be transformed with the given PassManager instance. compile_config: Compile config to use for veriy the correctness of model graph after each pass. If not specified, the compile config of the calling EdgeProgramManager will be used. It will be used in as compile config of returned EdgeProgramManager. Returns: EdgeProgramManager: A copy of the calling EdgeProgramManager with the transformations applied. \"\"\" compile_config = compile_config or self.compile_config new_programs: Dict[str, ExportedProgram] = {} # Cast passes parameter upfront. passes_seq: Optional[Sequence[PassType]] = None passes_dict: Optional[Dict[str, Sequence[PassType]]] = None pass_manager: Optional[PassManager] = None if isinstance(passes, Sequence): passes_seq = passes if isinstance(passes, dict): passes_dict = passes if isinstance(passes, PassManager): pass_manager = passes for name, program in self._edge_programs.items(): # If the method name is enforced, but not matched, we skip transformation. if ( isinstance(passes, dict) and passes_dict and name not in passes_dict.keys() ): new_programs[name] = copy.deepcopy(program) continue # Depending on the passes parameter, call the corresponding transform function. if passes_seq is not None: new_programs[name] = _transform(program, *passes_seq) elif passes_dict is not None: new_programs[name] = _transform(program, *passes_dict[name]) elif pass_manager is not None: new_programs[name] = _transform_with_pass_manager(program, pass_manager) # Verify the correctness of model graph after each transformation. EXIREdgeDialectVerifier(edge_compile_config=compile_config)( new_programs[name].graph_module ) epm = EdgeProgramManager( new_programs, copy.deepcopy(self._config_methods), compile_config ) epm._etrecord = self._etrecord return epm @et_logger(\"to_backend\") def to_backend( self, partitioner: Union[Partitioner, Dict[str, Partitioner]], ) -\u003e \"EdgeProgramManager\": \"\"\" Returns a semantically-equivalent program to the one given as input, but with portions of each program in the EdgeProgramManager targeted for delegation as determined by the partitioner. Args: partitioner: The partitioner can either be a Partitioner subclass instance, or a dictionary mapping method names to Partitioner subclass instance. If it is a Partitioner subclass, all programs in the given EdgeProgramManager will be lowered using the given partitioner. If it is a dictionary, only method names specified in the dictionary will be lowered with the given partitioner. The Partitioner subclass instance is in charge with tagging portions of the input program for delegation. A valid partitioner must return PartitionerResult including valid partition_tags: Dict[str, DelegationSpec], where each key is a tag name and the nodes with same tag will be fused a one subgraph and delegated to backend specififed in delegation spec. Returns: EdgeProgramManager: A copy of the calling EdgeProgramManager with the specified subgraphs lowered. \"\"\" new_edge_programs: Dict[str, ExportedProgram] = {} method_to_partitioner: Dict[str, Partitioner] = {} if not isinstance(partitioner, dict): method_to_partitioner = {name: partitioner for name in self._edge_programs} else: method_to_partitioner = partitioner method_to_programs_and_partitioners = MethodProgramsPartitionerSpec( self._edge_programs, method_to_partitioner, ) new_edge_programs = to_backend(method_to_programs_and_partitioners) config = EdgeCompileConfig(_check_ir_validity=False) epm = EdgeProgramManager( new_edge_programs, copy.deepcopy(self._config_methods), config, ) epm._etrecord = self._etrecord return epm @et_logger(\"to_executorch\") def to_executorch( # noqa (FLAKE8) C901 self, config: Optional[ExecutorchBackendConfig] = None, ) -\u003e \"ExecutorchProgramManager\": \"\"\" Transforms the program to the ExecuTorch backend. Args: config: An optional argument used to provide greater control over the transformation to the ExecuTorch backend. Returns: ExecutorchProgramManager: A manager representing the state of the EdgeProgramManager after it has been transformed to the ExecuTorch backend. \"\"\" config = config if config else ExecutorchBackendConfig() execution_programs: Dict[str, ExportedProgram] = {} for name, program in self._edge_programs.items(): if config.do_quant_fusion_and_const_prop: if program.graph_signature.backward_signature is not None: raise Exception( \"Cannot run do_quant_fusion_and_const_prop on a graph with a backward signature intended for on-device training.\" \" Please set do_quant_fusion_and_const_prop to False in the ExecutorchBackendConfig.\" ) program = quant_fusion_and_const_prop_pass(program) if config.run_reinplace_pass: program = reinplace_pass(program) program = weights_to_outputs_pass(program) program = unsafe_remove_auto_functionalized_pass(program) gm, new_signature = insert_write_back_for_buffers_pass(program) new_gm = program.graph_module for p in edge_to_executorch_passes(config, name): new_gm_res = p(new_gm) assert new_gm_res is not None new_gm = new_gm_res.graph_module if isinstance(p, SpecPropPass): # Note that this is a hacky way to get around the fact that # placeholder nodes corresponding to the parameters of the graph module # shall not participate in memory planning. It increases runtime memory # footprint. # Proper way would be to have ExportPass work with ExportedProgram # instead of GraphModule. This is because ExportPass should work # on top of the export artifact of torch.export whichi s ExportedProgram. # Working with GraphModule does not provide all the information contained # in the ExportedProgram # TODO(who?) p.update_placeholder_tensor_specs(program, new_gm) # Tag constant weights. if ( isinstance(config.external_constants, bool) and config.external_constants ): new_gm_res = external_constants_pass(new_gm) new_gm = new_gm_res.graph_module elif callable(config.external_constants): new_gm_res = external_constants_pass(new_gm, config.external_constants) new_gm = new_gm_res.graph_module # Tag mutable weights. if config.external_mutable_weights: new_gm_res = external_mutable_weights_pass(new_gm, program) new_gm = new_gm_res.graph_module if isinstance(config.memory_planning_pass, dict): memory_planning_pass = config.memory_planning_pass.get( name, ExecutorchBackendConfig().memory_planning_pass ) else: memory_planning_pass = config.memory_planning_pass # TODO(jakeszwe): Follow up with compiler on if the deepcopy is necessary and if so how to make it work if hasattr(memory_planning_pass, \"run\"): new_gm_res = memory_planning_pass.run(new_gm, new_signature) else: new_gm_res = memory_planning_pass(new_gm) # WARNING: DO NOT ADD ANY MORE PASSES AFTER MEMORY PLANNING PASS. # THERE ARE A LOT OF ASSUMPTIONS IN THE STACK THAT MEMORY PLANNING IS THE LAST PASS BEFORE THE EMITTER. assert new_gm_res is not None new_gm = new_gm_res.graph_module _copy_module(program.graph_module, new_gm) execution_programs[name] = program # After running memory planning on all entry points we can run the cross entry point memory planning if isinstance(config.memory_planning_pass, dict): for memory_planning_pass in config.memory_planning_pass.values(): if hasattr(memory_planning_pass, \"run_multimethod\"): memory_planning_pass.run_multimethod() else: memory_planning_pass = config.memory_planning_pass if hasattr(memory_planning_pass, \"run_multimethod\"): memory_planning_pass.run_multimethod() et_pm = ExecutorchProgramManager( execution_programs, self._config_methods, config, self._named_data_store.get_named_data_store_output(), ) if self._etrecord is not None: self._etrecord.add_executorch_program(et_pm) et_pm._etrecord = self._etrecord return et_pm [docs] class ExecutorchProgramManager: \"\"\" Package of one or more `ExportedPrograms` in Execution dialect. Designed to simplify lowering to ExecuTorch. See: https://pytorch.org/executorch/main/ir-exir When the ExecutorchProgramManager is constructed the ExportedPrograms in execution dialect are used to form the executorch binary (in a process called emission) and then serialized to a buffer. Manages the final link in the lowering chain of ATen -\u003e Edge -\u003e ExecuTorch. \"\"\" def __init__( self, execution_programs: Dict[str, ExportedProgram], config_methods: Optional[Dict[str, Any]] = None, backend_config: Optional[ExecutorchBackendConfig] = None, named_data: Optional[NamedDataStoreOutput] = None, ): \"\"\" End users should not call this constructor directly. Instead, they should use :func:\u0027to_executorch\u0027 to construct an ExecutorchProgramManager. Constructs an ExecutorchProgramManager from a set of exported programs in execution dialect. Args: execution_programs: A dictionary of method name to the corresponding ExportedProgram. config_methods: A dictionary of method name to the config value returned by that method in eager mode. backend_config: An optional argument used to provide greater control over the emission and serialization. \"\"\" # Set up methods self._execution_programs: Dict[str, ExportedProgram] = execution_programs self._config_methods: Optional[Dict[str, Any]] = config_methods # Named data from EdgeProgramManager self._named_data: Optional[NamedDataStoreOutput] = named_data backend_config = backend_config or ExecutorchBackendConfig() # Emit methods self._emitter_output: EmitterOutput = emit_program( self._execution_programs, backend_config.emit_stacktrace, self._config_methods, backend_config.emit_mutable_buffer_names, ) # Serialize emitter output, ready to be written to a file. from executorch.extension.flat_tensor.serialize.serialize import ( FlatTensorConfig, FlatTensorSerializer, ) self._data_serializer = FlatTensorSerializer( FlatTensorConfig(segment_alignment=backend_config.segment_alignment) ) self._pte_data, self._tensor_data = serialize_for_executorch( self._emitter_output, backend_config, self._data_serializer, self._named_data, ) self._buffer: Optional[bytes] = None self._etrecord = None @property def methods(self) -\u003e Set[str]: \"\"\" Returns the set of methods in this ExecutorchProgramManager. \"\"\" return set(self._execution_programs.keys()) @property def config_methods(self) -\u003e Set[str]: \"\"\" Returns the set of config methods in this ExecutorchProgramManager. \"\"\" return set(self._config_methods.keys()) if self._config_methods else set() [docs] def exported_program(self, method_name: str = \"forward\") -\u003e ExportedProgram: \"\"\" Returns the ExportedProgram specified by \u0027method_name\u0027. \"\"\" return self._execution_programs[method_name] [docs] def dump_executorch_program( self, verbose: bool = False, out: Optional[TextIO] = None ) -\u003e None: \"\"\" Prints the ExecuTorch binary in a human readable format. Args: verbose (bool): If False prints the binary in a condensed format. If True prints the binary 1-1 with the specification in the schema. out: If None, prints to stdout. If non-None, writes the string to that stream object. It can be a file object, a StringIO object, or any other TextIO subclass. \"\"\" if verbose: pretty_print(self._emitter_output.program, out=out) else: print_program(self._emitter_output.program, out=out) @property def debug_handle_map(self) -\u003e Dict[int, Union[int, List[int]]]: return self._emitter_output.debug_handle_map @property def delegate_map( self, ) -\u003e Dict[str, Dict[int, Dict[str, Union[str, _DelegateDebugIdentifierMap]]]]: return self._emitter_output.method_to_delegate_debug_id_map @property def instruction_id_to_num_outs_map( self, ) -\u003e Dict[str, Dict[int, Union[int, List[int]]]]: return self._emitter_output.instruction_id_to_num_outs_map @property def executorch_program(self) -\u003e Program: \"\"\" Returns the object that represents the ExecuTorch binary before serialization. \"\"\" return self._emitter_output.program @property def buffer(self) -\u003e bytes: \"\"\"Returns the serialized ExecuTorch binary as a byte string. Note that the call to `buffer` may allocate a very large amount of contiguous memory, depending on the model size. If writing to a file, use `write_to_file` which won\u0027t incur additional copies. \"\"\" # TODO(T181494963): update pybinding to remove buffer cache, which can consume large # amounts of memory longer than necessary. if self._buffer is None: self._buffer = bytes(self._pte_data) return self._buffer def get_etrecord(self): \"\"\" Get the generated ETRecord if etrecord generation was enabled. Returns: ETRecord object if generation was enabled, None otherwise Raises: RuntimeError: if ETRecord object was not generated. \"\"\" if self._etrecord is None: raise RuntimeError(\"ETRecord was not generated\") return self._etrecord def write_to_file(self, open_file: io.BufferedIOBase) -\u003e None: \"\"\" Writes the serialized ExecuTorch binary to the file at `open_file`. Prefer to use this over `buffer`, as it writes to file without copying into a contiguous block of memory first, reducing the peak memory usage. \"\"\" self._pte_data.write_to_file(open_file) def write_tensor_data_to_file(self, outdir) -\u003e None: \"\"\" Writes the serialized ExecuTorch data files to the directory at `outdir`. \"\"\" assert self._tensor_data is not None for filename, cord in self._tensor_data.items(): if not filename.endswith(\".ptd\"): filename += \".ptd\" with open(os.path.join(outdir, f\"{filename}\"), \"wb\") as f: logging.info(f\"Writing data file to {filename}\") cord.write_to_file(f) def save(self, path: str) -\u003e None: \"\"\" Saves the serialized ExecuTorch binary to the file at `path`. \"\"\" if path[-4:] != \".pte\": logging.error(f\"Path {path} does not end with .pte\") raise ValueError(f\"Path {path} does not end with .pte\") try: with open(path, \"wb\") as file: self.write_to_file(file) logging.info(f\"Saved exported program to {path}\") except Exception as e: logging.error(f\"Error while saving to {path}: {e}\")",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "https://pytorch.org/docs/stable/_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/_modules/executorch/exir/program/_program.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
  <script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
  
  </body>
</html>