


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta name="robots" content="noindex">
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>executorch.exir.lowered_backend_module &mdash; ExecuTorch main documentation</title>
  

  
  
    <link rel="shortcut icon" href="../../../_static/ExecuTorch-Logo-cropped.svg"/>
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/progress-bar.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />


  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
    <!-- End Google Tag Manager -->
  


  
  <script src="../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Learn
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class=dropdown-title>Get Started</span>
                  <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                  <p>Whats new in PyTorch tutorials</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                  <p>Familiarize yourself with PyTorch concepts and modules</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                  <p>Bite-size, ready-to-deploy PyTorch code examples</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                  <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class="dropdown-title">Tools</span>
                  <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class=dropdown-title>Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class=dropdown-title>Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2023">
                  <span class="dropdown-title">Contributor Awards - 2023</span>
                  <p>Award winners announced at this year's PyTorch Conference</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">About PyTorch Edge</span>
                  <p>Build innovative and privacy-aware AI experiences for edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
                  <span class="dropdown-title">ExecuTorch</span>
                  <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
                </a>
              </div>
            </div>  
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">PyTorch Domains</span>
                  <p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Blogs & News 
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">PyTorch Blog</span>
                  <p>Catch up on the latest technical news and happenings</p>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
                  <span class="dropdown-title">Community Blog</span>
                  <p>Stories from the PyTorch ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/videos">
                  <span class="dropdown-title">Videos</span>
                  <p>Learn about the latest PyTorch tutorials, new, and more </p>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn more about the PyTorch Foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                  <p></p>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="https://pytorch.org/join" data-cta="join">
                Become a Member
              </a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pytorch.org/executorch/versions.html'>main &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
    
         
         
         
              <p class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../intro-overview.html">ExecuTorch Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../intro-how-it-works.html">How ExecuTorch Works</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting-started-architecture.html">High-level Architecture and Components of ExecuTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../concepts.html">ExecuTorch Concepts</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../getting-started-setup.html">Setting Up ExecuTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../export-overview.html">Exporting to ExecuTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../runtime-build-and-cross-compilation.html">Building with CMake</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/export-to-executorch-tutorial.html">Exporting to ExecuTorch Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../running-a-model-cpp-tutorial.html">Running an ExecuTorch Model in C++ Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../extension-module.html">Running an ExecuTorch Model Using the Module Extension in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/sdk-integration-tutorial.html">Using the ExecuTorch SDK to Profile a Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../demo-apps-ios.html">Building an ExecuTorch iOS Demo App</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../demo-apps-android.html">Building an ExecuTorch Android Demo App</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples-end-to-end-to-lower-model-to-delegate.html">Lowering a Model as a Delegate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorial-xnnpack-delegate-lowering.html">Building and Running ExecuTorch with XNNPACK Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../build-run-vulkan.html">Building and Running ExecuTorch with the Vulkan Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../executorch-arm-delegate-tutorial.html">Building and Running ExecuTorch with ARM Ethos-U Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../build-run-coreml.html">Building and Running ExecuTorch with Core ML Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../build-run-mps.html">Building and Running ExecuTorch with MPS Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../build-run-qualcomm-ai-engine-direct-backend.html">Building and Running ExecuTorch with Qualcomm AI Engine Direct Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../build-run-xtensa.html">Building and Running ExecuTorch on Xtensa HiFi4 DSP</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Working with LLMs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../llm/getting-started.html">Getting Started with LLMs via ExecuTorch</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../export-to-executorch-api-reference.html">Export to ExecuTorch API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../executorch-runtime-api-reference.html">ExecuTorch Runtime API Reference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">IR Specification</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../ir-exir.html">Export IR Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ir-ops-set-definition.html">Definition of the Core ATen Operator Set</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Compiler Entry Points</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../compiler-delegate-and-partitioner.html">Backend and Delegate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../compiler-backend-dialect.html">Backend Dialect</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../compiler-custom-compiler-passes.html">Custom Compiler Passes and Partitioners</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../compiler-memory-planning.html">Memory Planning</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Runtime</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../runtime-overview.html">ExecuTorch Runtime Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../runtime-backend-delegate-implementation-and-linking.html">Backend Delegate Implementation and Linking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../runtime-platform-abstraction-layer.html">Runtime Platform Abstraction Layer (PAL)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../portable-cpp-programming.html">Portable C++ Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pte-file-format.html"><code class="docutils literal notranslate"><span class="pre">.pte</span></code> file format</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quantization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../quantization-overview.html">Quantization Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Kernel Library</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../kernel-library-overview.html">Overview of ExecuTorch’s Kernel Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../kernel-library-custom-aten-kernel.html">Kernel Registration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../kernel-library-selective-build.html">Kernel Library Selective Build</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Backend Delegates</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../native-delegates-executorch-xnnpack-delegate.html">ExecuTorch XNNPACK delegate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../native-delegates-executorch-vulkan-delegate.html">ExecuTorch Vulkan Delegate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../backend-delegates-integration.html">Integrating a Backend Delegate into ExecuTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../backend-delegates-dependencies.html">Third-Party Dependency Management for Backend Delegates</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../debug-backend-delegate.html">Debug Backend Delegate</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">SDK</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../sdk-overview.html">Introduction to the ExecuTorch SDK</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sdk-bundled-io.html">Bundled Program – a Tool for ExecuTorch Model Validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sdk-etrecord.html">Prerequisite | ETRecord - ExecuTorch Record</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sdk-etdump.html">Prerequisite | ETDump - ExecuTorch Dump</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sdk-profiling.html">Profiling Models in ExecuTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sdk-debugging.html">Debugging Models in ExecuTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sdk-inspector.html">Inspector APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sdk-delegate-integration.html">SDK Delegate Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sdk-tutorial.html">SDK usage tutorial</a></li>
</ul>

         

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../index.html">Module code</a> &gt;</li>
        
      <li>executorch.exir.lowered_backend_module</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        


          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for executorch.exir.lowered_backend_module</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates.</span>
<span class="c1"># All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the BSD-style license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>

<span class="c1"># pyre-strict</span>

<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">operator</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.utils._pytree</span> <span class="k">as</span> <span class="nn">pytree</span>
<span class="kn">from</span> <span class="nn">executorch.exir._serialize</span> <span class="kn">import</span> <span class="n">_serialize_pte_binary</span>
<span class="kn">from</span> <span class="nn">executorch.exir.backend.compile_spec_schema</span> <span class="kn">import</span> <span class="n">CompileSpec</span>
<span class="kn">from</span> <span class="nn">executorch.exir.delegate</span> <span class="kn">import</span> <span class="n">executorch_call_delegate</span><span class="p">,</span> <span class="n">get_lowered_module_name</span>
<span class="kn">from</span> <span class="nn">executorch.exir.emit</span> <span class="kn">import</span> <span class="n">emit_program</span>

<span class="kn">from</span> <span class="nn">executorch.exir.graph_module</span> <span class="kn">import</span> <span class="n">_get_submodule</span>

<span class="kn">from</span> <span class="nn">executorch.exir.passes.memory_planning_pass</span> <span class="kn">import</span> <span class="n">MemoryPlanningPass</span>
<span class="kn">from</span> <span class="nn">executorch.exir.passes.spec_prop_pass</span> <span class="kn">import</span> <span class="n">make_spec</span><span class="p">,</span> <span class="n">SpecPropPass</span>
<span class="kn">from</span> <span class="nn">executorch.exir.schema</span> <span class="kn">import</span> <span class="n">Program</span>

<span class="kn">from</span> <span class="nn">executorch.exir.tracer</span> <span class="kn">import</span> <span class="n">Value</span>

<span class="kn">from</span> <span class="nn">torch._subclasses</span> <span class="kn">import</span> <span class="n">FakeTensor</span>
<span class="kn">from</span> <span class="nn">torch.export.exported_program</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ConstantArgument</span><span class="p">,</span>
    <span class="n">ExportedProgram</span><span class="p">,</span>
    <span class="n">ExportGraphSignature</span><span class="p">,</span>
    <span class="n">InputKind</span><span class="p">,</span>
    <span class="n">InputSpec</span><span class="p">,</span>
    <span class="n">ModuleCallEntry</span><span class="p">,</span>
    <span class="n">ModuleCallSignature</span><span class="p">,</span>
    <span class="n">OutputKind</span><span class="p">,</span>
    <span class="n">OutputSpec</span><span class="p">,</span>
    <span class="n">TensorArgument</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">torch.fx.passes.utils.fuser_utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">erase_nodes</span><span class="p">,</span>
    <span class="n">fuse_as_graphmodule</span><span class="p">,</span>
    <span class="n">insert_subgm</span><span class="p">,</span>
    <span class="n">legalize_graph</span><span class="p">,</span>
    <span class="n">NodeList</span><span class="p">,</span>
    <span class="n">topo_sort</span><span class="p">,</span>
<span class="p">)</span>


<div class="viewcode-block" id="LoweredBackendModule"><a class="viewcode-back" href="../../../export-to-executorch-api-reference.html#executorch.exir.backend.backend_api.LoweredBackendModule">[docs]</a><span class="k">class</span> <span class="nc">LoweredBackendModule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A subclass of nn.Module that is generated for modules containing</span>
<span class="sd">    delegated functions. This is can be created by calling `to_backend`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_backend_id</span><span class="p">:</span> <span class="nb">str</span>  <span class="c1"># The backend&#39;s name</span>
    <span class="n">_processed_bytes</span><span class="p">:</span> <span class="nb">bytes</span>  <span class="c1"># The delegate blobs created from backend.preprocess</span>
    <span class="n">_compile_specs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span>
        <span class="n">CompileSpec</span>
    <span class="p">]</span>  <span class="c1"># A list of backend-specific objects with static metadata to configure the &quot;compilation&quot; process.</span>
    <span class="n">_original_exported_program</span><span class="p">:</span> <span class="n">ExportedProgram</span>  <span class="c1"># The original EXIR module</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">edge_program</span><span class="p">:</span> <span class="n">ExportedProgram</span><span class="p">,</span>
        <span class="n">backend_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">processed_bytes</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">,</span>
        <span class="n">compile_specs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">CompileSpec</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_original_exported_program</span> <span class="o">=</span> <span class="n">edge_program</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_backend_id</span> <span class="o">=</span> <span class="n">backend_id</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_processed_bytes</span> <span class="o">=</span> <span class="n">processed_bytes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_compile_specs</span> <span class="o">=</span> <span class="n">compile_specs</span>

    <span class="c1"># pyre-ignore</span>
    <span class="k">def</span> <span class="nf">__deepcopy__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">memo</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Any</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="s2">&quot;LoweredBackendModule&quot;</span><span class="p">:</span>
        <span class="c1"># Copy exported program</span>
        <span class="n">copied_program</span> <span class="o">=</span> <span class="n">ExportedProgram</span><span class="p">(</span>
            <span class="n">root</span><span class="o">=</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_original_exported_program</span><span class="o">.</span><span class="n">graph_module</span><span class="p">),</span>
            <span class="n">graph</span><span class="o">=</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_original_exported_program</span><span class="o">.</span><span class="n">graph</span><span class="p">),</span>
            <span class="n">graph_signature</span><span class="o">=</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_original_exported_program</span><span class="o">.</span><span class="n">graph_signature</span>
            <span class="p">),</span>
            <span class="n">state_dict</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_original_exported_program</span><span class="o">.</span><span class="n">state_dict</span><span class="p">,</span>
            <span class="n">range_constraints</span><span class="o">=</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_original_exported_program</span><span class="o">.</span><span class="n">range_constraints</span>
            <span class="p">),</span>
            <span class="n">module_call_graph</span><span class="o">=</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_original_exported_program</span><span class="o">.</span><span class="n">module_call_graph</span>
            <span class="p">),</span>
            <span class="n">verifier</span><span class="o">=</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_original_exported_program</span><span class="o">.</span><span class="n">verifier</span><span class="p">),</span>
            <span class="n">constants</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_original_exported_program</span><span class="o">.</span><span class="n">constants</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">res</span> <span class="o">=</span> <span class="n">LoweredBackendModule</span><span class="p">(</span>
            <span class="n">edge_program</span><span class="o">=</span><span class="n">copied_program</span><span class="p">,</span>
            <span class="n">backend_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_backend_id</span><span class="p">,</span>
            <span class="n">processed_bytes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_processed_bytes</span><span class="p">,</span>
            <span class="n">compile_specs</span><span class="o">=</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_compile_specs</span><span class="p">,</span> <span class="n">memo</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="n">res</span><span class="o">.</span><span class="n">meta</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;meta&quot;</span><span class="p">,</span> <span class="p">{}))</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">backend_id</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the backends name.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backend_id</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">processed_bytes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bytes</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the delegate blob created from backend.preprocess</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_processed_bytes</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">compile_specs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">CompileSpec</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a list of backend-specific objects with static metadata to configure the &quot;compilation&quot; process.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compile_specs</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">original_module</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ExportedProgram</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the original EXIR module</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_original_exported_program</span>

    <span class="c1"># TODO(chenlai): consolidate the seriailization config with serialize_to_flatbuffer api</span>
<div class="viewcode-block" id="LoweredBackendModule.buffer"><a class="viewcode-back" href="../../../export-to-executorch-api-reference.html#executorch.exir.backend.backend_api.LoweredBackendModule.buffer">[docs]</a>    <span class="k">def</span> <span class="nf">buffer</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">extract_delegate_segments</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">segment_alignment</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4096</span><span class="p">,</span>
        <span class="n">constant_tensor_alignment</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">delegate_alignment</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bytes</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a buffer containing the serialized ExecuTorch binary.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO(T181463742): avoid calling bytes(..) which incurs large copies.</span>
        <span class="n">out</span> <span class="o">=</span> <span class="nb">bytes</span><span class="p">(</span>
            <span class="n">_serialize_pte_binary</span><span class="p">(</span>
                <span class="n">program</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">program</span><span class="p">(),</span>
                <span class="n">extract_delegate_segments</span><span class="o">=</span><span class="n">extract_delegate_segments</span><span class="p">,</span>
                <span class="n">segment_alignment</span><span class="o">=</span><span class="n">segment_alignment</span><span class="p">,</span>
                <span class="n">constant_tensor_alignment</span><span class="o">=</span><span class="n">constant_tensor_alignment</span><span class="p">,</span>
                <span class="n">delegate_alignment</span><span class="o">=</span><span class="n">delegate_alignment</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span></div>

    <span class="c1"># TODO(chenlai): re-consider recapture instead of manually constructing the program because</span>
    <span class="c1"># the meta data construction is done manually.</span>
    <span class="k">def</span> <span class="nf">program</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">emit_stacktrace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Program</span><span class="p">:</span>
        <span class="c1"># Fix autodpes introuces cyclic dependencies:</span>
        <span class="c1"># program -&gt; verifier -&gt; lowered_backend_module -&gt; program</span>
        <span class="c1"># @manual</span>
        <span class="kn">from</span> <span class="nn">executorch.exir.program._program</span> <span class="kn">import</span> <span class="p">(</span>
            <span class="n">_get_updated_graph_signature</span><span class="p">,</span>
            <span class="n">_transform</span><span class="p">,</span>
        <span class="p">)</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the object that represents the ExecuTorch binary before serialization.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Creates a new module based on the original module. The original module will</span>
        <span class="c1"># look something like following:</span>
        <span class="c1">#</span>
        <span class="c1"># opcode         name                 target            args                                        kwargs</span>
        <span class="c1"># -------------  -------------------  ----------------  ------------------------------------------  --------</span>
        <span class="c1"># placeholder    arg0_1               arg0_1            ()                                          {}</span>
        <span class="c1"># placeholder    arg1_1               arg1_1            ()                                          {}</span>
        <span class="c1"># call_function  aten_repeat_default  *                 (arg1_1, [4, 1])                            {}</span>
        <span class="c1"># call_function  aten_mul_tensor      *                 (aten_repeat_default, aten_repeat_default)  {}</span>
        <span class="c1"># call_function  aten_add_tensor      *                 (arg1_1, arg1_1)                            {}</span>
        <span class="c1"># output         output               output            ([aten_mul_tensor, aten_add_tensor],)       {}</span>
        <span class="c1">#</span>
        <span class="c1"># if the whole module is lowered, the resulting lowered module look like</span>
        <span class="c1">#</span>
        <span class="c1"># opcode         name                      target                       args                                kwargs</span>
        <span class="c1"># -------------  ------------------------  ---------------------------  ----------------------------------  --------</span>
        <span class="c1"># placeholder    arg0_1                    arg0_1                       ()                                  {}</span>
        <span class="c1"># placeholder    arg1_1                    arg1_1                       ()                                  {}</span>
        <span class="c1"># get_attr       lowered_module_0          lowered_module_0             ()                                  {}</span>
        <span class="c1"># call_function  executorch_call_delegate  executorch_call_delegate     (lowered_module_0, arg0_1, arg1_1)  {}</span>
        <span class="c1"># call_function  getitem                   &lt;built-in function getitem&gt;  (executorch_call_delegate, 0)       {}</span>
        <span class="c1"># call_function  getitem_1                 &lt;built-in function getitem&gt;  (executorch_call_delegate, 1)       {}</span>
        <span class="c1"># output         output_1                  output                       ([getitem, getitem_1],)             {}</span>
        <span class="c1">#</span>
        <span class="c1"># We&#39;ll remove all call_function nodes, insert an call_delegate node, inserting getitems nodes to get the result for call_delegate node</span>
        <span class="c1"># and return the list of getitems as the output</span>

        <span class="n">lowered_exported_program</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_original_exported_program</span><span class="p">)</span>

        <span class="c1"># The real input nodes are the ones not buffer or parameter</span>
        <span class="n">all_input_nodes</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">node</span>
            <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;placeholder&quot;</span>
                <span class="ow">and</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span>
                <span class="ow">not</span> <span class="ow">in</span> <span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">graph_signature</span><span class="o">.</span><span class="n">inputs_to_buffers</span>
                <span class="ow">and</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span>
                <span class="ow">not</span> <span class="ow">in</span> <span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">graph_signature</span><span class="o">.</span><span class="n">inputs_to_parameters</span>
            <span class="p">)</span>
        <span class="p">]</span>

        <span class="n">output_node</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">node</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span> <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;output&quot;</span>
        <span class="p">]</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_node</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;There should be only one output node&quot;</span>

        <span class="c1"># Step 1. Cleaning up the graph before inserting the call_delegate node</span>
        <span class="c1"># Remove the original output node</span>
        <span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">erase_node</span><span class="p">(</span><span class="n">output_node</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># Remove all the everything else except the input</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">!=</span> <span class="s2">&quot;placeholder&quot;</span><span class="p">:</span>
                <span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">erase_node</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

        <span class="c1"># Find placeholders that are parameters or buffers, remove them from the main graph</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;placeholder&quot;</span> <span class="ow">and</span> <span class="p">(</span>
                <span class="n">node</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">graph_signature</span><span class="o">.</span><span class="n">inputs_to_buffers</span>
                <span class="ow">or</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span>
                <span class="ow">in</span> <span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">graph_signature</span><span class="o">.</span><span class="n">inputs_to_parameters</span>
            <span class="p">):</span>
                <span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">erase_node</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

        <span class="c1"># Step 2. Start constructing the graph</span>
        <span class="n">lowered_name</span> <span class="o">=</span> <span class="n">get_lowered_module_name</span><span class="p">(</span>
            <span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">graph_module</span><span class="p">,</span> <span class="bp">self</span>
        <span class="p">)</span>
        <span class="c1"># Insert the lowered module to the graph module as an attibute</span>
        <span class="n">lowered_node</span> <span class="o">=</span> <span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="n">lowered_name</span><span class="p">)</span>

        <span class="c1"># Insert a call_delegate node to the graph module, with arguments from the arg list</span>
        <span class="n">delegate_node</span> <span class="o">=</span> <span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">call_function</span><span class="p">(</span>
            <span class="n">executorch_call_delegate</span><span class="p">,</span> <span class="p">(</span><span class="n">lowered_node</span><span class="p">,</span> <span class="o">*</span><span class="n">all_input_nodes</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="c1"># Get the output list. Since the output node is a tuple of list, like ([aten_mul_tensor, aten_add_tensor],)</span>
        <span class="c1"># We add some handling logic to get the list `[aten_mul_tensor, aten_add_tensor]` properly</span>
        <span class="n">original_output_nodes</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">node</span>
            <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_original_exported_program</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span>
            <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;output&quot;</span>
        <span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">delegate_node</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s2">&quot;spec&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
            <span class="p">[</span><span class="n">make_spec</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s2">&quot;val&quot;</span><span class="p">])</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">original_output_nodes</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">delegate_node</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s2">&quot;val&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
            <span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s2">&quot;val&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">original_output_nodes</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="c1"># The getitem nodes that are going to be inserted to the lowered graph module</span>
        <span class="n">getitem_nodes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">original_output_nodes</span><span class="p">)):</span>
            <span class="n">getitem_node</span> <span class="o">=</span> <span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">call_function</span><span class="p">(</span>
                <span class="n">operator</span><span class="o">.</span><span class="n">getitem</span><span class="p">,</span>
                <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">delegate_node</span><span class="p">,</span> <span class="n">i</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="n">getitem_node</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s2">&quot;val&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">delegate_node</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s2">&quot;val&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
            <span class="n">getitem_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">getitem_node</span><span class="p">)</span>
        <span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">getitem_nodes</span><span class="p">)</span>

        <span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">graph_module</span><span class="o">.</span><span class="n">recompile</span><span class="p">()</span>
        <span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">lint</span><span class="p">()</span>

        <span class="c1"># Users output will be the get items nodes instead</span>
        <span class="n">output_specs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">OutputSpec</span><span class="p">(</span>
                <span class="n">kind</span><span class="o">=</span><span class="n">OutputKind</span><span class="o">.</span><span class="n">USER_OUTPUT</span><span class="p">,</span>
                <span class="n">arg</span><span class="o">=</span><span class="n">TensorArgument</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">getitem_node</span><span class="o">.</span><span class="n">name</span><span class="p">),</span>
                <span class="n">target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">getitem_node</span> <span class="ow">in</span> <span class="n">getitem_nodes</span>
        <span class="p">]</span>
        <span class="c1"># All data are consumed by the delegates so they should be removed from the state dict.</span>
        <span class="n">inputs_to_parameters</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">graph_signature</span><span class="o">.</span><span class="n">inputs_to_parameters</span>
        <span class="p">)</span>
        <span class="n">inputs_to_buffers</span> <span class="o">=</span> <span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">graph_signature</span><span class="o">.</span><span class="n">inputs_to_buffers</span>
        <span class="n">input_specs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">InputSpec</span><span class="p">(</span>
                <span class="n">kind</span><span class="o">=</span><span class="n">InputKind</span><span class="o">.</span><span class="n">USER_INPUT</span><span class="p">,</span>
                <span class="n">arg</span><span class="o">=</span><span class="n">TensorArgument</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">),</span>
                <span class="n">target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">user_input</span> <span class="ow">in</span> <span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">graph_signature</span><span class="o">.</span><span class="n">user_inputs</span>
            <span class="k">if</span> <span class="n">user_input</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">inputs_to_parameters</span>
            <span class="ow">and</span> <span class="n">user_input</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">inputs_to_buffers</span>
        <span class="p">]</span>

        <span class="c1"># Double check the ExportedProgram data(especially everything except graph) is good</span>
        <span class="n">exported_program</span> <span class="o">=</span> <span class="n">ExportedProgram</span><span class="p">(</span>
            <span class="n">root</span><span class="o">=</span><span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">graph_module</span><span class="p">,</span>
            <span class="n">graph</span><span class="o">=</span><span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span>
            <span class="n">graph_signature</span><span class="o">=</span><span class="n">_get_updated_graph_signature</span><span class="p">(</span>
                <span class="n">ExportGraphSignature</span><span class="p">(</span>
                    <span class="n">input_specs</span><span class="o">=</span><span class="n">input_specs</span><span class="p">,</span> <span class="n">output_specs</span><span class="o">=</span><span class="n">output_specs</span>
                <span class="p">),</span>
                <span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">graph_module</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="c1"># TODO: May need to set lowered_exported_program.call_spec = CallSpec(None, None)</span>
            <span class="c1"># somewhere as we should pass it a list of tensors to the lowered module and output a</span>
            <span class="c1"># list of tensors. Putting call_spec=lowered_exported_program.call_spec is correct here as the</span>
            <span class="c1"># inputs/outputs to the toplevel program will be in the format of the eager module.</span>
            <span class="n">state_dict</span><span class="o">=</span><span class="p">{},</span>  <span class="c1"># None because all data are consumed by delegate</span>
            <span class="n">range_constraints</span><span class="o">=</span><span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">range_constraints</span><span class="p">,</span>
            <span class="n">module_call_graph</span><span class="o">=</span><span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">module_call_graph</span><span class="p">,</span>
            <span class="n">example_inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">verifier</span><span class="o">=</span><span class="n">lowered_exported_program</span><span class="o">.</span><span class="n">verifier</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">exported_program</span> <span class="o">=</span> <span class="n">_transform</span><span class="p">(</span>
            <span class="n">exported_program</span><span class="p">,</span> <span class="n">SpecPropPass</span><span class="p">(),</span> <span class="n">MemoryPlanningPass</span><span class="p">(</span><span class="s2">&quot;greedy&quot;</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">emitted_program</span> <span class="o">=</span> <span class="n">emit_program</span><span class="p">(</span>
            <span class="n">exported_program</span><span class="p">,</span> <span class="n">emit_stacktrace</span><span class="o">=</span><span class="n">emit_stacktrace</span>
        <span class="p">)</span><span class="o">.</span><span class="n">program</span>
        <span class="k">return</span> <span class="n">emitted_program</span>

    <span class="c1"># Used to patch each delegated function with a call_delegate call</span>
    <span class="c1"># @staticmethod</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Value</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Value</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Value</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">executorch_call_delegate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span></div>


<span class="c1"># TODO(zhxchen17) Try ExportPass</span>
<span class="k">def</span> <span class="nf">_fixup_output_node</span><span class="p">(</span><span class="n">gm</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">gm</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;output&quot;</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">gm</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">inserting_before</span><span class="p">(</span><span class="n">node</span><span class="p">):</span>
                <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">args</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">Node</span><span class="p">):</span>
                    <span class="n">val</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">meta</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;val&quot;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                        <span class="c1"># If a list is returned, in some cases it is represented as a</span>
                        <span class="c1"># singular node, like `split_copy_tensor` but EXIR will return a</span>
                        <span class="c1"># opened-up list like `[getitem1, getitem2]`</span>
                        <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span>
                            <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">Proxy</span><span class="p">(</span><span class="n">outputs</span><span class="p">)[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">node</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">val</span><span class="p">))</span>
                        <span class="p">]</span>
            <span class="n">returns</span><span class="p">,</span> <span class="n">out_spec</span> <span class="o">=</span> <span class="n">pytree</span><span class="o">.</span><span class="n">tree_flatten</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
            <span class="n">node</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="n">returns</span><span class="p">,)</span>
            <span class="k">return</span>


<span class="k">def</span> <span class="nf">arrange_graph_placeholders</span><span class="p">(</span>
    <span class="n">gm</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">,</span> <span class="n">owning_program</span><span class="p">:</span> <span class="n">ExportedProgram</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Modifies the graph of the given graphmodule with one that contains the same nodes as the original,</span>
<span class="sd">    but with placeholders in order of (Params + Buffers) (User Inputs)</span>

<span class="sd">    This is used by the delegate api which disturbs the placeholder ordering when creating a submodule</span>
<span class="sd">    from partitioned nodes</span>

<span class="sd">    Args:</span>
<span class="sd">        gm: The graph module that we want arranged</span>
<span class="sd">        owning_program: ExportedProgram that the submodule (gm) belongs to</span>

<span class="sd">    Returns:</span>
<span class="sd">        The graph module in-placed arranged</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">new_graph</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>

    <span class="n">node_map</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># mapping of nodes from old graph to new graph</span>

    <span class="n">graph_sign</span> <span class="o">=</span> <span class="n">owning_program</span><span class="o">.</span><span class="n">graph_signature</span>

    <span class="c1"># Add all placeholders into the graph first:</span>
    <span class="n">param_nodes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">buffer_nodes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">input_nodes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">gm</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">!=</span> <span class="s2">&quot;placeholder&quot;</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">graph_sign</span><span class="o">.</span><span class="n">inputs_to_parameters</span><span class="p">:</span>
            <span class="n">param_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">graph_sign</span><span class="o">.</span><span class="n">inputs_to_buffers</span><span class="p">:</span>
            <span class="n">buffer_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">input_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">param_node</span> <span class="ow">in</span> <span class="n">param_nodes</span><span class="p">:</span>
        <span class="n">new_node</span> <span class="o">=</span> <span class="n">new_graph</span><span class="o">.</span><span class="n">node_copy</span><span class="p">(</span><span class="n">param_node</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">node_map</span><span class="p">[</span><span class="n">x</span><span class="p">])</span>
        <span class="n">node_map</span><span class="p">[</span><span class="n">param_node</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_node</span>
    <span class="k">for</span> <span class="n">buffer_node</span> <span class="ow">in</span> <span class="n">buffer_nodes</span><span class="p">:</span>
        <span class="n">new_node</span> <span class="o">=</span> <span class="n">new_graph</span><span class="o">.</span><span class="n">node_copy</span><span class="p">(</span><span class="n">buffer_node</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">node_map</span><span class="p">[</span><span class="n">x</span><span class="p">])</span>
        <span class="n">node_map</span><span class="p">[</span><span class="n">buffer_node</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_node</span>
    <span class="k">for</span> <span class="n">input_node</span> <span class="ow">in</span> <span class="n">input_nodes</span><span class="p">:</span>
        <span class="n">new_node</span> <span class="o">=</span> <span class="n">new_graph</span><span class="o">.</span><span class="n">node_copy</span><span class="p">(</span><span class="n">input_node</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">node_map</span><span class="p">[</span><span class="n">x</span><span class="p">])</span>
        <span class="n">node_map</span><span class="p">[</span><span class="n">input_node</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_node</span>

    <span class="c1"># Now add all the other nodes in order</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">gm</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;placeholder&quot;</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="n">new_node</span> <span class="o">=</span> <span class="n">new_graph</span><span class="o">.</span><span class="n">node_copy</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">node_map</span><span class="p">[</span><span class="n">x</span><span class="p">])</span>
        <span class="n">node_map</span><span class="p">[</span><span class="n">node</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_node</span>

    <span class="c1"># lint to ensure correctness</span>
    <span class="n">new_graph</span><span class="o">.</span><span class="n">lint</span><span class="p">()</span>

    <span class="n">new_graph</span><span class="o">.</span><span class="n">_codegen</span> <span class="o">=</span> <span class="n">gm</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">_codegen</span>
    <span class="n">gm</span><span class="o">.</span><span class="n">graph</span> <span class="o">=</span> <span class="n">new_graph</span>

    <span class="k">return</span> <span class="n">gm</span>


<span class="c1"># TODO Don&#39;t regenerate new signature manually.</span>
<span class="k">def</span> <span class="nf">_get_new_signature</span><span class="p">(</span>  <span class="c1"># noqa: C901</span>
    <span class="n">original_program</span><span class="p">:</span> <span class="n">ExportedProgram</span><span class="p">,</span>
    <span class="n">gm</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">,</span>
    <span class="n">tag</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
    <span class="n">ExportGraphSignature</span><span class="p">,</span>
    <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">]],</span>
    <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ScriptObject</span><span class="p">]],</span>
<span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">        tag: If tag is None, this means that we are constructing the graph</span>
<span class="sd">        signature for the toplevel graph, after delegation. We need to do this</span>
<span class="sd">        because sometimes delegates will swallow some parameters/buffers, so we</span>
<span class="sd">        need to update the graph signature/state dict to reflect these changes.</span>
<span class="sd">        Otherwise, if tag is not None, this means we are constructing the graph</span>
<span class="sd">        signature for the delegated modules. In this case, we need to look</span>
<span class="sd">        through the input nodes and see which ones were originally</span>
<span class="sd">        parameters/buffers, and lower them down to the delegate.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">old_signature</span> <span class="o">=</span> <span class="n">original_program</span><span class="o">.</span><span class="n">graph_signature</span>

    <span class="n">input_specs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">output_specs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">new_signature</span> <span class="o">=</span> <span class="n">ExportGraphSignature</span><span class="p">(</span>
        <span class="n">input_specs</span><span class="o">=</span><span class="n">input_specs</span><span class="p">,</span> <span class="n">output_specs</span><span class="o">=</span><span class="n">output_specs</span>
    <span class="p">)</span>
    <span class="n">new_state_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">new_constants</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="n">placeholder_nodes</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">node</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">original_program</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span> <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;placeholder&quot;</span>
    <span class="p">]</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">placeholder_nodes</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">old_signature</span><span class="o">.</span><span class="n">input_specs</span><span class="p">)</span>
    <span class="n">input_node_to_sig</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">placeholder_nodes</span><span class="p">,</span> <span class="n">old_signature</span><span class="o">.</span><span class="n">input_specs</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">gm</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
        <span class="n">is_tagged</span> <span class="o">=</span> <span class="n">tag</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">node</span><span class="o">.</span><span class="n">meta</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;delegation_tag&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="o">==</span> <span class="n">tag</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;placeholder&quot;</span><span class="p">:</span>

            <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">input_node_to_sig</span><span class="p">:</span>
                <span class="k">assert</span> <span class="n">tag</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="n">input_specs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">InputSpec</span><span class="p">(</span>
                        <span class="n">kind</span><span class="o">=</span><span class="n">InputKind</span><span class="o">.</span><span class="n">USER_INPUT</span><span class="p">,</span>
                        <span class="n">arg</span><span class="o">=</span><span class="n">TensorArgument</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">),</span>
                        <span class="n">target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>
                <span class="k">continue</span>

            <span class="n">orig_input_spec</span> <span class="o">=</span> <span class="n">input_node_to_sig</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">orig_input_spec</span><span class="o">.</span><span class="n">arg</span><span class="p">,</span> <span class="n">TensorArgument</span><span class="p">):</span>
                <span class="n">input_specs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">orig_input_spec</span><span class="p">)</span>

            <span class="k">elif</span> <span class="n">is_tagged</span><span class="p">:</span>
                <span class="n">input_specs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">orig_input_spec</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">orig_input_spec</span><span class="o">.</span><span class="n">kind</span> <span class="o">==</span> <span class="n">InputKind</span><span class="o">.</span><span class="n">PARAMETER</span><span class="p">:</span>
                    <span class="n">new_state_dict</span><span class="p">[</span><span class="n">orig_input_spec</span><span class="o">.</span><span class="n">target</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">original_program</span><span class="o">.</span><span class="n">state_dict</span><span class="p">[</span><span class="n">orig_input_spec</span><span class="o">.</span><span class="n">target</span><span class="p">]</span>
                    <span class="p">)</span>
                <span class="k">elif</span> <span class="p">(</span>
                    <span class="n">orig_input_spec</span><span class="o">.</span><span class="n">kind</span> <span class="o">==</span> <span class="n">InputKind</span><span class="o">.</span><span class="n">BUFFER</span>
                    <span class="ow">and</span> <span class="n">orig_input_spec</span><span class="o">.</span><span class="n">persistent</span>
                <span class="p">):</span>
                    <span class="n">new_state_dict</span><span class="p">[</span><span class="n">orig_input_spec</span><span class="o">.</span><span class="n">target</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">original_program</span><span class="o">.</span><span class="n">state_dict</span><span class="p">[</span><span class="n">orig_input_spec</span><span class="o">.</span><span class="n">target</span><span class="p">]</span>
                    <span class="p">)</span>
                <span class="k">elif</span> <span class="n">orig_input_spec</span><span class="o">.</span><span class="n">kind</span> <span class="o">==</span> <span class="n">InputKind</span><span class="o">.</span><span class="n">BUFFER</span><span class="p">:</span>
                    <span class="k">assert</span> <span class="ow">not</span> <span class="n">orig_input_spec</span><span class="o">.</span><span class="n">persistent</span>
                    <span class="n">new_constants</span><span class="p">[</span><span class="n">orig_input_spec</span><span class="o">.</span><span class="n">target</span><span class="p">]</span> <span class="o">=</span> <span class="n">original_program</span><span class="o">.</span><span class="n">constants</span><span class="p">[</span>
                        <span class="n">orig_input_spec</span><span class="o">.</span><span class="n">target</span>
                    <span class="p">]</span>
                <span class="k">elif</span> <span class="n">orig_input_spec</span><span class="o">.</span><span class="n">kind</span> <span class="ow">in</span> <span class="p">(</span>
                    <span class="n">InputKind</span><span class="o">.</span><span class="n">CONSTANT_TENSOR</span><span class="p">,</span>
                    <span class="n">InputKind</span><span class="o">.</span><span class="n">CUSTOM_OBJ</span><span class="p">,</span>
                <span class="p">):</span>
                    <span class="n">new_constants</span><span class="p">[</span><span class="n">orig_input_spec</span><span class="o">.</span><span class="n">target</span><span class="p">]</span> <span class="o">=</span> <span class="n">original_program</span><span class="o">.</span><span class="n">constants</span><span class="p">[</span>
                        <span class="n">orig_input_spec</span><span class="o">.</span><span class="n">target</span>
                    <span class="p">]</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">input_specs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">InputSpec</span><span class="p">(</span>
                        <span class="n">kind</span><span class="o">=</span><span class="n">InputKind</span><span class="o">.</span><span class="n">USER_INPUT</span><span class="p">,</span>
                        <span class="n">arg</span><span class="o">=</span><span class="n">TensorArgument</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">),</span>
                        <span class="n">target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;output&quot;</span><span class="p">:</span>
            <span class="n">output_nodes</span> <span class="o">=</span> <span class="n">pytree</span><span class="o">.</span><span class="n">tree_leaves</span><span class="p">((</span><span class="n">node</span><span class="o">.</span><span class="n">args</span><span class="p">,</span> <span class="n">node</span><span class="o">.</span><span class="n">kwargs</span><span class="p">))</span>

            <span class="k">if</span> <span class="n">tag</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># We are constructing output_specs for the delegate outputs.</span>
                <span class="c1"># These don&#39;t have any buffer mutations.</span>

                <span class="k">for</span> <span class="n">output_node</span> <span class="ow">in</span> <span class="n">output_nodes</span><span class="p">:</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_node</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">Node</span><span class="p">):</span>
                        <span class="n">output_specs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                            <span class="n">OutputSpec</span><span class="p">(</span>
                                <span class="n">kind</span><span class="o">=</span><span class="n">OutputKind</span><span class="o">.</span><span class="n">USER_OUTPUT</span><span class="p">,</span>
                                <span class="n">arg</span><span class="o">=</span><span class="n">ConstantArgument</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">output_node</span><span class="p">),</span>
                                <span class="n">target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="p">)</span>
                        <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">output_specs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                            <span class="n">OutputSpec</span><span class="p">(</span>
                                <span class="n">kind</span><span class="o">=</span><span class="n">OutputKind</span><span class="o">.</span><span class="n">USER_OUTPUT</span><span class="p">,</span>
                                <span class="n">arg</span><span class="o">=</span><span class="n">TensorArgument</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">output_node</span><span class="o">.</span><span class="n">name</span><span class="p">),</span>
                                <span class="n">target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="p">)</span>
                        <span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># We are reconstruting the toplevel module which contains</span>
                <span class="c1"># delegates. Delegation should not change the number of outputs</span>
                <span class="c1"># in the toplevel module, and it does not touch the mutated buffers</span>

                <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">old_signature</span><span class="o">.</span><span class="n">output_specs</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_nodes</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">prev_output_spec</span><span class="p">,</span> <span class="n">output_node</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                    <span class="n">old_signature</span><span class="o">.</span><span class="n">output_specs</span><span class="p">,</span> <span class="n">output_nodes</span>
                <span class="p">):</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_node</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">Node</span><span class="p">):</span>
                        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prev_output_spec</span><span class="o">.</span><span class="n">arg</span><span class="p">,</span> <span class="n">ConstantArgument</span><span class="p">)</span>
                        <span class="n">output_specs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                            <span class="n">OutputSpec</span><span class="p">(</span>
                                <span class="n">kind</span><span class="o">=</span><span class="n">OutputKind</span><span class="o">.</span><span class="n">USER_OUTPUT</span><span class="p">,</span>
                                <span class="n">arg</span><span class="o">=</span><span class="n">ConstantArgument</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">output_node</span><span class="p">),</span>
                                <span class="n">target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="p">)</span>
                        <span class="p">)</span>

                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">new_output_spec</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">prev_output_spec</span><span class="p">)</span>
                        <span class="n">new_output_spec</span><span class="o">.</span><span class="n">arg</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">output_node</span><span class="o">.</span><span class="n">name</span>
                        <span class="n">output_specs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_output_spec</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">new_signature</span><span class="p">,</span> <span class="n">new_state_dict</span><span class="p">,</span> <span class="n">new_constants</span>


<span class="k">def</span> <span class="nf">create_exported_program_from_submodule</span><span class="p">(</span>
    <span class="n">submodule</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">,</span>
    <span class="n">owning_program</span><span class="p">:</span> <span class="n">ExportedProgram</span><span class="p">,</span>
    <span class="n">tag</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ExportedProgram</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates an ExportedProgram from the given submodule using the parameters and buffers</span>
<span class="sd">    from the top-level owning program</span>

<span class="sd">    Args:</span>
<span class="sd">        submodule: submodule to create and exported program from</span>
<span class="sd">        owning_program: exported program containing the parameters and buffers used within</span>
<span class="sd">            the submodule</span>

<span class="sd">    Returns:</span>
<span class="sd">        The ExportedProgram created from submodule</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Arrange the submodule&#39;s placeholders in order</span>
    <span class="n">submodule</span> <span class="o">=</span> <span class="n">arrange_graph_placeholders</span><span class="p">(</span><span class="n">submodule</span><span class="p">,</span> <span class="n">owning_program</span><span class="p">)</span>

    <span class="c1"># Get updated graph signature</span>
    <span class="n">subgraph_signature</span><span class="p">,</span> <span class="n">subgraph_state_dict</span><span class="p">,</span> <span class="n">subgraph_constants</span> <span class="o">=</span> <span class="n">_get_new_signature</span><span class="p">(</span>
        <span class="n">owning_program</span><span class="p">,</span> <span class="n">submodule</span><span class="p">,</span> <span class="n">tag</span>
    <span class="p">)</span>

    <span class="n">in_spec</span> <span class="o">=</span> <span class="n">pytree</span><span class="o">.</span><span class="n">tree_flatten</span><span class="p">((</span><span class="nb">tuple</span><span class="p">(</span><span class="n">subgraph_signature</span><span class="o">.</span><span class="n">user_inputs</span><span class="p">),</span> <span class="p">{}))[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">out_spec</span> <span class="o">=</span> <span class="n">pytree</span><span class="o">.</span><span class="n">tree_flatten</span><span class="p">(</span><span class="n">subgraph_signature</span><span class="o">.</span><span class="n">user_outputs</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">ExportedProgram</span><span class="p">(</span>
        <span class="n">root</span><span class="o">=</span><span class="n">submodule</span><span class="p">,</span>
        <span class="n">graph</span><span class="o">=</span><span class="n">submodule</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span>
        <span class="n">graph_signature</span><span class="o">=</span><span class="n">subgraph_signature</span><span class="p">,</span>
        <span class="n">state_dict</span><span class="o">=</span><span class="n">subgraph_state_dict</span><span class="p">,</span>
        <span class="n">range_constraints</span><span class="o">=</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">owning_program</span><span class="o">.</span><span class="n">range_constraints</span><span class="p">),</span>
        <span class="n">module_call_graph</span><span class="o">=</span><span class="p">[</span>
            <span class="n">ModuleCallEntry</span><span class="p">(</span>
                <span class="s2">&quot;&quot;</span><span class="p">,</span>
                <span class="n">ModuleCallSignature</span><span class="p">(</span>
                    <span class="n">inputs</span><span class="o">=</span><span class="p">[],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[],</span> <span class="n">in_spec</span><span class="o">=</span><span class="n">in_spec</span><span class="p">,</span> <span class="n">out_spec</span><span class="o">=</span><span class="n">out_spec</span>
                <span class="p">),</span>
            <span class="p">)</span>
        <span class="p">],</span>
        <span class="n">verifier</span><span class="o">=</span><span class="n">owning_program</span><span class="o">.</span><span class="n">verifier</span><span class="p">,</span>
        <span class="n">constants</span><span class="o">=</span><span class="n">subgraph_constants</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">create_submodule_from_nodes</span><span class="p">(</span>
    <span class="n">gm</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">,</span>
    <span class="n">node_list</span><span class="p">:</span> <span class="n">NodeList</span><span class="p">,</span>
    <span class="n">tag</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">skip_legalize_graph</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">Node</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Modifies the given graph module in-place to separate out the given nodes</span>
<span class="sd">    into a submodule. The given node_list should form a fully connected</span>
<span class="sd">    subgraph.</span>

<span class="sd">    Args:</span>
<span class="sd">        gm: The graph module that we want to partition</span>
<span class="sd">        node_list: A list of nodes that belong in the partition</span>

<span class="sd">    Returns:</span>
<span class="sd">        The submodule that has been partitioned, the call_module node in the</span>
<span class="sd">        toplevel graph module calling the submodule</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sorted_nodes</span> <span class="o">=</span> <span class="n">topo_sort</span><span class="p">(</span><span class="n">node_list</span><span class="p">)</span>

    <span class="n">submodule_name</span> <span class="o">=</span> <span class="s2">&quot;fused_&quot;</span> <span class="o">+</span> <span class="n">tag</span>
    <span class="n">sub_gm</span><span class="p">,</span> <span class="n">orig_inputs</span><span class="p">,</span> <span class="n">orig_outputs</span> <span class="o">=</span> <span class="n">fuse_as_graphmodule</span><span class="p">(</span>
        <span class="n">gm</span><span class="p">,</span> <span class="n">sorted_nodes</span><span class="p">,</span> <span class="n">submodule_name</span>
    <span class="p">)</span>

    <span class="n">_fixup_output_node</span><span class="p">(</span><span class="n">sub_gm</span><span class="p">)</span>

    <span class="n">gm</span> <span class="o">=</span> <span class="n">insert_subgm</span><span class="p">(</span><span class="n">gm</span><span class="p">,</span> <span class="n">sub_gm</span><span class="p">,</span> <span class="n">orig_inputs</span><span class="p">,</span> <span class="n">orig_outputs</span><span class="p">)</span>
    <span class="n">submodule_node</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">gm</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;call_module&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">target</span> <span class="o">==</span> <span class="n">submodule_name</span><span class="p">:</span>
                <span class="n">submodule_node</span> <span class="o">=</span> <span class="n">node</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The submodule created with nodes </span><span class="si">{</span><span class="n">node_list</span><span class="si">}</span><span class="s2"> did not form </span><span class="se">\</span>
<span class="s2">                    one fully contained subgraph. Check that these nodes form a </span><span class="se">\</span>
<span class="s2">                    fully contained graph. Partitioned graph: </span><span class="si">{</span><span class="n">gm</span><span class="o">.</span><span class="n">graph</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">orig_outputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">orig_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s2">&quot;val&quot;</span><span class="p">],</span> <span class="n">FakeTensor</span><span class="p">):</span>
        <span class="c1"># If the original output is a single tensor, it has been</span>
        <span class="c1"># pytree.tree_flatten-ed to be a singleton list, so we want to replace</span>
        <span class="c1"># all uses with a getitem call to the 0th index of the result</span>
        <span class="k">with</span> <span class="n">gm</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">inserting_after</span><span class="p">(</span><span class="n">submodule_node</span><span class="p">):</span>
            <span class="n">proxy_out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">Proxy</span><span class="p">(</span><span class="n">submodule_node</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">node</span>  <span class="c1"># type: ignore[index]</span>
            <span class="n">submodule_node</span><span class="o">.</span><span class="n">replace_all_uses_with</span><span class="p">(</span><span class="n">proxy_out</span><span class="p">)</span>
            <span class="n">proxy_out</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s2">&quot;val&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">submodule_node</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s2">&quot;val&quot;</span><span class="p">]</span>
            <span class="c1"># Reset the args since it was overwritten in the previous line</span>
            <span class="n">proxy_out</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="n">submodule_node</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># fuse_as_graphmodule will automatically propagate the metadata of the</span>
        <span class="c1"># partition&#39;s last node to the getitem nodes that appear after the</span>
        <span class="c1"># call_module node. However, in the case of delegation we do not want</span>
        <span class="c1"># these getitem nodes to contain irrelevant previous metadata</span>
        <span class="c1"># (ex. source_fn, # nn_module_stack)</span>
        <span class="k">for</span> <span class="n">user_node</span> <span class="ow">in</span> <span class="n">submodule_node</span><span class="o">.</span><span class="n">users</span><span class="p">:</span>
            <span class="n">user_node</span><span class="o">.</span><span class="n">meta</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;nn_module_stack&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">user_node</span><span class="o">.</span><span class="n">meta</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;source_fn_stack&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="n">erase_nodes</span><span class="p">(</span><span class="n">gm</span><span class="p">,</span> <span class="n">sorted_nodes</span><span class="p">)</span>

    <span class="c1"># Topological sort original gm with newly created sub_gm</span>
    <span class="c1"># TODO : T153794167 Get rid of support for skipping legalize graph in create_submodule_from_nodes</span>
    <span class="c1"># once we transition to using fuse_by_partitions.</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">skip_legalize_graph</span><span class="p">:</span>
        <span class="n">legalize_graph</span><span class="p">(</span><span class="n">gm</span><span class="p">)</span>

    <span class="c1"># Get the call_module node</span>
    <span class="n">submodule_node</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">gm</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;call_module&quot;</span> <span class="ow">and</span> <span class="n">node</span><span class="o">.</span><span class="n">target</span> <span class="o">==</span> <span class="n">submodule_name</span><span class="p">:</span>
            <span class="n">submodule_node</span> <span class="o">=</span> <span class="n">node</span>
        <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;call_module&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The submodule created with nodes </span><span class="si">{</span><span class="n">node_list</span><span class="si">}</span><span class="s2"> did not form </span><span class="se">\</span>
<span class="s2">                one fully contained subgraph. Check that these nodes form a </span><span class="se">\</span>
<span class="s2">                fully contained graph. Partitioned graph: </span><span class="si">{</span><span class="n">gm</span><span class="o">.</span><span class="n">graph</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

    <span class="k">assert</span> <span class="p">(</span>
        <span class="n">submodule_node</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;No submodule was created with the nodes </span><span class="si">{</span><span class="n">node_list</span><span class="si">}</span><span class="s2"> in the graph </span><span class="si">{</span><span class="n">gm</span><span class="o">.</span><span class="n">graph</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="k">return</span> <span class="n">sub_gm</span><span class="p">,</span> <span class="n">submodule_node</span>


<span class="k">def</span> <span class="nf">get_lowered_submodules</span><span class="p">(</span>
    <span class="n">graph_module</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">LoweredBackendModule</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">Node</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a list of lowered modules that are in the given graph (does not look</span>
<span class="sd">    into submodules). Specifically, the returned value is a list containing a</span>
<span class="sd">    tuple of (name of the lowered module that&#39;s stored in the graph module, the</span>
<span class="sd">    lowered module itself, and the fx node that called this lowered module).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">lowered_submodules</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">graph_module</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;call_function&quot;</span> <span class="ow">and</span> <span class="n">node</span><span class="o">.</span><span class="n">target</span> <span class="o">==</span> <span class="n">executorch_call_delegate</span><span class="p">:</span>
            <span class="n">name</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="n">node</span> <span class="o">=</span> <span class="n">_get_submodule</span><span class="p">(</span><span class="n">graph_module</span><span class="p">,</span> <span class="n">node</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">LoweredBackendModule</span><span class="p">)</span>
            <span class="n">lowered_submodules</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">name</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="n">node</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">lowered_submodules</span>


<span class="k">def</span> <span class="nf">get_lowered_backend_modules</span><span class="p">(</span>
    <span class="n">graph_module</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">LoweredBackendModule</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a list of exported programs which were lowered by backen delegates</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">lowered_programs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">graph_module</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;call_function&quot;</span> <span class="ow">and</span> <span class="n">node</span><span class="o">.</span><span class="n">target</span> <span class="o">==</span> <span class="n">executorch_call_delegate</span><span class="p">:</span>
            <span class="n">lowered_backend_module</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">graph_module</span><span class="p">,</span> <span class="n">node</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
            <span class="n">lowered_programs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lowered_backend_module</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">lowered_programs</span>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2024, ExecuTorch.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>


        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
         <script src="../../../_static/jquery.js"></script>
         <script src="../../../_static/underscore.js"></script>
         <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../_static/doctools.js"></script>
         <script src="../../../_static/sphinx_highlight.js"></script>
         <script src="../../../_static/clipboard.min.js"></script>
         <script src="../../../_static/copybutton.js"></script>
         <script src="../../../_static/design-tabs.js"></script>
         <script src="../../../_static/js/progress-bar.js"></script>
     

  

  <script type="text/javascript" src="../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(false);
      });
  </script>
 
<script script type="text/javascript">
  var collapsedSections = ['Introduction', 'Getting Started', 'Working with LLMs', 'Exporting to ExecuTorch',  'API Reference', 'IR Specification', 'Compiler Entry Points', 'Runtime', 'Quantization', 'Kernel Library', 'Native Delegates', 'Backend Delegates', 'SDK', 'Tutorials']
</script>

 
<script type="text/javascript">
// Handle the right navigation in third level pages. Without this
// in third level, only the last item always selected. This is a hacky
// way and we should revise it eventually.
// #side-scroll-highlight is disabled in .css.
// Get all menu items
var menuItems = document.querySelectorAll('.pytorch-right-menu a.reference.internal');
// Add a click event listener to each menu item
for (var i = 0; i < menuItems.length; i++) {
  menuItems[i].addEventListener('click', function(event) {
    // Remove the 'side-scroll-highlight-local' class from all menu items
    for (var j = 0; j < menuItems.length; j++) {
      menuItems[j].classList.remove('side-scroll-highlight-local');
    }
    // Add the 'side-scroll-highlight-local' class to the clicked item
    event.target.classList.add('side-scroll-highlight-local');
  });
}
</script>

 
<script type="text/javascript">
  $(document).ready(function () {
    // Patch links on interactive tutorial pages to point
    // to the correct ExecuTorch URLs.
    var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
    if (downloadNote.length >= 1) {
      var tutorialUrl = $("#tutorial-type").text().substring($("#tutorial-type").text().indexOf("tutorials/") + 9); // 9 is the length of "tutorials/"
      var githubLink = "https://github.com/pytorch/executorch/blob/main/docs/source/tutorials_source" + tutorialUrl + ".py",
        notebookLink = $(".reference.download")[1].href,
        notebookDownloadPath = notebookLink.split('_downloads')[1],
        colabLink = "https://colab.research.google.com/github/pytorch/executorch/blob/gh-pages/main/_downloads" + notebookDownloadPath;

      $(".pytorch-call-to-action-links a[data-response='Run in Google Colab']").attr("href", colabLink);
      $(".pytorch-call-to-action-links a[data-response='View on Github']").attr("href", githubLink);
    }

    // Patch the "GitHub" link at the top of the page
    // to point to the ExecuTorch repo.
    var overwrite = function (_) {
      if ($(this).length > 0) {
        $(this)[0].href = "https://github.com/pytorch/executorch"
      }
    }
    // PC
    $(".main-menu a:contains('GitHub')").each(overwrite);
    // Overwrite link to Tutorials and Get Started top navigation. If these sections are moved
    // this overrides need to be updated.
    $(".main-menu a:contains('Tutorials')").attr("href", "https://pytorch.org/executorch/stable/index.html#tutorials-and-examples");
    $(".main-menu a:contains('Get Started')").attr("href", "https://pytorch.org/executorch/stable/getting-started-setup.html");
    // Mobile
    $(".mobile-menu a:contains('Github')").each(overwrite);
    // Overwrite link to Tutorials and Get Started top navigation. If these sections are moved
    // this overrides need to be updated.
    $(".mobile-menu a:contains('Tutorials')").attr("href", "https://pytorch.org/executorch/stable/index.html#tutorials-and-examples");
    $(".mobile-menu a:contains('Get Started')").attr("href", "https://pytorch.org/executorch/stable/getting-started-setup.html");

  });
</script>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
           <li class="resources-mobile-menu-title">
             <a>Learn</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/get-started">Get Started</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials">Tutorials</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
             </li>
           </ul>
           <li class="resources-mobile-menu-title">
             <a>Ecosystem</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/ecosystem">Tools</a>
             </li>
             <li>
               <a href="https://pytorch.org/#community-module">Community</a>
             </li>
             <li>
               <a href="https://discuss.pytorch.org/">Forums</a>
             </li>
             <li>
               <a href="https://pytorch.org/resources">Developer Resources</a>
             </li>
             <li>
               <a href="https://pytorch.org/ecosystem/contributor-awards-2023">Contributor Awards - 2023</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Edge</a>
           </li>

           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/edge">About PyTorch Edge</a>
             </li>
             
             <li>
               <a href="https://pytorch.org/executorch-overview">ExecuTorch</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Docs</a>
           </li>

           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/pytorch-domains">PyTorch Domains</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            <a>Blog & News</a>
          </li>
            
           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/blog/">PyTorch Blog</a>
            </li>
            <li>
              <a href="https://pytorch.org/community-blog">Community Blog</a>
            </li>

            <li>
              <a href="https://pytorch.org/videos">Videos</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>
            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>
          </ul>
          
          <li class="resources-mobile-menu-title">
            <a>About</a>
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>
            <li>
              <a href="https://pytorch.org/governing-board">Governing Board</a>
            </li>
          </ul>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>