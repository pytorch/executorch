
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
  <meta name="robots" content="noindex">
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Cadence Xtensa Backend &#8212; ExecuTorch main documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=047068a3" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=a8da1a53"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'embedded-cadence';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.15.4';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://docs.pytorch.org/executorch/executorch-versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'main';
        DOCUMENTATION_OPTIONS.show_version_warning_banner = true;
        </script>
    <link rel="canonical" href="https://docs.pytorch.org/executorch/embedded-cadence.html" />
    <link rel="icon" href="_static/executorch-chip-logo.svg"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="&lt;no title&gt;" href="embedded-arm-ethos-u.html" />
    <link rel="prev" title="Backends" href="embedded-backends.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->


<link rel="stylesheet" type="text/css" href="_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="_static/js/theme.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="https://docs.pytorch.org/docs/stable/_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy"
  content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" height="0" width="0"
    style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'GTM-T8XT4PS');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'main');
</script>
<noscript>
  <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1" />
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Repository configuration for tutorials -->

<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>

  </head>

<body data-feedback-url="https://github.com/pytorch/executorch" class="pytorch-body">
  
    <div class="container-fluid header-holder tutorials-header" id="header-holder">
   <div class="header-container-wrapper">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                <span>Learn</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started/locally">
                  <span class=dropdown-title>Get Started</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/webinars/">
                  <span class="dropdown-title">Webinars</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Community</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Landscape</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/join-ecosystem">
                  <span class="dropdown-title">Join the Ecosystem</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-hub/">
                  <span class="dropdown-title">Community Hub</span>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/">
                  <span class="dropdown-title">Forums</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contributor-awards/">
                  <span class="dropdown-title">Contributor Awards</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-events/">
                  <span class="dropdown-title">Community Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/programs/ambassadors/">
                  <span class="dropdown-title">PyTorch Ambassadors</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Projects</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/pytorch/">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/vllm/">
                  <span class="dropdown-title">vLLM</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/deepspeed/">
                  <span class="dropdown-title">DeepSpeed</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/host-your-project/">
                  <span class="dropdown-title">Host Your Project</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/ray/">
                  <span class="dropdown-title">RAY</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span> Docs</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/domains">
                  <span class="dropdown-title">Domains</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Blogs & News</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">Blog</span>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/announcements">
                  <span class="dropdown-title">Announcements</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/case-studies/">
                  <span class="dropdown-title">Case Studies</span>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                </a>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>About</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/members">
                  <span class="dropdown-title">Members</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact">
                  <span class="dropdown-title">Contact</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/wp-content/uploads/2025/09/pytorch_brand_guide_091925a.pdf">
                  <span class="dropdown-title">Brand Guidelines</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown main-menu-button">
              <a href="https://pytorch.org/join" data-cta="join">
                JOIN
              </a>
            </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu">
        <i class="fa-solid fa-ellipsis"></i>
      </a>
    </div>
  </div>
 </div>

 <!-- Begin Mobile Menu -->

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="header-container-wrapper">
      <div class="mobile-main-menu-header-container">
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu">
        </a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">
    <div class="main-menu">
      <ul>
         <li class="resources-mobile-menu-title">
           <a>Learn</a>
         </li>
         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/get-started/locally">Get Started</a>
           </li>
           <li>
             <a href="https://docs.pytorch.org/tutorials">Tutorials</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
           </li>
           <li>
            <a href="https://pytorch.org/webinars/">Webinars</a>
          </li>
        </ul>
         <li class="resources-mobile-menu-title">
           <a>Community</a>
         </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://landscape.pytorch.org/">Landscape</a>
          </li>
          <li>
             <a href="https://pytorch.org/join-ecosystem">Join the Ecosystem</a>
           </li>
           <li>
             <a href="https://pytorch.org/community-hub/">Community Hub</a>
           </li>
           <li>
             <a href="https://discuss.pytorch.org/">Forums</a>
           </li>
           <li>
             <a href="https://pytorch.org/resources">Developer Resources</a>
           </li>
           <li>
             <a href="https://pytorch.org/contributor-awards/">Contributor Awards</a>
           </li>
           <li>
            <a href="https://pytorch.org/community-events/">Community Events</a>
          </li>
          <li>
            <a href="https://pytorch.org/programs/ambassadors/">PyTorch Ambassadors</a>
          </li>
       </ul>

         <li class="resources-mobile-menu-title">
           <a>Projects</a>
         </li>

         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/projects/pytorch/">PyTorch</a>
           </li>

           <li>
             <a href="https://pytorch.org/projects/vllm/">vLLM</a>
           </li>
           <li>
            <a href="https://pytorch.org/projects/deepspeed/">DeepSpeed</a>
          </li>
          <li>
             <a href="https://pytorch.org/projects/host-your-project/">Host Your Project</a>
           </li>
         </ul>

         <li class="resources-mobile-menu-title">
           <a>Docs</a>
         </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://docs.pytorch.org/docs/stable/index.html">PyTorch</a>
          </li>

          <li>
            <a href="https://pytorch.org/domains">Domains</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>Blog & News</a>
        </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>
          <li>
            <a href="https://pytorch.org/announcements">Announcements</a>
          </li>

          <li>
            <a href="https://pytorch.org/case-studies/">Case Studies</a>
          </li>
          <li>
            <a href="https://pytorch.org/events">Events</a>
          </li>
          <li>
             <a href="https://pytorch.org/newsletter">Newsletter</a>
           </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>About</a>
        </li>

        <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
          </li>
          <li>
            <a href="https://pytorch.org/members">Members</a>
          </li>
          <li>
            <a href="https://pytorch.org/governing-board">Governing Board</a>
          </li>
          <li>
            <a href="https://pytorch.org/tac">Technical Advisory Council</a>
         </li>
         <li>
             <a href="https://pytorch.org/credits">Cloud Credit Program</a>
          </li>
          <li>
             <a href="https://pytorch.org/staff">Staff</a>
          </li>
          <li>
             <a href="https://pytorch.org/contact">Contact</a>
          </li>
        </ul>
      </ul>
    </div>
  </div>
</div>

<!-- End Mobile Menu -->
  
  
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/et-logo.png" class="logo__image only-light" alt="ExecuTorch main documentation - Home"/>
    <script>document.write(`<img src="_static/et-logo.png" class="logo__image only-dark" alt="ExecuTorch main documentation - Home"/>`);</script>
  
  
</a></div>
    
      <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-2"
      type="button"
      class="version-switcher__button btn btn-sm dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-2"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-2"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-2">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="intro-section.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="quick-start-section.html">
    Quick Start
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="edge-platforms-section.html">
    Edge
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="backends-section.html">
    Backends
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="llm/working-with-llms.html">
    LLMs
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="advanced-topics-section.html">
    Advanced
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="tools-section.html">
    Tools
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="api-section.html">
    API
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="support-section.html">
    Support
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/executorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/executorch" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="intro-section.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="quick-start-section.html">
    Quick Start
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="edge-platforms-section.html">
    Edge
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="backends-section.html">
    Backends
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="llm/working-with-llms.html">
    LLMs
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="advanced-topics-section.html">
    Advanced
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="tools-section.html">
    Tools
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="api-section.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="support-section.html">
    Support
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/executorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/executorch" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Edge Platforms</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="android-section.html">Android</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="using-executorch-android.html">Using ExecuTorch on Android</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="android-backends.html">Backends</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="android-xnnpack.html">XNNPACK Backend</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="android-vulkan.html">Vulkan Backend</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="android-qualcomm.html">Qualcomm AI Engine Backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="android-mediatek.html">MediaTek Backend</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="android-arm-vgf.html">Arm VGF Backend</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="backends/samsung/samsung-overview.html">Samsung Exynos Backend</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="backends/samsung/samsung-partitioner.html">Partitioner API</a></li>
<li class="toctree-l4"><a class="reference internal" href="backends/samsung/samsung-quantization.html">Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="backends/samsung/samsung-op-support.html">Operator Support</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="android-examples.html">Examples &amp; Demos</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="backends/arm-vgf/tutorials/arm-vgf-tutorials.html">Arm VGF Backend Tutorials</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="backends/arm-vgf/tutorials/vgf-getting-started.html">Getting Started Tutorial</a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="ios-section.html">iOS</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="using-executorch-ios.html">Using ExecuTorch on iOS</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="ios-backends.html">Backends</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="ios-coreml.html">Core ML Backend</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="ios-mps.html">MPS Backend</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="ios-xnnpack.html">XNNPACK Backend</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="ios-examples.html">Examples &amp; Demos</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="desktop-section.html">Desktop &amp; Laptop Platforms</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="using-executorch-cpp.html">Using ExecuTorch with C++</a></li>
<li class="toctree-l2"><a class="reference internal" href="using-executorch-building-from-source.html">Building from Source</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="desktop-backends.html">Backends</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="desktop-xnnpack.html">XNNPACK Backend</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="desktop-openvino.html">Building and Running ExecuTorch with OpenVINO Backend</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="raspberry_pi_llama_tutorial.html">ExecuTorch on Raspberry Pi</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="embedded-section.html">Embedded Systems</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="executorch-runtime-api-reference.html">Runtime API Reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="running-a-model-cpp-tutorial.html">Detailed C++ Runtime APIs Tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="extension-module.html">Running an ExecuTorch Model Using the Module Extension in C++</a></li>
<li class="toctree-l2"><a class="reference internal" href="extension-tensor.html">Managing Tensor Memory in C++</a></li>
<li class="toctree-l2"><a class="reference internal" href="using-executorch-cpp.html">Using ExecuTorch with C++</a></li>
<li class="toctree-l2"><a class="reference internal" href="using-executorch-building-from-source.html">Building from Source</a></li>
<li class="toctree-l2 current active has-children"><a class="reference internal" href="embedded-backends.html">Backends</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l3 current active"><a class="current reference internal" href="#">Cadence Xtensa Backend</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="embedded-nxp.html">NXP eIQ Neutron Backend</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="raspberry_pi_llama_tutorial.html">ExecuTorch on Raspberry Pi</a></li>
<li class="toctree-l2"><a class="reference internal" href="pico2_tutorial.html">Pico2: A simple MNIST Tutorial</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="using-executorch-troubleshooting.html">Profiling and Debugging</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">





<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="edge-platforms-section.html" class="nav-link">Edge</a></li>
    
    
    <li class="breadcrumb-item"><i class="fa-solid fa-ellipsis"></i></li>
    
    
    <li class="breadcrumb-item"><a href="embedded-backends.html" class="nav-link">Backends</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Cadence...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
  
<div id="searchbox"></div>
  <article class="bd-article" id="pytorch-article">
    <!-- Hidden breadcrumb schema for SEO only -->
    <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <link itemprop="item" href="edge-platforms-section.html">
        <meta itemprop="name" content="Edge">
        <meta itemprop="position" content="1">
      </div>
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <link itemprop="item" href="embedded-section.html">
        <meta itemprop="name" content="Embedded Systems">
        <meta itemprop="position" content="2">
      </div>
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <link itemprop="item" href="embedded-backends.html">
        <meta itemprop="name" content="Backends">
        <meta itemprop="position" content="3">
      </div>
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <meta itemprop="name" content="Cadence Xtensa Backend">
        <meta itemprop="position" content="4">
      </div>
    </div>

    
    

    
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="cadence-xtensa-backend">
<h1>Cadence Xtensa Backend<a class="headerlink" href="#cadence-xtensa-backend" title="Link to this heading">#</a></h1>
<p>In this tutorial we will walk you through the process of getting setup to build ExecuTorch for Cadence Xtensa DSPs and running models on them.</p>
<p><a class="reference external" href="https://www.cadence.com/en_US/home.html">Cadence</a> is both a hardware and software vendor, providing solutions for many computational workloads, including to run on power-limited embedded devices. The Cadence backend supports multiple DSP families optimized for different workloads:</p>
<ul class="simple">
<li><p><strong>HiFi Audio DSPs</strong> (HiFi4/HiFi5): Optimized for audio processing, speech recognition, and wake word detection</p></li>
<li><p><strong>Fusion G3 DSPs</strong>: General-purpose AI acceleration</p></li>
<li><p><strong>Vision P-Series DSPs</strong>: Specialized for computer vision and CNN workloads</p></li>
</ul>
<p>In addition to the chip, the HiFi4 Neural Network Library (<a class="reference external" href="https://github.com/foss-xtensa/nnlib-hifi4">nnlib</a>) offers an optimized set of library functions commonly used in NN processing that we utilize in this example to demonstrate how common operations can be accelerated.</p>
<p>For an overview of the Cadence ExecuTorch integration with performance benchmarks, see the blog post: <a class="reference external" href="https://community.cadence.com/cadence_blogs_8/b/ip/posts/running-optimized-pytorch-models-on-cadence-dsps-with-executorch">Running Optimized PyTorch Models on Cadence DSPs with ExecuTorch</a>.</p>
<p>On top of being able to run on the Xtensa HiFi4 DSP, another goal of this tutorial is to demonstrate how portable ExecuTorch is and its ability to run on a low-power embedded device such as the Xtensa HiFi4 DSP. This workflow does not require any delegates, it uses custom operators and compiler passes to enhance the model and make it more suitable to running on Xtensa HiFi4 DSPs. A custom <a class="reference external" href="https://pytorch.org/tutorials/prototype/quantization_in_pytorch_2_0_export_tutorial.html">quantizer</a> is used to represent activations and weights as <code class="docutils literal notranslate"><span class="pre">uint8</span></code> instead of <code class="docutils literal notranslate"><span class="pre">float</span></code>, and call appropriate operators. Finally, custom kernels optimized with Xtensa intrinsics provide runtime acceleration.</p>
<div class="sd-container-fluid sd-sphinx-override sd-mb-4 docutils">
<div class="sd-row sd-row-cols-2 sd-row-cols-xs-2 sd-row-cols-sm-2 sd-row-cols-md-2 sd-row-cols-lg-2 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm card-prerequisites docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
What you will learn in this tutorial:</div>
<ul class="simple">
<li><p class="sd-card-text">In this tutorial you will learn how to export a quantized model with a linear operation targeted for the Xtensa HiFi4 DSP.</p></li>
<li><p class="sd-card-text">You will also learn how to compile and deploy the ExecuTorch runtime with the kernels required for running the quantized model generated in the previous step on the Xtensa HiFi4 DSP.</p></li>
</ul>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm card-prerequisites docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Tutorials we recommend you complete before this:</div>
<ul class="simple">
<li><p class="sd-card-text"><a class="reference internal" href="intro-how-it-works.html"><span class="std std-doc">Introduction to ExecuTorch</span></a></p></li>
<li><p class="sd-card-text"><a class="reference internal" href="getting-started.html"><span class="std std-doc">Getting Started</span></a></p></li>
<li><p class="sd-card-text"><a class="reference internal" href="using-executorch-building-from-source.html"><span class="std std-doc">Building ExecuTorch with CMake</span></a></p></li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The linux part of this tutorial has been designed and tested on Ubuntu 22.04 LTS, and requires glibc 2.34. Workarounds are available for other distributions, but will not be covered in this tutorial.</p>
</div>
<section id="prerequisites-hardware-and-software">
<h2>Prerequisites (Hardware and Software)<a class="headerlink" href="#prerequisites-hardware-and-software" title="Link to this heading">#</a></h2>
<p>In order to be able to succesfully build and run ExecuTorch on a Xtensa HiFi4 DSP you’ll need the following hardware and software components.</p>
<section id="hardware">
<h3>Hardware<a class="headerlink" href="#hardware" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://www.nxp.com/design/development-boards/i-mx-evaluation-and-development-boards/i-mx-rt600-evaluation-kit:MIMXRT685-EVK">i.MX RT600 Evaluation Kit</a></p></li>
</ul>
</section>
<section id="software">
<h3>Software<a class="headerlink" href="#software" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>x86-64 Linux system (For compiling the DSP binaries)</p></li>
<li><p><a class="reference external" href="https://www.nxp.com/design/software/development-software/mcuxpresso-software-and-tools-/mcuxpresso-integrated-development-environment-ide:MCUXpresso-IDE">MCUXpresso IDE</a></p>
<ul>
<li><p>This IDE is supported on multiple platforms including MacOS. You can use it on any of the supported platforms as you’ll only be using this to flash the board with the DSP images that you’ll be building later on in this tutorial.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://www.segger.com/downloads/jlink/">J-Link</a></p>
<ul>
<li><p>Needed to flash the board with the firmware images. You can install this on the same platform that you installed the MCUXpresso IDE on.</p></li>
<li><p>Note: depending on the version of the NXP board, another probe than JLink might be installed. In any case, flashing is done using the MCUXpresso IDE in a similar way.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://mcuxpresso.nxp.com/en/select?device=EVK-MIMXRT685">MCUXpresso SDK</a></p>
<ul>
<li><p>Download this SDK to your Linux machine, extract it and take a note of the path where you store it. You’ll need this later.</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://tensilicatools.com/platform/i-mx-rt600/">Xtensa compiler</a></p>
<ul>
<li><p>Download this to your Linux machine. This is needed to build ExecuTorch for the HiFi4 DSP.</p></li>
</ul>
</li>
<li><p>For cases with optimized kernels, the <a class="reference external" href="https://github.com/foss-xtensa/nnlib-hifi4">nnlib repo</a>.</p></li>
</ul>
</section>
</section>
<section id="setting-up-developer-environment">
<h2>Setting up Developer Environment<a class="headerlink" href="#setting-up-developer-environment" title="Link to this heading">#</a></h2>
<p>Step 1. In order to be able to successfully install all the software components specified above users will need to go through the NXP tutorial linked below. Although the tutorial itself walks through a Windows setup, most of the steps translate over to a Linux installation too.</p>
<p><a class="reference external" href="https://www.nxp.com/document/guide/getting-started-with-i-mx-rt600-evaluation-kit:GS-MIMXRT685-EVK?section=plug-it-in">NXP tutorial on setting up the board and dev environment</a></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Before proceeding forward to the next section users should be able to succesfullly flash the <strong>dsp_mu_polling_cm33</strong> sample application from the tutorial above and notice output on the UART console indicating that the Cortex-M33 and HiFi4 DSP are talking to each other.</p>
</div>
<p>Step 2. Make sure you have completed the ExecuTorch setup tutorials linked to at the top of this page.</p>
</section>
<section id="working-tree-description">
<h2>Working Tree Description<a class="headerlink" href="#working-tree-description" title="Link to this heading">#</a></h2>
<p>The working tree is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>executorch
├── backends
│   └── cadence
│       ├── aot                      # Ahead-of-Time compilation tools
│       │   ├── compiler.py         # Main compilation API
│       │   ├── export_example.py   # Export workflow example
│       │   ├── quantizer/          # Quantization infrastructure
│       │   │   ├── quantizer.py    # Multiple quantizer implementations
│       │   │   ├── patterns.py     # Quantization patterns
│       │   │   └── fusion_pass.py  # Op fusion pass
│       │   ├── passes.py           # Graph optimization passes
│       │   ├── functions.yaml      # Generic operator definitions
│       │   ├── functions_hifi.yaml # HiFi-specific definitions
│       │   ├── functions_fusion_g3.yaml # Fusion G3 definitions
│       │   └── functions_vision.yaml # Vision-specific definitions
│       ├── runtime/                # Runtime execution infrastructure
│       ├── utils/                  # Build utilities (FACTO, header gen)
│       ├── hifi/                   # HiFi Audio DSP family (70+ ops)
│       │   ├── kernels            # Optimized HiFi4/HiFi5 kernels
│       │   ├── operators          # HiFi operator implementations
│       │   └── third-party
│       │       └── nnlib          # Cadence NNLIB integration
│       ├── fusion_g3/             # Fusion G3 DSP family (25+ ops)
│       │   ├── kernels
│       │   ├── operators
│       │   └── third-party
│       │       └── nnlib
│       ├── vision/                # Vision P-Series DSP family (17+ ops)
│       │   ├── kernels
│       │   ├── operators
│       │   └── third-party        # Vision-specific library
│       └── generic/               # Generic fallback implementations (15+ ops)
│           └── operators
└── examples
    └── cadence
        ├── models                 # 9 example models
        │   ├── rnnt_encoder.py   # ASR encoder (ConvEmformer)
        │   ├── rnnt_predictor.py # ASR predictor
        │   ├── rnnt_joiner.py    # ASR joiner
        │   ├── wav2vec2.py       # Self-supervised speech
        │   ├── mobilenet_v2.py   # Image classification
        │   ├── resnet18.py       # Image classification
        │   ├── resnet50.py       # Image classification
        │   ├── vision_transformer.py # ViT
        │   └── babyllama.py      # Small LLM
        └── operators             # Operator test examples
            ├── test_add_op.py    # Add operation tests
            ├── test_quantized_linear_op.py
            ├── test_quantized_conv1d_op.py
            ├── test_requantize_op.py
            └── test_g3_ops.py    # FACTO-based G3 tests
</pre></div>
</div>
<p><em><strong>AoT (Ahead-of-Time) Components</strong></em>:</p>
<p>The AoT folder contains all of the python scripts and functions needed to export the model to an ExecuTorch <code class="docutils literal notranslate"><span class="pre">.pte</span></code> file. The main components include:</p>
<ul class="simple">
<li><p><strong>Compiler API</strong> (<a class="reference external" href="https://github.com/pytorch/executorch/blob/main/backends/cadence/aot/compiler.py">compiler.py</a>): High-level APIs for model compilation including <code class="docutils literal notranslate"><span class="pre">trace()</span></code>, <code class="docutils literal notranslate"><span class="pre">quantize_pt2()</span></code>, <code class="docutils literal notranslate"><span class="pre">export_to_edge()</span></code>, and <code class="docutils literal notranslate"><span class="pre">export_to_cadence()</span></code>.</p></li>
<li><p><strong>Quantizer</strong> (<a class="reference external" href="https://github.com/pytorch/executorch/blob/main/backends/cadence/aot/quantizer/quantizer.py">quantizer/quantizer.py</a>): Multiple quantization strategies:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">CadenceDefaultQuantizer</span></code>: Standard A8W8 (8-bit asymmetric activations, 8-bit weights)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">CadenceWithLayerNormQuantizer</span></code>: Adds layer normalization support</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">CadenceWakeWordQuantizer</span></code>: Optimized for audio wake word models</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">CadenceW8A32MixedQuantizer</span></code>: Experimental mixed precision (8-bit weights, 32-bit activations)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">CadenceWithSoftmaxQuantizer</span></code>: Includes A16 (16-bit activation) softmax</p></li>
</ul>
</li>
<li><p><strong>Compiler Passes</strong> (<a class="reference external" href="https://github.com/pytorch/executorch/blob/main/backends/cadence/aot/passes.py">passes.py</a>): Graph optimization passes including operator fusion, replacement, simplification, and reordering.</p></li>
<li><p><strong>Operator Registrations</strong> (<a class="reference external" href="https://github.com/pytorch/executorch/blob/main/backends/cadence/aot/ops_registrations.py">ops_registrations.py</a>): Registers 100+ custom Cadence operators with meta kernels for shape inference. Supports quantized operations for conv1d/2d, linear, matmul, layer norm, and more.</p></li>
<li><p><strong>Export Example</strong> (<a class="reference external" href="https://github.com/pytorch/executorch/blob/main/backends/cadence/aot/export_example.py">export_example.py</a>): Reference implementation demonstrating the complete export workflow from model to <code class="docutils literal notranslate"><span class="pre">.pte</span></code> file.</p></li>
</ul>
<p><em><strong>DSP Family-Specific Implementations</strong></em>:</p>
<p>Each DSP family has its own optimized operator and kernel implementations:</p>
<ul class="simple">
<li><p><strong>HiFi</strong>: Extensive support for quantized convolutions (1D/2D, depthwise, dilated), linear, matmul, layer norm, ReLU, add, and more. Uses Cadence NNLIB for optimized primitives.</p></li>
<li><p><strong>Fusion G3</strong>: General-purpose operations including arithmetic (add, sub, mul, div), activations (sigmoid, tanh, softmax), layer normalization, and tensor manipulation.</p></li>
<li><p><strong>Vision</strong>: Vision-focused operations including quantized conv, linear, matmul, im2row transformation, and softmax with custom vision library.</p></li>
<li><p><strong>Generic</strong>: Reference implementations used as fallback when DSP-specific optimizations aren’t available.</p></li>
</ul>
<p><em><strong>Kernels</strong></em>:</p>
<p>The kernels folders contain optimized implementations that use Xtensa intrinsics to deliver high performance at low power. Each DSP family has its own kernel implementations tuned for the specific architecture characteristics.</p>
</section>
<section id="build">
<h2>Build<a class="headerlink" href="#build" title="Link to this heading">#</a></h2>
<p>In this step, you will generate the ExecuTorch program from different models. You’ll then use this Program (the <code class="docutils literal notranslate"><span class="pre">.pte</span></code> file) during the runtime build step to bake this Program into the DSP image.</p>
<section id="model-export-examples">
<h3>Model Export Examples<a class="headerlink" href="#model-export-examples" title="Link to this heading">#</a></h3>
<p>The Cadence backend provides multiple example models covering different use cases:</p>
<p><em><strong>Simple Model</strong></em>:</p>
<p>The first, simple model is meant to test that all components of this tutorial are working properly, and simply does an add operation. The generated file is called <code class="docutils literal notranslate"><span class="pre">add.pte</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>executorch
python3<span class="w"> </span>-m<span class="w"> </span>examples.portable.scripts.export<span class="w"> </span>--model_name<span class="o">=</span><span class="s2">&quot;add&quot;</span>
</pre></div>
</div>
<p><em><strong>Quantized Operators</strong></em>:</p>
<p>Test individual quantized operations:</p>
<ul>
<li><p><strong>Quantized Linear</strong>: <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html">Linear</a> operation (32→16 features). Linear is the backbone of most ASR models.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>examples.cadence.operators.test_quantized_linear_op
</pre></div>
</div>
</li>
<li><p><strong>Quantized Conv1D</strong>: <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html">Conv1d</a> operation (8→16 channels). Important for wake word and denoising models.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>examples.cadence.operators.test_quantized_conv1d_op
</pre></div>
</div>
</li>
<li><p><strong>Requantize Operation</strong>: Tests dtype conversion between different quantized types.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>examples.cadence.operators.test_requantize_op
</pre></div>
</div>
</li>
</ul>
<p>In all cases the generated file is called <code class="docutils literal notranslate"><span class="pre">CadenceDemoModel.pte</span></code>.</p>
<p><em><strong>Speech/Audio Models</strong></em>:</p>
<p>The torchaudio <a class="reference external" href="https://docs.pytorch.org/audio/stable/generated/torchaudio.pipelines.EMFORMER_RNNT_BASE_LIBRISPEECH.html">RNNT-emformer</a> model is an Automatic Speech Recognition (ASR) model, comprised of three different submodels:</p>
<ul>
<li><p><strong>RNNT Predictor</strong>: Sequence of basic ops (embedding, ReLU, linear, layer norm)</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>examples.cadence.models.rnnt_predictor
</pre></div>
</div>
</li>
<li><p><strong>RNNT Encoder</strong>: ConvEmformer-based encoder with time reduction and transformer layers</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>examples.cadence.models.rnnt_encoder
</pre></div>
</div>
</li>
<li><p><strong>RNNT Joiner</strong>: Joint network combining encoder and predictor outputs</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>examples.cadence.models.rnnt_joiner
</pre></div>
</div>
</li>
<li><p><strong>Wav2Vec 2.0</strong>: Self-supervised speech representation model</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>examples.cadence.models.wav2vec2
</pre></div>
</div>
</li>
</ul>
<p><em><strong>Computer Vision Models</strong></em>:</p>
<ul>
<li><p><strong>MobileNet V2</strong>: Efficient image classification</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>examples.cadence.models.mobilenet_v2
</pre></div>
</div>
</li>
<li><p><strong>ResNet-18</strong>: Image classification</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>examples.cadence.models.resnet18
</pre></div>
</div>
</li>
<li><p><strong>ResNet-50</strong>: Deeper image classification</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>examples.cadence.models.resnet50
</pre></div>
</div>
</li>
<li><p><strong>Vision Transformer (ViT)</strong>: Transformer-based vision model</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>examples.cadence.models.vision_transformer
</pre></div>
</div>
</li>
</ul>
<p><em><strong>Language Model</strong></em>:</p>
<ul>
<li><p><strong>Baby LLaMA</strong>: Small LLM for testing transformer operations on DSP</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>examples.cadence.models.babyllama
</pre></div>
</div>
</li>
</ul>
<p>All model exports generate <code class="docutils literal notranslate"><span class="pre">CadenceDemoModel.pte</span></code> files ready for deployment.</p>
</section>
<section id="runtime">
<h3>Runtime<a class="headerlink" href="#runtime" title="Link to this heading">#</a></h3>
<p><strong>Building the DSP firmware image</strong>
In this step, you’ll be building the DSP firmware image that consists of the sample ExecuTorch runner along with the Program generated from the previous step. This image when loaded onto the DSP will run through the model that this Program consists of.</p>
<p><em><strong>Step 1</strong></em>. Configure the environment variables needed to point to the Xtensa toolchain that you have installed in the previous step. The three environment variables that need to be set include:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Directory in which the Xtensa toolchain was installed</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">XTENSA_TOOLCHAIN</span><span class="o">=</span>/home/user_name/cadence/XtDevTools/install/tools
<span class="c1"># The version of the toolchain that was installed. This is essentially the name of the directory</span>
<span class="c1"># that is present in the XTENSA_TOOLCHAIN directory from above.</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">TOOLCHAIN_VER</span><span class="o">=</span>RI-2023.11-linux
<span class="c1"># The Xtensa core that you&#39;re targeting.</span>
<span class="c1"># For HiFi4 (NXP RT600):</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">XTENSA_CORE</span><span class="o">=</span>VANILLA_HIFI
<span class="c1"># For Fusion G3:</span>
<span class="c1"># export XTENSA_CORE=VANILLA_G3</span>
<span class="c1"># For Vision P6:</span>
<span class="c1"># export XTENSA_CORE=VANILLA_VISION</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The Cadence backend supports multiple DSP families:</p>
<ul class="simple">
<li><p><strong>HiFi Audio DSPs</strong> (HiFi4/HiFi5): Core <code class="docutils literal notranslate"><span class="pre">VANILLA_HIFI</span></code>, enable with <code class="docutils literal notranslate"><span class="pre">-DEXECUTORCH_NNLIB_OPT=ON</span></code></p></li>
<li><p><strong>Fusion G3 DSPs</strong>: Core <code class="docutils literal notranslate"><span class="pre">VANILLA_G3</span></code>, enable with <code class="docutils literal notranslate"><span class="pre">-DEXECUTORCH_FUSION_G3_OPT=ON</span></code></p></li>
<li><p><strong>Vision P-Series DSPs</strong>: Core <code class="docutils literal notranslate"><span class="pre">VANILLA_VISION</span></code>, enable with <code class="docutils literal notranslate"><span class="pre">-DEXECUTORCH_VISION_OPT=ON</span></code></p></li>
</ul>
</div>
<p><em><strong>Step 2</strong></em>. Clone the <a class="reference external" href="https://github.com/foss-xtensa/nnlib-hifi4">nnlib repo</a>, which contains optimized kernels and primitives for HiFi4 DSPs, with <code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">clone</span> <span class="pre">git&#64;github.com:foss-xtensa/nnlib-hifi4.git</span></code>.</p>
<p><em><strong>Step 3</strong></em>. Run the CMake build.
In order to run the CMake build, you need the path to the following:</p>
<ul class="simple">
<li><p>The Program generated in the previous step</p></li>
<li><p>Path to the NXP SDK root. This should have been installed already in the <a class="reference internal" href="#setting-up-developer-environment">Setting up Developer Environment</a> section. This is the directory that contains the folders such as boards, components, devices, and other.</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>executorch
./install_executorch.sh<span class="w"> </span>--clean
mkdir<span class="w"> </span>cmake-out
<span class="c1"># prebuild and install executorch library</span>
cmake<span class="w"> </span>-DCMAKE_TOOLCHAIN_FILE<span class="o">=</span>&lt;path_to_executorch&gt;/backends/cadence/cadence.cmake<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-DCMAKE_INSTALL_PREFIX<span class="o">=</span>cmake-out<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-DCMAKE_BUILD_TYPE<span class="o">=</span>Debug<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-DPYTHON_EXECUTABLE<span class="o">=</span>python3<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-DEXECUTORCH_BUILD_EXTENSION_RUNNER_UTIL<span class="o">=</span>ON<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-DEXECUTORCH_BUILD_EXECUTOR_RUNNER<span class="o">=</span>OFF<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-DEXECUTORCH_BUILD_PTHREADPOOL<span class="o">=</span>OFF<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-DEXECUTORCH_BUILD_CPUINFO<span class="o">=</span>OFF<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-Bcmake-out<span class="w"> </span>.

cmake<span class="w"> </span>--build<span class="w"> </span>cmake-out<span class="w"> </span>-j&lt;num_cores&gt;<span class="w"> </span>--target<span class="w"> </span>install<span class="w"> </span>--config<span class="w"> </span>Debug
<span class="c1"># build cadence runner</span>
cmake<span class="w"> </span>-DCMAKE_BUILD_TYPE<span class="o">=</span>Debug<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-DCMAKE_TOOLCHAIN_FILE<span class="o">=</span>&lt;path_to_executorch&gt;/examples/backends/cadence.cmake<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-DCMAKE_PREFIX_PATH<span class="o">=</span>&lt;path_to_executorch&gt;/cmake-out<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-DMODEL_PATH<span class="o">=</span>&lt;path_to_program_file_generated_in_previous_step&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-DNXP_SDK_ROOT_DIR<span class="o">=</span>&lt;path_to_nxp_sdk_root&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-DNN_LIB_BASE_DIR<span class="o">=</span>&lt;path_to_nnlib_cloned_in_step_2&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-Bcmake-out/examples/cadence<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>examples/cadence

cmake<span class="w"> </span>--build<span class="w"> </span>cmake-out/examples/cadence<span class="w"> </span>-j8<span class="w"> </span>-t<span class="w"> </span>cadence_executorch_example
</pre></div>
</div>
<p>After having succesfully run the above step you should see two binary files in their CMake output directory.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>&gt;<span class="w"> </span>ls<span class="w"> </span>cmake-xt/*.bin
cmake-xt/dsp_data_release.bin<span class="w">  </span>cmake-xt/dsp_text_release.bin
</pre></div>
</div>
</section>
</section>
<section id="deploying-and-running-on-device">
<h2>Deploying and Running on Device<a class="headerlink" href="#deploying-and-running-on-device" title="Link to this heading">#</a></h2>
<p><em><strong>Step 1</strong></em>. You now take the DSP binary images generated from the previous step and copy them over into your NXP workspace created in the <a class="reference internal" href="#setting-up-developer-environment">Setting up  Developer Environment</a> section. Copy the DSP images into the <code class="docutils literal notranslate"><span class="pre">dsp_binary</span></code> section highlighted in the image below.</p>
<p><img alt="MCUXpresso IDE" src="_images/dsp_binary.png" /></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As long as binaries have been built using the Xtensa toolchain on Linux, flashing the board and running on the chip can be done only with the MCUXpresso IDE, which is available on all platforms (Linux, MacOS, Windows).</p>
</div>
<p><em><strong>Step 2</strong></em>. Clean your work space</p>
<p><em><strong>Step 3</strong></em>. Click <strong>Debug your Project</strong> which will flash the board with your binaries.</p>
<p>On the UART console connected to your board (at a default baud rate of 115200), you should see an output similar to this:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>&gt;<span class="w"> </span>screen<span class="w"> </span>/dev/tty.usbmodem0007288234991<span class="w"> </span><span class="m">115200</span>
Executed<span class="w"> </span>model
Model<span class="w"> </span>executed<span class="w"> </span>successfully.
First<span class="w"> </span><span class="m">20</span><span class="w"> </span>elements<span class="w"> </span>of<span class="w"> </span>output<span class="w"> </span><span class="m">0</span>
<span class="m">0</span>.165528<span class="w">   </span><span class="m">0</span>.331055<span class="w"> </span>...
</pre></div>
</div>
</section>
<section id="conclusion-and-future-work">
<h2>Conclusion and Future Work<a class="headerlink" href="#conclusion-and-future-work" title="Link to this heading">#</a></h2>
<p>In this tutorial, you have learned how to export a quantized operation, build the ExecuTorch runtime and run this model on the Xtensa HiFi4 DSP chip.</p>
<p>The (quantized linear) model in this tutorial is a typical operation appearing in ASR models, and can be extended to a complete ASR model by creating the model as a new test and adding the needed operators/kernels to <a class="reference external" href="https://github.com/pytorch/executorch/blob/main/backends/cadence/hifi/operators">operators</a> and <a class="reference external" href="https://github.com/pytorch/executorch/blob/main/backends/cadence/hifi/kernels">kernels</a>.</p>
<p>Other models can be created following the same structure, always assuming that operators and kernels are available.</p>
</section>
</section>


                </article>
              
  </article>
  
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
    <a class="left-prev"
       href="embedded-backends.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Backends</p>
      </div>
    </a>
    <a class="right-next"
       href="embedded-arm-ethos-u.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">&lt;no title&gt;</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>

<div class="footer-info">
  <p class="copyright">
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="embedded-backends.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Backends</p>
      </div>
    </a>
    <a class="right-next"
       href="embedded-arm-ethos-u.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">&lt;no title&gt;</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prerequisites-hardware-and-software">Prerequisites (Hardware and Software)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hardware">Hardware</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#software">Software</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setting-up-developer-environment">Setting up Developer Environment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#working-tree-description">Working Tree Description</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#build">Build</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-export-examples">Model Export Examples</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#runtime">Runtime</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deploying-and-running-on-device">Deploying and Running on Device</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion-and-future-work">Conclusion and Future Work</a></li>
</ul>
  </nav></div>
    
       <div class="sidebar-secondary-item">

  
  <div class="tocsection editthispage">
    <a href="https://github.com/pytorch/executorch/edit/main/docs/source/embedded-cadence.md">
      <i class="fa-solid fa-pencil"></i>
      
      
        
          Edit on GitHub
        
      
    </a>
  </div>
</div>
    
       <div class="sidebar-secondary-item">
    <div class="tocsection sourcelink">
      <a href="_sources/embedded-cadence.md.txt">
        <i class="fa-solid fa-file-lines"></i> Show Source
      </a>
    </div>
</div>
    




</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  

<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4">
        <h2>Docs</h2>
        <p>Access comprehensive developer documentation for PyTorch</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/docs/stable/index.html">View Docs</a>
      </div>

      <div class="col-md-4">
        <h2>Tutorials</h2>
        <p>Get in-depth tutorials for beginners and advanced developers</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/tutorials">View Tutorials</a>
      </div>

      <div class="col-md-4">
        <h2>Resources</h2>
        <p>Find development resources and get your questions answered</p>
        <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
      </div>
    </div>
  </div>
</div>




<footer class="site-footer">

  <div class="container footer-container">

    <div class="newsletter" id="newsletter">

      <p class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and
        the latest news</p>


      <script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/embed/v2.js"></script>
      <script>
        hbspt.forms.create({
          region: "na1",
          portalId: "8112310",
          formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
        });
      </script>


      <p class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its
        projects regarding their events, training, research, developments, and related announcements. I understand that
        I can unsubscribe at any time using the links in the footers of the emails I receive. <a
          href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>

    </div>

    <div class="lf-grid">
      <ul class="social-links">
        <li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-0.51 -0.26 26.45 26.45" aria-label="Facebook">
              <path fill="currentColor"
                d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z" />
            </svg>
          </a></li>
        <li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 300 300" aria-label="X">
              <path fill="currentColor"
                d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66" />
            </svg>
          </a></li>
        <li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0.21 0.27 34.45 25.07" aria-label="YouTube">
              <path fill="currentColor"
                d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z" />
            </svg>
          </a></li>
        <li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-10.23 -10.23 531.96 531.96" aria-label="LinkedIn">
              <rect width="512" height="512" rx="0" fill="currentColor" />
              <circle fill="#000" cx="142" cy="138" r="37" />
              <path stroke="#000" stroke-width="66" d="M244 194v198M142 194v198" />
              <path fill="#000"
                d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32" />
            </svg>
          </a></li>
        <li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.16 -0.03 21.19 21.19" aria-label="Slack">
              <path fill="currentColor"
                d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z">
              </path>
            </svg>
          </a></li>
        <li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.14 -0.17 38.02 33.02" aria-label="WeChat">
              <path fill="currentColor"
                d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z">
              </path>
              <path fill="currentColor"
                d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z">
              </path>
            </svg>
          </a></li>
      </ul>
    </div>
    
    <div class="privacy-policy">
      <div class="copyright">
      
        <p>
          &copy; PyTorch. Copyright © The Linux Foundation®. All rights reserved. The Linux Foundation has registered
          trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark
          usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a
            href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a
            href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
        </p>
        
      </div>
    </div>


  </div>
</footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/img/pytorch-x.svg">
  </div>
</div>
  
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2024, ExecuTorch.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  <script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "Cadence Xtensa Backend",
       "headline": "Cadence Xtensa Backend",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/embedded-cadence.html",
       "articleBody": "Cadence Xtensa Backend# In this tutorial we will walk you through the process of getting setup to build ExecuTorch for Cadence Xtensa DSPs and running models on them. Cadence is both a hardware and software vendor, providing solutions for many computational workloads, including to run on power-limited embedded devices. The Cadence backend supports multiple DSP families optimized for different workloads: HiFi Audio DSPs (HiFi4/HiFi5): Optimized for audio processing, speech recognition, and wake word detection Fusion G3 DSPs: General-purpose AI acceleration Vision P-Series DSPs: Specialized for computer vision and CNN workloads In addition to the chip, the HiFi4 Neural Network Library (nnlib) offers an optimized set of library functions commonly used in NN processing that we utilize in this example to demonstrate how common operations can be accelerated. For an overview of the Cadence ExecuTorch integration with performance benchmarks, see the blog post: Running Optimized PyTorch Models on Cadence DSPs with ExecuTorch. On top of being able to run on the Xtensa HiFi4 DSP, another goal of this tutorial is to demonstrate how portable ExecuTorch is and its ability to run on a low-power embedded device such as the Xtensa HiFi4 DSP. This workflow does not require any delegates, it uses custom operators and compiler passes to enhance the model and make it more suitable to running on Xtensa HiFi4 DSPs. A custom quantizer is used to represent activations and weights as uint8 instead of float, and call appropriate operators. Finally, custom kernels optimized with Xtensa intrinsics provide runtime acceleration. What you will learn in this tutorial: In this tutorial you will learn how to export a quantized model with a linear operation targeted for the Xtensa HiFi4 DSP. You will also learn how to compile and deploy the ExecuTorch runtime with the kernels required for running the quantized model generated in the previous step on the Xtensa HiFi4 DSP. Tutorials we recommend you complete before this: Introduction to ExecuTorch Getting Started Building ExecuTorch with CMake Note The linux part of this tutorial has been designed and tested on Ubuntu 22.04 LTS, and requires glibc 2.34. Workarounds are available for other distributions, but will not be covered in this tutorial. Prerequisites (Hardware and Software)# In order to be able to succesfully build and run ExecuTorch on a Xtensa HiFi4 DSP you\u2019ll need the following hardware and software components. Hardware# i.MX RT600 Evaluation Kit Software# x86-64 Linux system (For compiling the DSP binaries) MCUXpresso IDE This IDE is supported on multiple platforms including MacOS. You can use it on any of the supported platforms as you\u2019ll only be using this to flash the board with the DSP images that you\u2019ll be building later on in this tutorial. J-Link Needed to flash the board with the firmware images. You can install this on the same platform that you installed the MCUXpresso IDE on. Note: depending on the version of the NXP board, another probe than JLink might be installed. In any case, flashing is done using the MCUXpresso IDE in a similar way. MCUXpresso SDK Download this SDK to your Linux machine, extract it and take a note of the path where you store it. You\u2019ll need this later. Xtensa compiler Download this to your Linux machine. This is needed to build ExecuTorch for the HiFi4 DSP. For cases with optimized kernels, the nnlib repo. Setting up Developer Environment# Step 1. In order to be able to successfully install all the software components specified above users will need to go through the NXP tutorial linked below. Although the tutorial itself walks through a Windows setup, most of the steps translate over to a Linux installation too. NXP tutorial on setting up the board and dev environment Note Before proceeding forward to the next section users should be able to succesfullly flash the dsp_mu_polling_cm33 sample application from the tutorial above and notice output on the UART console indicating that the Cortex-M33 and HiFi4 DSP are talking to each other. Step 2. Make sure you have completed the ExecuTorch setup tutorials linked to at the top of this page. Working Tree Description# The working tree is: executorch \u251c\u2500\u2500 backends \u2502 \u2514\u2500\u2500 cadence \u2502 \u251c\u2500\u2500 aot # Ahead-of-Time compilation tools \u2502 \u2502 \u251c\u2500\u2500 compiler.py # Main compilation API \u2502 \u2502 \u251c\u2500\u2500 export_example.py # Export workflow example \u2502 \u2502 \u251c\u2500\u2500 quantizer/ # Quantization infrastructure \u2502 \u2502 \u2502 \u251c\u2500\u2500 quantizer.py # Multiple quantizer implementations \u2502 \u2502 \u2502 \u251c\u2500\u2500 patterns.py # Quantization patterns \u2502 \u2502 \u2502 \u2514\u2500\u2500 fusion_pass.py # Op fusion pass \u2502 \u2502 \u251c\u2500\u2500 passes.py # Graph optimization passes \u2502 \u2502 \u251c\u2500\u2500 functions.yaml # Generic operator definitions \u2502 \u2502 \u251c\u2500\u2500 functions_hifi.yaml # HiFi-specific definitions \u2502 \u2502 \u251c\u2500\u2500 functions_fusion_g3.yaml # Fusion G3 definitions \u2502 \u2502 \u2514\u2500\u2500 functions_vision.yaml # Vision-specific definitions \u2502 \u251c\u2500\u2500 runtime/ # Runtime execution infrastructure \u2502 \u251c\u2500\u2500 utils/ # Build utilities (FACTO, header gen) \u2502 \u251c\u2500\u2500 hifi/ # HiFi Audio DSP family (70+ ops) \u2502 \u2502 \u251c\u2500\u2500 kernels # Optimized HiFi4/HiFi5 kernels \u2502 \u2502 \u251c\u2500\u2500 operators # HiFi operator implementations \u2502 \u2502 \u2514\u2500\u2500 third-party \u2502 \u2502 \u2514\u2500\u2500 nnlib # Cadence NNLIB integration \u2502 \u251c\u2500\u2500 fusion_g3/ # Fusion G3 DSP family (25+ ops) \u2502 \u2502 \u251c\u2500\u2500 kernels \u2502 \u2502 \u251c\u2500\u2500 operators \u2502 \u2502 \u2514\u2500\u2500 third-party \u2502 \u2502 \u2514\u2500\u2500 nnlib \u2502 \u251c\u2500\u2500 vision/ # Vision P-Series DSP family (17+ ops) \u2502 \u2502 \u251c\u2500\u2500 kernels \u2502 \u2502 \u251c\u2500\u2500 operators \u2502 \u2502 \u2514\u2500\u2500 third-party # Vision-specific library \u2502 \u2514\u2500\u2500 generic/ # Generic fallback implementations (15+ ops) \u2502 \u2514\u2500\u2500 operators \u2514\u2500\u2500 examples \u2514\u2500\u2500 cadence \u251c\u2500\u2500 models # 9 example models \u2502 \u251c\u2500\u2500 rnnt_encoder.py # ASR encoder (ConvEmformer) \u2502 \u251c\u2500\u2500 rnnt_predictor.py # ASR predictor \u2502 \u251c\u2500\u2500 rnnt_joiner.py # ASR joiner \u2502 \u251c\u2500\u2500 wav2vec2.py # Self-supervised speech \u2502 \u251c\u2500\u2500 mobilenet_v2.py # Image classification \u2502 \u251c\u2500\u2500 resnet18.py # Image classification \u2502 \u251c\u2500\u2500 resnet50.py # Image classification \u2502 \u251c\u2500\u2500 vision_transformer.py # ViT \u2502 \u2514\u2500\u2500 babyllama.py # Small LLM \u2514\u2500\u2500 operators # Operator test examples \u251c\u2500\u2500 test_add_op.py # Add operation tests \u251c\u2500\u2500 test_quantized_linear_op.py \u251c\u2500\u2500 test_quantized_conv1d_op.py \u251c\u2500\u2500 test_requantize_op.py \u2514\u2500\u2500 test_g3_ops.py # FACTO-based G3 tests AoT (Ahead-of-Time) Components: The AoT folder contains all of the python scripts and functions needed to export the model to an ExecuTorch .pte file. The main components include: Compiler API (compiler.py): High-level APIs for model compilation including trace(), quantize_pt2(), export_to_edge(), and export_to_cadence(). Quantizer (quantizer/quantizer.py): Multiple quantization strategies: CadenceDefaultQuantizer: Standard A8W8 (8-bit asymmetric activations, 8-bit weights) CadenceWithLayerNormQuantizer: Adds layer normalization support CadenceWakeWordQuantizer: Optimized for audio wake word models CadenceW8A32MixedQuantizer: Experimental mixed precision (8-bit weights, 32-bit activations) CadenceWithSoftmaxQuantizer: Includes A16 (16-bit activation) softmax Compiler Passes (passes.py): Graph optimization passes including operator fusion, replacement, simplification, and reordering. Operator Registrations (ops_registrations.py): Registers 100+ custom Cadence operators with meta kernels for shape inference. Supports quantized operations for conv1d/2d, linear, matmul, layer norm, and more. Export Example (export_example.py): Reference implementation demonstrating the complete export workflow from model to .pte file. DSP Family-Specific Implementations: Each DSP family has its own optimized operator and kernel implementations: HiFi: Extensive support for quantized convolutions (1D/2D, depthwise, dilated), linear, matmul, layer norm, ReLU, add, and more. Uses Cadence NNLIB for optimized primitives. Fusion G3: General-purpose operations including arithmetic (add, sub, mul, div), activations (sigmoid, tanh, softmax), layer normalization, and tensor manipulation. Vision: Vision-focused operations including quantized conv, linear, matmul, im2row transformation, and softmax with custom vision library. Generic: Reference implementations used as fallback when DSP-specific optimizations aren\u2019t available. Kernels: The kernels folders contain optimized implementations that use Xtensa intrinsics to deliver high performance at low power. Each DSP family has its own kernel implementations tuned for the specific architecture characteristics. Build# In this step, you will generate the ExecuTorch program from different models. You\u2019ll then use this Program (the .pte file) during the runtime build step to bake this Program into the DSP image. Model Export Examples# The Cadence backend provides multiple example models covering different use cases: Simple Model: The first, simple model is meant to test that all components of this tutorial are working properly, and simply does an add operation. The generated file is called add.pte. cd executorch python3 -m examples.portable.scripts.export --model_name=\"add\" Quantized Operators: Test individual quantized operations: Quantized Linear: Linear operation (32\u219216 features). Linear is the backbone of most ASR models. python3 -m examples.cadence.operators.test_quantized_linear_op Quantized Conv1D: Conv1d operation (8\u219216 channels). Important for wake word and denoising models. python3 -m examples.cadence.operators.test_quantized_conv1d_op Requantize Operation: Tests dtype conversion between different quantized types. python3 -m examples.cadence.operators.test_requantize_op In all cases the generated file is called CadenceDemoModel.pte. Speech/Audio Models: The torchaudio RNNT-emformer model is an Automatic Speech Recognition (ASR) model, comprised of three different submodels: RNNT Predictor: Sequence of basic ops (embedding, ReLU, linear, layer norm) python3 -m examples.cadence.models.rnnt_predictor RNNT Encoder: ConvEmformer-based encoder with time reduction and transformer layers python3 -m examples.cadence.models.rnnt_encoder RNNT Joiner: Joint network combining encoder and predictor outputs python3 -m examples.cadence.models.rnnt_joiner Wav2Vec 2.0: Self-supervised speech representation model python3 -m examples.cadence.models.wav2vec2 Computer Vision Models: MobileNet V2: Efficient image classification python3 -m examples.cadence.models.mobilenet_v2 ResNet-18: Image classification python3 -m examples.cadence.models.resnet18 ResNet-50: Deeper image classification python3 -m examples.cadence.models.resnet50 Vision Transformer (ViT): Transformer-based vision model python3 -m examples.cadence.models.vision_transformer Language Model: Baby LLaMA: Small LLM for testing transformer operations on DSP python3 -m examples.cadence.models.babyllama All model exports generate CadenceDemoModel.pte files ready for deployment. Runtime# Building the DSP firmware image In this step, you\u2019ll be building the DSP firmware image that consists of the sample ExecuTorch runner along with the Program generated from the previous step. This image when loaded onto the DSP will run through the model that this Program consists of. Step 1. Configure the environment variables needed to point to the Xtensa toolchain that you have installed in the previous step. The three environment variables that need to be set include: # Directory in which the Xtensa toolchain was installed export XTENSA_TOOLCHAIN=/home/user_name/cadence/XtDevTools/install/tools # The version of the toolchain that was installed. This is essentially the name of the directory # that is present in the XTENSA_TOOLCHAIN directory from above. export TOOLCHAIN_VER=RI-2023.11-linux # The Xtensa core that you\u0027re targeting. # For HiFi4 (NXP RT600): export XTENSA_CORE=VANILLA_HIFI # For Fusion G3: # export XTENSA_CORE=VANILLA_G3 # For Vision P6: # export XTENSA_CORE=VANILLA_VISION Note The Cadence backend supports multiple DSP families: HiFi Audio DSPs (HiFi4/HiFi5): Core VANILLA_HIFI, enable with -DEXECUTORCH_NNLIB_OPT=ON Fusion G3 DSPs: Core VANILLA_G3, enable with -DEXECUTORCH_FUSION_G3_OPT=ON Vision P-Series DSPs: Core VANILLA_VISION, enable with -DEXECUTORCH_VISION_OPT=ON Step 2. Clone the nnlib repo, which contains optimized kernels and primitives for HiFi4 DSPs, with git clone git@github.com:foss-xtensa/nnlib-hifi4.git. Step 3. Run the CMake build. In order to run the CMake build, you need the path to the following: The Program generated in the previous step Path to the NXP SDK root. This should have been installed already in the Setting up Developer Environment section. This is the directory that contains the folders such as boards, components, devices, and other. cd executorch ./install_executorch.sh --clean mkdir cmake-out # prebuild and install executorch library cmake -DCMAKE_TOOLCHAIN_FILE=\u003cpath_to_executorch\u003e/backends/cadence/cadence.cmake \\ -DCMAKE_INSTALL_PREFIX=cmake-out \\ -DCMAKE_BUILD_TYPE=Debug \\ -DPYTHON_EXECUTABLE=python3 \\ -DEXECUTORCH_BUILD_EXTENSION_RUNNER_UTIL=ON \\ -DEXECUTORCH_BUILD_EXECUTOR_RUNNER=OFF \\ -DEXECUTORCH_BUILD_PTHREADPOOL=OFF \\ -DEXECUTORCH_BUILD_CPUINFO=OFF \\ -Bcmake-out . cmake --build cmake-out -j\u003cnum_cores\u003e --target install --config Debug # build cadence runner cmake -DCMAKE_BUILD_TYPE=Debug \\ -DCMAKE_TOOLCHAIN_FILE=\u003cpath_to_executorch\u003e/examples/backends/cadence.cmake \\ -DCMAKE_PREFIX_PATH=\u003cpath_to_executorch\u003e/cmake-out \\ -DMODEL_PATH=\u003cpath_to_program_file_generated_in_previous_step\u003e \\ -DNXP_SDK_ROOT_DIR=\u003cpath_to_nxp_sdk_root\u003e \\ -DNN_LIB_BASE_DIR=\u003cpath_to_nnlib_cloned_in_step_2\u003e \\ -Bcmake-out/examples/cadence \\ examples/cadence cmake --build cmake-out/examples/cadence -j8 -t cadence_executorch_example After having succesfully run the above step you should see two binary files in their CMake output directory. \u003e ls cmake-xt/*.bin cmake-xt/dsp_data_release.bin cmake-xt/dsp_text_release.bin Deploying and Running on Device# Step 1. You now take the DSP binary images generated from the previous step and copy them over into your NXP workspace created in the Setting up Developer Environment section. Copy the DSP images into the dsp_binary section highlighted in the image below. Note As long as binaries have been built using the Xtensa toolchain on Linux, flashing the board and running on the chip can be done only with the MCUXpresso IDE, which is available on all platforms (Linux, MacOS, Windows). Step 2. Clean your work space Step 3. Click Debug your Project which will flash the board with your binaries. On the UART console connected to your board (at a default baud rate of 115200), you should see an output similar to this: \u003e screen /dev/tty.usbmodem0007288234991 115200 Executed model Model executed successfully. First 20 elements of output 0 0.165528 0.331055 ... Conclusion and Future Work# In this tutorial, you have learned how to export a quantized operation, build the ExecuTorch runtime and run this model on the Xtensa HiFi4 DSP chip. The (quantized linear) model in this tutorial is a typical operation appearing in ASR models, and can be extended to a complete ASR model by creating the model as a new test and adding the needed operators/kernels to operators and kernels. Other models can be created following the same structure, always assuming that operators and kernels are available.",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "https://pytorch.org/docs/stable/_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/embedded-cadence.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
  <script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
  
  </body>
</html>