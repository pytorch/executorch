{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0.dev20240505\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from executorch.examples.models.llama2.source_transformation.quantize import dynamically_quantize_per_channel, WeightOnlyInt8Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_min = -128\n",
    "range_max = 127\n",
    "\n",
    "weight_float = torch.randn(4, 4)\n",
    "activation = torch.randn(4, 4)\n",
    "weight, scales, _ = dynamically_quantize_per_channel(\n",
    "    weight_float, range_min, range_max, torch.int8, None, scales_dtype=weight_float.dtype,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = scales.squeeze(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  76,   14,  127,  -66],\n",
      "        [ 127,   65,   64,  -12],\n",
      "        [-128,   87,  -11,  -81],\n",
      "        [ -15,  -15, -128,  -46]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0102, 0.0142, 0.0177, 0.0196])\n"
     ]
    }
   ],
   "source": [
    "print(scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7735,  0.1411,  1.3022, -0.6775],\n",
      "        [ 1.8120,  0.9258,  0.9135, -0.1759],\n",
      "        [-2.2527,  1.5385, -0.1945, -1.4349],\n",
      "        [-0.2999, -0.2957, -2.5002, -0.9040]])\n"
     ]
    }
   ],
   "source": [
    "print(weight_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5251,  2.7241, -0.4740,  0.3813],\n",
      "        [-0.9735, -0.1196, -1.0898,  1.3676],\n",
      "        [ 0.6301,  0.2436,  0.8839, -0.4392],\n",
      "        [-1.7449, -0.7084, -0.4021, -1.0763]])\n"
     ]
    }
   ],
   "source": [
    "print(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = F.linear(activation, weight.to(dtype=activation.dtype)) * scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6662, -0.7324,  7.1829,  0.4931],\n",
      "        [-3.1083, -3.0920,  0.2722,  1.8234],\n",
      "        [ 1.9665,  2.2411, -0.5937, -2.0793],\n",
      "        [-1.2517, -3.9859,  4.4758,  2.7017]])\n"
     ]
    }
   ],
   "source": [
    "print(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch._C import DispatchKey\n",
    "torch.ops.aten._weight_int8pack_mm.default.has_kernel_for_dispatch_key(DispatchKey.MPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6662, -0.7324,  7.1829,  0.4931],\n",
      "        [-3.1083, -3.0920,  0.2722,  1.8234],\n",
      "        [ 1.9665,  2.2411, -0.5937, -2.0793],\n",
      "        [-1.2517, -3.9859,  4.4758,  2.7017]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "res2 = torch.ops.aten._weight_int8pack_mm(activation.to(device='mps'), weight.to(device='mps'), scales=scales.to(device='mps'))\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6301,  0.2436,  0.8839, -0.4392])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation[2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.8120,  0.9258,  0.9135, -0.1759])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_float[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5703)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(activation[2, :], weight_float[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1271, -1.0495, -1.1300,  0.1153],\n",
       "        [ 5.1776,  3.3572,  3.4860, -0.3586],\n",
       "        [ 0.8612,  2.5703, -2.0016,  0.2567],\n",
       "        [-1.1237,  0.8256, -3.4993, -0.1149]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.linear(activation, weight_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from executorch.examples.models.llama2.builder import load_llama_model, DType\n",
    "from executorch.examples.models.llama2.source_transformation.quantize import WeightOnlyInt8QuantHandler\n",
    "from executorch.examples.models.llama2.source_transformation.sdpa import replace_sdpa_with_simple_sdpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2024-05-08 23:47:52,092 builder.py:84] Loading model with checkpoint=stories110M.pt, params=params.json, use_kv_cache=True, weight_type=WeightType.LLAMA\n",
      "[INFO 2024-05-08 23:47:52,234 builder.py:105] Loaded model with dtype=torch.float32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantize * ('layers.0.attention.wq', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.0.attention.wk', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.0.attention.wv', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.0.attention.wo', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.0.feed_forward.w1', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.0.feed_forward.w2', Linear(in_features=2048, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.0.feed_forward.w3', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.1.attention.wq', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.1.attention.wk', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.1.attention.wv', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.1.attention.wo', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.1.feed_forward.w1', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.1.feed_forward.w2', Linear(in_features=2048, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.1.feed_forward.w3', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.2.attention.wq', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.2.attention.wk', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.2.attention.wv', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.2.attention.wo', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.2.feed_forward.w1', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.2.feed_forward.w2', Linear(in_features=2048, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.2.feed_forward.w3', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.3.attention.wq', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.3.attention.wk', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.3.attention.wv', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.3.attention.wo', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.3.feed_forward.w1', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.3.feed_forward.w2', Linear(in_features=2048, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.3.feed_forward.w3', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.4.attention.wq', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.4.attention.wk', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.4.attention.wv', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.4.attention.wo', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.4.feed_forward.w1', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.4.feed_forward.w2', Linear(in_features=2048, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.4.feed_forward.w3', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.5.attention.wq', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.5.attention.wk', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.5.attention.wv', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.5.attention.wo', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.5.feed_forward.w1', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.5.feed_forward.w2', Linear(in_features=2048, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.5.feed_forward.w3', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.6.attention.wq', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.6.attention.wk', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.6.attention.wv', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.6.attention.wo', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.6.feed_forward.w1', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.6.feed_forward.w2', Linear(in_features=2048, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.6.feed_forward.w3', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.7.attention.wq', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.7.attention.wk', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.7.attention.wv', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.7.attention.wo', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.7.feed_forward.w1', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.7.feed_forward.w2', Linear(in_features=2048, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.7.feed_forward.w3', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.8.attention.wq', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.8.attention.wk', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.8.attention.wv', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.8.attention.wo', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.8.feed_forward.w1', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.8.feed_forward.w2', Linear(in_features=2048, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.8.feed_forward.w3', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.9.attention.wq', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.9.attention.wk', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.9.attention.wv', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.9.attention.wo', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.9.feed_forward.w1', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.9.feed_forward.w2', Linear(in_features=2048, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.9.feed_forward.w3', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.10.attention.wq', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.10.attention.wk', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.10.attention.wv', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.10.attention.wo', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.10.feed_forward.w1', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.10.feed_forward.w2', Linear(in_features=2048, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.10.feed_forward.w3', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.11.attention.wq', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.11.attention.wk', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.11.attention.wv', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.11.attention.wo', Linear(in_features=768, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.11.feed_forward.w1', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.11.feed_forward.w2', Linear(in_features=2048, out_features=768, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('layers.11.feed_forward.w3', Linear(in_features=768, out_features=2048, bias=False)) with group_size None, bitwidth 8\n",
      "quantize * ('output', Linear(in_features=768, out_features=32000, bias=False)) with group_size None, bitwidth 8\n"
     ]
    }
   ],
   "source": [
    "# stories110M\n",
    "\n",
    "checkpoint = \"stories110M.pt\"\n",
    "params = \"params.json\"\n",
    "transforms = [\n",
    "    lambda m: WeightOnlyInt8QuantHandler(m).quantized_model(),\n",
    "    replace_sdpa_with_simple_sdpa,\n",
    "]\n",
    "\n",
    "model = load_llama_model(\n",
    "    checkpoint=checkpoint,\n",
    "    params_path=params,\n",
    "    use_kv_cache=True,\n",
    ").to_dtype(DType.fp32).source_transform(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from executorch.backends.apple.mps.partition.mps_partitioner import (\n",
    "    MPSPartitioner,\n",
    ")\n",
    "from executorch.exir.backend.backend_details import CompileSpec\n",
    "compile_specs = [CompileSpec(\"use_fp16\", bytes([True]))]\n",
    "\n",
    "partitioners = [\n",
    "    MPSPartitioner(compile_specs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2024-05-08 23:48:05,952 xnnpack_partitioner.py:555] Found 85 subgraphs to be partitioned.\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/emit/_emitter.py:1474: UserWarning: Mutation on a buffer in the model is detected. ExecuTorch assumes buffers that are mutated in the graph have a meaningless initial state, only the shape and dtype will be serialized.\n",
      "  warnings.warn(\n",
      "[INFO 2024-05-08 23:48:23,675 builder.py:341] Required memory for activation in bytes: [0, 459548672]\n",
      "[INFO 2024-05-08 23:48:23,852 utils.py:113] Saved exported program to stories110M_int8_xnnpack.pte\n"
     ]
    }
   ],
   "source": [
    "from executorch.examples.models.llama2.lib.partitioner_lib import get_xnnpack_partitioner\n",
    "\n",
    "builder = model.export_to_edge(None).to_backend([get_xnnpack_partitioner()]).to_executorch().save_to_pte(\"stories110M_int8_xnnpack.pte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/emit/_emitter.py:1474: UserWarning: Mutation on a buffer in the model is detected. ExecuTorch assumes buffers that are mutated in the graph have a meaningless initial state, only the shape and dtype will be serialized.\n",
      "  warnings.warn(\n",
      "[INFO 2024-05-08 18:05:25,534 builder.py:341] Required memory for activation in bytes: [0, 418116608]\n"
     ]
    }
   ],
   "source": [
    "builder = model.export_to_edge(None).to_executorch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2024-05-08 17:52:10,435 mps_partitioner.py:121] Found 1 subgraphs to be partitioned.\n",
      "[INFO 2024-05-08 17:52:10,438 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 17:52:10,439 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 17:52:10,440 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 17:52:10,441 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 17:52:10,442 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 17:52:10,442 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 17:52:10,444 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 17:52:10,444 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 17:52:10,445 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 17:52:10,445 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 17:52:10,447 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 17:52:10,447 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 17:52:10,448 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 17:52:10,448 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 17:52:10,450 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 17:52:10,450 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 17:52:10,451 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 17:52:10,452 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 17:52:10,453 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 17:52:10,453 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 17:52:10,454 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 17:52:10,455 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 17:52:10,456 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 17:52:10,457 utils.py:527] The buffer node is a mutated buffer node, which is not constant.\n",
      "[INFO 2024-05-08 17:52:11,139 mps_preprocess.py:115] Visiting: aten_embedding_default, aten.embedding.default\n",
      "[INFO 2024-05-08 17:52:11,140 mps_preprocess.py:115] Visiting: aten_index_tensor, aten.index.Tensor\n",
      "[INFO 2024-05-08 17:52:11,140 mps_preprocess.py:115] Visiting: aten_index_tensor_1, aten.index.Tensor\n",
      "[INFO 2024-05-08 17:52:11,140 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_4, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,141 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_12, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,141 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_20, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,141 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_28, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,142 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_36, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,142 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_44, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,142 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_52, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,143 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_60, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,143 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_68, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,143 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_76, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,143 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_84, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,144 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_92, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,144 mps_preprocess.py:115] Visiting: aten_mul_tensor, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,144 mps_preprocess.py:115] Visiting: aten_view_copy_default_5, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,145 mps_preprocess.py:115] Visiting: aten_view_copy_default_25, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,145 mps_preprocess.py:115] Visiting: aten_view_copy_default_45, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,145 mps_preprocess.py:115] Visiting: aten_view_copy_default_65, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,146 mps_preprocess.py:115] Visiting: aten_view_copy_default_85, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,146 mps_preprocess.py:115] Visiting: aten_view_copy_default_105, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,146 mps_preprocess.py:115] Visiting: aten_view_copy_default_125, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,147 mps_preprocess.py:115] Visiting: aten_view_copy_default_145, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,147 mps_preprocess.py:115] Visiting: aten_view_copy_default_165, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,147 mps_preprocess.py:115] Visiting: aten_view_copy_default_185, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,147 mps_preprocess.py:115] Visiting: aten_view_copy_default_205, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,148 mps_preprocess.py:115] Visiting: aten_view_copy_default_225, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,148 mps_preprocess.py:115] Visiting: aten_view_copy_default_6, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,148 mps_preprocess.py:115] Visiting: aten_view_copy_default_26, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,149 mps_preprocess.py:115] Visiting: aten_view_copy_default_46, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,149 mps_preprocess.py:115] Visiting: aten_view_copy_default_66, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,149 mps_preprocess.py:115] Visiting: aten_view_copy_default_86, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,149 mps_preprocess.py:115] Visiting: aten_view_copy_default_106, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,150 mps_preprocess.py:115] Visiting: aten_view_copy_default_126, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,150 mps_preprocess.py:115] Visiting: aten_view_copy_default_146, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,150 mps_preprocess.py:115] Visiting: aten_view_copy_default_166, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,150 mps_preprocess.py:115] Visiting: aten_view_copy_default_186, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,151 mps_preprocess.py:115] Visiting: aten_view_copy_default_206, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,151 mps_preprocess.py:115] Visiting: aten_view_copy_default_226, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,151 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_5, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,152 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_13, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,152 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_21, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,152 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_29, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,153 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_37, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,153 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_45, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,153 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_53, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,153 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_61, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,153 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_69, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,154 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_77, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,154 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_85, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,155 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_93, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,155 mps_preprocess.py:115] Visiting: aten_mean_dim, aten.mean.dim\n",
      "[INFO 2024-05-08 17:52:11,156 mps_preprocess.py:115] Visiting: aten_index_tensor_2, aten.index.Tensor\n",
      "[INFO 2024-05-08 17:52:11,156 mps_preprocess.py:115] Visiting: aten_index_tensor_3, aten.index.Tensor\n",
      "[INFO 2024-05-08 17:52:11,156 mps_preprocess.py:115] Visiting: aten_index_tensor_4, aten.index.Tensor\n",
      "[INFO 2024-05-08 17:52:11,157 mps_preprocess.py:115] Visiting: aten_index_tensor_5, aten.index.Tensor\n",
      "[INFO 2024-05-08 17:52:11,157 mps_preprocess.py:115] Visiting: aten_index_tensor_6, aten.index.Tensor\n",
      "[INFO 2024-05-08 17:52:11,157 mps_preprocess.py:115] Visiting: aten_index_tensor_7, aten.index.Tensor\n",
      "[INFO 2024-05-08 17:52:11,157 mps_preprocess.py:115] Visiting: aten_index_tensor_8, aten.index.Tensor\n",
      "[INFO 2024-05-08 17:52:11,158 mps_preprocess.py:115] Visiting: aten_index_tensor_9, aten.index.Tensor\n",
      "[INFO 2024-05-08 17:52:11,158 mps_preprocess.py:115] Visiting: aten_index_tensor_10, aten.index.Tensor\n",
      "[INFO 2024-05-08 17:52:11,158 mps_preprocess.py:115] Visiting: aten_index_tensor_11, aten.index.Tensor\n",
      "[INFO 2024-05-08 17:52:11,159 mps_preprocess.py:115] Visiting: aten_index_tensor_12, aten.index.Tensor\n",
      "[INFO 2024-05-08 17:52:11,159 mps_preprocess.py:115] Visiting: aten_index_tensor_13, aten.index.Tensor\n",
      "[INFO 2024-05-08 17:52:11,159 mps_preprocess.py:115] Visiting: aten_add_tensor, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,160 mps_preprocess.py:115] Visiting: aten__to_copy_default, aten._to_copy.default\n",
      "[INFO 2024-05-08 17:52:11,160 mps_preprocess.py:115] Visiting: aten__to_copy_default_1, aten._to_copy.default\n",
      "[INFO 2024-05-08 17:52:11,160 mps_preprocess.py:115] Visiting: aten__to_copy_default_2, aten._to_copy.default\n",
      "[INFO 2024-05-08 17:52:11,160 mps_preprocess.py:115] Visiting: aten__to_copy_default_3, aten._to_copy.default\n",
      "[INFO 2024-05-08 17:52:11,160 mps_preprocess.py:115] Visiting: aten__to_copy_default_4, aten._to_copy.default\n",
      "[INFO 2024-05-08 17:52:11,161 mps_preprocess.py:115] Visiting: aten__to_copy_default_5, aten._to_copy.default\n",
      "[INFO 2024-05-08 17:52:11,161 mps_preprocess.py:115] Visiting: aten__to_copy_default_6, aten._to_copy.default\n",
      "[INFO 2024-05-08 17:52:11,161 mps_preprocess.py:115] Visiting: aten__to_copy_default_7, aten._to_copy.default\n",
      "[INFO 2024-05-08 17:52:11,161 mps_preprocess.py:115] Visiting: aten__to_copy_default_8, aten._to_copy.default\n",
      "[INFO 2024-05-08 17:52:11,161 mps_preprocess.py:115] Visiting: aten__to_copy_default_9, aten._to_copy.default\n",
      "[INFO 2024-05-08 17:52:11,162 mps_preprocess.py:115] Visiting: aten__to_copy_default_10, aten._to_copy.default\n",
      "[INFO 2024-05-08 17:52:11,162 mps_preprocess.py:115] Visiting: aten__to_copy_default_11, aten._to_copy.default\n",
      "[INFO 2024-05-08 17:52:11,162 mps_preprocess.py:115] Visiting: aten_rsqrt_default, aten.rsqrt.default\n",
      "[INFO 2024-05-08 17:52:11,162 mps_preprocess.py:115] Visiting: aten_mul_tensor_1, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,163 mps_preprocess.py:115] Visiting: aten_mul_tensor_2, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,163 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,163 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_1, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,164 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_2, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,164 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,164 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_1, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,165 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_2, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,165 mps_preprocess.py:115] Visiting: aten_view_copy_default, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,165 mps_preprocess.py:115] Visiting: aten_view_copy_default_1, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,165 mps_preprocess.py:115] Visiting: aten_view_copy_default_2, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,166 mps_preprocess.py:115] Visiting: aten_view_copy_default_3, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,166 mps_preprocess.py:115] Visiting: aten_view_copy_default_4, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,166 mps_preprocess.py:115] Visiting: aten_permute_copy_default_2, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,166 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,167 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_1, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,167 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_2, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,167 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_3, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,168 mps_preprocess.py:115] Visiting: aten_view_copy_default_10, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,168 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_3, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,168 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_4, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,169 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_5, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,169 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_6, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,169 mps_preprocess.py:115] Visiting: aten_index_put_default_1, aten.index_put.default\n",
      "[INFO 2024-05-08 17:52:11,169 mps_preprocess.py:115] Visiting: aten_mul_tensor_3, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,170 mps_preprocess.py:115] Visiting: aten_mul_tensor_5, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,170 mps_preprocess.py:115] Visiting: aten_mul_tensor_4, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,170 mps_preprocess.py:115] Visiting: aten_mul_tensor_6, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,171 mps_preprocess.py:115] Visiting: aten_mul_tensor_7, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,171 mps_preprocess.py:115] Visiting: aten_mul_tensor_9, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,171 mps_preprocess.py:115] Visiting: aten_mul_tensor_8, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,172 mps_preprocess.py:115] Visiting: aten_mul_tensor_10, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,172 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_2, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,174 mps_preprocess.py:115] Visiting: aten_sub_tensor, aten.sub.Tensor\n",
      "[INFO 2024-05-08 17:52:11,175 mps_preprocess.py:115] Visiting: aten_add_tensor_1, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,175 mps_preprocess.py:115] Visiting: aten_sub_tensor_1, aten.sub.Tensor\n",
      "[INFO 2024-05-08 17:52:11,175 mps_preprocess.py:115] Visiting: aten_add_tensor_2, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,176 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_3, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,176 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,177 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_1, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,177 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_2, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,177 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_3, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,178 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_7, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,178 mps_preprocess.py:115] Visiting: aten_cat_default, aten.cat.default\n",
      "[INFO 2024-05-08 17:52:11,178 mps_preprocess.py:115] Visiting: aten_cat_default_1, aten.cat.default\n",
      "[INFO 2024-05-08 17:52:11,179 mps_preprocess.py:115] Visiting: aten_expand_copy_default_1, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,179 mps_preprocess.py:115] Visiting: aten_view_copy_default_7, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,179 mps_preprocess.py:115] Visiting: aten_view_copy_default_8, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,180 mps_preprocess.py:115] Visiting: aten_clone_default_1, aten.clone.default\n",
      "[INFO 2024-05-08 17:52:11,180 mps_preprocess.py:115] Visiting: aten_permute_copy_default, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,180 mps_preprocess.py:115] Visiting: aten_permute_copy_default_1, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,180 mps_preprocess.py:115] Visiting: aten_view_copy_default_12, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,181 mps_preprocess.py:115] Visiting: aten_expand_copy_default_2, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,181 mps_preprocess.py:115] Visiting: aten_view_copy_default_9, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,181 mps_preprocess.py:115] Visiting: aten_expand_copy_default_5, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,182 mps_preprocess.py:115] Visiting: aten_view_copy_default_13, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,182 mps_preprocess.py:115] Visiting: aten_index_put_default, aten.index_put.default\n",
      "[INFO 2024-05-08 17:52:11,182 mps_preprocess.py:115] Visiting: aten_view_copy_default_17, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,182 mps_preprocess.py:115] Visiting: aten_slice_scatter_default, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,183 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_1, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,184 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_6, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,184 mps_preprocess.py:115] Visiting: aten_expand_copy_default, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,184 mps_preprocess.py:115] Visiting: aten_clone_default, aten.clone.default\n",
      "[INFO 2024-05-08 17:52:11,185 mps_preprocess.py:115] Visiting: aten_view_copy_default_11, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,185 mps_preprocess.py:115] Visiting: aten_permute_copy_default_3, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,185 mps_preprocess.py:115] Visiting: aten_expand_copy_default_3, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,185 mps_preprocess.py:115] Visiting: aten_view_copy_default_14, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,186 mps_preprocess.py:115] Visiting: aten_bmm_default, aten.bmm.default\n",
      "[INFO 2024-05-08 17:52:11,186 mps_preprocess.py:115] Visiting: aten_view_copy_default_15, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,186 mps_preprocess.py:115] Visiting: aten_mul_tensor_11, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,187 mps_preprocess.py:115] Visiting: aten_add_tensor_3, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,187 mps_preprocess.py:115] Visiting: aten__softmax_default, aten._softmax.default\n",
      "[INFO 2024-05-08 17:52:11,188 mps_preprocess.py:115] Visiting: aten_expand_copy_default_4, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,188 mps_preprocess.py:115] Visiting: aten_view_copy_default_16, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,188 mps_preprocess.py:115] Visiting: aten_bmm_default_1, aten.bmm.default\n",
      "[INFO 2024-05-08 17:52:11,189 mps_preprocess.py:115] Visiting: aten_view_copy_default_18, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,189 mps_preprocess.py:115] Visiting: aten_permute_copy_default_4, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,189 mps_preprocess.py:115] Visiting: aten_view_copy_default_19, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,190 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_7, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,190 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_3, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,190 mps_preprocess.py:115] Visiting: aten_add_tensor_4, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,191 mps_preprocess.py:115] Visiting: aten_mul_tensor_12, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,191 mps_preprocess.py:115] Visiting: aten_mean_dim_1, aten.mean.dim\n",
      "[INFO 2024-05-08 17:52:11,191 mps_preprocess.py:115] Visiting: aten_add_tensor_5, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,192 mps_preprocess.py:115] Visiting: aten_rsqrt_default_1, aten.rsqrt.default\n",
      "[INFO 2024-05-08 17:52:11,192 mps_preprocess.py:115] Visiting: aten_mul_tensor_13, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,192 mps_preprocess.py:115] Visiting: aten_mul_tensor_14, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,192 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_8, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,193 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_9, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,193 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_4, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,193 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_5, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,194 mps_preprocess.py:115] Visiting: aten_sigmoid_default, aten.sigmoid.default\n",
      "[INFO 2024-05-08 17:52:11,194 mps_preprocess.py:115] Visiting: aten_mul_tensor_15, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,194 mps_preprocess.py:115] Visiting: aten_mul_tensor_16, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,194 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_6, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,195 mps_preprocess.py:115] Visiting: aten_add_tensor_6, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,195 mps_preprocess.py:115] Visiting: aten_mul_tensor_17, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,195 mps_preprocess.py:115] Visiting: aten_mean_dim_2, aten.mean.dim\n",
      "[INFO 2024-05-08 17:52:11,196 mps_preprocess.py:115] Visiting: aten_add_tensor_7, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,196 mps_preprocess.py:115] Visiting: aten_rsqrt_default_2, aten.rsqrt.default\n",
      "[INFO 2024-05-08 17:52:11,196 mps_preprocess.py:115] Visiting: aten_mul_tensor_18, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,197 mps_preprocess.py:115] Visiting: aten_mul_tensor_19, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,197 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_10, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,197 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_11, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,198 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_12, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,198 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_7, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,198 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_8, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,198 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_9, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,199 mps_preprocess.py:115] Visiting: aten_view_copy_default_20, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,199 mps_preprocess.py:115] Visiting: aten_view_copy_default_21, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,199 mps_preprocess.py:115] Visiting: aten_view_copy_default_22, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,199 mps_preprocess.py:115] Visiting: aten_view_copy_default_23, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,200 mps_preprocess.py:115] Visiting: aten_view_copy_default_24, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,200 mps_preprocess.py:115] Visiting: aten_permute_copy_default_7, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,200 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_4, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,200 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_5, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,201 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_6, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,201 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_7, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,201 mps_preprocess.py:115] Visiting: aten_view_copy_default_30, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,202 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_13, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,202 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_14, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,202 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_15, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,203 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_16, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,203 mps_preprocess.py:115] Visiting: aten_index_put_default_3, aten.index_put.default\n",
      "[INFO 2024-05-08 17:52:11,203 mps_preprocess.py:115] Visiting: aten_mul_tensor_20, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,204 mps_preprocess.py:115] Visiting: aten_mul_tensor_22, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,204 mps_preprocess.py:115] Visiting: aten_mul_tensor_21, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,204 mps_preprocess.py:115] Visiting: aten_mul_tensor_23, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,205 mps_preprocess.py:115] Visiting: aten_mul_tensor_24, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,205 mps_preprocess.py:115] Visiting: aten_mul_tensor_26, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,205 mps_preprocess.py:115] Visiting: aten_mul_tensor_25, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,205 mps_preprocess.py:115] Visiting: aten_mul_tensor_27, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,206 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_6, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,207 mps_preprocess.py:115] Visiting: aten_sub_tensor_2, aten.sub.Tensor\n",
      "[INFO 2024-05-08 17:52:11,207 mps_preprocess.py:115] Visiting: aten_add_tensor_8, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,207 mps_preprocess.py:115] Visiting: aten_sub_tensor_3, aten.sub.Tensor\n",
      "[INFO 2024-05-08 17:52:11,208 mps_preprocess.py:115] Visiting: aten_add_tensor_9, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,208 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_7, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,209 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_8, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,209 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_9, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,209 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_10, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,210 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_11, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,210 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_15, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,210 mps_preprocess.py:115] Visiting: aten_cat_default_2, aten.cat.default\n",
      "[INFO 2024-05-08 17:52:11,211 mps_preprocess.py:115] Visiting: aten_cat_default_3, aten.cat.default\n",
      "[INFO 2024-05-08 17:52:11,211 mps_preprocess.py:115] Visiting: aten_expand_copy_default_7, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,211 mps_preprocess.py:115] Visiting: aten_view_copy_default_27, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,212 mps_preprocess.py:115] Visiting: aten_view_copy_default_28, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,212 mps_preprocess.py:115] Visiting: aten_clone_default_3, aten.clone.default\n",
      "[INFO 2024-05-08 17:52:11,212 mps_preprocess.py:115] Visiting: aten_permute_copy_default_5, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,212 mps_preprocess.py:115] Visiting: aten_permute_copy_default_6, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,213 mps_preprocess.py:115] Visiting: aten_view_copy_default_32, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,213 mps_preprocess.py:115] Visiting: aten_expand_copy_default_8, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,213 mps_preprocess.py:115] Visiting: aten_view_copy_default_29, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,214 mps_preprocess.py:115] Visiting: aten_expand_copy_default_11, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,214 mps_preprocess.py:115] Visiting: aten_view_copy_default_33, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,214 mps_preprocess.py:115] Visiting: aten_index_put_default_2, aten.index_put.default\n",
      "[INFO 2024-05-08 17:52:11,214 mps_preprocess.py:115] Visiting: aten_view_copy_default_37, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,215 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_4, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,215 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_5, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,216 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_14, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,216 mps_preprocess.py:115] Visiting: aten_expand_copy_default_6, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,217 mps_preprocess.py:115] Visiting: aten_clone_default_2, aten.clone.default\n",
      "[INFO 2024-05-08 17:52:11,217 mps_preprocess.py:115] Visiting: aten_view_copy_default_31, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,217 mps_preprocess.py:115] Visiting: aten_permute_copy_default_8, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,217 mps_preprocess.py:115] Visiting: aten_expand_copy_default_9, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,218 mps_preprocess.py:115] Visiting: aten_view_copy_default_34, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,218 mps_preprocess.py:115] Visiting: aten_bmm_default_2, aten.bmm.default\n",
      "[INFO 2024-05-08 17:52:11,218 mps_preprocess.py:115] Visiting: aten_view_copy_default_35, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,219 mps_preprocess.py:115] Visiting: aten_mul_tensor_28, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,219 mps_preprocess.py:115] Visiting: aten_add_tensor_10, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,219 mps_preprocess.py:115] Visiting: aten__softmax_default_1, aten._softmax.default\n",
      "[INFO 2024-05-08 17:52:11,220 mps_preprocess.py:115] Visiting: aten_expand_copy_default_10, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,220 mps_preprocess.py:115] Visiting: aten_view_copy_default_36, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,220 mps_preprocess.py:115] Visiting: aten_bmm_default_3, aten.bmm.default\n",
      "[INFO 2024-05-08 17:52:11,221 mps_preprocess.py:115] Visiting: aten_view_copy_default_38, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,221 mps_preprocess.py:115] Visiting: aten_permute_copy_default_9, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,221 mps_preprocess.py:115] Visiting: aten_view_copy_default_39, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,221 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_17, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,222 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_10, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,222 mps_preprocess.py:115] Visiting: aten_add_tensor_11, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,222 mps_preprocess.py:115] Visiting: aten_mul_tensor_29, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,223 mps_preprocess.py:115] Visiting: aten_mean_dim_3, aten.mean.dim\n",
      "[INFO 2024-05-08 17:52:11,223 mps_preprocess.py:115] Visiting: aten_add_tensor_12, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,223 mps_preprocess.py:115] Visiting: aten_rsqrt_default_3, aten.rsqrt.default\n",
      "[INFO 2024-05-08 17:52:11,223 mps_preprocess.py:115] Visiting: aten_mul_tensor_30, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,224 mps_preprocess.py:115] Visiting: aten_mul_tensor_31, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,224 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_18, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,224 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_19, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,224 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_11, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,225 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_12, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,225 mps_preprocess.py:115] Visiting: aten_sigmoid_default_1, aten.sigmoid.default\n",
      "[INFO 2024-05-08 17:52:11,226 mps_preprocess.py:115] Visiting: aten_mul_tensor_32, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,226 mps_preprocess.py:115] Visiting: aten_mul_tensor_33, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,226 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_13, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,227 mps_preprocess.py:115] Visiting: aten_add_tensor_13, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,227 mps_preprocess.py:115] Visiting: aten_mul_tensor_34, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,227 mps_preprocess.py:115] Visiting: aten_mean_dim_4, aten.mean.dim\n",
      "[INFO 2024-05-08 17:52:11,228 mps_preprocess.py:115] Visiting: aten_add_tensor_14, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,228 mps_preprocess.py:115] Visiting: aten_rsqrt_default_4, aten.rsqrt.default\n",
      "[INFO 2024-05-08 17:52:11,228 mps_preprocess.py:115] Visiting: aten_mul_tensor_35, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,229 mps_preprocess.py:115] Visiting: aten_mul_tensor_36, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,229 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_20, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,229 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_21, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,230 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_22, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,230 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_14, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,230 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_15, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,231 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_16, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,231 mps_preprocess.py:115] Visiting: aten_view_copy_default_40, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,231 mps_preprocess.py:115] Visiting: aten_view_copy_default_41, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,232 mps_preprocess.py:115] Visiting: aten_view_copy_default_42, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,232 mps_preprocess.py:115] Visiting: aten_view_copy_default_43, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,232 mps_preprocess.py:115] Visiting: aten_view_copy_default_44, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,233 mps_preprocess.py:115] Visiting: aten_permute_copy_default_12, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,233 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_8, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,233 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_9, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,233 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_10, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,233 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_11, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,234 mps_preprocess.py:115] Visiting: aten_view_copy_default_50, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,234 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_23, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,234 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_24, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,235 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_25, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,235 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_26, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,235 mps_preprocess.py:115] Visiting: aten_index_put_default_5, aten.index_put.default\n",
      "[INFO 2024-05-08 17:52:11,235 mps_preprocess.py:115] Visiting: aten_mul_tensor_37, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,236 mps_preprocess.py:115] Visiting: aten_mul_tensor_39, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,236 mps_preprocess.py:115] Visiting: aten_mul_tensor_38, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,236 mps_preprocess.py:115] Visiting: aten_mul_tensor_40, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,237 mps_preprocess.py:115] Visiting: aten_mul_tensor_41, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,237 mps_preprocess.py:115] Visiting: aten_mul_tensor_43, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,237 mps_preprocess.py:115] Visiting: aten_mul_tensor_42, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,237 mps_preprocess.py:115] Visiting: aten_mul_tensor_44, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,238 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_10, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,239 mps_preprocess.py:115] Visiting: aten_sub_tensor_4, aten.sub.Tensor\n",
      "[INFO 2024-05-08 17:52:11,239 mps_preprocess.py:115] Visiting: aten_add_tensor_15, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,239 mps_preprocess.py:115] Visiting: aten_sub_tensor_5, aten.sub.Tensor\n",
      "[INFO 2024-05-08 17:52:11,239 mps_preprocess.py:115] Visiting: aten_add_tensor_16, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,240 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_11, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,241 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_16, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,241 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_17, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,241 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_18, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,242 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_19, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,242 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_23, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,242 mps_preprocess.py:115] Visiting: aten_cat_default_4, aten.cat.default\n",
      "[INFO 2024-05-08 17:52:11,243 mps_preprocess.py:115] Visiting: aten_cat_default_5, aten.cat.default\n",
      "[INFO 2024-05-08 17:52:11,243 mps_preprocess.py:115] Visiting: aten_expand_copy_default_13, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,243 mps_preprocess.py:115] Visiting: aten_view_copy_default_47, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,244 mps_preprocess.py:115] Visiting: aten_view_copy_default_48, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,244 mps_preprocess.py:115] Visiting: aten_clone_default_5, aten.clone.default\n",
      "[INFO 2024-05-08 17:52:11,244 mps_preprocess.py:115] Visiting: aten_permute_copy_default_10, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,245 mps_preprocess.py:115] Visiting: aten_permute_copy_default_11, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,245 mps_preprocess.py:115] Visiting: aten_view_copy_default_52, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,245 mps_preprocess.py:115] Visiting: aten_expand_copy_default_14, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,245 mps_preprocess.py:115] Visiting: aten_view_copy_default_49, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,246 mps_preprocess.py:115] Visiting: aten_expand_copy_default_17, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,246 mps_preprocess.py:115] Visiting: aten_view_copy_default_53, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,246 mps_preprocess.py:115] Visiting: aten_index_put_default_4, aten.index_put.default\n",
      "[INFO 2024-05-08 17:52:11,246 mps_preprocess.py:115] Visiting: aten_view_copy_default_57, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,247 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_8, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,248 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_9, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,248 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_22, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,248 mps_preprocess.py:115] Visiting: aten_expand_copy_default_12, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,249 mps_preprocess.py:115] Visiting: aten_clone_default_4, aten.clone.default\n",
      "[INFO 2024-05-08 17:52:11,249 mps_preprocess.py:115] Visiting: aten_view_copy_default_51, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,249 mps_preprocess.py:115] Visiting: aten_permute_copy_default_13, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,249 mps_preprocess.py:115] Visiting: aten_expand_copy_default_15, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,250 mps_preprocess.py:115] Visiting: aten_view_copy_default_54, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,250 mps_preprocess.py:115] Visiting: aten_bmm_default_4, aten.bmm.default\n",
      "[INFO 2024-05-08 17:52:11,250 mps_preprocess.py:115] Visiting: aten_view_copy_default_55, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,251 mps_preprocess.py:115] Visiting: aten_mul_tensor_45, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,251 mps_preprocess.py:115] Visiting: aten_add_tensor_17, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,251 mps_preprocess.py:115] Visiting: aten__softmax_default_2, aten._softmax.default\n",
      "[INFO 2024-05-08 17:52:11,252 mps_preprocess.py:115] Visiting: aten_expand_copy_default_16, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,252 mps_preprocess.py:115] Visiting: aten_view_copy_default_56, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,252 mps_preprocess.py:115] Visiting: aten_bmm_default_5, aten.bmm.default\n",
      "[INFO 2024-05-08 17:52:11,252 mps_preprocess.py:115] Visiting: aten_view_copy_default_58, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,253 mps_preprocess.py:115] Visiting: aten_permute_copy_default_14, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,253 mps_preprocess.py:115] Visiting: aten_view_copy_default_59, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,253 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_27, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,254 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_17, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,254 mps_preprocess.py:115] Visiting: aten_add_tensor_18, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,254 mps_preprocess.py:115] Visiting: aten_mul_tensor_46, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,255 mps_preprocess.py:115] Visiting: aten_mean_dim_5, aten.mean.dim\n",
      "[INFO 2024-05-08 17:52:11,255 mps_preprocess.py:115] Visiting: aten_add_tensor_19, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,255 mps_preprocess.py:115] Visiting: aten_rsqrt_default_5, aten.rsqrt.default\n",
      "[INFO 2024-05-08 17:52:11,255 mps_preprocess.py:115] Visiting: aten_mul_tensor_47, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,256 mps_preprocess.py:115] Visiting: aten_mul_tensor_48, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,256 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_28, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,256 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_29, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,257 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_18, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,257 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_19, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,257 mps_preprocess.py:115] Visiting: aten_sigmoid_default_2, aten.sigmoid.default\n",
      "[INFO 2024-05-08 17:52:11,257 mps_preprocess.py:115] Visiting: aten_mul_tensor_49, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,258 mps_preprocess.py:115] Visiting: aten_mul_tensor_50, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,258 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_20, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,258 mps_preprocess.py:115] Visiting: aten_add_tensor_20, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,259 mps_preprocess.py:115] Visiting: aten_mul_tensor_51, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,259 mps_preprocess.py:115] Visiting: aten_mean_dim_6, aten.mean.dim\n",
      "[INFO 2024-05-08 17:52:11,259 mps_preprocess.py:115] Visiting: aten_add_tensor_21, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,260 mps_preprocess.py:115] Visiting: aten_rsqrt_default_6, aten.rsqrt.default\n",
      "[INFO 2024-05-08 17:52:11,260 mps_preprocess.py:115] Visiting: aten_mul_tensor_52, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,260 mps_preprocess.py:115] Visiting: aten_mul_tensor_53, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,261 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_30, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,261 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_31, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,261 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_32, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,262 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_21, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,262 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_22, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,262 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_23, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,262 mps_preprocess.py:115] Visiting: aten_view_copy_default_60, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,263 mps_preprocess.py:115] Visiting: aten_view_copy_default_61, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,263 mps_preprocess.py:115] Visiting: aten_view_copy_default_62, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,263 mps_preprocess.py:115] Visiting: aten_view_copy_default_63, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,264 mps_preprocess.py:115] Visiting: aten_view_copy_default_64, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,264 mps_preprocess.py:115] Visiting: aten_permute_copy_default_17, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,265 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_12, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,265 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_13, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,265 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_14, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,266 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_15, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,266 mps_preprocess.py:115] Visiting: aten_view_copy_default_70, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,266 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_33, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,267 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_34, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,267 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_35, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,267 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_36, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,267 mps_preprocess.py:115] Visiting: aten_index_put_default_7, aten.index_put.default\n",
      "[INFO 2024-05-08 17:52:11,268 mps_preprocess.py:115] Visiting: aten_mul_tensor_54, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,268 mps_preprocess.py:115] Visiting: aten_mul_tensor_56, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,268 mps_preprocess.py:115] Visiting: aten_mul_tensor_55, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,269 mps_preprocess.py:115] Visiting: aten_mul_tensor_57, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,269 mps_preprocess.py:115] Visiting: aten_mul_tensor_58, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,269 mps_preprocess.py:115] Visiting: aten_mul_tensor_60, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,270 mps_preprocess.py:115] Visiting: aten_mul_tensor_59, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,270 mps_preprocess.py:115] Visiting: aten_mul_tensor_61, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,270 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_14, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,271 mps_preprocess.py:115] Visiting: aten_sub_tensor_6, aten.sub.Tensor\n",
      "[INFO 2024-05-08 17:52:11,272 mps_preprocess.py:115] Visiting: aten_add_tensor_22, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,272 mps_preprocess.py:115] Visiting: aten_sub_tensor_7, aten.sub.Tensor\n",
      "[INFO 2024-05-08 17:52:11,272 mps_preprocess.py:115] Visiting: aten_add_tensor_23, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,273 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_15, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,273 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_24, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,274 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_25, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,274 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_26, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,274 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_27, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,275 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_31, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,275 mps_preprocess.py:115] Visiting: aten_cat_default_6, aten.cat.default\n",
      "[INFO 2024-05-08 17:52:11,275 mps_preprocess.py:115] Visiting: aten_cat_default_7, aten.cat.default\n",
      "[INFO 2024-05-08 17:52:11,276 mps_preprocess.py:115] Visiting: aten_expand_copy_default_19, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,276 mps_preprocess.py:115] Visiting: aten_view_copy_default_67, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,276 mps_preprocess.py:115] Visiting: aten_view_copy_default_68, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,277 mps_preprocess.py:115] Visiting: aten_clone_default_7, aten.clone.default\n",
      "[INFO 2024-05-08 17:52:11,277 mps_preprocess.py:115] Visiting: aten_permute_copy_default_15, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,277 mps_preprocess.py:115] Visiting: aten_permute_copy_default_16, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,277 mps_preprocess.py:115] Visiting: aten_view_copy_default_72, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,278 mps_preprocess.py:115] Visiting: aten_expand_copy_default_20, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,278 mps_preprocess.py:115] Visiting: aten_view_copy_default_69, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,278 mps_preprocess.py:115] Visiting: aten_expand_copy_default_23, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,278 mps_preprocess.py:115] Visiting: aten_view_copy_default_73, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,279 mps_preprocess.py:115] Visiting: aten_index_put_default_6, aten.index_put.default\n",
      "[INFO 2024-05-08 17:52:11,279 mps_preprocess.py:115] Visiting: aten_view_copy_default_77, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,279 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_12, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,280 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_13, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,281 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_30, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,281 mps_preprocess.py:115] Visiting: aten_expand_copy_default_18, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,281 mps_preprocess.py:115] Visiting: aten_clone_default_6, aten.clone.default\n",
      "[INFO 2024-05-08 17:52:11,281 mps_preprocess.py:115] Visiting: aten_view_copy_default_71, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,282 mps_preprocess.py:115] Visiting: aten_permute_copy_default_18, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,282 mps_preprocess.py:115] Visiting: aten_expand_copy_default_21, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,282 mps_preprocess.py:115] Visiting: aten_view_copy_default_74, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,283 mps_preprocess.py:115] Visiting: aten_bmm_default_6, aten.bmm.default\n",
      "[INFO 2024-05-08 17:52:11,283 mps_preprocess.py:115] Visiting: aten_view_copy_default_75, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,283 mps_preprocess.py:115] Visiting: aten_mul_tensor_62, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,283 mps_preprocess.py:115] Visiting: aten_add_tensor_24, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,284 mps_preprocess.py:115] Visiting: aten__softmax_default_3, aten._softmax.default\n",
      "[INFO 2024-05-08 17:52:11,284 mps_preprocess.py:115] Visiting: aten_expand_copy_default_22, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,284 mps_preprocess.py:115] Visiting: aten_view_copy_default_76, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,285 mps_preprocess.py:115] Visiting: aten_bmm_default_7, aten.bmm.default\n",
      "[INFO 2024-05-08 17:52:11,409 mps_preprocess.py:115] Visiting: aten_view_copy_default_78, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,410 mps_preprocess.py:115] Visiting: aten_permute_copy_default_19, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,411 mps_preprocess.py:115] Visiting: aten_view_copy_default_79, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,411 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_37, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,411 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_24, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,411 mps_preprocess.py:115] Visiting: aten_add_tensor_25, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,412 mps_preprocess.py:115] Visiting: aten_mul_tensor_63, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,412 mps_preprocess.py:115] Visiting: aten_mean_dim_7, aten.mean.dim\n",
      "[INFO 2024-05-08 17:52:11,412 mps_preprocess.py:115] Visiting: aten_add_tensor_26, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,413 mps_preprocess.py:115] Visiting: aten_rsqrt_default_7, aten.rsqrt.default\n",
      "[INFO 2024-05-08 17:52:11,413 mps_preprocess.py:115] Visiting: aten_mul_tensor_64, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,413 mps_preprocess.py:115] Visiting: aten_mul_tensor_65, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,414 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_38, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,414 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_39, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,414 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_25, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,415 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_26, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,415 mps_preprocess.py:115] Visiting: aten_sigmoid_default_3, aten.sigmoid.default\n",
      "[INFO 2024-05-08 17:52:11,415 mps_preprocess.py:115] Visiting: aten_mul_tensor_66, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,415 mps_preprocess.py:115] Visiting: aten_mul_tensor_67, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,415 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_27, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,416 mps_preprocess.py:115] Visiting: aten_add_tensor_27, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,416 mps_preprocess.py:115] Visiting: aten_mul_tensor_68, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,416 mps_preprocess.py:115] Visiting: aten_mean_dim_8, aten.mean.dim\n",
      "[INFO 2024-05-08 17:52:11,416 mps_preprocess.py:115] Visiting: aten_add_tensor_28, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,417 mps_preprocess.py:115] Visiting: aten_rsqrt_default_8, aten.rsqrt.default\n",
      "[INFO 2024-05-08 17:52:11,417 mps_preprocess.py:115] Visiting: aten_mul_tensor_69, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,417 mps_preprocess.py:115] Visiting: aten_mul_tensor_70, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,417 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_40, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,418 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_41, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,418 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_42, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,418 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_28, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,419 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_29, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,419 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_30, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,419 mps_preprocess.py:115] Visiting: aten_view_copy_default_80, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,419 mps_preprocess.py:115] Visiting: aten_view_copy_default_81, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,420 mps_preprocess.py:115] Visiting: aten_view_copy_default_82, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,420 mps_preprocess.py:115] Visiting: aten_view_copy_default_83, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,421 mps_preprocess.py:115] Visiting: aten_view_copy_default_84, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,421 mps_preprocess.py:115] Visiting: aten_permute_copy_default_22, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,421 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_16, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,422 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_17, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,422 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_18, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,423 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_19, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,423 mps_preprocess.py:115] Visiting: aten_view_copy_default_90, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,423 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_43, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,424 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_44, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,424 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_45, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,424 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_46, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,425 mps_preprocess.py:115] Visiting: aten_index_put_default_9, aten.index_put.default\n",
      "[INFO 2024-05-08 17:52:11,425 mps_preprocess.py:115] Visiting: aten_mul_tensor_71, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,425 mps_preprocess.py:115] Visiting: aten_mul_tensor_73, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,426 mps_preprocess.py:115] Visiting: aten_mul_tensor_72, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,426 mps_preprocess.py:115] Visiting: aten_mul_tensor_74, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,427 mps_preprocess.py:115] Visiting: aten_mul_tensor_75, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,427 mps_preprocess.py:115] Visiting: aten_mul_tensor_77, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,427 mps_preprocess.py:115] Visiting: aten_mul_tensor_76, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,427 mps_preprocess.py:115] Visiting: aten_mul_tensor_78, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,428 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_18, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,428 mps_preprocess.py:115] Visiting: aten_sub_tensor_8, aten.sub.Tensor\n",
      "[INFO 2024-05-08 17:52:11,429 mps_preprocess.py:115] Visiting: aten_add_tensor_29, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,429 mps_preprocess.py:115] Visiting: aten_sub_tensor_9, aten.sub.Tensor\n",
      "[INFO 2024-05-08 17:52:11,429 mps_preprocess.py:115] Visiting: aten_add_tensor_30, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,429 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_19, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,430 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_32, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,431 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_33, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,431 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_34, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,431 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_35, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,431 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_39, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,432 mps_preprocess.py:115] Visiting: aten_cat_default_8, aten.cat.default\n",
      "[INFO 2024-05-08 17:52:11,432 mps_preprocess.py:115] Visiting: aten_cat_default_9, aten.cat.default\n",
      "[INFO 2024-05-08 17:52:11,432 mps_preprocess.py:115] Visiting: aten_expand_copy_default_25, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,433 mps_preprocess.py:115] Visiting: aten_view_copy_default_87, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,433 mps_preprocess.py:115] Visiting: aten_view_copy_default_88, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,433 mps_preprocess.py:115] Visiting: aten_clone_default_9, aten.clone.default\n",
      "[INFO 2024-05-08 17:52:11,434 mps_preprocess.py:115] Visiting: aten_permute_copy_default_20, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,434 mps_preprocess.py:115] Visiting: aten_permute_copy_default_21, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,435 mps_preprocess.py:115] Visiting: aten_view_copy_default_92, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,437 mps_preprocess.py:115] Visiting: aten_expand_copy_default_26, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,437 mps_preprocess.py:115] Visiting: aten_view_copy_default_89, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,438 mps_preprocess.py:115] Visiting: aten_expand_copy_default_29, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,439 mps_preprocess.py:115] Visiting: aten_view_copy_default_93, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,440 mps_preprocess.py:115] Visiting: aten_index_put_default_8, aten.index_put.default\n",
      "[INFO 2024-05-08 17:52:11,441 mps_preprocess.py:115] Visiting: aten_view_copy_default_97, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,441 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_16, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,443 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_17, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,444 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_38, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,445 mps_preprocess.py:115] Visiting: aten_expand_copy_default_24, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,445 mps_preprocess.py:115] Visiting: aten_clone_default_8, aten.clone.default\n",
      "[INFO 2024-05-08 17:52:11,446 mps_preprocess.py:115] Visiting: aten_view_copy_default_91, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,446 mps_preprocess.py:115] Visiting: aten_permute_copy_default_23, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,447 mps_preprocess.py:115] Visiting: aten_expand_copy_default_27, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,447 mps_preprocess.py:115] Visiting: aten_view_copy_default_94, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,448 mps_preprocess.py:115] Visiting: aten_bmm_default_8, aten.bmm.default\n",
      "[INFO 2024-05-08 17:52:11,448 mps_preprocess.py:115] Visiting: aten_view_copy_default_95, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,448 mps_preprocess.py:115] Visiting: aten_mul_tensor_79, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,449 mps_preprocess.py:115] Visiting: aten_add_tensor_31, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,449 mps_preprocess.py:115] Visiting: aten__softmax_default_4, aten._softmax.default\n",
      "[INFO 2024-05-08 17:52:11,450 mps_preprocess.py:115] Visiting: aten_expand_copy_default_28, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,450 mps_preprocess.py:115] Visiting: aten_view_copy_default_96, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,451 mps_preprocess.py:115] Visiting: aten_bmm_default_9, aten.bmm.default\n",
      "[INFO 2024-05-08 17:52:11,452 mps_preprocess.py:115] Visiting: aten_view_copy_default_98, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,452 mps_preprocess.py:115] Visiting: aten_permute_copy_default_24, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,453 mps_preprocess.py:115] Visiting: aten_view_copy_default_99, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,454 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_47, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,455 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_31, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,455 mps_preprocess.py:115] Visiting: aten_add_tensor_32, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,456 mps_preprocess.py:115] Visiting: aten_mul_tensor_80, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,457 mps_preprocess.py:115] Visiting: aten_mean_dim_9, aten.mean.dim\n",
      "[INFO 2024-05-08 17:52:11,458 mps_preprocess.py:115] Visiting: aten_add_tensor_33, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,458 mps_preprocess.py:115] Visiting: aten_rsqrt_default_9, aten.rsqrt.default\n",
      "[INFO 2024-05-08 17:52:11,459 mps_preprocess.py:115] Visiting: aten_mul_tensor_81, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,460 mps_preprocess.py:115] Visiting: aten_mul_tensor_82, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,460 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_48, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,461 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_49, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,462 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_32, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,463 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_33, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,463 mps_preprocess.py:115] Visiting: aten_sigmoid_default_4, aten.sigmoid.default\n",
      "[INFO 2024-05-08 17:52:11,463 mps_preprocess.py:115] Visiting: aten_mul_tensor_83, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,464 mps_preprocess.py:115] Visiting: aten_mul_tensor_84, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,464 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_34, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,465 mps_preprocess.py:115] Visiting: aten_add_tensor_34, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,465 mps_preprocess.py:115] Visiting: aten_mul_tensor_85, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,466 mps_preprocess.py:115] Visiting: aten_mean_dim_10, aten.mean.dim\n",
      "[INFO 2024-05-08 17:52:11,466 mps_preprocess.py:115] Visiting: aten_add_tensor_35, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,467 mps_preprocess.py:115] Visiting: aten_rsqrt_default_10, aten.rsqrt.default\n",
      "[INFO 2024-05-08 17:52:11,467 mps_preprocess.py:115] Visiting: aten_mul_tensor_86, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,468 mps_preprocess.py:115] Visiting: aten_mul_tensor_87, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,468 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_50, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,469 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_51, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,469 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_52, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,470 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_35, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,470 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_36, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,471 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_37, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,471 mps_preprocess.py:115] Visiting: aten_view_copy_default_100, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,471 mps_preprocess.py:115] Visiting: aten_view_copy_default_101, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,472 mps_preprocess.py:115] Visiting: aten_view_copy_default_102, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,472 mps_preprocess.py:115] Visiting: aten_view_copy_default_103, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,472 mps_preprocess.py:115] Visiting: aten_view_copy_default_104, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,473 mps_preprocess.py:115] Visiting: aten_permute_copy_default_27, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,473 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_20, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,473 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_21, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,474 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_22, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,474 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_23, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,474 mps_preprocess.py:115] Visiting: aten_view_copy_default_110, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,475 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_53, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,475 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_54, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,475 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_55, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,476 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_56, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,476 mps_preprocess.py:115] Visiting: aten_index_put_default_11, aten.index_put.default\n",
      "[INFO 2024-05-08 17:52:11,477 mps_preprocess.py:115] Visiting: aten_mul_tensor_88, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,477 mps_preprocess.py:115] Visiting: aten_mul_tensor_90, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,514 mps_preprocess.py:115] Visiting: aten_mul_tensor_89, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,515 mps_preprocess.py:115] Visiting: aten_mul_tensor_91, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,515 mps_preprocess.py:115] Visiting: aten_mul_tensor_92, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,515 mps_preprocess.py:115] Visiting: aten_mul_tensor_94, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,515 mps_preprocess.py:115] Visiting: aten_mul_tensor_93, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,516 mps_preprocess.py:115] Visiting: aten_mul_tensor_95, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,516 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_22, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,517 mps_preprocess.py:115] Visiting: aten_sub_tensor_10, aten.sub.Tensor\n",
      "[INFO 2024-05-08 17:52:11,517 mps_preprocess.py:115] Visiting: aten_add_tensor_36, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,517 mps_preprocess.py:115] Visiting: aten_sub_tensor_11, aten.sub.Tensor\n",
      "[INFO 2024-05-08 17:52:11,518 mps_preprocess.py:115] Visiting: aten_add_tensor_37, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,518 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_23, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,519 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_40, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,519 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_41, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,519 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_42, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,520 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_43, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,520 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_47, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,520 mps_preprocess.py:115] Visiting: aten_cat_default_10, aten.cat.default\n",
      "[INFO 2024-05-08 17:52:11,520 mps_preprocess.py:115] Visiting: aten_cat_default_11, aten.cat.default\n",
      "[INFO 2024-05-08 17:52:11,521 mps_preprocess.py:115] Visiting: aten_expand_copy_default_31, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,521 mps_preprocess.py:115] Visiting: aten_view_copy_default_107, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,521 mps_preprocess.py:115] Visiting: aten_view_copy_default_108, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,522 mps_preprocess.py:115] Visiting: aten_clone_default_11, aten.clone.default\n",
      "[INFO 2024-05-08 17:52:11,522 mps_preprocess.py:115] Visiting: aten_permute_copy_default_25, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,522 mps_preprocess.py:115] Visiting: aten_permute_copy_default_26, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,522 mps_preprocess.py:115] Visiting: aten_view_copy_default_112, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,523 mps_preprocess.py:115] Visiting: aten_expand_copy_default_32, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,523 mps_preprocess.py:115] Visiting: aten_view_copy_default_109, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,523 mps_preprocess.py:115] Visiting: aten_expand_copy_default_35, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,523 mps_preprocess.py:115] Visiting: aten_view_copy_default_113, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,524 mps_preprocess.py:115] Visiting: aten_index_put_default_10, aten.index_put.default\n",
      "[INFO 2024-05-08 17:52:11,524 mps_preprocess.py:115] Visiting: aten_view_copy_default_117, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,524 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_20, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,525 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_21, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,525 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_46, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,526 mps_preprocess.py:115] Visiting: aten_expand_copy_default_30, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,526 mps_preprocess.py:115] Visiting: aten_clone_default_10, aten.clone.default\n",
      "[INFO 2024-05-08 17:52:11,527 mps_preprocess.py:115] Visiting: aten_view_copy_default_111, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,527 mps_preprocess.py:115] Visiting: aten_permute_copy_default_28, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,527 mps_preprocess.py:115] Visiting: aten_expand_copy_default_33, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,528 mps_preprocess.py:115] Visiting: aten_view_copy_default_114, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,528 mps_preprocess.py:115] Visiting: aten_bmm_default_10, aten.bmm.default\n",
      "[INFO 2024-05-08 17:52:11,528 mps_preprocess.py:115] Visiting: aten_view_copy_default_115, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,529 mps_preprocess.py:115] Visiting: aten_mul_tensor_96, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,529 mps_preprocess.py:115] Visiting: aten_add_tensor_38, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,529 mps_preprocess.py:115] Visiting: aten__softmax_default_5, aten._softmax.default\n",
      "[INFO 2024-05-08 17:52:11,530 mps_preprocess.py:115] Visiting: aten_expand_copy_default_34, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,530 mps_preprocess.py:115] Visiting: aten_view_copy_default_116, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,530 mps_preprocess.py:115] Visiting: aten_bmm_default_11, aten.bmm.default\n",
      "[INFO 2024-05-08 17:52:11,531 mps_preprocess.py:115] Visiting: aten_view_copy_default_118, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,531 mps_preprocess.py:115] Visiting: aten_permute_copy_default_29, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,531 mps_preprocess.py:115] Visiting: aten_view_copy_default_119, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,532 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_57, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,532 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_38, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,532 mps_preprocess.py:115] Visiting: aten_add_tensor_39, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,532 mps_preprocess.py:115] Visiting: aten_mul_tensor_97, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,533 mps_preprocess.py:115] Visiting: aten_mean_dim_11, aten.mean.dim\n",
      "[INFO 2024-05-08 17:52:11,533 mps_preprocess.py:115] Visiting: aten_add_tensor_40, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,533 mps_preprocess.py:115] Visiting: aten_rsqrt_default_11, aten.rsqrt.default\n",
      "[INFO 2024-05-08 17:52:11,534 mps_preprocess.py:115] Visiting: aten_mul_tensor_98, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,534 mps_preprocess.py:115] Visiting: aten_mul_tensor_99, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,534 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_58, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,535 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_59, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,535 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_39, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,535 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_40, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,536 mps_preprocess.py:115] Visiting: aten_sigmoid_default_5, aten.sigmoid.default\n",
      "[INFO 2024-05-08 17:52:11,536 mps_preprocess.py:115] Visiting: aten_mul_tensor_100, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,536 mps_preprocess.py:115] Visiting: aten_mul_tensor_101, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,537 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_41, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,537 mps_preprocess.py:115] Visiting: aten_add_tensor_41, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,537 mps_preprocess.py:115] Visiting: aten_mul_tensor_102, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,537 mps_preprocess.py:115] Visiting: aten_mean_dim_12, aten.mean.dim\n",
      "[INFO 2024-05-08 17:52:11,538 mps_preprocess.py:115] Visiting: aten_add_tensor_42, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,538 mps_preprocess.py:115] Visiting: aten_rsqrt_default_12, aten.rsqrt.default\n",
      "[INFO 2024-05-08 17:52:11,538 mps_preprocess.py:115] Visiting: aten_mul_tensor_103, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,539 mps_preprocess.py:115] Visiting: aten_mul_tensor_104, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,539 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_60, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,539 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_61, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,540 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_62, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,540 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_42, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,540 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_43, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,541 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_44, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,541 mps_preprocess.py:115] Visiting: aten_view_copy_default_120, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,541 mps_preprocess.py:115] Visiting: aten_view_copy_default_121, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,541 mps_preprocess.py:115] Visiting: aten_view_copy_default_122, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,542 mps_preprocess.py:115] Visiting: aten_view_copy_default_123, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,542 mps_preprocess.py:115] Visiting: aten_view_copy_default_124, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,542 mps_preprocess.py:115] Visiting: aten_permute_copy_default_32, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,543 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_24, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,543 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_25, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,543 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_26, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,544 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_27, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,544 mps_preprocess.py:115] Visiting: aten_view_copy_default_130, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,544 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_63, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,545 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_64, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,545 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_65, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,545 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_66, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,546 mps_preprocess.py:115] Visiting: aten_index_put_default_13, aten.index_put.default\n",
      "[INFO 2024-05-08 17:52:11,546 mps_preprocess.py:115] Visiting: aten_mul_tensor_105, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,546 mps_preprocess.py:115] Visiting: aten_mul_tensor_107, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,547 mps_preprocess.py:115] Visiting: aten_mul_tensor_106, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,547 mps_preprocess.py:115] Visiting: aten_mul_tensor_108, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,548 mps_preprocess.py:115] Visiting: aten_mul_tensor_109, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,549 mps_preprocess.py:115] Visiting: aten_mul_tensor_111, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,549 mps_preprocess.py:115] Visiting: aten_mul_tensor_110, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,549 mps_preprocess.py:115] Visiting: aten_mul_tensor_112, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,549 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_26, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,550 mps_preprocess.py:115] Visiting: aten_sub_tensor_12, aten.sub.Tensor\n",
      "[INFO 2024-05-08 17:52:11,551 mps_preprocess.py:115] Visiting: aten_add_tensor_43, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,551 mps_preprocess.py:115] Visiting: aten_sub_tensor_13, aten.sub.Tensor\n",
      "[INFO 2024-05-08 17:52:11,552 mps_preprocess.py:115] Visiting: aten_add_tensor_44, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,552 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_27, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,553 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_48, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,553 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_49, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,554 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_50, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,554 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_51, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,554 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_55, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,555 mps_preprocess.py:115] Visiting: aten_cat_default_12, aten.cat.default\n",
      "[INFO 2024-05-08 17:52:11,555 mps_preprocess.py:115] Visiting: aten_cat_default_13, aten.cat.default\n",
      "[INFO 2024-05-08 17:52:11,556 mps_preprocess.py:115] Visiting: aten_expand_copy_default_37, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,556 mps_preprocess.py:115] Visiting: aten_view_copy_default_127, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,557 mps_preprocess.py:115] Visiting: aten_view_copy_default_128, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,557 mps_preprocess.py:115] Visiting: aten_clone_default_13, aten.clone.default\n",
      "[INFO 2024-05-08 17:52:11,557 mps_preprocess.py:115] Visiting: aten_permute_copy_default_30, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,557 mps_preprocess.py:115] Visiting: aten_permute_copy_default_31, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,558 mps_preprocess.py:115] Visiting: aten_view_copy_default_132, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,558 mps_preprocess.py:115] Visiting: aten_expand_copy_default_38, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,558 mps_preprocess.py:115] Visiting: aten_view_copy_default_129, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,559 mps_preprocess.py:115] Visiting: aten_expand_copy_default_41, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,559 mps_preprocess.py:115] Visiting: aten_view_copy_default_133, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,560 mps_preprocess.py:115] Visiting: aten_index_put_default_12, aten.index_put.default\n",
      "[INFO 2024-05-08 17:52:11,560 mps_preprocess.py:115] Visiting: aten_view_copy_default_137, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,560 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_24, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,561 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_25, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,562 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_54, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,562 mps_preprocess.py:115] Visiting: aten_expand_copy_default_36, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,563 mps_preprocess.py:115] Visiting: aten_clone_default_12, aten.clone.default\n",
      "[INFO 2024-05-08 17:52:11,563 mps_preprocess.py:115] Visiting: aten_view_copy_default_131, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,563 mps_preprocess.py:115] Visiting: aten_permute_copy_default_33, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,564 mps_preprocess.py:115] Visiting: aten_expand_copy_default_39, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,564 mps_preprocess.py:115] Visiting: aten_view_copy_default_134, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,564 mps_preprocess.py:115] Visiting: aten_bmm_default_12, aten.bmm.default\n",
      "[INFO 2024-05-08 17:52:11,564 mps_preprocess.py:115] Visiting: aten_view_copy_default_135, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,565 mps_preprocess.py:115] Visiting: aten_mul_tensor_113, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,565 mps_preprocess.py:115] Visiting: aten_add_tensor_45, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,565 mps_preprocess.py:115] Visiting: aten__softmax_default_6, aten._softmax.default\n",
      "[INFO 2024-05-08 17:52:11,565 mps_preprocess.py:115] Visiting: aten_expand_copy_default_40, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,566 mps_preprocess.py:115] Visiting: aten_view_copy_default_136, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,566 mps_preprocess.py:115] Visiting: aten_bmm_default_13, aten.bmm.default\n",
      "[INFO 2024-05-08 17:52:11,567 mps_preprocess.py:115] Visiting: aten_view_copy_default_138, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,567 mps_preprocess.py:115] Visiting: aten_permute_copy_default_34, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,567 mps_preprocess.py:115] Visiting: aten_view_copy_default_139, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,567 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_67, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,568 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_45, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,568 mps_preprocess.py:115] Visiting: aten_add_tensor_46, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,568 mps_preprocess.py:115] Visiting: aten_mul_tensor_114, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,569 mps_preprocess.py:115] Visiting: aten_mean_dim_13, aten.mean.dim\n",
      "[INFO 2024-05-08 17:52:11,569 mps_preprocess.py:115] Visiting: aten_add_tensor_47, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,569 mps_preprocess.py:115] Visiting: aten_rsqrt_default_13, aten.rsqrt.default\n",
      "[INFO 2024-05-08 17:52:11,570 mps_preprocess.py:115] Visiting: aten_mul_tensor_115, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,570 mps_preprocess.py:115] Visiting: aten_mul_tensor_116, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,570 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_68, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,571 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_69, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,572 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_46, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,572 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_47, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,573 mps_preprocess.py:115] Visiting: aten_sigmoid_default_6, aten.sigmoid.default\n",
      "[INFO 2024-05-08 17:52:11,573 mps_preprocess.py:115] Visiting: aten_mul_tensor_117, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,573 mps_preprocess.py:115] Visiting: aten_mul_tensor_118, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,573 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_48, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,574 mps_preprocess.py:115] Visiting: aten_add_tensor_48, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,574 mps_preprocess.py:115] Visiting: aten_mul_tensor_119, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,574 mps_preprocess.py:115] Visiting: aten_mean_dim_14, aten.mean.dim\n",
      "[INFO 2024-05-08 17:52:11,574 mps_preprocess.py:115] Visiting: aten_add_tensor_49, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,575 mps_preprocess.py:115] Visiting: aten_rsqrt_default_14, aten.rsqrt.default\n",
      "[INFO 2024-05-08 17:52:11,575 mps_preprocess.py:115] Visiting: aten_mul_tensor_120, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,576 mps_preprocess.py:115] Visiting: aten_mul_tensor_121, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,576 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_70, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,576 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_71, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,577 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_72, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,577 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_49, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,577 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_50, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,577 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_51, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,578 mps_preprocess.py:115] Visiting: aten_view_copy_default_140, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,578 mps_preprocess.py:115] Visiting: aten_view_copy_default_141, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,579 mps_preprocess.py:115] Visiting: aten_view_copy_default_142, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,579 mps_preprocess.py:115] Visiting: aten_view_copy_default_143, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,579 mps_preprocess.py:115] Visiting: aten_view_copy_default_144, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,580 mps_preprocess.py:115] Visiting: aten_permute_copy_default_37, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,580 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_28, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,581 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_29, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,581 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_30, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,581 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_31, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,582 mps_preprocess.py:115] Visiting: aten_view_copy_default_150, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,582 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_73, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,582 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_74, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,584 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_75, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,587 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_76, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,595 mps_preprocess.py:115] Visiting: aten_index_put_default_15, aten.index_put.default\n",
      "[INFO 2024-05-08 17:52:11,598 mps_preprocess.py:115] Visiting: aten_mul_tensor_122, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,600 mps_preprocess.py:115] Visiting: aten_mul_tensor_124, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,602 mps_preprocess.py:115] Visiting: aten_mul_tensor_123, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,604 mps_preprocess.py:115] Visiting: aten_mul_tensor_125, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,608 mps_preprocess.py:115] Visiting: aten_mul_tensor_126, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,609 mps_preprocess.py:115] Visiting: aten_mul_tensor_128, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,611 mps_preprocess.py:115] Visiting: aten_mul_tensor_127, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,612 mps_preprocess.py:115] Visiting: aten_mul_tensor_129, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,615 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_30, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,620 mps_preprocess.py:115] Visiting: aten_sub_tensor_14, aten.sub.Tensor\n",
      "[INFO 2024-05-08 17:52:11,621 mps_preprocess.py:115] Visiting: aten_add_tensor_50, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,623 mps_preprocess.py:115] Visiting: aten_sub_tensor_15, aten.sub.Tensor\n",
      "[INFO 2024-05-08 17:52:11,623 mps_preprocess.py:115] Visiting: aten_add_tensor_51, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,625 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_31, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,627 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_56, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,628 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_57, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,628 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_58, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,628 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_59, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,628 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_63, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,629 mps_preprocess.py:115] Visiting: aten_cat_default_14, aten.cat.default\n",
      "[INFO 2024-05-08 17:52:11,629 mps_preprocess.py:115] Visiting: aten_cat_default_15, aten.cat.default\n",
      "[INFO 2024-05-08 17:52:11,629 mps_preprocess.py:115] Visiting: aten_expand_copy_default_43, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,630 mps_preprocess.py:115] Visiting: aten_view_copy_default_147, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,630 mps_preprocess.py:115] Visiting: aten_view_copy_default_148, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,630 mps_preprocess.py:115] Visiting: aten_clone_default_15, aten.clone.default\n",
      "[INFO 2024-05-08 17:52:11,630 mps_preprocess.py:115] Visiting: aten_permute_copy_default_35, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,630 mps_preprocess.py:115] Visiting: aten_permute_copy_default_36, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,631 mps_preprocess.py:115] Visiting: aten_view_copy_default_152, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,631 mps_preprocess.py:115] Visiting: aten_expand_copy_default_44, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,631 mps_preprocess.py:115] Visiting: aten_view_copy_default_149, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,632 mps_preprocess.py:115] Visiting: aten_expand_copy_default_47, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,632 mps_preprocess.py:115] Visiting: aten_view_copy_default_153, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,632 mps_preprocess.py:115] Visiting: aten_index_put_default_14, aten.index_put.default\n",
      "[INFO 2024-05-08 17:52:11,633 mps_preprocess.py:115] Visiting: aten_view_copy_default_157, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,633 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_28, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,635 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_29, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,636 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_62, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,637 mps_preprocess.py:115] Visiting: aten_expand_copy_default_42, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,637 mps_preprocess.py:115] Visiting: aten_clone_default_14, aten.clone.default\n",
      "[INFO 2024-05-08 17:52:11,637 mps_preprocess.py:115] Visiting: aten_view_copy_default_151, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,637 mps_preprocess.py:115] Visiting: aten_permute_copy_default_38, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,637 mps_preprocess.py:115] Visiting: aten_expand_copy_default_45, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,638 mps_preprocess.py:115] Visiting: aten_view_copy_default_154, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,638 mps_preprocess.py:115] Visiting: aten_bmm_default_14, aten.bmm.default\n",
      "[INFO 2024-05-08 17:52:11,639 mps_preprocess.py:115] Visiting: aten_view_copy_default_155, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,639 mps_preprocess.py:115] Visiting: aten_mul_tensor_130, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,639 mps_preprocess.py:115] Visiting: aten_add_tensor_52, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,640 mps_preprocess.py:115] Visiting: aten__softmax_default_7, aten._softmax.default\n",
      "[INFO 2024-05-08 17:52:11,640 mps_preprocess.py:115] Visiting: aten_expand_copy_default_46, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,640 mps_preprocess.py:115] Visiting: aten_view_copy_default_156, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,641 mps_preprocess.py:115] Visiting: aten_bmm_default_15, aten.bmm.default\n",
      "[INFO 2024-05-08 17:52:11,641 mps_preprocess.py:115] Visiting: aten_view_copy_default_158, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,641 mps_preprocess.py:115] Visiting: aten_permute_copy_default_39, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,642 mps_preprocess.py:115] Visiting: aten_view_copy_default_159, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,642 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_77, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,642 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_52, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,643 mps_preprocess.py:115] Visiting: aten_add_tensor_53, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,643 mps_preprocess.py:115] Visiting: aten_mul_tensor_131, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,643 mps_preprocess.py:115] Visiting: aten_mean_dim_15, aten.mean.dim\n",
      "[INFO 2024-05-08 17:52:11,644 mps_preprocess.py:115] Visiting: aten_add_tensor_54, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,644 mps_preprocess.py:115] Visiting: aten_rsqrt_default_15, aten.rsqrt.default\n",
      "[INFO 2024-05-08 17:52:11,644 mps_preprocess.py:115] Visiting: aten_mul_tensor_132, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,645 mps_preprocess.py:115] Visiting: aten_mul_tensor_133, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,645 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_78, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,645 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_79, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,645 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_53, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,646 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_54, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,646 mps_preprocess.py:115] Visiting: aten_sigmoid_default_7, aten.sigmoid.default\n",
      "[INFO 2024-05-08 17:52:11,646 mps_preprocess.py:115] Visiting: aten_mul_tensor_134, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,647 mps_preprocess.py:115] Visiting: aten_mul_tensor_135, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,647 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_55, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,647 mps_preprocess.py:115] Visiting: aten_add_tensor_55, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,648 mps_preprocess.py:115] Visiting: aten_mul_tensor_136, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,648 mps_preprocess.py:115] Visiting: aten_mean_dim_16, aten.mean.dim\n",
      "[INFO 2024-05-08 17:52:11,648 mps_preprocess.py:115] Visiting: aten_add_tensor_56, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,649 mps_preprocess.py:115] Visiting: aten_rsqrt_default_16, aten.rsqrt.default\n",
      "[INFO 2024-05-08 17:52:11,649 mps_preprocess.py:115] Visiting: aten_mul_tensor_137, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,649 mps_preprocess.py:115] Visiting: aten_mul_tensor_138, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,649 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_80, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,650 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_81, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,650 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_82, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,650 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_56, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,651 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_57, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,651 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_58, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,651 mps_preprocess.py:115] Visiting: aten_view_copy_default_160, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,651 mps_preprocess.py:115] Visiting: aten_view_copy_default_161, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,652 mps_preprocess.py:115] Visiting: aten_view_copy_default_162, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,652 mps_preprocess.py:115] Visiting: aten_view_copy_default_163, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,652 mps_preprocess.py:115] Visiting: aten_view_copy_default_164, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,653 mps_preprocess.py:115] Visiting: aten_permute_copy_default_42, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,653 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_32, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,653 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_33, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,653 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_34, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,654 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_35, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,654 mps_preprocess.py:115] Visiting: aten_view_copy_default_170, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,654 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_83, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,655 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_84, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,655 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_85, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,655 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_86, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,656 mps_preprocess.py:115] Visiting: aten_index_put_default_17, aten.index_put.default\n",
      "[INFO 2024-05-08 17:52:11,656 mps_preprocess.py:115] Visiting: aten_mul_tensor_139, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,656 mps_preprocess.py:115] Visiting: aten_mul_tensor_141, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,656 mps_preprocess.py:115] Visiting: aten_mul_tensor_140, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,656 mps_preprocess.py:115] Visiting: aten_mul_tensor_142, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,657 mps_preprocess.py:115] Visiting: aten_mul_tensor_143, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,657 mps_preprocess.py:115] Visiting: aten_mul_tensor_145, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,657 mps_preprocess.py:115] Visiting: aten_mul_tensor_144, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,657 mps_preprocess.py:115] Visiting: aten_mul_tensor_146, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,658 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_34, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,658 mps_preprocess.py:115] Visiting: aten_sub_tensor_16, aten.sub.Tensor\n",
      "[INFO 2024-05-08 17:52:11,659 mps_preprocess.py:115] Visiting: aten_add_tensor_57, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,659 mps_preprocess.py:115] Visiting: aten_sub_tensor_17, aten.sub.Tensor\n",
      "[INFO 2024-05-08 17:52:11,659 mps_preprocess.py:115] Visiting: aten_add_tensor_58, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,660 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_35, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,660 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_64, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,660 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_65, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,661 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_66, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,661 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_67, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,661 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_71, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,661 mps_preprocess.py:115] Visiting: aten_cat_default_16, aten.cat.default\n",
      "[INFO 2024-05-08 17:52:11,662 mps_preprocess.py:115] Visiting: aten_cat_default_17, aten.cat.default\n",
      "[INFO 2024-05-08 17:52:11,662 mps_preprocess.py:115] Visiting: aten_expand_copy_default_49, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,662 mps_preprocess.py:115] Visiting: aten_view_copy_default_167, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,662 mps_preprocess.py:115] Visiting: aten_view_copy_default_168, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,663 mps_preprocess.py:115] Visiting: aten_clone_default_17, aten.clone.default\n",
      "[INFO 2024-05-08 17:52:11,663 mps_preprocess.py:115] Visiting: aten_permute_copy_default_40, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,663 mps_preprocess.py:115] Visiting: aten_permute_copy_default_41, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,663 mps_preprocess.py:115] Visiting: aten_view_copy_default_172, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,664 mps_preprocess.py:115] Visiting: aten_expand_copy_default_50, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,664 mps_preprocess.py:115] Visiting: aten_view_copy_default_169, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,664 mps_preprocess.py:115] Visiting: aten_expand_copy_default_53, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,664 mps_preprocess.py:115] Visiting: aten_view_copy_default_173, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,665 mps_preprocess.py:115] Visiting: aten_index_put_default_16, aten.index_put.default\n",
      "[INFO 2024-05-08 17:52:11,665 mps_preprocess.py:115] Visiting: aten_view_copy_default_177, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,665 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_32, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,666 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_33, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,728 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_70, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,729 mps_preprocess.py:115] Visiting: aten_expand_copy_default_48, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,729 mps_preprocess.py:115] Visiting: aten_clone_default_16, aten.clone.default\n",
      "[INFO 2024-05-08 17:52:11,729 mps_preprocess.py:115] Visiting: aten_view_copy_default_171, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,729 mps_preprocess.py:115] Visiting: aten_permute_copy_default_43, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,730 mps_preprocess.py:115] Visiting: aten_expand_copy_default_51, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,730 mps_preprocess.py:115] Visiting: aten_view_copy_default_174, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,730 mps_preprocess.py:115] Visiting: aten_bmm_default_16, aten.bmm.default\n",
      "[INFO 2024-05-08 17:52:11,731 mps_preprocess.py:115] Visiting: aten_view_copy_default_175, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,731 mps_preprocess.py:115] Visiting: aten_mul_tensor_147, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,731 mps_preprocess.py:115] Visiting: aten_add_tensor_59, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,732 mps_preprocess.py:115] Visiting: aten__softmax_default_8, aten._softmax.default\n",
      "[INFO 2024-05-08 17:52:11,732 mps_preprocess.py:115] Visiting: aten_expand_copy_default_52, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,732 mps_preprocess.py:115] Visiting: aten_view_copy_default_176, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,733 mps_preprocess.py:115] Visiting: aten_bmm_default_17, aten.bmm.default\n",
      "[INFO 2024-05-08 17:52:11,733 mps_preprocess.py:115] Visiting: aten_view_copy_default_178, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,733 mps_preprocess.py:115] Visiting: aten_permute_copy_default_44, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,734 mps_preprocess.py:115] Visiting: aten_view_copy_default_179, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,734 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_87, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,734 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_59, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,735 mps_preprocess.py:115] Visiting: aten_add_tensor_60, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,735 mps_preprocess.py:115] Visiting: aten_mul_tensor_148, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,735 mps_preprocess.py:115] Visiting: aten_mean_dim_17, aten.mean.dim\n",
      "[INFO 2024-05-08 17:52:11,736 mps_preprocess.py:115] Visiting: aten_add_tensor_61, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,736 mps_preprocess.py:115] Visiting: aten_rsqrt_default_17, aten.rsqrt.default\n",
      "[INFO 2024-05-08 17:52:11,736 mps_preprocess.py:115] Visiting: aten_mul_tensor_149, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,737 mps_preprocess.py:115] Visiting: aten_mul_tensor_150, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,737 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_88, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,737 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_89, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,738 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_60, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,738 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_61, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,739 mps_preprocess.py:115] Visiting: aten_sigmoid_default_8, aten.sigmoid.default\n",
      "[INFO 2024-05-08 17:52:11,739 mps_preprocess.py:115] Visiting: aten_mul_tensor_151, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,739 mps_preprocess.py:115] Visiting: aten_mul_tensor_152, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,740 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_62, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,740 mps_preprocess.py:115] Visiting: aten_add_tensor_62, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,740 mps_preprocess.py:115] Visiting: aten_mul_tensor_153, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,741 mps_preprocess.py:115] Visiting: aten_mean_dim_18, aten.mean.dim\n",
      "[INFO 2024-05-08 17:52:11,741 mps_preprocess.py:115] Visiting: aten_add_tensor_63, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,741 mps_preprocess.py:115] Visiting: aten_rsqrt_default_18, aten.rsqrt.default\n",
      "[INFO 2024-05-08 17:52:11,742 mps_preprocess.py:115] Visiting: aten_mul_tensor_154, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,742 mps_preprocess.py:115] Visiting: aten_mul_tensor_155, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,743 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_90, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,743 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_91, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,743 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_92, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,744 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_63, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,744 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_64, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,744 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_65, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,745 mps_preprocess.py:115] Visiting: aten_view_copy_default_180, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,745 mps_preprocess.py:115] Visiting: aten_view_copy_default_181, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,745 mps_preprocess.py:115] Visiting: aten_view_copy_default_182, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,746 mps_preprocess.py:115] Visiting: aten_view_copy_default_183, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,746 mps_preprocess.py:115] Visiting: aten_view_copy_default_184, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,746 mps_preprocess.py:115] Visiting: aten_permute_copy_default_47, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,746 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_36, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,747 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_37, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,747 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_38, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,747 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_39, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,748 mps_preprocess.py:115] Visiting: aten_view_copy_default_190, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,748 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_93, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,748 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_94, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,748 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_95, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,749 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_96, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,749 mps_preprocess.py:115] Visiting: aten_index_put_default_19, aten.index_put.default\n",
      "[INFO 2024-05-08 17:52:11,749 mps_preprocess.py:115] Visiting: aten_mul_tensor_156, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,749 mps_preprocess.py:115] Visiting: aten_mul_tensor_158, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,750 mps_preprocess.py:115] Visiting: aten_mul_tensor_157, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,750 mps_preprocess.py:115] Visiting: aten_mul_tensor_159, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,750 mps_preprocess.py:115] Visiting: aten_mul_tensor_160, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,751 mps_preprocess.py:115] Visiting: aten_mul_tensor_162, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,751 mps_preprocess.py:115] Visiting: aten_mul_tensor_161, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,751 mps_preprocess.py:115] Visiting: aten_mul_tensor_163, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,751 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_38, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,752 mps_preprocess.py:115] Visiting: aten_sub_tensor_18, aten.sub.Tensor\n",
      "[INFO 2024-05-08 17:52:11,752 mps_preprocess.py:115] Visiting: aten_add_tensor_64, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,753 mps_preprocess.py:115] Visiting: aten_sub_tensor_19, aten.sub.Tensor\n",
      "[INFO 2024-05-08 17:52:11,753 mps_preprocess.py:115] Visiting: aten_add_tensor_65, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,753 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_39, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,754 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_72, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,755 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_73, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,755 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_74, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,755 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_75, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,756 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_79, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,756 mps_preprocess.py:115] Visiting: aten_cat_default_18, aten.cat.default\n",
      "[INFO 2024-05-08 17:52:11,756 mps_preprocess.py:115] Visiting: aten_cat_default_19, aten.cat.default\n",
      "[INFO 2024-05-08 17:52:11,757 mps_preprocess.py:115] Visiting: aten_expand_copy_default_55, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,757 mps_preprocess.py:115] Visiting: aten_view_copy_default_187, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,757 mps_preprocess.py:115] Visiting: aten_view_copy_default_188, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,757 mps_preprocess.py:115] Visiting: aten_clone_default_19, aten.clone.default\n",
      "[INFO 2024-05-08 17:52:11,758 mps_preprocess.py:115] Visiting: aten_permute_copy_default_45, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,758 mps_preprocess.py:115] Visiting: aten_permute_copy_default_46, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,758 mps_preprocess.py:115] Visiting: aten_view_copy_default_192, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,758 mps_preprocess.py:115] Visiting: aten_expand_copy_default_56, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,759 mps_preprocess.py:115] Visiting: aten_view_copy_default_189, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,759 mps_preprocess.py:115] Visiting: aten_expand_copy_default_59, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,759 mps_preprocess.py:115] Visiting: aten_view_copy_default_193, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,760 mps_preprocess.py:115] Visiting: aten_index_put_default_18, aten.index_put.default\n",
      "[INFO 2024-05-08 17:52:11,760 mps_preprocess.py:115] Visiting: aten_view_copy_default_197, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,760 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_36, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,761 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_37, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,762 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_78, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,762 mps_preprocess.py:115] Visiting: aten_expand_copy_default_54, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,763 mps_preprocess.py:115] Visiting: aten_clone_default_18, aten.clone.default\n",
      "[INFO 2024-05-08 17:52:11,763 mps_preprocess.py:115] Visiting: aten_view_copy_default_191, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,763 mps_preprocess.py:115] Visiting: aten_permute_copy_default_48, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,764 mps_preprocess.py:115] Visiting: aten_expand_copy_default_57, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,764 mps_preprocess.py:115] Visiting: aten_view_copy_default_194, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,764 mps_preprocess.py:115] Visiting: aten_bmm_default_18, aten.bmm.default\n",
      "[INFO 2024-05-08 17:52:11,765 mps_preprocess.py:115] Visiting: aten_view_copy_default_195, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,765 mps_preprocess.py:115] Visiting: aten_mul_tensor_164, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,765 mps_preprocess.py:115] Visiting: aten_add_tensor_66, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,765 mps_preprocess.py:115] Visiting: aten__softmax_default_9, aten._softmax.default\n",
      "[INFO 2024-05-08 17:52:11,766 mps_preprocess.py:115] Visiting: aten_expand_copy_default_58, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,766 mps_preprocess.py:115] Visiting: aten_view_copy_default_196, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,767 mps_preprocess.py:115] Visiting: aten_bmm_default_19, aten.bmm.default\n",
      "[INFO 2024-05-08 17:52:11,767 mps_preprocess.py:115] Visiting: aten_view_copy_default_198, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,767 mps_preprocess.py:115] Visiting: aten_permute_copy_default_49, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,768 mps_preprocess.py:115] Visiting: aten_view_copy_default_199, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,768 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_97, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,768 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_66, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,769 mps_preprocess.py:115] Visiting: aten_add_tensor_67, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,769 mps_preprocess.py:115] Visiting: aten_mul_tensor_165, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,770 mps_preprocess.py:115] Visiting: aten_mean_dim_19, aten.mean.dim\n",
      "[INFO 2024-05-08 17:52:11,770 mps_preprocess.py:115] Visiting: aten_add_tensor_68, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,770 mps_preprocess.py:115] Visiting: aten_rsqrt_default_19, aten.rsqrt.default\n",
      "[INFO 2024-05-08 17:52:11,771 mps_preprocess.py:115] Visiting: aten_mul_tensor_166, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,771 mps_preprocess.py:115] Visiting: aten_mul_tensor_167, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,771 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_98, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,772 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_99, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,772 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_67, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,773 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_68, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,773 mps_preprocess.py:115] Visiting: aten_sigmoid_default_9, aten.sigmoid.default\n",
      "[INFO 2024-05-08 17:52:11,773 mps_preprocess.py:115] Visiting: aten_mul_tensor_168, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,774 mps_preprocess.py:115] Visiting: aten_mul_tensor_169, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,774 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_69, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,774 mps_preprocess.py:115] Visiting: aten_add_tensor_69, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,775 mps_preprocess.py:115] Visiting: aten_mul_tensor_170, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,775 mps_preprocess.py:115] Visiting: aten_mean_dim_20, aten.mean.dim\n",
      "[INFO 2024-05-08 17:52:11,776 mps_preprocess.py:115] Visiting: aten_add_tensor_70, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,776 mps_preprocess.py:115] Visiting: aten_rsqrt_default_20, aten.rsqrt.default\n",
      "[INFO 2024-05-08 17:52:11,777 mps_preprocess.py:115] Visiting: aten_mul_tensor_171, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,777 mps_preprocess.py:115] Visiting: aten_mul_tensor_172, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,777 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_100, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,778 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_101, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,778 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_102, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,778 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_70, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,779 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_71, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,779 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_72, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,779 mps_preprocess.py:115] Visiting: aten_view_copy_default_200, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,780 mps_preprocess.py:115] Visiting: aten_view_copy_default_201, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,780 mps_preprocess.py:115] Visiting: aten_view_copy_default_202, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,781 mps_preprocess.py:115] Visiting: aten_view_copy_default_203, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,781 mps_preprocess.py:115] Visiting: aten_view_copy_default_204, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,781 mps_preprocess.py:115] Visiting: aten_permute_copy_default_52, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,782 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_40, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,782 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_41, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,782 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_42, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,783 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_43, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,783 mps_preprocess.py:115] Visiting: aten_view_copy_default_210, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,783 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_103, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,784 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_104, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,784 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_105, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,784 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_106, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,785 mps_preprocess.py:115] Visiting: aten_index_put_default_21, aten.index_put.default\n",
      "[INFO 2024-05-08 17:52:11,785 mps_preprocess.py:115] Visiting: aten_mul_tensor_173, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,785 mps_preprocess.py:115] Visiting: aten_mul_tensor_175, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,786 mps_preprocess.py:115] Visiting: aten_mul_tensor_174, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,786 mps_preprocess.py:115] Visiting: aten_mul_tensor_176, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,786 mps_preprocess.py:115] Visiting: aten_mul_tensor_177, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,787 mps_preprocess.py:115] Visiting: aten_mul_tensor_179, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,787 mps_preprocess.py:115] Visiting: aten_mul_tensor_178, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,788 mps_preprocess.py:115] Visiting: aten_mul_tensor_180, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,788 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_42, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,789 mps_preprocess.py:115] Visiting: aten_sub_tensor_20, aten.sub.Tensor\n",
      "[INFO 2024-05-08 17:52:11,789 mps_preprocess.py:115] Visiting: aten_add_tensor_71, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,790 mps_preprocess.py:115] Visiting: aten_sub_tensor_21, aten.sub.Tensor\n",
      "[INFO 2024-05-08 17:52:11,790 mps_preprocess.py:115] Visiting: aten_add_tensor_72, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,791 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_43, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,792 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_80, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,792 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_81, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,793 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_82, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,793 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_83, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,794 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_87, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,794 mps_preprocess.py:115] Visiting: aten_cat_default_20, aten.cat.default\n",
      "[INFO 2024-05-08 17:52:11,795 mps_preprocess.py:115] Visiting: aten_cat_default_21, aten.cat.default\n",
      "[INFO 2024-05-08 17:52:11,795 mps_preprocess.py:115] Visiting: aten_expand_copy_default_61, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,795 mps_preprocess.py:115] Visiting: aten_view_copy_default_207, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,795 mps_preprocess.py:115] Visiting: aten_view_copy_default_208, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,796 mps_preprocess.py:115] Visiting: aten_clone_default_21, aten.clone.default\n",
      "[INFO 2024-05-08 17:52:11,796 mps_preprocess.py:115] Visiting: aten_permute_copy_default_50, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,796 mps_preprocess.py:115] Visiting: aten_permute_copy_default_51, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,797 mps_preprocess.py:115] Visiting: aten_view_copy_default_212, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,797 mps_preprocess.py:115] Visiting: aten_expand_copy_default_62, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,797 mps_preprocess.py:115] Visiting: aten_view_copy_default_209, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,798 mps_preprocess.py:115] Visiting: aten_expand_copy_default_65, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,798 mps_preprocess.py:115] Visiting: aten_view_copy_default_213, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,799 mps_preprocess.py:115] Visiting: aten_index_put_default_20, aten.index_put.default\n",
      "[INFO 2024-05-08 17:52:11,799 mps_preprocess.py:115] Visiting: aten_view_copy_default_217, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,799 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_40, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,800 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_41, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,801 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_86, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,801 mps_preprocess.py:115] Visiting: aten_expand_copy_default_60, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,801 mps_preprocess.py:115] Visiting: aten_clone_default_20, aten.clone.default\n",
      "[INFO 2024-05-08 17:52:11,801 mps_preprocess.py:115] Visiting: aten_view_copy_default_211, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,802 mps_preprocess.py:115] Visiting: aten_permute_copy_default_53, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,802 mps_preprocess.py:115] Visiting: aten_expand_copy_default_63, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,802 mps_preprocess.py:115] Visiting: aten_view_copy_default_214, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,803 mps_preprocess.py:115] Visiting: aten_bmm_default_20, aten.bmm.default\n",
      "[INFO 2024-05-08 17:52:11,803 mps_preprocess.py:115] Visiting: aten_view_copy_default_215, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,804 mps_preprocess.py:115] Visiting: aten_mul_tensor_181, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,804 mps_preprocess.py:115] Visiting: aten_add_tensor_73, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,805 mps_preprocess.py:115] Visiting: aten__softmax_default_10, aten._softmax.default\n",
      "[INFO 2024-05-08 17:52:11,805 mps_preprocess.py:115] Visiting: aten_expand_copy_default_64, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,806 mps_preprocess.py:115] Visiting: aten_view_copy_default_216, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,806 mps_preprocess.py:115] Visiting: aten_bmm_default_21, aten.bmm.default\n",
      "[INFO 2024-05-08 17:52:11,806 mps_preprocess.py:115] Visiting: aten_view_copy_default_218, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,807 mps_preprocess.py:115] Visiting: aten_permute_copy_default_54, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,807 mps_preprocess.py:115] Visiting: aten_view_copy_default_219, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,807 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_107, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,808 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_73, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,808 mps_preprocess.py:115] Visiting: aten_add_tensor_74, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,809 mps_preprocess.py:115] Visiting: aten_mul_tensor_182, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,809 mps_preprocess.py:115] Visiting: aten_mean_dim_21, aten.mean.dim\n",
      "[INFO 2024-05-08 17:52:11,810 mps_preprocess.py:115] Visiting: aten_add_tensor_75, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,810 mps_preprocess.py:115] Visiting: aten_rsqrt_default_21, aten.rsqrt.default\n",
      "[INFO 2024-05-08 17:52:11,810 mps_preprocess.py:115] Visiting: aten_mul_tensor_183, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,811 mps_preprocess.py:115] Visiting: aten_mul_tensor_184, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,811 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_108, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,812 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_109, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,812 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_74, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,812 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_75, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,813 mps_preprocess.py:115] Visiting: aten_sigmoid_default_10, aten.sigmoid.default\n",
      "[INFO 2024-05-08 17:52:11,813 mps_preprocess.py:115] Visiting: aten_mul_tensor_185, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,813 mps_preprocess.py:115] Visiting: aten_mul_tensor_186, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,814 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_76, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,814 mps_preprocess.py:115] Visiting: aten_add_tensor_76, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,814 mps_preprocess.py:115] Visiting: aten_mul_tensor_187, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,814 mps_preprocess.py:115] Visiting: aten_mean_dim_22, aten.mean.dim\n",
      "[INFO 2024-05-08 17:52:11,815 mps_preprocess.py:115] Visiting: aten_add_tensor_77, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,815 mps_preprocess.py:115] Visiting: aten_rsqrt_default_22, aten.rsqrt.default\n",
      "[INFO 2024-05-08 17:52:11,816 mps_preprocess.py:115] Visiting: aten_mul_tensor_188, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,816 mps_preprocess.py:115] Visiting: aten_mul_tensor_189, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,816 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_110, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,816 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_111, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,817 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_112, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,817 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_77, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,817 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_78, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,818 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_79, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,818 mps_preprocess.py:115] Visiting: aten_view_copy_default_220, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,819 mps_preprocess.py:115] Visiting: aten_view_copy_default_221, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,819 mps_preprocess.py:115] Visiting: aten_view_copy_default_222, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,819 mps_preprocess.py:115] Visiting: aten_view_copy_default_223, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,820 mps_preprocess.py:115] Visiting: aten_view_copy_default_224, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,820 mps_preprocess.py:115] Visiting: aten_permute_copy_default_57, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,821 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_44, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,821 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_45, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,822 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_46, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,822 mps_preprocess.py:115] Visiting: aten_slice_copy_tensor_47, aten.slice_copy.Tensor\n",
      "[INFO 2024-05-08 17:52:11,822 mps_preprocess.py:115] Visiting: aten_view_copy_default_230, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,822 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_113, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,823 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_114, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,823 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_115, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,823 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_116, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,824 mps_preprocess.py:115] Visiting: aten_index_put_default_23, aten.index_put.default\n",
      "[INFO 2024-05-08 17:52:11,824 mps_preprocess.py:115] Visiting: aten_mul_tensor_190, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,824 mps_preprocess.py:115] Visiting: aten_mul_tensor_192, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,825 mps_preprocess.py:115] Visiting: aten_mul_tensor_191, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,825 mps_preprocess.py:115] Visiting: aten_mul_tensor_193, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,825 mps_preprocess.py:115] Visiting: aten_mul_tensor_194, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,825 mps_preprocess.py:115] Visiting: aten_mul_tensor_196, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,826 mps_preprocess.py:115] Visiting: aten_mul_tensor_195, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,826 mps_preprocess.py:115] Visiting: aten_mul_tensor_197, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,826 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_46, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,828 mps_preprocess.py:115] Visiting: aten_sub_tensor_22, aten.sub.Tensor\n",
      "[INFO 2024-05-08 17:52:11,828 mps_preprocess.py:115] Visiting: aten_add_tensor_78, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,828 mps_preprocess.py:115] Visiting: aten_sub_tensor_23, aten.sub.Tensor\n",
      "[INFO 2024-05-08 17:52:11,829 mps_preprocess.py:115] Visiting: aten_add_tensor_79, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,829 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_47, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,830 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_88, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,830 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_89, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,830 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_90, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,831 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_91, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,831 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_95, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,831 mps_preprocess.py:115] Visiting: aten_cat_default_22, aten.cat.default\n",
      "[INFO 2024-05-08 17:52:11,832 mps_preprocess.py:115] Visiting: aten_cat_default_23, aten.cat.default\n",
      "[INFO 2024-05-08 17:52:11,832 mps_preprocess.py:115] Visiting: aten_expand_copy_default_67, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,832 mps_preprocess.py:115] Visiting: aten_view_copy_default_227, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,833 mps_preprocess.py:115] Visiting: aten_view_copy_default_228, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,833 mps_preprocess.py:115] Visiting: aten_clone_default_23, aten.clone.default\n",
      "[INFO 2024-05-08 17:52:11,833 mps_preprocess.py:115] Visiting: aten_permute_copy_default_55, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,834 mps_preprocess.py:115] Visiting: aten_permute_copy_default_56, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,834 mps_preprocess.py:115] Visiting: aten_view_copy_default_232, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,834 mps_preprocess.py:115] Visiting: aten_expand_copy_default_68, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,835 mps_preprocess.py:115] Visiting: aten_view_copy_default_229, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,835 mps_preprocess.py:115] Visiting: aten_expand_copy_default_71, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,836 mps_preprocess.py:115] Visiting: aten_view_copy_default_233, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,836 mps_preprocess.py:115] Visiting: aten_index_put_default_22, aten.index_put.default\n",
      "[INFO 2024-05-08 17:52:11,837 mps_preprocess.py:115] Visiting: aten_view_copy_default_237, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,837 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_44, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,838 mps_preprocess.py:115] Visiting: aten_slice_scatter_default_45, aten.slice_scatter.default\n",
      "[INFO 2024-05-08 17:52:11,839 mps_preprocess.py:115] Visiting: aten_unsqueeze_copy_default_94, aten.unsqueeze_copy.default\n",
      "[INFO 2024-05-08 17:52:11,839 mps_preprocess.py:115] Visiting: aten_expand_copy_default_66, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,840 mps_preprocess.py:115] Visiting: aten_clone_default_22, aten.clone.default\n",
      "[INFO 2024-05-08 17:52:11,840 mps_preprocess.py:115] Visiting: aten_view_copy_default_231, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,840 mps_preprocess.py:115] Visiting: aten_permute_copy_default_58, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,841 mps_preprocess.py:115] Visiting: aten_expand_copy_default_69, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,841 mps_preprocess.py:115] Visiting: aten_view_copy_default_234, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,841 mps_preprocess.py:115] Visiting: aten_bmm_default_22, aten.bmm.default\n",
      "[INFO 2024-05-08 17:52:11,842 mps_preprocess.py:115] Visiting: aten_view_copy_default_235, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,842 mps_preprocess.py:115] Visiting: aten_mul_tensor_198, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,842 mps_preprocess.py:115] Visiting: aten_add_tensor_80, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,843 mps_preprocess.py:115] Visiting: aten__softmax_default_11, aten._softmax.default\n",
      "[INFO 2024-05-08 17:52:11,843 mps_preprocess.py:115] Visiting: aten_expand_copy_default_70, aten.expand_copy.default\n",
      "[INFO 2024-05-08 17:52:11,843 mps_preprocess.py:115] Visiting: aten_view_copy_default_236, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,844 mps_preprocess.py:115] Visiting: aten_bmm_default_23, aten.bmm.default\n",
      "[INFO 2024-05-08 17:52:11,844 mps_preprocess.py:115] Visiting: aten_view_copy_default_238, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,844 mps_preprocess.py:115] Visiting: aten_permute_copy_default_59, aten.permute_copy.default\n",
      "[INFO 2024-05-08 17:52:11,845 mps_preprocess.py:115] Visiting: aten_view_copy_default_239, aten.view_copy.default\n",
      "[INFO 2024-05-08 17:52:11,845 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_117, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,845 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_80, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,846 mps_preprocess.py:115] Visiting: aten_add_tensor_81, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,846 mps_preprocess.py:115] Visiting: aten_mul_tensor_199, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,846 mps_preprocess.py:115] Visiting: aten_mean_dim_23, aten.mean.dim\n",
      "[INFO 2024-05-08 17:52:11,847 mps_preprocess.py:115] Visiting: aten_add_tensor_82, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,847 mps_preprocess.py:115] Visiting: aten_rsqrt_default_23, aten.rsqrt.default\n",
      "[INFO 2024-05-08 17:52:11,847 mps_preprocess.py:115] Visiting: aten_mul_tensor_200, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,847 mps_preprocess.py:115] Visiting: aten_mul_tensor_201, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,848 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_118, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,848 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_119, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,848 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_81, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,849 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_82, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,849 mps_preprocess.py:115] Visiting: aten_sigmoid_default_11, aten.sigmoid.default\n",
      "[INFO 2024-05-08 17:52:11,849 mps_preprocess.py:115] Visiting: aten_mul_tensor_202, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,882 mps_preprocess.py:115] Visiting: aten_mul_tensor_203, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,883 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_83, aten._weight_int8pack_mm.default\n",
      "[INFO 2024-05-08 17:52:11,883 mps_preprocess.py:115] Visiting: aten_add_tensor_83, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,884 mps_preprocess.py:115] Visiting: aten_mul_tensor_204, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,884 mps_preprocess.py:115] Visiting: aten_mean_dim_24, aten.mean.dim\n",
      "[INFO 2024-05-08 17:52:11,884 mps_preprocess.py:115] Visiting: aten_add_tensor_84, aten.add.Tensor\n",
      "[INFO 2024-05-08 17:52:11,885 mps_preprocess.py:115] Visiting: aten_rsqrt_default_24, aten.rsqrt.default\n",
      "[INFO 2024-05-08 17:52:11,885 mps_preprocess.py:115] Visiting: aten_mul_tensor_205, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,885 mps_preprocess.py:115] Visiting: aten_mul_tensor_206, aten.mul.Tensor\n",
      "[INFO 2024-05-08 17:52:11,886 mps_preprocess.py:115] Visiting: aten_squeeze_copy_dims_120, aten.squeeze_copy.dims\n",
      "[INFO 2024-05-08 17:52:11,886 mps_preprocess.py:115] Visiting: aten__weight_int8pack_mm_default_84, aten._weight_int8pack_mm.default\n",
      "/Users/larryliu/miniconda3/envs/executorch/lib/python3.11/site-packages/executorch/exir/emit/_emitter.py:1474: UserWarning: Mutation on a buffer in the model is detected. ExecuTorch assumes buffers that are mutated in the graph have a meaningless initial state, only the shape and dtype will be serialized.\n",
      "  warnings.warn(\n",
      "[INFO 2024-05-08 17:52:38,420 builder.py:341] Required memory for activation in bytes: [0, 19002368]\n"
     ]
    }
   ],
   "source": [
    "builder = model.export_to_edge(None).to_backend(partitioners).to_executorch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %b_layers_0_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_0_attention_sdpa_kv_cache_k_cache]\n",
      "    %b_layers_0_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_0_attention_sdpa_kv_cache_v_cache]\n",
      "    %b_layers_1_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_1_attention_sdpa_kv_cache_k_cache]\n",
      "    %b_layers_1_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_1_attention_sdpa_kv_cache_v_cache]\n",
      "    %b_layers_2_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_2_attention_sdpa_kv_cache_k_cache]\n",
      "    %b_layers_2_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_2_attention_sdpa_kv_cache_v_cache]\n",
      "    %b_layers_3_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_3_attention_sdpa_kv_cache_k_cache]\n",
      "    %b_layers_3_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_3_attention_sdpa_kv_cache_v_cache]\n",
      "    %b_layers_4_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_4_attention_sdpa_kv_cache_k_cache]\n",
      "    %b_layers_4_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_4_attention_sdpa_kv_cache_v_cache]\n",
      "    %b_layers_5_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_5_attention_sdpa_kv_cache_k_cache]\n",
      "    %b_layers_5_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_5_attention_sdpa_kv_cache_v_cache]\n",
      "    %b_layers_6_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_6_attention_sdpa_kv_cache_k_cache]\n",
      "    %b_layers_6_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_6_attention_sdpa_kv_cache_v_cache]\n",
      "    %b_layers_7_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_7_attention_sdpa_kv_cache_k_cache]\n",
      "    %b_layers_7_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_7_attention_sdpa_kv_cache_v_cache]\n",
      "    %b_layers_8_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_8_attention_sdpa_kv_cache_k_cache]\n",
      "    %b_layers_8_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_8_attention_sdpa_kv_cache_v_cache]\n",
      "    %b_layers_9_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_9_attention_sdpa_kv_cache_k_cache]\n",
      "    %b_layers_9_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_9_attention_sdpa_kv_cache_v_cache]\n",
      "    %b_layers_10_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_10_attention_sdpa_kv_cache_k_cache]\n",
      "    %b_layers_10_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_10_attention_sdpa_kv_cache_v_cache]\n",
      "    %b_layers_11_attention_sdpa_kv_cache_k_cache : [num_users=4] = placeholder[target=b_layers_11_attention_sdpa_kv_cache_k_cache]\n",
      "    %b_layers_11_attention_sdpa_kv_cache_v_cache : [num_users=4] = placeholder[target=b_layers_11_attention_sdpa_kv_cache_v_cache]\n",
      "    %tokens : [num_users=1] = placeholder[target=tokens]\n",
      "    %input_pos : [num_users=37] = placeholder[target=input_pos]\n",
      "    %lowered_module_0 : [num_users=1] = get_attr[target=lowered_module_0]\n",
      "    %executorch_call_delegate : [num_users=8] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_0, %tokens, %input_pos), kwargs = {})\n",
      "    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 0), kwargs = {})\n",
      "    %getitem_1 : [num_users=11] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 1), kwargs = {})\n",
      "    %getitem_2 : [num_users=11] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 2), kwargs = {})\n",
      "    %getitem_3 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 3), kwargs = {})\n",
      "    %getitem_4 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 4), kwargs = {})\n",
      "    %getitem_5 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 5), kwargs = {})\n",
      "    %getitem_6 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 6), kwargs = {})\n",
      "    %getitem_7 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 7), kwargs = {})\n",
      "    %alloc : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_0_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_6), kwargs = {out: %alloc})\n",
      "    %alloc_1 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_1 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_0_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_7), kwargs = {out: %alloc_1})\n",
      "    %alloc_2 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_0_attention_sdpa_kv_cache_v_cache, %aten_index_put_default, 1, 0, 9223372036854775807), kwargs = {out: %alloc_2})\n",
      "    %alloc_3 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_1 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_0_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_1, 1, 0, 9223372036854775807), kwargs = {out: %alloc_3})\n",
      "    %alloc_4 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_2 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_0_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default, 0, 0, 9223372036854775807), kwargs = {out: %alloc_4})\n",
      "    %alloc_5 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_3 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_0_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_1, 0, 0, 9223372036854775807), kwargs = {out: %alloc_5})\n",
      "    %lowered_module_1 : [num_users=1] = get_attr[target=lowered_module_1]\n",
      "    %executorch_call_delegate_1 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_1, %getitem_1, %getitem_2, %getitem_5, %aten_slice_scatter_default_2, %aten_slice_scatter_default_3, %input_pos, %getitem_3, %getitem_4, %getitem), kwargs = {})\n",
      "    %getitem_8 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_1, 0), kwargs = {})\n",
      "    %getitem_9 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_1, 1), kwargs = {})\n",
      "    %getitem_10 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_1, 2), kwargs = {})\n",
      "    %getitem_11 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_1, 3), kwargs = {})\n",
      "    %getitem_12 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_1, 4), kwargs = {})\n",
      "    %getitem_13 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_1, 5), kwargs = {})\n",
      "    %alloc_6 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_2 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_1_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_12), kwargs = {out: %alloc_6})\n",
      "    %alloc_7 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_3 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_1_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_13), kwargs = {out: %alloc_7})\n",
      "    %alloc_8 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_4 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_1_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_2, 1, 0, 9223372036854775807), kwargs = {out: %alloc_8})\n",
      "    %alloc_9 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_5 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_1_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_3, 1, 0, 9223372036854775807), kwargs = {out: %alloc_9})\n",
      "    %alloc_10 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_6 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_1_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_4, 0, 0, 9223372036854775807), kwargs = {out: %alloc_10})\n",
      "    %alloc_11 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_7 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_1_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_5, 0, 0, 9223372036854775807), kwargs = {out: %alloc_11})\n",
      "    %lowered_module_2 : [num_users=1] = get_attr[target=lowered_module_2]\n",
      "    %executorch_call_delegate_2 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_2, %getitem_1, %getitem_2, %getitem_11, %aten_slice_scatter_default_6, %aten_slice_scatter_default_7, %input_pos, %getitem_8, %getitem_9, %getitem_10), kwargs = {})\n",
      "    %getitem_14 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_2, 0), kwargs = {})\n",
      "    %getitem_15 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_2, 1), kwargs = {})\n",
      "    %getitem_16 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_2, 2), kwargs = {})\n",
      "    %getitem_17 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_2, 3), kwargs = {})\n",
      "    %getitem_18 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_2, 4), kwargs = {})\n",
      "    %getitem_19 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_2, 5), kwargs = {})\n",
      "    %alloc_12 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_4 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_2_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_18), kwargs = {out: %alloc_12})\n",
      "    %alloc_13 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_5 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_2_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_19), kwargs = {out: %alloc_13})\n",
      "    %alloc_14 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_8 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_2_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_4, 1, 0, 9223372036854775807), kwargs = {out: %alloc_14})\n",
      "    %alloc_15 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_9 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_2_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_5, 1, 0, 9223372036854775807), kwargs = {out: %alloc_15})\n",
      "    %alloc_16 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_10 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_2_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_8, 0, 0, 9223372036854775807), kwargs = {out: %alloc_16})\n",
      "    %alloc_17 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_11 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_2_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_9, 0, 0, 9223372036854775807), kwargs = {out: %alloc_17})\n",
      "    %lowered_module_3 : [num_users=1] = get_attr[target=lowered_module_3]\n",
      "    %executorch_call_delegate_3 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_3, %getitem_1, %getitem_2, %getitem_17, %aten_slice_scatter_default_10, %aten_slice_scatter_default_11, %input_pos, %getitem_14, %getitem_15, %getitem_16), kwargs = {})\n",
      "    %getitem_20 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_3, 0), kwargs = {})\n",
      "    %getitem_21 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_3, 1), kwargs = {})\n",
      "    %getitem_22 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_3, 2), kwargs = {})\n",
      "    %getitem_23 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_3, 3), kwargs = {})\n",
      "    %getitem_24 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_3, 4), kwargs = {})\n",
      "    %getitem_25 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_3, 5), kwargs = {})\n",
      "    %alloc_18 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_6 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_3_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_24), kwargs = {out: %alloc_18})\n",
      "    %alloc_19 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_7 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_3_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_25), kwargs = {out: %alloc_19})\n",
      "    %alloc_20 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_12 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_3_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_6, 1, 0, 9223372036854775807), kwargs = {out: %alloc_20})\n",
      "    %alloc_21 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_13 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_3_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_7, 1, 0, 9223372036854775807), kwargs = {out: %alloc_21})\n",
      "    %alloc_22 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_14 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_3_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_12, 0, 0, 9223372036854775807), kwargs = {out: %alloc_22})\n",
      "    %alloc_23 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_15 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_3_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_13, 0, 0, 9223372036854775807), kwargs = {out: %alloc_23})\n",
      "    %lowered_module_4 : [num_users=1] = get_attr[target=lowered_module_4]\n",
      "    %executorch_call_delegate_4 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_4, %getitem_1, %getitem_2, %getitem_23, %aten_slice_scatter_default_14, %aten_slice_scatter_default_15, %input_pos, %getitem_20, %getitem_21, %getitem_22), kwargs = {})\n",
      "    %getitem_26 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_4, 0), kwargs = {})\n",
      "    %getitem_27 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_4, 1), kwargs = {})\n",
      "    %getitem_28 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_4, 2), kwargs = {})\n",
      "    %getitem_29 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_4, 3), kwargs = {})\n",
      "    %getitem_30 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_4, 4), kwargs = {})\n",
      "    %getitem_31 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_4, 5), kwargs = {})\n",
      "    %alloc_24 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_8 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_4_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_30), kwargs = {out: %alloc_24})\n",
      "    %alloc_25 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_9 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_4_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_31), kwargs = {out: %alloc_25})\n",
      "    %alloc_26 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_16 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_4_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_8, 1, 0, 9223372036854775807), kwargs = {out: %alloc_26})\n",
      "    %alloc_27 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_17 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_4_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_9, 1, 0, 9223372036854775807), kwargs = {out: %alloc_27})\n",
      "    %alloc_28 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_18 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_4_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_16, 0, 0, 9223372036854775807), kwargs = {out: %alloc_28})\n",
      "    %alloc_29 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_19 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_4_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_17, 0, 0, 9223372036854775807), kwargs = {out: %alloc_29})\n",
      "    %lowered_module_5 : [num_users=1] = get_attr[target=lowered_module_5]\n",
      "    %executorch_call_delegate_5 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_5, %getitem_1, %getitem_2, %getitem_29, %aten_slice_scatter_default_18, %aten_slice_scatter_default_19, %input_pos, %getitem_26, %getitem_27, %getitem_28), kwargs = {})\n",
      "    %getitem_32 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_5, 0), kwargs = {})\n",
      "    %getitem_33 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_5, 1), kwargs = {})\n",
      "    %getitem_34 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_5, 2), kwargs = {})\n",
      "    %getitem_35 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_5, 3), kwargs = {})\n",
      "    %getitem_36 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_5, 4), kwargs = {})\n",
      "    %getitem_37 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_5, 5), kwargs = {})\n",
      "    %alloc_30 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_10 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_5_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_36), kwargs = {out: %alloc_30})\n",
      "    %alloc_31 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_11 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_5_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_37), kwargs = {out: %alloc_31})\n",
      "    %alloc_32 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_20 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_5_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_10, 1, 0, 9223372036854775807), kwargs = {out: %alloc_32})\n",
      "    %alloc_33 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_21 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_5_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_11, 1, 0, 9223372036854775807), kwargs = {out: %alloc_33})\n",
      "    %alloc_34 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_22 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_5_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_20, 0, 0, 9223372036854775807), kwargs = {out: %alloc_34})\n",
      "    %alloc_35 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_23 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_5_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_21, 0, 0, 9223372036854775807), kwargs = {out: %alloc_35})\n",
      "    %lowered_module_6 : [num_users=1] = get_attr[target=lowered_module_6]\n",
      "    %executorch_call_delegate_6 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_6, %getitem_1, %getitem_2, %getitem_35, %aten_slice_scatter_default_22, %aten_slice_scatter_default_23, %input_pos, %getitem_32, %getitem_33, %getitem_34), kwargs = {})\n",
      "    %getitem_38 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_6, 0), kwargs = {})\n",
      "    %getitem_39 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_6, 1), kwargs = {})\n",
      "    %getitem_40 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_6, 2), kwargs = {})\n",
      "    %getitem_41 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_6, 3), kwargs = {})\n",
      "    %getitem_42 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_6, 4), kwargs = {})\n",
      "    %getitem_43 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_6, 5), kwargs = {})\n",
      "    %alloc_36 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_12 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_6_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_42), kwargs = {out: %alloc_36})\n",
      "    %alloc_37 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_13 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_6_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_43), kwargs = {out: %alloc_37})\n",
      "    %alloc_38 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_24 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_6_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_12, 1, 0, 9223372036854775807), kwargs = {out: %alloc_38})\n",
      "    %alloc_39 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_25 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_6_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_13, 1, 0, 9223372036854775807), kwargs = {out: %alloc_39})\n",
      "    %alloc_40 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_26 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_6_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_24, 0, 0, 9223372036854775807), kwargs = {out: %alloc_40})\n",
      "    %alloc_41 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_27 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_6_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_25, 0, 0, 9223372036854775807), kwargs = {out: %alloc_41})\n",
      "    %lowered_module_7 : [num_users=1] = get_attr[target=lowered_module_7]\n",
      "    %executorch_call_delegate_7 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_7, %getitem_1, %getitem_2, %getitem_41, %aten_slice_scatter_default_26, %aten_slice_scatter_default_27, %input_pos, %getitem_38, %getitem_39, %getitem_40), kwargs = {})\n",
      "    %getitem_44 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_7, 0), kwargs = {})\n",
      "    %getitem_45 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_7, 1), kwargs = {})\n",
      "    %getitem_46 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_7, 2), kwargs = {})\n",
      "    %getitem_47 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_7, 3), kwargs = {})\n",
      "    %getitem_48 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_7, 4), kwargs = {})\n",
      "    %getitem_49 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_7, 5), kwargs = {})\n",
      "    %alloc_42 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_14 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_7_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_48), kwargs = {out: %alloc_42})\n",
      "    %alloc_43 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_15 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_7_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_49), kwargs = {out: %alloc_43})\n",
      "    %alloc_44 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_28 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_7_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_14, 1, 0, 9223372036854775807), kwargs = {out: %alloc_44})\n",
      "    %alloc_45 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_29 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_7_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_15, 1, 0, 9223372036854775807), kwargs = {out: %alloc_45})\n",
      "    %alloc_46 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_30 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_7_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_28, 0, 0, 9223372036854775807), kwargs = {out: %alloc_46})\n",
      "    %alloc_47 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_31 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_7_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_29, 0, 0, 9223372036854775807), kwargs = {out: %alloc_47})\n",
      "    %lowered_module_8 : [num_users=1] = get_attr[target=lowered_module_8]\n",
      "    %executorch_call_delegate_8 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_8, %getitem_1, %getitem_2, %getitem_47, %aten_slice_scatter_default_30, %aten_slice_scatter_default_31, %input_pos, %getitem_44, %getitem_45, %getitem_46), kwargs = {})\n",
      "    %getitem_50 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_8, 0), kwargs = {})\n",
      "    %getitem_51 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_8, 1), kwargs = {})\n",
      "    %getitem_52 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_8, 2), kwargs = {})\n",
      "    %getitem_53 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_8, 3), kwargs = {})\n",
      "    %getitem_54 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_8, 4), kwargs = {})\n",
      "    %getitem_55 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_8, 5), kwargs = {})\n",
      "    %alloc_48 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_16 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_8_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_54), kwargs = {out: %alloc_48})\n",
      "    %alloc_49 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_17 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_8_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_55), kwargs = {out: %alloc_49})\n",
      "    %alloc_50 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_32 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_8_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_16, 1, 0, 9223372036854775807), kwargs = {out: %alloc_50})\n",
      "    %alloc_51 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_33 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_8_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_17, 1, 0, 9223372036854775807), kwargs = {out: %alloc_51})\n",
      "    %alloc_52 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_34 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_8_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_32, 0, 0, 9223372036854775807), kwargs = {out: %alloc_52})\n",
      "    %alloc_53 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_35 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_8_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_33, 0, 0, 9223372036854775807), kwargs = {out: %alloc_53})\n",
      "    %lowered_module_9 : [num_users=1] = get_attr[target=lowered_module_9]\n",
      "    %executorch_call_delegate_9 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_9, %getitem_1, %getitem_2, %getitem_53, %aten_slice_scatter_default_34, %aten_slice_scatter_default_35, %input_pos, %getitem_50, %getitem_51, %getitem_52), kwargs = {})\n",
      "    %getitem_56 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_9, 0), kwargs = {})\n",
      "    %getitem_57 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_9, 1), kwargs = {})\n",
      "    %getitem_58 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_9, 2), kwargs = {})\n",
      "    %getitem_59 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_9, 3), kwargs = {})\n",
      "    %getitem_60 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_9, 4), kwargs = {})\n",
      "    %getitem_61 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_9, 5), kwargs = {})\n",
      "    %alloc_54 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_18 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_9_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_60), kwargs = {out: %alloc_54})\n",
      "    %alloc_55 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_19 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_9_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_61), kwargs = {out: %alloc_55})\n",
      "    %alloc_56 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_36 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_9_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_18, 1, 0, 9223372036854775807), kwargs = {out: %alloc_56})\n",
      "    %alloc_57 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_37 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_9_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_19, 1, 0, 9223372036854775807), kwargs = {out: %alloc_57})\n",
      "    %alloc_58 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_38 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_9_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_36, 0, 0, 9223372036854775807), kwargs = {out: %alloc_58})\n",
      "    %alloc_59 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_39 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_9_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_37, 0, 0, 9223372036854775807), kwargs = {out: %alloc_59})\n",
      "    %lowered_module_10 : [num_users=1] = get_attr[target=lowered_module_10]\n",
      "    %executorch_call_delegate_10 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_10, %getitem_1, %getitem_2, %getitem_59, %aten_slice_scatter_default_38, %aten_slice_scatter_default_39, %input_pos, %getitem_56, %getitem_57, %getitem_58), kwargs = {})\n",
      "    %getitem_62 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_10, 0), kwargs = {})\n",
      "    %getitem_63 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_10, 1), kwargs = {})\n",
      "    %getitem_64 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_10, 2), kwargs = {})\n",
      "    %getitem_65 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_10, 3), kwargs = {})\n",
      "    %getitem_66 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_10, 4), kwargs = {})\n",
      "    %getitem_67 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_10, 5), kwargs = {})\n",
      "    %alloc_60 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_20 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_10_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_66), kwargs = {out: %alloc_60})\n",
      "    %alloc_61 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_21 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_10_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_67), kwargs = {out: %alloc_61})\n",
      "    %alloc_62 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_40 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_10_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_20, 1, 0, 9223372036854775807), kwargs = {out: %alloc_62})\n",
      "    %alloc_63 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_41 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_10_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_21, 1, 0, 9223372036854775807), kwargs = {out: %alloc_63})\n",
      "    %alloc_64 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_42 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_10_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_40, 0, 0, 9223372036854775807), kwargs = {out: %alloc_64})\n",
      "    %alloc_65 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_43 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_10_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_41, 0, 0, 9223372036854775807), kwargs = {out: %alloc_65})\n",
      "    %lowered_module_11 : [num_users=1] = get_attr[target=lowered_module_11]\n",
      "    %executorch_call_delegate_11 : [num_users=6] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_11, %getitem_1, %getitem_2, %getitem_65, %aten_slice_scatter_default_42, %aten_slice_scatter_default_43, %input_pos, %getitem_62, %getitem_63, %getitem_64), kwargs = {})\n",
      "    %getitem_68 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_11, 0), kwargs = {})\n",
      "    %getitem_69 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_11, 1), kwargs = {})\n",
      "    %getitem_70 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_11, 2), kwargs = {})\n",
      "    %getitem_71 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_11, 3), kwargs = {})\n",
      "    %getitem_72 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_11, 4), kwargs = {})\n",
      "    %getitem_73 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_11, 5), kwargs = {})\n",
      "    %alloc_66 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_22 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_11_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %getitem_72), kwargs = {out: %alloc_66})\n",
      "    %alloc_67 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_index_put_default_23 : [num_users=1] = call_function[target=torch.ops.aten.index_put.out](args = (%b_layers_11_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %getitem_73), kwargs = {out: %alloc_67})\n",
      "    %alloc_68 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_44 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_11_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_22, 1, 0, 9223372036854775807), kwargs = {out: %alloc_68})\n",
      "    %alloc_69 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_45 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_11_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_23, 1, 0, 9223372036854775807), kwargs = {out: %alloc_69})\n",
      "    %alloc_70 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_46 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_11_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_44, 0, 0, 9223372036854775807), kwargs = {out: %alloc_70})\n",
      "    %alloc_71 : [num_users=1] = call_function[target=executorch.exir.memory.alloc](args = (((1, 12, 128, 64), torch.float32),), kwargs = {})\n",
      "    %aten_slice_scatter_default_47 : [num_users=2] = call_function[target=torch.ops.aten.slice_scatter.out](args = (%b_layers_11_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_45, 0, 0, 9223372036854775807), kwargs = {out: %alloc_71})\n",
      "    %lowered_module_12 : [num_users=1] = get_attr[target=lowered_module_12]\n",
      "    %executorch_call_delegate_12 : [num_users=1] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_12, %getitem_71, %aten_slice_scatter_default_47, %aten_slice_scatter_default_46, %input_pos, %getitem_68, %getitem_69, %getitem_70), kwargs = {})\n",
      "    %getitem_74 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate_12, 0), kwargs = {})\n",
      "    %copy_ : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_0_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_3), kwargs = {})\n",
      "    %copy__1 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_0_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_2), kwargs = {})\n",
      "    %copy__2 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_1_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_7), kwargs = {})\n",
      "    %copy__3 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_1_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_6), kwargs = {})\n",
      "    %copy__4 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_2_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_11), kwargs = {})\n",
      "    %copy__5 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_2_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_10), kwargs = {})\n",
      "    %copy__6 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_3_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_15), kwargs = {})\n",
      "    %copy__7 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_3_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_14), kwargs = {})\n",
      "    %copy__8 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_4_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_19), kwargs = {})\n",
      "    %copy__9 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_4_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_18), kwargs = {})\n",
      "    %copy__10 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_5_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_23), kwargs = {})\n",
      "    %copy__11 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_5_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_22), kwargs = {})\n",
      "    %copy__12 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_6_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_27), kwargs = {})\n",
      "    %copy__13 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_6_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_26), kwargs = {})\n",
      "    %copy__14 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_7_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_31), kwargs = {})\n",
      "    %copy__15 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_7_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_30), kwargs = {})\n",
      "    %copy__16 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_8_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_35), kwargs = {})\n",
      "    %copy__17 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_8_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_34), kwargs = {})\n",
      "    %copy__18 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_9_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_39), kwargs = {})\n",
      "    %copy__19 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_9_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_38), kwargs = {})\n",
      "    %copy__20 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_10_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_43), kwargs = {})\n",
      "    %copy__21 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_10_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_42), kwargs = {})\n",
      "    %copy__22 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_11_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_47), kwargs = {})\n",
      "    %copy__23 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_11_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_46), kwargs = {})\n",
      "    return (getitem_74,)\n"
     ]
    }
   ],
   "source": [
    "print(model.edge_manager._edge_programs['forward'].graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "  %b_layers_0_attention_sdpa_kv_cache_k_cache : [num_users=2] = placeholder[target=b_layers_0_attention_sdpa_kv_cache_k_cache]\n",
      "  %b_layers_0_attention_sdpa_kv_cache_v_cache : [num_users=2] = placeholder[target=b_layers_0_attention_sdpa_kv_cache_v_cache]\n",
      "  %b_layers_1_attention_sdpa_kv_cache_k_cache : [num_users=2] = placeholder[target=b_layers_1_attention_sdpa_kv_cache_k_cache]\n",
      "  %b_layers_1_attention_sdpa_kv_cache_v_cache : [num_users=2] = placeholder[target=b_layers_1_attention_sdpa_kv_cache_v_cache]\n",
      "  %b_layers_2_attention_sdpa_kv_cache_k_cache : [num_users=2] = placeholder[target=b_layers_2_attention_sdpa_kv_cache_k_cache]\n",
      "  %b_layers_2_attention_sdpa_kv_cache_v_cache : [num_users=2] = placeholder[target=b_layers_2_attention_sdpa_kv_cache_v_cache]\n",
      "  %b_layers_3_attention_sdpa_kv_cache_k_cache : [num_users=2] = placeholder[target=b_layers_3_attention_sdpa_kv_cache_k_cache]\n",
      "  %b_layers_3_attention_sdpa_kv_cache_v_cache : [num_users=2] = placeholder[target=b_layers_3_attention_sdpa_kv_cache_v_cache]\n",
      "  %b_layers_4_attention_sdpa_kv_cache_k_cache : [num_users=2] = placeholder[target=b_layers_4_attention_sdpa_kv_cache_k_cache]\n",
      "  %b_layers_4_attention_sdpa_kv_cache_v_cache : [num_users=2] = placeholder[target=b_layers_4_attention_sdpa_kv_cache_v_cache]\n",
      "  %b_layers_5_attention_sdpa_kv_cache_k_cache : [num_users=2] = placeholder[target=b_layers_5_attention_sdpa_kv_cache_k_cache]\n",
      "  %b_layers_5_attention_sdpa_kv_cache_v_cache : [num_users=2] = placeholder[target=b_layers_5_attention_sdpa_kv_cache_v_cache]\n",
      "  %b_layers_6_attention_sdpa_kv_cache_k_cache : [num_users=2] = placeholder[target=b_layers_6_attention_sdpa_kv_cache_k_cache]\n",
      "  %b_layers_6_attention_sdpa_kv_cache_v_cache : [num_users=2] = placeholder[target=b_layers_6_attention_sdpa_kv_cache_v_cache]\n",
      "  %b_layers_7_attention_sdpa_kv_cache_k_cache : [num_users=2] = placeholder[target=b_layers_7_attention_sdpa_kv_cache_k_cache]\n",
      "  %b_layers_7_attention_sdpa_kv_cache_v_cache : [num_users=2] = placeholder[target=b_layers_7_attention_sdpa_kv_cache_v_cache]\n",
      "  %b_layers_8_attention_sdpa_kv_cache_k_cache : [num_users=2] = placeholder[target=b_layers_8_attention_sdpa_kv_cache_k_cache]\n",
      "  %b_layers_8_attention_sdpa_kv_cache_v_cache : [num_users=2] = placeholder[target=b_layers_8_attention_sdpa_kv_cache_v_cache]\n",
      "  %b_layers_9_attention_sdpa_kv_cache_k_cache : [num_users=2] = placeholder[target=b_layers_9_attention_sdpa_kv_cache_k_cache]\n",
      "  %b_layers_9_attention_sdpa_kv_cache_v_cache : [num_users=2] = placeholder[target=b_layers_9_attention_sdpa_kv_cache_v_cache]\n",
      "  %b_layers_10_attention_sdpa_kv_cache_k_cache : [num_users=2] = placeholder[target=b_layers_10_attention_sdpa_kv_cache_k_cache]\n",
      "  %b_layers_10_attention_sdpa_kv_cache_v_cache : [num_users=2] = placeholder[target=b_layers_10_attention_sdpa_kv_cache_v_cache]\n",
      "  %b_layers_11_attention_sdpa_kv_cache_k_cache : [num_users=2] = placeholder[target=b_layers_11_attention_sdpa_kv_cache_k_cache]\n",
      "  %b_layers_11_attention_sdpa_kv_cache_v_cache : [num_users=2] = placeholder[target=b_layers_11_attention_sdpa_kv_cache_v_cache]\n",
      "  %tokens : [num_users=1] = placeholder[target=tokens]\n",
      "  %input_pos : [num_users=1] = placeholder[target=input_pos]\n",
      "  %lowered_module_0 : [num_users=1] = get_attr[target=lowered_module_0]\n",
      "    backend_id: MPSBackend\n",
      "    lowered graph():\n",
      "      %p_tok_embeddings_weight : [num_users=1] = placeholder[target=p_tok_embeddings_weight]\n",
      "      %p_layers_0_attention_norm_weight : [num_users=1] = placeholder[target=p_layers_0_attention_norm_weight]\n",
      "      %p_layers_0_ffn_norm_weight : [num_users=1] = placeholder[target=p_layers_0_ffn_norm_weight]\n",
      "      %p_layers_1_attention_norm_weight : [num_users=1] = placeholder[target=p_layers_1_attention_norm_weight]\n",
      "      %p_layers_1_ffn_norm_weight : [num_users=1] = placeholder[target=p_layers_1_ffn_norm_weight]\n",
      "      %p_layers_2_attention_norm_weight : [num_users=1] = placeholder[target=p_layers_2_attention_norm_weight]\n",
      "      %p_layers_2_ffn_norm_weight : [num_users=1] = placeholder[target=p_layers_2_ffn_norm_weight]\n",
      "      %p_layers_3_attention_norm_weight : [num_users=1] = placeholder[target=p_layers_3_attention_norm_weight]\n",
      "      %p_layers_3_ffn_norm_weight : [num_users=1] = placeholder[target=p_layers_3_ffn_norm_weight]\n",
      "      %p_layers_4_attention_norm_weight : [num_users=1] = placeholder[target=p_layers_4_attention_norm_weight]\n",
      "      %p_layers_4_ffn_norm_weight : [num_users=1] = placeholder[target=p_layers_4_ffn_norm_weight]\n",
      "      %p_layers_5_attention_norm_weight : [num_users=1] = placeholder[target=p_layers_5_attention_norm_weight]\n",
      "      %p_layers_5_ffn_norm_weight : [num_users=1] = placeholder[target=p_layers_5_ffn_norm_weight]\n",
      "      %p_layers_6_attention_norm_weight : [num_users=1] = placeholder[target=p_layers_6_attention_norm_weight]\n",
      "      %p_layers_6_ffn_norm_weight : [num_users=1] = placeholder[target=p_layers_6_ffn_norm_weight]\n",
      "      %p_layers_7_attention_norm_weight : [num_users=1] = placeholder[target=p_layers_7_attention_norm_weight]\n",
      "      %p_layers_7_ffn_norm_weight : [num_users=1] = placeholder[target=p_layers_7_ffn_norm_weight]\n",
      "      %p_layers_8_attention_norm_weight : [num_users=1] = placeholder[target=p_layers_8_attention_norm_weight]\n",
      "      %p_layers_8_ffn_norm_weight : [num_users=1] = placeholder[target=p_layers_8_ffn_norm_weight]\n",
      "      %p_layers_9_attention_norm_weight : [num_users=1] = placeholder[target=p_layers_9_attention_norm_weight]\n",
      "      %p_layers_9_ffn_norm_weight : [num_users=1] = placeholder[target=p_layers_9_ffn_norm_weight]\n",
      "      %p_layers_10_attention_norm_weight : [num_users=1] = placeholder[target=p_layers_10_attention_norm_weight]\n",
      "      %p_layers_10_ffn_norm_weight : [num_users=1] = placeholder[target=p_layers_10_ffn_norm_weight]\n",
      "      %p_layers_11_attention_norm_weight : [num_users=1] = placeholder[target=p_layers_11_attention_norm_weight]\n",
      "      %p_layers_11_ffn_norm_weight : [num_users=1] = placeholder[target=p_layers_11_ffn_norm_weight]\n",
      "      %p_norm_weight : [num_users=1] = placeholder[target=p_norm_weight]\n",
      "      %b_freqs_cos : [num_users=1] = placeholder[target=b_freqs_cos]\n",
      "      %b_freqs_sin : [num_users=1] = placeholder[target=b_freqs_sin]\n",
      "      %b_layers_0_attention_wq_weight : [num_users=1] = placeholder[target=b_layers_0_attention_wq_weight]\n",
      "      %b_layers_0_attention_wq_scales : [num_users=1] = placeholder[target=b_layers_0_attention_wq_scales]\n",
      "      %b_layers_0_attention_wk_weight : [num_users=1] = placeholder[target=b_layers_0_attention_wk_weight]\n",
      "      %b_layers_0_attention_wk_scales : [num_users=1] = placeholder[target=b_layers_0_attention_wk_scales]\n",
      "      %b_layers_0_attention_wv_weight : [num_users=1] = placeholder[target=b_layers_0_attention_wv_weight]\n",
      "      %b_layers_0_attention_wv_scales : [num_users=1] = placeholder[target=b_layers_0_attention_wv_scales]\n",
      "      %b_layers_0_attention_mask : [num_users=1] = placeholder[target=b_layers_0_attention_mask]\n",
      "      %b_layers_0_attention_wo_weight : [num_users=1] = placeholder[target=b_layers_0_attention_wo_weight]\n",
      "      %b_layers_0_attention_wo_scales : [num_users=1] = placeholder[target=b_layers_0_attention_wo_scales]\n",
      "      %b_layers_0_feed_forward_w1_weight : [num_users=1] = placeholder[target=b_layers_0_feed_forward_w1_weight]\n",
      "      %b_layers_0_feed_forward_w1_scales : [num_users=1] = placeholder[target=b_layers_0_feed_forward_w1_scales]\n",
      "      %b_layers_0_feed_forward_w3_weight : [num_users=1] = placeholder[target=b_layers_0_feed_forward_w3_weight]\n",
      "      %b_layers_0_feed_forward_w3_scales : [num_users=1] = placeholder[target=b_layers_0_feed_forward_w3_scales]\n",
      "      %b_layers_0_feed_forward_w2_weight : [num_users=1] = placeholder[target=b_layers_0_feed_forward_w2_weight]\n",
      "      %b_layers_0_feed_forward_w2_scales : [num_users=1] = placeholder[target=b_layers_0_feed_forward_w2_scales]\n",
      "      %b_layers_1_attention_wq_weight : [num_users=1] = placeholder[target=b_layers_1_attention_wq_weight]\n",
      "      %b_layers_1_attention_wq_scales : [num_users=1] = placeholder[target=b_layers_1_attention_wq_scales]\n",
      "      %b_layers_1_attention_wk_weight : [num_users=1] = placeholder[target=b_layers_1_attention_wk_weight]\n",
      "      %b_layers_1_attention_wk_scales : [num_users=1] = placeholder[target=b_layers_1_attention_wk_scales]\n",
      "      %b_layers_1_attention_wv_weight : [num_users=1] = placeholder[target=b_layers_1_attention_wv_weight]\n",
      "      %b_layers_1_attention_wv_scales : [num_users=1] = placeholder[target=b_layers_1_attention_wv_scales]\n",
      "      %b_layers_1_attention_mask : [num_users=1] = placeholder[target=b_layers_1_attention_mask]\n",
      "      %b_layers_1_attention_wo_weight : [num_users=1] = placeholder[target=b_layers_1_attention_wo_weight]\n",
      "      %b_layers_1_attention_wo_scales : [num_users=1] = placeholder[target=b_layers_1_attention_wo_scales]\n",
      "      %b_layers_1_feed_forward_w1_weight : [num_users=1] = placeholder[target=b_layers_1_feed_forward_w1_weight]\n",
      "      %b_layers_1_feed_forward_w1_scales : [num_users=1] = placeholder[target=b_layers_1_feed_forward_w1_scales]\n",
      "      %b_layers_1_feed_forward_w3_weight : [num_users=1] = placeholder[target=b_layers_1_feed_forward_w3_weight]\n",
      "      %b_layers_1_feed_forward_w3_scales : [num_users=1] = placeholder[target=b_layers_1_feed_forward_w3_scales]\n",
      "      %b_layers_1_feed_forward_w2_weight : [num_users=1] = placeholder[target=b_layers_1_feed_forward_w2_weight]\n",
      "      %b_layers_1_feed_forward_w2_scales : [num_users=1] = placeholder[target=b_layers_1_feed_forward_w2_scales]\n",
      "      %b_layers_2_attention_wq_weight : [num_users=1] = placeholder[target=b_layers_2_attention_wq_weight]\n",
      "      %b_layers_2_attention_wq_scales : [num_users=1] = placeholder[target=b_layers_2_attention_wq_scales]\n",
      "      %b_layers_2_attention_wk_weight : [num_users=1] = placeholder[target=b_layers_2_attention_wk_weight]\n",
      "      %b_layers_2_attention_wk_scales : [num_users=1] = placeholder[target=b_layers_2_attention_wk_scales]\n",
      "      %b_layers_2_attention_wv_weight : [num_users=1] = placeholder[target=b_layers_2_attention_wv_weight]\n",
      "      %b_layers_2_attention_wv_scales : [num_users=1] = placeholder[target=b_layers_2_attention_wv_scales]\n",
      "      %b_layers_2_attention_mask : [num_users=1] = placeholder[target=b_layers_2_attention_mask]\n",
      "      %b_layers_2_attention_wo_weight : [num_users=1] = placeholder[target=b_layers_2_attention_wo_weight]\n",
      "      %b_layers_2_attention_wo_scales : [num_users=1] = placeholder[target=b_layers_2_attention_wo_scales]\n",
      "      %b_layers_2_feed_forward_w1_weight : [num_users=1] = placeholder[target=b_layers_2_feed_forward_w1_weight]\n",
      "      %b_layers_2_feed_forward_w1_scales : [num_users=1] = placeholder[target=b_layers_2_feed_forward_w1_scales]\n",
      "      %b_layers_2_feed_forward_w3_weight : [num_users=1] = placeholder[target=b_layers_2_feed_forward_w3_weight]\n",
      "      %b_layers_2_feed_forward_w3_scales : [num_users=1] = placeholder[target=b_layers_2_feed_forward_w3_scales]\n",
      "      %b_layers_2_feed_forward_w2_weight : [num_users=1] = placeholder[target=b_layers_2_feed_forward_w2_weight]\n",
      "      %b_layers_2_feed_forward_w2_scales : [num_users=1] = placeholder[target=b_layers_2_feed_forward_w2_scales]\n",
      "      %b_layers_3_attention_wq_weight : [num_users=1] = placeholder[target=b_layers_3_attention_wq_weight]\n",
      "      %b_layers_3_attention_wq_scales : [num_users=1] = placeholder[target=b_layers_3_attention_wq_scales]\n",
      "      %b_layers_3_attention_wk_weight : [num_users=1] = placeholder[target=b_layers_3_attention_wk_weight]\n",
      "      %b_layers_3_attention_wk_scales : [num_users=1] = placeholder[target=b_layers_3_attention_wk_scales]\n",
      "      %b_layers_3_attention_wv_weight : [num_users=1] = placeholder[target=b_layers_3_attention_wv_weight]\n",
      "      %b_layers_3_attention_wv_scales : [num_users=1] = placeholder[target=b_layers_3_attention_wv_scales]\n",
      "      %b_layers_3_attention_mask : [num_users=1] = placeholder[target=b_layers_3_attention_mask]\n",
      "      %b_layers_3_attention_wo_weight : [num_users=1] = placeholder[target=b_layers_3_attention_wo_weight]\n",
      "      %b_layers_3_attention_wo_scales : [num_users=1] = placeholder[target=b_layers_3_attention_wo_scales]\n",
      "      %b_layers_3_feed_forward_w1_weight : [num_users=1] = placeholder[target=b_layers_3_feed_forward_w1_weight]\n",
      "      %b_layers_3_feed_forward_w1_scales : [num_users=1] = placeholder[target=b_layers_3_feed_forward_w1_scales]\n",
      "      %b_layers_3_feed_forward_w3_weight : [num_users=1] = placeholder[target=b_layers_3_feed_forward_w3_weight]\n",
      "      %b_layers_3_feed_forward_w3_scales : [num_users=1] = placeholder[target=b_layers_3_feed_forward_w3_scales]\n",
      "      %b_layers_3_feed_forward_w2_weight : [num_users=1] = placeholder[target=b_layers_3_feed_forward_w2_weight]\n",
      "      %b_layers_3_feed_forward_w2_scales : [num_users=1] = placeholder[target=b_layers_3_feed_forward_w2_scales]\n",
      "      %b_layers_4_attention_wq_weight : [num_users=1] = placeholder[target=b_layers_4_attention_wq_weight]\n",
      "      %b_layers_4_attention_wq_scales : [num_users=1] = placeholder[target=b_layers_4_attention_wq_scales]\n",
      "      %b_layers_4_attention_wk_weight : [num_users=1] = placeholder[target=b_layers_4_attention_wk_weight]\n",
      "      %b_layers_4_attention_wk_scales : [num_users=1] = placeholder[target=b_layers_4_attention_wk_scales]\n",
      "      %b_layers_4_attention_wv_weight : [num_users=1] = placeholder[target=b_layers_4_attention_wv_weight]\n",
      "      %b_layers_4_attention_wv_scales : [num_users=1] = placeholder[target=b_layers_4_attention_wv_scales]\n",
      "      %b_layers_4_attention_mask : [num_users=1] = placeholder[target=b_layers_4_attention_mask]\n",
      "      %b_layers_4_attention_wo_weight : [num_users=1] = placeholder[target=b_layers_4_attention_wo_weight]\n",
      "      %b_layers_4_attention_wo_scales : [num_users=1] = placeholder[target=b_layers_4_attention_wo_scales]\n",
      "      %b_layers_4_feed_forward_w1_weight : [num_users=1] = placeholder[target=b_layers_4_feed_forward_w1_weight]\n",
      "      %b_layers_4_feed_forward_w1_scales : [num_users=1] = placeholder[target=b_layers_4_feed_forward_w1_scales]\n",
      "      %b_layers_4_feed_forward_w3_weight : [num_users=1] = placeholder[target=b_layers_4_feed_forward_w3_weight]\n",
      "      %b_layers_4_feed_forward_w3_scales : [num_users=1] = placeholder[target=b_layers_4_feed_forward_w3_scales]\n",
      "      %b_layers_4_feed_forward_w2_weight : [num_users=1] = placeholder[target=b_layers_4_feed_forward_w2_weight]\n",
      "      %b_layers_4_feed_forward_w2_scales : [num_users=1] = placeholder[target=b_layers_4_feed_forward_w2_scales]\n",
      "      %b_layers_5_attention_wq_weight : [num_users=1] = placeholder[target=b_layers_5_attention_wq_weight]\n",
      "      %b_layers_5_attention_wq_scales : [num_users=1] = placeholder[target=b_layers_5_attention_wq_scales]\n",
      "      %b_layers_5_attention_wk_weight : [num_users=1] = placeholder[target=b_layers_5_attention_wk_weight]\n",
      "      %b_layers_5_attention_wk_scales : [num_users=1] = placeholder[target=b_layers_5_attention_wk_scales]\n",
      "      %b_layers_5_attention_wv_weight : [num_users=1] = placeholder[target=b_layers_5_attention_wv_weight]\n",
      "      %b_layers_5_attention_wv_scales : [num_users=1] = placeholder[target=b_layers_5_attention_wv_scales]\n",
      "      %b_layers_5_attention_mask : [num_users=1] = placeholder[target=b_layers_5_attention_mask]\n",
      "      %b_layers_5_attention_wo_weight : [num_users=1] = placeholder[target=b_layers_5_attention_wo_weight]\n",
      "      %b_layers_5_attention_wo_scales : [num_users=1] = placeholder[target=b_layers_5_attention_wo_scales]\n",
      "      %b_layers_5_feed_forward_w1_weight : [num_users=1] = placeholder[target=b_layers_5_feed_forward_w1_weight]\n",
      "      %b_layers_5_feed_forward_w1_scales : [num_users=1] = placeholder[target=b_layers_5_feed_forward_w1_scales]\n",
      "      %b_layers_5_feed_forward_w3_weight : [num_users=1] = placeholder[target=b_layers_5_feed_forward_w3_weight]\n",
      "      %b_layers_5_feed_forward_w3_scales : [num_users=1] = placeholder[target=b_layers_5_feed_forward_w3_scales]\n",
      "      %b_layers_5_feed_forward_w2_weight : [num_users=1] = placeholder[target=b_layers_5_feed_forward_w2_weight]\n",
      "      %b_layers_5_feed_forward_w2_scales : [num_users=1] = placeholder[target=b_layers_5_feed_forward_w2_scales]\n",
      "      %b_layers_6_attention_wq_weight : [num_users=1] = placeholder[target=b_layers_6_attention_wq_weight]\n",
      "      %b_layers_6_attention_wq_scales : [num_users=1] = placeholder[target=b_layers_6_attention_wq_scales]\n",
      "      %b_layers_6_attention_wk_weight : [num_users=1] = placeholder[target=b_layers_6_attention_wk_weight]\n",
      "      %b_layers_6_attention_wk_scales : [num_users=1] = placeholder[target=b_layers_6_attention_wk_scales]\n",
      "      %b_layers_6_attention_wv_weight : [num_users=1] = placeholder[target=b_layers_6_attention_wv_weight]\n",
      "      %b_layers_6_attention_wv_scales : [num_users=1] = placeholder[target=b_layers_6_attention_wv_scales]\n",
      "      %b_layers_6_attention_mask : [num_users=1] = placeholder[target=b_layers_6_attention_mask]\n",
      "      %b_layers_6_attention_wo_weight : [num_users=1] = placeholder[target=b_layers_6_attention_wo_weight]\n",
      "      %b_layers_6_attention_wo_scales : [num_users=1] = placeholder[target=b_layers_6_attention_wo_scales]\n",
      "      %b_layers_6_feed_forward_w1_weight : [num_users=1] = placeholder[target=b_layers_6_feed_forward_w1_weight]\n",
      "      %b_layers_6_feed_forward_w1_scales : [num_users=1] = placeholder[target=b_layers_6_feed_forward_w1_scales]\n",
      "      %b_layers_6_feed_forward_w3_weight : [num_users=1] = placeholder[target=b_layers_6_feed_forward_w3_weight]\n",
      "      %b_layers_6_feed_forward_w3_scales : [num_users=1] = placeholder[target=b_layers_6_feed_forward_w3_scales]\n",
      "      %b_layers_6_feed_forward_w2_weight : [num_users=1] = placeholder[target=b_layers_6_feed_forward_w2_weight]\n",
      "      %b_layers_6_feed_forward_w2_scales : [num_users=1] = placeholder[target=b_layers_6_feed_forward_w2_scales]\n",
      "      %b_layers_7_attention_wq_weight : [num_users=1] = placeholder[target=b_layers_7_attention_wq_weight]\n",
      "      %b_layers_7_attention_wq_scales : [num_users=1] = placeholder[target=b_layers_7_attention_wq_scales]\n",
      "      %b_layers_7_attention_wk_weight : [num_users=1] = placeholder[target=b_layers_7_attention_wk_weight]\n",
      "      %b_layers_7_attention_wk_scales : [num_users=1] = placeholder[target=b_layers_7_attention_wk_scales]\n",
      "      %b_layers_7_attention_wv_weight : [num_users=1] = placeholder[target=b_layers_7_attention_wv_weight]\n",
      "      %b_layers_7_attention_wv_scales : [num_users=1] = placeholder[target=b_layers_7_attention_wv_scales]\n",
      "      %b_layers_7_attention_mask : [num_users=1] = placeholder[target=b_layers_7_attention_mask]\n",
      "      %b_layers_7_attention_wo_weight : [num_users=1] = placeholder[target=b_layers_7_attention_wo_weight]\n",
      "      %b_layers_7_attention_wo_scales : [num_users=1] = placeholder[target=b_layers_7_attention_wo_scales]\n",
      "      %b_layers_7_feed_forward_w1_weight : [num_users=1] = placeholder[target=b_layers_7_feed_forward_w1_weight]\n",
      "      %b_layers_7_feed_forward_w1_scales : [num_users=1] = placeholder[target=b_layers_7_feed_forward_w1_scales]\n",
      "      %b_layers_7_feed_forward_w3_weight : [num_users=1] = placeholder[target=b_layers_7_feed_forward_w3_weight]\n",
      "      %b_layers_7_feed_forward_w3_scales : [num_users=1] = placeholder[target=b_layers_7_feed_forward_w3_scales]\n",
      "      %b_layers_7_feed_forward_w2_weight : [num_users=1] = placeholder[target=b_layers_7_feed_forward_w2_weight]\n",
      "      %b_layers_7_feed_forward_w2_scales : [num_users=1] = placeholder[target=b_layers_7_feed_forward_w2_scales]\n",
      "      %b_layers_8_attention_wq_weight : [num_users=1] = placeholder[target=b_layers_8_attention_wq_weight]\n",
      "      %b_layers_8_attention_wq_scales : [num_users=1] = placeholder[target=b_layers_8_attention_wq_scales]\n",
      "      %b_layers_8_attention_wk_weight : [num_users=1] = placeholder[target=b_layers_8_attention_wk_weight]\n",
      "      %b_layers_8_attention_wk_scales : [num_users=1] = placeholder[target=b_layers_8_attention_wk_scales]\n",
      "      %b_layers_8_attention_wv_weight : [num_users=1] = placeholder[target=b_layers_8_attention_wv_weight]\n",
      "      %b_layers_8_attention_wv_scales : [num_users=1] = placeholder[target=b_layers_8_attention_wv_scales]\n",
      "      %b_layers_8_attention_mask : [num_users=1] = placeholder[target=b_layers_8_attention_mask]\n",
      "      %b_layers_8_attention_wo_weight : [num_users=1] = placeholder[target=b_layers_8_attention_wo_weight]\n",
      "      %b_layers_8_attention_wo_scales : [num_users=1] = placeholder[target=b_layers_8_attention_wo_scales]\n",
      "      %b_layers_8_feed_forward_w1_weight : [num_users=1] = placeholder[target=b_layers_8_feed_forward_w1_weight]\n",
      "      %b_layers_8_feed_forward_w1_scales : [num_users=1] = placeholder[target=b_layers_8_feed_forward_w1_scales]\n",
      "      %b_layers_8_feed_forward_w3_weight : [num_users=1] = placeholder[target=b_layers_8_feed_forward_w3_weight]\n",
      "      %b_layers_8_feed_forward_w3_scales : [num_users=1] = placeholder[target=b_layers_8_feed_forward_w3_scales]\n",
      "      %b_layers_8_feed_forward_w2_weight : [num_users=1] = placeholder[target=b_layers_8_feed_forward_w2_weight]\n",
      "      %b_layers_8_feed_forward_w2_scales : [num_users=1] = placeholder[target=b_layers_8_feed_forward_w2_scales]\n",
      "      %b_layers_9_attention_wq_weight : [num_users=1] = placeholder[target=b_layers_9_attention_wq_weight]\n",
      "      %b_layers_9_attention_wq_scales : [num_users=1] = placeholder[target=b_layers_9_attention_wq_scales]\n",
      "      %b_layers_9_attention_wk_weight : [num_users=1] = placeholder[target=b_layers_9_attention_wk_weight]\n",
      "      %b_layers_9_attention_wk_scales : [num_users=1] = placeholder[target=b_layers_9_attention_wk_scales]\n",
      "      %b_layers_9_attention_wv_weight : [num_users=1] = placeholder[target=b_layers_9_attention_wv_weight]\n",
      "      %b_layers_9_attention_wv_scales : [num_users=1] = placeholder[target=b_layers_9_attention_wv_scales]\n",
      "      %b_layers_9_attention_mask : [num_users=1] = placeholder[target=b_layers_9_attention_mask]\n",
      "      %b_layers_9_attention_wo_weight : [num_users=1] = placeholder[target=b_layers_9_attention_wo_weight]\n",
      "      %b_layers_9_attention_wo_scales : [num_users=1] = placeholder[target=b_layers_9_attention_wo_scales]\n",
      "      %b_layers_9_feed_forward_w1_weight : [num_users=1] = placeholder[target=b_layers_9_feed_forward_w1_weight]\n",
      "      %b_layers_9_feed_forward_w1_scales : [num_users=1] = placeholder[target=b_layers_9_feed_forward_w1_scales]\n",
      "      %b_layers_9_feed_forward_w3_weight : [num_users=1] = placeholder[target=b_layers_9_feed_forward_w3_weight]\n",
      "      %b_layers_9_feed_forward_w3_scales : [num_users=1] = placeholder[target=b_layers_9_feed_forward_w3_scales]\n",
      "      %b_layers_9_feed_forward_w2_weight : [num_users=1] = placeholder[target=b_layers_9_feed_forward_w2_weight]\n",
      "      %b_layers_9_feed_forward_w2_scales : [num_users=1] = placeholder[target=b_layers_9_feed_forward_w2_scales]\n",
      "      %b_layers_10_attention_wq_weight : [num_users=1] = placeholder[target=b_layers_10_attention_wq_weight]\n",
      "      %b_layers_10_attention_wq_scales : [num_users=1] = placeholder[target=b_layers_10_attention_wq_scales]\n",
      "      %b_layers_10_attention_wk_weight : [num_users=1] = placeholder[target=b_layers_10_attention_wk_weight]\n",
      "      %b_layers_10_attention_wk_scales : [num_users=1] = placeholder[target=b_layers_10_attention_wk_scales]\n",
      "      %b_layers_10_attention_wv_weight : [num_users=1] = placeholder[target=b_layers_10_attention_wv_weight]\n",
      "      %b_layers_10_attention_wv_scales : [num_users=1] = placeholder[target=b_layers_10_attention_wv_scales]\n",
      "      %b_layers_10_attention_mask : [num_users=1] = placeholder[target=b_layers_10_attention_mask]\n",
      "      %b_layers_10_attention_wo_weight : [num_users=1] = placeholder[target=b_layers_10_attention_wo_weight]\n",
      "      %b_layers_10_attention_wo_scales : [num_users=1] = placeholder[target=b_layers_10_attention_wo_scales]\n",
      "      %b_layers_10_feed_forward_w1_weight : [num_users=1] = placeholder[target=b_layers_10_feed_forward_w1_weight]\n",
      "      %b_layers_10_feed_forward_w1_scales : [num_users=1] = placeholder[target=b_layers_10_feed_forward_w1_scales]\n",
      "      %b_layers_10_feed_forward_w3_weight : [num_users=1] = placeholder[target=b_layers_10_feed_forward_w3_weight]\n",
      "      %b_layers_10_feed_forward_w3_scales : [num_users=1] = placeholder[target=b_layers_10_feed_forward_w3_scales]\n",
      "      %b_layers_10_feed_forward_w2_weight : [num_users=1] = placeholder[target=b_layers_10_feed_forward_w2_weight]\n",
      "      %b_layers_10_feed_forward_w2_scales : [num_users=1] = placeholder[target=b_layers_10_feed_forward_w2_scales]\n",
      "      %b_layers_11_attention_wq_weight : [num_users=1] = placeholder[target=b_layers_11_attention_wq_weight]\n",
      "      %b_layers_11_attention_wq_scales : [num_users=1] = placeholder[target=b_layers_11_attention_wq_scales]\n",
      "      %b_layers_11_attention_wk_weight : [num_users=1] = placeholder[target=b_layers_11_attention_wk_weight]\n",
      "      %b_layers_11_attention_wk_scales : [num_users=1] = placeholder[target=b_layers_11_attention_wk_scales]\n",
      "      %b_layers_11_attention_wv_weight : [num_users=1] = placeholder[target=b_layers_11_attention_wv_weight]\n",
      "      %b_layers_11_attention_wv_scales : [num_users=1] = placeholder[target=b_layers_11_attention_wv_scales]\n",
      "      %b_layers_11_attention_mask : [num_users=1] = placeholder[target=b_layers_11_attention_mask]\n",
      "      %b_layers_11_attention_wo_weight : [num_users=1] = placeholder[target=b_layers_11_attention_wo_weight]\n",
      "      %b_layers_11_attention_wo_scales : [num_users=1] = placeholder[target=b_layers_11_attention_wo_scales]\n",
      "      %b_layers_11_feed_forward_w1_weight : [num_users=1] = placeholder[target=b_layers_11_feed_forward_w1_weight]\n",
      "      %b_layers_11_feed_forward_w1_scales : [num_users=1] = placeholder[target=b_layers_11_feed_forward_w1_scales]\n",
      "      %b_layers_11_feed_forward_w3_weight : [num_users=1] = placeholder[target=b_layers_11_feed_forward_w3_weight]\n",
      "      %b_layers_11_feed_forward_w3_scales : [num_users=1] = placeholder[target=b_layers_11_feed_forward_w3_scales]\n",
      "      %b_layers_11_feed_forward_w2_weight : [num_users=1] = placeholder[target=b_layers_11_feed_forward_w2_weight]\n",
      "      %b_layers_11_feed_forward_w2_scales : [num_users=1] = placeholder[target=b_layers_11_feed_forward_w2_scales]\n",
      "      %b_output_weight : [num_users=1] = placeholder[target=b_output_weight]\n",
      "      %b_output_scales : [num_users=1] = placeholder[target=b_output_scales]\n",
      "      %_lifted_tensor_constant208 : [num_users=1] = placeholder[target=_lifted_tensor_constant208]\n",
      "      %_lifted_tensor_constant209 : [num_users=1] = placeholder[target=_lifted_tensor_constant209]\n",
      "      %_lifted_tensor_constant210 : [num_users=1] = placeholder[target=_lifted_tensor_constant210]\n",
      "      %_lifted_tensor_constant211 : [num_users=1] = placeholder[target=_lifted_tensor_constant211]\n",
      "      %_lifted_tensor_constant212 : [num_users=1] = placeholder[target=_lifted_tensor_constant212]\n",
      "      %_lifted_tensor_constant213 : [num_users=1] = placeholder[target=_lifted_tensor_constant213]\n",
      "      %_lifted_tensor_constant214 : [num_users=1] = placeholder[target=_lifted_tensor_constant214]\n",
      "      %_lifted_tensor_constant215 : [num_users=1] = placeholder[target=_lifted_tensor_constant215]\n",
      "      %_lifted_tensor_constant216 : [num_users=1] = placeholder[target=_lifted_tensor_constant216]\n",
      "      %_lifted_tensor_constant217 : [num_users=1] = placeholder[target=_lifted_tensor_constant217]\n",
      "      %_lifted_tensor_constant218 : [num_users=1] = placeholder[target=_lifted_tensor_constant218]\n",
      "      %_lifted_tensor_constant219 : [num_users=1] = placeholder[target=_lifted_tensor_constant219]\n",
      "      %_lifted_tensor_constant220 : [num_users=1] = placeholder[target=_lifted_tensor_constant220]\n",
      "      %_lifted_tensor_constant221 : [num_users=1] = placeholder[target=_lifted_tensor_constant221]\n",
      "      %_lifted_tensor_constant222 : [num_users=1] = placeholder[target=_lifted_tensor_constant222]\n",
      "      %_lifted_tensor_constant223 : [num_users=1] = placeholder[target=_lifted_tensor_constant223]\n",
      "      %_lifted_tensor_constant224 : [num_users=1] = placeholder[target=_lifted_tensor_constant224]\n",
      "      %_lifted_tensor_constant225 : [num_users=1] = placeholder[target=_lifted_tensor_constant225]\n",
      "      %_lifted_tensor_constant226 : [num_users=1] = placeholder[target=_lifted_tensor_constant226]\n",
      "      %_lifted_tensor_constant227 : [num_users=1] = placeholder[target=_lifted_tensor_constant227]\n",
      "      %_lifted_tensor_constant228 : [num_users=1] = placeholder[target=_lifted_tensor_constant228]\n",
      "      %_lifted_tensor_constant229 : [num_users=1] = placeholder[target=_lifted_tensor_constant229]\n",
      "      %_lifted_tensor_constant230 : [num_users=1] = placeholder[target=_lifted_tensor_constant230]\n",
      "      %_lifted_tensor_constant231 : [num_users=1] = placeholder[target=_lifted_tensor_constant231]\n",
      "      %_lifted_tensor_constant232 : [num_users=1] = placeholder[target=_lifted_tensor_constant232]\n",
      "      %_lifted_tensor_constant233 : [num_users=1] = placeholder[target=_lifted_tensor_constant233]\n",
      "      %_lifted_tensor_constant234 : [num_users=1] = placeholder[target=_lifted_tensor_constant234]\n",
      "      %_lifted_tensor_constant235 : [num_users=1] = placeholder[target=_lifted_tensor_constant235]\n",
      "      %_lifted_tensor_constant236 : [num_users=1] = placeholder[target=_lifted_tensor_constant236]\n",
      "      %_lifted_tensor_constant237 : [num_users=1] = placeholder[target=_lifted_tensor_constant237]\n",
      "      %_lifted_tensor_constant238 : [num_users=1] = placeholder[target=_lifted_tensor_constant238]\n",
      "      %_lifted_tensor_constant239 : [num_users=1] = placeholder[target=_lifted_tensor_constant239]\n",
      "      %_lifted_tensor_constant240 : [num_users=1] = placeholder[target=_lifted_tensor_constant240]\n",
      "      %_lifted_tensor_constant241 : [num_users=1] = placeholder[target=_lifted_tensor_constant241]\n",
      "      %_lifted_tensor_constant242 : [num_users=1] = placeholder[target=_lifted_tensor_constant242]\n",
      "      %_lifted_tensor_constant243 : [num_users=1] = placeholder[target=_lifted_tensor_constant243]\n",
      "      %_lifted_tensor_constant244 : [num_users=1] = placeholder[target=_lifted_tensor_constant244]\n",
      "      %b_layers_0_attention_sdpa_kv_cache_v_cache : [num_users=3] = placeholder[target=b_layers_0_attention_sdpa_kv_cache_v_cache]\n",
      "      %b_layers_0_attention_sdpa_kv_cache_k_cache : [num_users=3] = placeholder[target=b_layers_0_attention_sdpa_kv_cache_k_cache]\n",
      "      %b_layers_1_attention_sdpa_kv_cache_v_cache : [num_users=3] = placeholder[target=b_layers_1_attention_sdpa_kv_cache_v_cache]\n",
      "      %b_layers_1_attention_sdpa_kv_cache_k_cache : [num_users=3] = placeholder[target=b_layers_1_attention_sdpa_kv_cache_k_cache]\n",
      "      %b_layers_2_attention_sdpa_kv_cache_v_cache : [num_users=3] = placeholder[target=b_layers_2_attention_sdpa_kv_cache_v_cache]\n",
      "      %b_layers_2_attention_sdpa_kv_cache_k_cache : [num_users=3] = placeholder[target=b_layers_2_attention_sdpa_kv_cache_k_cache]\n",
      "      %b_layers_3_attention_sdpa_kv_cache_v_cache : [num_users=3] = placeholder[target=b_layers_3_attention_sdpa_kv_cache_v_cache]\n",
      "      %b_layers_3_attention_sdpa_kv_cache_k_cache : [num_users=3] = placeholder[target=b_layers_3_attention_sdpa_kv_cache_k_cache]\n",
      "      %b_layers_4_attention_sdpa_kv_cache_v_cache : [num_users=3] = placeholder[target=b_layers_4_attention_sdpa_kv_cache_v_cache]\n",
      "      %b_layers_4_attention_sdpa_kv_cache_k_cache : [num_users=3] = placeholder[target=b_layers_4_attention_sdpa_kv_cache_k_cache]\n",
      "      %b_layers_5_attention_sdpa_kv_cache_v_cache : [num_users=3] = placeholder[target=b_layers_5_attention_sdpa_kv_cache_v_cache]\n",
      "      %b_layers_5_attention_sdpa_kv_cache_k_cache : [num_users=3] = placeholder[target=b_layers_5_attention_sdpa_kv_cache_k_cache]\n",
      "      %b_layers_6_attention_sdpa_kv_cache_v_cache : [num_users=3] = placeholder[target=b_layers_6_attention_sdpa_kv_cache_v_cache]\n",
      "      %b_layers_6_attention_sdpa_kv_cache_k_cache : [num_users=3] = placeholder[target=b_layers_6_attention_sdpa_kv_cache_k_cache]\n",
      "      %b_layers_7_attention_sdpa_kv_cache_v_cache : [num_users=3] = placeholder[target=b_layers_7_attention_sdpa_kv_cache_v_cache]\n",
      "      %b_layers_7_attention_sdpa_kv_cache_k_cache : [num_users=3] = placeholder[target=b_layers_7_attention_sdpa_kv_cache_k_cache]\n",
      "      %b_layers_8_attention_sdpa_kv_cache_v_cache : [num_users=3] = placeholder[target=b_layers_8_attention_sdpa_kv_cache_v_cache]\n",
      "      %b_layers_8_attention_sdpa_kv_cache_k_cache : [num_users=3] = placeholder[target=b_layers_8_attention_sdpa_kv_cache_k_cache]\n",
      "      %b_layers_9_attention_sdpa_kv_cache_v_cache : [num_users=3] = placeholder[target=b_layers_9_attention_sdpa_kv_cache_v_cache]\n",
      "      %b_layers_9_attention_sdpa_kv_cache_k_cache : [num_users=3] = placeholder[target=b_layers_9_attention_sdpa_kv_cache_k_cache]\n",
      "      %b_layers_10_attention_sdpa_kv_cache_v_cache : [num_users=3] = placeholder[target=b_layers_10_attention_sdpa_kv_cache_v_cache]\n",
      "      %b_layers_10_attention_sdpa_kv_cache_k_cache : [num_users=3] = placeholder[target=b_layers_10_attention_sdpa_kv_cache_k_cache]\n",
      "      %b_layers_11_attention_sdpa_kv_cache_v_cache : [num_users=3] = placeholder[target=b_layers_11_attention_sdpa_kv_cache_v_cache]\n",
      "      %b_layers_11_attention_sdpa_kv_cache_k_cache : [num_users=3] = placeholder[target=b_layers_11_attention_sdpa_kv_cache_k_cache]\n",
      "      %tokens : [num_users=1] = placeholder[target=tokens]\n",
      "      %input_pos : [num_users=38] = placeholder[target=input_pos]\n",
      "      %aten_embedding_default : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.embedding.default](args = (%p_tok_embeddings_weight, %tokens), kwargs = {})\n",
      "      %aten_index_tensor : [num_users=12] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%b_freqs_cos, [%input_pos]), kwargs = {})\n",
      "      %aten_index_tensor_1 : [num_users=12] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%b_freqs_sin, [%input_pos]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%b_layers_0_attention_mask, 0), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%b_layers_1_attention_mask, 0), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%b_layers_2_attention_mask, 0), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_28 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%b_layers_3_attention_mask, 0), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_36 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%b_layers_4_attention_mask, 0), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_44 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%b_layers_5_attention_mask, 0), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_52 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%b_layers_6_attention_mask, 0), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_60 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%b_layers_7_attention_mask, 0), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_68 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%b_layers_8_attention_mask, 0), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_76 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%b_layers_9_attention_mask, 0), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_84 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%b_layers_10_attention_mask, 0), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_92 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%b_layers_11_attention_mask, 0), kwargs = {})\n",
      "      %aten_mul_tensor : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_embedding_default, %aten_embedding_default), kwargs = {})\n",
      "      %aten_view_copy_default_5 : [num_users=4] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_25 : [num_users=4] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_45 : [num_users=4] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_65 : [num_users=4] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_85 : [num_users=4] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_105 : [num_users=4] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_125 : [num_users=4] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_145 : [num_users=4] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_165 : [num_users=4] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_185 : [num_users=4] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_205 : [num_users=4] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_225 : [num_users=4] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_6 : [num_users=4] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor_1, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_26 : [num_users=4] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor_1, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_46 : [num_users=4] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor_1, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_66 : [num_users=4] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor_1, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_86 : [num_users=4] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor_1, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_106 : [num_users=4] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor_1, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_126 : [num_users=4] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor_1, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_146 : [num_users=4] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor_1, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_166 : [num_users=4] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor_1, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_186 : [num_users=4] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor_1, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_206 : [num_users=4] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor_1, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_view_copy_default_226 : [num_users=4] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_index_tensor_1, [1, 1, 1, 32]), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_unsqueeze_copy_default_4, 1), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_unsqueeze_copy_default_12, 1), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_unsqueeze_copy_default_20, 1), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_29 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_unsqueeze_copy_default_28, 1), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_37 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_unsqueeze_copy_default_36, 1), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_45 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_unsqueeze_copy_default_44, 1), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_53 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_unsqueeze_copy_default_52, 1), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_61 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_unsqueeze_copy_default_60, 1), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_69 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_unsqueeze_copy_default_68, 1), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_77 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_unsqueeze_copy_default_76, 1), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_85 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_unsqueeze_copy_default_84, 1), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_93 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_unsqueeze_copy_default_92, 1), kwargs = {})\n",
      "      %aten_mean_dim : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor, [-1], True), kwargs = {})\n",
      "      %aten_index_tensor_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%aten_unsqueeze_copy_default_5, [None, None, %input_pos]), kwargs = {})\n",
      "      %aten_index_tensor_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%aten_unsqueeze_copy_default_13, [None, None, %input_pos]), kwargs = {})\n",
      "      %aten_index_tensor_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%aten_unsqueeze_copy_default_21, [None, None, %input_pos]), kwargs = {})\n",
      "      %aten_index_tensor_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%aten_unsqueeze_copy_default_29, [None, None, %input_pos]), kwargs = {})\n",
      "      %aten_index_tensor_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%aten_unsqueeze_copy_default_37, [None, None, %input_pos]), kwargs = {})\n",
      "      %aten_index_tensor_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%aten_unsqueeze_copy_default_45, [None, None, %input_pos]), kwargs = {})\n",
      "      %aten_index_tensor_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%aten_unsqueeze_copy_default_53, [None, None, %input_pos]), kwargs = {})\n",
      "      %aten_index_tensor_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%aten_unsqueeze_copy_default_61, [None, None, %input_pos]), kwargs = {})\n",
      "      %aten_index_tensor_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%aten_unsqueeze_copy_default_69, [None, None, %input_pos]), kwargs = {})\n",
      "      %aten_index_tensor_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%aten_unsqueeze_copy_default_77, [None, None, %input_pos]), kwargs = {})\n",
      "      %aten_index_tensor_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%aten_unsqueeze_copy_default_85, [None, None, %input_pos]), kwargs = {})\n",
      "      %aten_index_tensor_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index.Tensor](args = (%aten_unsqueeze_copy_default_93, [None, None, %input_pos]), kwargs = {})\n",
      "      %aten_add_tensor : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim, %_lifted_tensor_constant208), kwargs = {})\n",
      "      %aten__to_copy_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%aten_index_tensor_2,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%aten_index_tensor_3,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%aten_index_tensor_4,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%aten_index_tensor_5,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%aten_index_tensor_6,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%aten_index_tensor_7,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%aten_index_tensor_8,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%aten_index_tensor_9,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%aten_index_tensor_10,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%aten_index_tensor_11,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%aten_index_tensor_12,), kwargs = {dtype: torch.float32})\n",
      "      %aten__to_copy_default_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._to_copy.default](args = (%aten_index_tensor_13,), kwargs = {dtype: torch.float32})\n",
      "      %aten_rsqrt_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor,), kwargs = {})\n",
      "      %aten_mul_tensor_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_embedding_default, %aten_rsqrt_default), kwargs = {})\n",
      "      %aten_mul_tensor_2 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_1, %p_layers_0_attention_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_2, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_2, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_2, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims, %b_layers_0_attention_wq_weight, %b_layers_0_attention_wq_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_1, %b_layers_0_attention_wk_weight, %b_layers_0_attention_wk_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_2, %b_layers_0_attention_wv_weight, %b_layers_0_attention_wv_scales), kwargs = {})\n",
      "      %aten_view_copy_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_1, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_2, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_3 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_4 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_1, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_permute_copy_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_2, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_slice_copy_tensor : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_3, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_3, 4, 1, 2), kwargs = {})\n",
      "      %aten_slice_copy_tensor_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_4, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_4, 4, 1, 2), kwargs = {})\n",
      "      %aten_view_copy_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_2, [12, 1, 64]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_3 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_4 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_1, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_5 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_2, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_6 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_3, [4]), kwargs = {})\n",
      "      %aten_index_put_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index_put.default](args = (%b_layers_0_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %aten_view_copy_default_10), kwargs = {})\n",
      "      %aten_mul_tensor_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_3, %aten_view_copy_default_5), kwargs = {})\n",
      "      %aten_mul_tensor_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_3, %aten_view_copy_default_6), kwargs = {})\n",
      "      %aten_mul_tensor_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_4, %aten_view_copy_default_6), kwargs = {})\n",
      "      %aten_mul_tensor_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_4, %aten_view_copy_default_5), kwargs = {})\n",
      "      %aten_mul_tensor_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_5, %aten_view_copy_default_5), kwargs = {})\n",
      "      %aten_mul_tensor_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_5, %aten_view_copy_default_6), kwargs = {})\n",
      "      %aten_mul_tensor_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_6, %aten_view_copy_default_6), kwargs = {})\n",
      "      %aten_mul_tensor_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_6, %aten_view_copy_default_5), kwargs = {})\n",
      "      %aten_slice_scatter_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_0_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_1, 1, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_sub_tensor : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_3, %aten_mul_tensor_4), kwargs = {})\n",
      "      %aten_add_tensor_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_5, %aten_mul_tensor_6), kwargs = {})\n",
      "      %aten_sub_tensor_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_7, %aten_mul_tensor_8), kwargs = {})\n",
      "      %aten_add_tensor_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_9, %aten_mul_tensor_10), kwargs = {})\n",
      "      %aten_slice_scatter_default_3 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_0_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_2, 0, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_1, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_1, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_2, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_3, 2), kwargs = {})\n",
      "      %aten_cat_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default, %aten_unsqueeze_copy_default_1], -1), kwargs = {})\n",
      "      %aten_cat_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_2, %aten_unsqueeze_copy_default_3], -1), kwargs = {})\n",
      "      %aten_expand_copy_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_7, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_1, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_clone_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_1,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_permute_copy_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_7, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_permute_copy_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_8, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_1, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_1, [12, 1, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_view_copy_default_12, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_2, [12, 1, 64]), kwargs = {})\n",
      "      %aten_index_put_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index_put.default](args = (%b_layers_0_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %aten_view_copy_default_9), kwargs = {})\n",
      "      %aten_view_copy_default_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_5, [12, 128, 64]), kwargs = {})\n",
      "      %aten_slice_scatter_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_0_attention_sdpa_kv_cache_k_cache, %aten_index_put_default, 1, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_slice_scatter_default_1 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_0_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default, 0, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_1, 2), kwargs = {})\n",
      "      %aten_expand_copy_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_6, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_clone_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_view_copy_default_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_11, [0, 1, 3, 2]), kwargs = {})\n",
      "      %aten_expand_copy_default_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_3, [1, 12, 64, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_3, [12, 64, 128]), kwargs = {})\n",
      "      %aten_bmm_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_13, %aten_view_copy_default_14), kwargs = {})\n",
      "      %aten_view_copy_default_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_mul_tensor_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_view_copy_default_15, %_lifted_tensor_constant209), kwargs = {})\n",
      "      %aten_add_tensor_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_11, %aten__to_copy_default), kwargs = {})\n",
      "      %aten__softmax_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._softmax.default](args = (%aten_add_tensor_3, -1, False), kwargs = {})\n",
      "      %aten_expand_copy_default_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten__softmax_default, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_4, [12, 1, 128]), kwargs = {})\n",
      "      %aten_bmm_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_16, %aten_view_copy_default_17), kwargs = {})\n",
      "      %aten_view_copy_default_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_1, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_18, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_4, [1, 1, 768]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_view_copy_default_19, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_7, %b_layers_0_attention_wo_weight, %b_layers_0_attention_wo_scales), kwargs = {})\n",
      "      %aten_add_tensor_4 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_embedding_default, %aten__weight_int8pack_mm_default_3), kwargs = {})\n",
      "      %aten_mul_tensor_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_4, %aten_add_tensor_4), kwargs = {})\n",
      "      %aten_mean_dim_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_12, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_1, %_lifted_tensor_constant210), kwargs = {})\n",
      "      %aten_rsqrt_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_5,), kwargs = {})\n",
      "      %aten_mul_tensor_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_4, %aten_rsqrt_default_1), kwargs = {})\n",
      "      %aten_mul_tensor_14 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_13, %p_layers_0_ffn_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_14, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_14, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_4 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_8, %b_layers_0_feed_forward_w1_weight, %b_layers_0_feed_forward_w1_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_9, %b_layers_0_feed_forward_w3_weight, %b_layers_0_feed_forward_w3_scales), kwargs = {})\n",
      "      %aten_sigmoid_default : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sigmoid.default](args = (%aten__weight_int8pack_mm_default_4,), kwargs = {})\n",
      "      %aten_mul_tensor_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten__weight_int8pack_mm_default_4, %aten_sigmoid_default), kwargs = {})\n",
      "      %aten_mul_tensor_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_15, %aten__weight_int8pack_mm_default_5), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_mul_tensor_16, %b_layers_0_feed_forward_w2_weight, %b_layers_0_feed_forward_w2_scales), kwargs = {})\n",
      "      %aten_add_tensor_6 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_4, %aten__weight_int8pack_mm_default_6), kwargs = {})\n",
      "      %aten_mul_tensor_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_6, %aten_add_tensor_6), kwargs = {})\n",
      "      %aten_mean_dim_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_17, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_2, %_lifted_tensor_constant211), kwargs = {})\n",
      "      %aten_rsqrt_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_7,), kwargs = {})\n",
      "      %aten_mul_tensor_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_6, %aten_rsqrt_default_2), kwargs = {})\n",
      "      %aten_mul_tensor_19 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_18, %p_layers_1_attention_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_19, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_19, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_19, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_10, %b_layers_1_attention_wq_weight, %b_layers_1_attention_wq_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_11, %b_layers_1_attention_wk_weight, %b_layers_1_attention_wk_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_12, %b_layers_1_attention_wv_weight, %b_layers_1_attention_wv_scales), kwargs = {})\n",
      "      %aten_view_copy_default_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_7, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_8, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_9, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_23 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_20, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_24 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_21, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_permute_copy_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_22, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_23, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_23, 4, 1, 2), kwargs = {})\n",
      "      %aten_slice_copy_tensor_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_24, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_24, 4, 1, 2), kwargs = {})\n",
      "      %aten_view_copy_default_30 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_7, [12, 1, 64]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_13 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_4, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_14 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_5, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_15 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_6, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_16 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_7, [4]), kwargs = {})\n",
      "      %aten_index_put_default_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index_put.default](args = (%b_layers_1_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %aten_view_copy_default_30), kwargs = {})\n",
      "      %aten_mul_tensor_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_13, %aten_view_copy_default_25), kwargs = {})\n",
      "      %aten_mul_tensor_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_13, %aten_view_copy_default_26), kwargs = {})\n",
      "      %aten_mul_tensor_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_14, %aten_view_copy_default_26), kwargs = {})\n",
      "      %aten_mul_tensor_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_14, %aten_view_copy_default_25), kwargs = {})\n",
      "      %aten_mul_tensor_24 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_15, %aten_view_copy_default_25), kwargs = {})\n",
      "      %aten_mul_tensor_26 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_15, %aten_view_copy_default_26), kwargs = {})\n",
      "      %aten_mul_tensor_25 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_16, %aten_view_copy_default_26), kwargs = {})\n",
      "      %aten_mul_tensor_27 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_16, %aten_view_copy_default_25), kwargs = {})\n",
      "      %aten_slice_scatter_default_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_1_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_3, 1, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_sub_tensor_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_20, %aten_mul_tensor_21), kwargs = {})\n",
      "      %aten_add_tensor_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_22, %aten_mul_tensor_23), kwargs = {})\n",
      "      %aten_sub_tensor_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_24, %aten_mul_tensor_25), kwargs = {})\n",
      "      %aten_add_tensor_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_26, %aten_mul_tensor_27), kwargs = {})\n",
      "      %aten_slice_scatter_default_7 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_1_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_6, 0, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_2, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_8, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_3, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_9, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_7, 2), kwargs = {})\n",
      "      %aten_cat_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_8, %aten_unsqueeze_copy_default_9], -1), kwargs = {})\n",
      "      %aten_cat_default_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_10, %aten_unsqueeze_copy_default_11], -1), kwargs = {})\n",
      "      %aten_expand_copy_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_15, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_27 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_2, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_28 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_3, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_clone_default_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_7,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_permute_copy_default_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_27, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_permute_copy_default_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_28, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_32 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_3, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_5, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_29 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_6, [12, 1, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_view_copy_default_32, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_33 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_8, [12, 1, 64]), kwargs = {})\n",
      "      %aten_index_put_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index_put.default](args = (%b_layers_1_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %aten_view_copy_default_29), kwargs = {})\n",
      "      %aten_view_copy_default_37 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_11, [12, 128, 64]), kwargs = {})\n",
      "      %aten_slice_scatter_default_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_1_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_2, 1, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_slice_scatter_default_5 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_1_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_4, 0, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_5, 2), kwargs = {})\n",
      "      %aten_expand_copy_default_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_14, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_clone_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_6,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_view_copy_default_31 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_2, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_31, [0, 1, 3, 2]), kwargs = {})\n",
      "      %aten_expand_copy_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_8, [1, 12, 64, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_34 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_9, [12, 64, 128]), kwargs = {})\n",
      "      %aten_bmm_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_33, %aten_view_copy_default_34), kwargs = {})\n",
      "      %aten_view_copy_default_35 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_2, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_mul_tensor_28 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_view_copy_default_35, %_lifted_tensor_constant212), kwargs = {})\n",
      "      %aten_add_tensor_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_28, %aten__to_copy_default_1), kwargs = {})\n",
      "      %aten__softmax_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._softmax.default](args = (%aten_add_tensor_10, -1, False), kwargs = {})\n",
      "      %aten_expand_copy_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten__softmax_default_1, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_36 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_10, [12, 1, 128]), kwargs = {})\n",
      "      %aten_bmm_default_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_36, %aten_view_copy_default_37), kwargs = {})\n",
      "      %aten_view_copy_default_38 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_3, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_38, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_39 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_9, [1, 1, 768]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_view_copy_default_39, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_17, %b_layers_1_attention_wo_weight, %b_layers_1_attention_wo_scales), kwargs = {})\n",
      "      %aten_add_tensor_11 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_6, %aten__weight_int8pack_mm_default_10), kwargs = {})\n",
      "      %aten_mul_tensor_29 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_11, %aten_add_tensor_11), kwargs = {})\n",
      "      %aten_mean_dim_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_29, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_3, %_lifted_tensor_constant213), kwargs = {})\n",
      "      %aten_rsqrt_default_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_12,), kwargs = {})\n",
      "      %aten_mul_tensor_30 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_11, %aten_rsqrt_default_3), kwargs = {})\n",
      "      %aten_mul_tensor_31 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_30, %p_layers_1_ffn_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_31, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_31, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_11 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_18, %b_layers_1_feed_forward_w1_weight, %b_layers_1_feed_forward_w1_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_19, %b_layers_1_feed_forward_w3_weight, %b_layers_1_feed_forward_w3_scales), kwargs = {})\n",
      "      %aten_sigmoid_default_1 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sigmoid.default](args = (%aten__weight_int8pack_mm_default_11,), kwargs = {})\n",
      "      %aten_mul_tensor_32 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten__weight_int8pack_mm_default_11, %aten_sigmoid_default_1), kwargs = {})\n",
      "      %aten_mul_tensor_33 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_32, %aten__weight_int8pack_mm_default_12), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_mul_tensor_33, %b_layers_1_feed_forward_w2_weight, %b_layers_1_feed_forward_w2_scales), kwargs = {})\n",
      "      %aten_add_tensor_13 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_11, %aten__weight_int8pack_mm_default_13), kwargs = {})\n",
      "      %aten_mul_tensor_34 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_13, %aten_add_tensor_13), kwargs = {})\n",
      "      %aten_mean_dim_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_34, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_4, %_lifted_tensor_constant214), kwargs = {})\n",
      "      %aten_rsqrt_default_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_14,), kwargs = {})\n",
      "      %aten_mul_tensor_35 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_13, %aten_rsqrt_default_4), kwargs = {})\n",
      "      %aten_mul_tensor_36 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_35, %p_layers_2_attention_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_36, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_36, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_36, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_20, %b_layers_2_attention_wq_weight, %b_layers_2_attention_wq_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_21, %b_layers_2_attention_wk_weight, %b_layers_2_attention_wk_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_22, %b_layers_2_attention_wv_weight, %b_layers_2_attention_wv_scales), kwargs = {})\n",
      "      %aten_view_copy_default_40 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_14, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_41 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_15, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_42 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_16, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_43 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_40, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_44 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_41, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_permute_copy_default_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_42, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_43, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_43, 4, 1, 2), kwargs = {})\n",
      "      %aten_slice_copy_tensor_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_44, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_44, 4, 1, 2), kwargs = {})\n",
      "      %aten_view_copy_default_50 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_12, [12, 1, 64]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_23 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_8, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_24 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_9, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_25 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_10, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_26 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_11, [4]), kwargs = {})\n",
      "      %aten_index_put_default_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index_put.default](args = (%b_layers_2_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %aten_view_copy_default_50), kwargs = {})\n",
      "      %aten_mul_tensor_37 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_23, %aten_view_copy_default_45), kwargs = {})\n",
      "      %aten_mul_tensor_39 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_23, %aten_view_copy_default_46), kwargs = {})\n",
      "      %aten_mul_tensor_38 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_24, %aten_view_copy_default_46), kwargs = {})\n",
      "      %aten_mul_tensor_40 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_24, %aten_view_copy_default_45), kwargs = {})\n",
      "      %aten_mul_tensor_41 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_25, %aten_view_copy_default_45), kwargs = {})\n",
      "      %aten_mul_tensor_43 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_25, %aten_view_copy_default_46), kwargs = {})\n",
      "      %aten_mul_tensor_42 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_26, %aten_view_copy_default_46), kwargs = {})\n",
      "      %aten_mul_tensor_44 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_26, %aten_view_copy_default_45), kwargs = {})\n",
      "      %aten_slice_scatter_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_2_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_5, 1, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_sub_tensor_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_37, %aten_mul_tensor_38), kwargs = {})\n",
      "      %aten_add_tensor_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_39, %aten_mul_tensor_40), kwargs = {})\n",
      "      %aten_sub_tensor_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_41, %aten_mul_tensor_42), kwargs = {})\n",
      "      %aten_add_tensor_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_43, %aten_mul_tensor_44), kwargs = {})\n",
      "      %aten_slice_scatter_default_11 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_2_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_10, 0, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_4, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_15, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_5, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_16, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_11, 2), kwargs = {})\n",
      "      %aten_cat_default_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_16, %aten_unsqueeze_copy_default_17], -1), kwargs = {})\n",
      "      %aten_cat_default_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_18, %aten_unsqueeze_copy_default_19], -1), kwargs = {})\n",
      "      %aten_expand_copy_default_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_23, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_47 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_4, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_48 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_5, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_clone_default_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_13,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_permute_copy_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_47, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_permute_copy_default_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_48, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_52 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_5, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_10, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_49 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_11, [12, 1, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_view_copy_default_52, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_53 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_14, [12, 1, 64]), kwargs = {})\n",
      "      %aten_index_put_default_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index_put.default](args = (%b_layers_2_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %aten_view_copy_default_49), kwargs = {})\n",
      "      %aten_view_copy_default_57 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_17, [12, 128, 64]), kwargs = {})\n",
      "      %aten_slice_scatter_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_2_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_4, 1, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_slice_scatter_default_9 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_2_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_8, 0, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_9, 2), kwargs = {})\n",
      "      %aten_expand_copy_default_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_22, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_clone_default_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_12,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_view_copy_default_51 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_4, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_51, [0, 1, 3, 2]), kwargs = {})\n",
      "      %aten_expand_copy_default_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_13, [1, 12, 64, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_54 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_15, [12, 64, 128]), kwargs = {})\n",
      "      %aten_bmm_default_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_53, %aten_view_copy_default_54), kwargs = {})\n",
      "      %aten_view_copy_default_55 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_4, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_mul_tensor_45 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_view_copy_default_55, %_lifted_tensor_constant215), kwargs = {})\n",
      "      %aten_add_tensor_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_45, %aten__to_copy_default_2), kwargs = {})\n",
      "      %aten__softmax_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._softmax.default](args = (%aten_add_tensor_17, -1, False), kwargs = {})\n",
      "      %aten_expand_copy_default_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten__softmax_default_2, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_56 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_16, [12, 1, 128]), kwargs = {})\n",
      "      %aten_bmm_default_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_56, %aten_view_copy_default_57), kwargs = {})\n",
      "      %aten_view_copy_default_58 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_5, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_58, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_59 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_14, [1, 1, 768]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_27 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_view_copy_default_59, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_27, %b_layers_2_attention_wo_weight, %b_layers_2_attention_wo_scales), kwargs = {})\n",
      "      %aten_add_tensor_18 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_13, %aten__weight_int8pack_mm_default_17), kwargs = {})\n",
      "      %aten_mul_tensor_46 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_18, %aten_add_tensor_18), kwargs = {})\n",
      "      %aten_mean_dim_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_46, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_5, %_lifted_tensor_constant216), kwargs = {})\n",
      "      %aten_rsqrt_default_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_19,), kwargs = {})\n",
      "      %aten_mul_tensor_47 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_18, %aten_rsqrt_default_5), kwargs = {})\n",
      "      %aten_mul_tensor_48 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_47, %p_layers_2_ffn_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_28 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_48, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_29 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_48, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_18 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_28, %b_layers_2_feed_forward_w1_weight, %b_layers_2_feed_forward_w1_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_29, %b_layers_2_feed_forward_w3_weight, %b_layers_2_feed_forward_w3_scales), kwargs = {})\n",
      "      %aten_sigmoid_default_2 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sigmoid.default](args = (%aten__weight_int8pack_mm_default_18,), kwargs = {})\n",
      "      %aten_mul_tensor_49 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten__weight_int8pack_mm_default_18, %aten_sigmoid_default_2), kwargs = {})\n",
      "      %aten_mul_tensor_50 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_49, %aten__weight_int8pack_mm_default_19), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_mul_tensor_50, %b_layers_2_feed_forward_w2_weight, %b_layers_2_feed_forward_w2_scales), kwargs = {})\n",
      "      %aten_add_tensor_20 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_18, %aten__weight_int8pack_mm_default_20), kwargs = {})\n",
      "      %aten_mul_tensor_51 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_20, %aten_add_tensor_20), kwargs = {})\n",
      "      %aten_mean_dim_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_51, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_6, %_lifted_tensor_constant217), kwargs = {})\n",
      "      %aten_rsqrt_default_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_21,), kwargs = {})\n",
      "      %aten_mul_tensor_52 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_20, %aten_rsqrt_default_6), kwargs = {})\n",
      "      %aten_mul_tensor_53 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_52, %p_layers_3_attention_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_30 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_53, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_31 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_53, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_32 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_53, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_30, %b_layers_3_attention_wq_weight, %b_layers_3_attention_wq_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_31, %b_layers_3_attention_wk_weight, %b_layers_3_attention_wk_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_32, %b_layers_3_attention_wv_weight, %b_layers_3_attention_wv_scales), kwargs = {})\n",
      "      %aten_view_copy_default_60 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_21, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_61 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_22, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_62 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_23, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_63 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_60, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_64 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_61, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_permute_copy_default_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_62, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_63, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_63, 4, 1, 2), kwargs = {})\n",
      "      %aten_slice_copy_tensor_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_64, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_64, 4, 1, 2), kwargs = {})\n",
      "      %aten_view_copy_default_70 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_17, [12, 1, 64]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_33 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_12, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_34 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_13, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_35 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_14, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_36 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_15, [4]), kwargs = {})\n",
      "      %aten_index_put_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index_put.default](args = (%b_layers_3_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %aten_view_copy_default_70), kwargs = {})\n",
      "      %aten_mul_tensor_54 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_33, %aten_view_copy_default_65), kwargs = {})\n",
      "      %aten_mul_tensor_56 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_33, %aten_view_copy_default_66), kwargs = {})\n",
      "      %aten_mul_tensor_55 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_34, %aten_view_copy_default_66), kwargs = {})\n",
      "      %aten_mul_tensor_57 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_34, %aten_view_copy_default_65), kwargs = {})\n",
      "      %aten_mul_tensor_58 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_35, %aten_view_copy_default_65), kwargs = {})\n",
      "      %aten_mul_tensor_60 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_35, %aten_view_copy_default_66), kwargs = {})\n",
      "      %aten_mul_tensor_59 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_36, %aten_view_copy_default_66), kwargs = {})\n",
      "      %aten_mul_tensor_61 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_36, %aten_view_copy_default_65), kwargs = {})\n",
      "      %aten_slice_scatter_default_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_3_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_7, 1, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_sub_tensor_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_54, %aten_mul_tensor_55), kwargs = {})\n",
      "      %aten_add_tensor_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_56, %aten_mul_tensor_57), kwargs = {})\n",
      "      %aten_sub_tensor_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_58, %aten_mul_tensor_59), kwargs = {})\n",
      "      %aten_add_tensor_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_60, %aten_mul_tensor_61), kwargs = {})\n",
      "      %aten_slice_scatter_default_15 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_3_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_14, 0, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_24 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_6, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_25 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_22, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_26 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_7, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_27 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_23, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_31 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_15, 2), kwargs = {})\n",
      "      %aten_cat_default_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_24, %aten_unsqueeze_copy_default_25], -1), kwargs = {})\n",
      "      %aten_cat_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_26, %aten_unsqueeze_copy_default_27], -1), kwargs = {})\n",
      "      %aten_expand_copy_default_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_31, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_67 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_6, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_68 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_7, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_clone_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_19,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_permute_copy_default_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_67, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_permute_copy_default_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_68, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_72 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_7, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_15, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_69 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_16, [12, 1, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_view_copy_default_72, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_73 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_20, [12, 1, 64]), kwargs = {})\n",
      "      %aten_index_put_default_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index_put.default](args = (%b_layers_3_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %aten_view_copy_default_69), kwargs = {})\n",
      "      %aten_view_copy_default_77 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_23, [12, 128, 64]), kwargs = {})\n",
      "      %aten_slice_scatter_default_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_3_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_6, 1, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_slice_scatter_default_13 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_3_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_12, 0, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_30 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_13, 2), kwargs = {})\n",
      "      %aten_expand_copy_default_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_30, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_clone_default_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_18,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_view_copy_default_71 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_6, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_71, [0, 1, 3, 2]), kwargs = {})\n",
      "      %aten_expand_copy_default_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_18, [1, 12, 64, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_74 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_21, [12, 64, 128]), kwargs = {})\n",
      "      %aten_bmm_default_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_73, %aten_view_copy_default_74), kwargs = {})\n",
      "      %aten_view_copy_default_75 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_6, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_mul_tensor_62 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_view_copy_default_75, %_lifted_tensor_constant218), kwargs = {})\n",
      "      %aten_add_tensor_24 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_62, %aten__to_copy_default_3), kwargs = {})\n",
      "      %aten__softmax_default_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._softmax.default](args = (%aten_add_tensor_24, -1, False), kwargs = {})\n",
      "      %aten_expand_copy_default_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten__softmax_default_3, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_76 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_22, [12, 1, 128]), kwargs = {})\n",
      "      %aten_bmm_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_76, %aten_view_copy_default_77), kwargs = {})\n",
      "      %aten_view_copy_default_78 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_7, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_78, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_79 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_19, [1, 1, 768]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_37 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_view_copy_default_79, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_24 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_37, %b_layers_3_attention_wo_weight, %b_layers_3_attention_wo_scales), kwargs = {})\n",
      "      %aten_add_tensor_25 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_20, %aten__weight_int8pack_mm_default_24), kwargs = {})\n",
      "      %aten_mul_tensor_63 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_25, %aten_add_tensor_25), kwargs = {})\n",
      "      %aten_mean_dim_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_63, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_26 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_7, %_lifted_tensor_constant219), kwargs = {})\n",
      "      %aten_rsqrt_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_26,), kwargs = {})\n",
      "      %aten_mul_tensor_64 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_25, %aten_rsqrt_default_7), kwargs = {})\n",
      "      %aten_mul_tensor_65 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_64, %p_layers_3_ffn_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_38 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_65, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_39 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_65, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_25 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_38, %b_layers_3_feed_forward_w1_weight, %b_layers_3_feed_forward_w1_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_26 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_39, %b_layers_3_feed_forward_w3_weight, %b_layers_3_feed_forward_w3_scales), kwargs = {})\n",
      "      %aten_sigmoid_default_3 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sigmoid.default](args = (%aten__weight_int8pack_mm_default_25,), kwargs = {})\n",
      "      %aten_mul_tensor_66 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten__weight_int8pack_mm_default_25, %aten_sigmoid_default_3), kwargs = {})\n",
      "      %aten_mul_tensor_67 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_66, %aten__weight_int8pack_mm_default_26), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_27 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_mul_tensor_67, %b_layers_3_feed_forward_w2_weight, %b_layers_3_feed_forward_w2_scales), kwargs = {})\n",
      "      %aten_add_tensor_27 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_25, %aten__weight_int8pack_mm_default_27), kwargs = {})\n",
      "      %aten_mul_tensor_68 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_27, %aten_add_tensor_27), kwargs = {})\n",
      "      %aten_mean_dim_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_68, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_28 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_8, %_lifted_tensor_constant220), kwargs = {})\n",
      "      %aten_rsqrt_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_28,), kwargs = {})\n",
      "      %aten_mul_tensor_69 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_27, %aten_rsqrt_default_8), kwargs = {})\n",
      "      %aten_mul_tensor_70 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_69, %p_layers_4_attention_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_40 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_70, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_41 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_70, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_42 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_70, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_28 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_40, %b_layers_4_attention_wq_weight, %b_layers_4_attention_wq_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_29 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_41, %b_layers_4_attention_wk_weight, %b_layers_4_attention_wk_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_30 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_42, %b_layers_4_attention_wv_weight, %b_layers_4_attention_wv_scales), kwargs = {})\n",
      "      %aten_view_copy_default_80 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_28, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_81 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_29, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_82 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_30, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_83 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_80, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_84 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_81, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_permute_copy_default_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_82, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_83, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_83, 4, 1, 2), kwargs = {})\n",
      "      %aten_slice_copy_tensor_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_84, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_84, 4, 1, 2), kwargs = {})\n",
      "      %aten_view_copy_default_90 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_22, [12, 1, 64]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_43 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_16, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_44 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_17, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_45 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_18, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_46 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_19, [4]), kwargs = {})\n",
      "      %aten_index_put_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index_put.default](args = (%b_layers_4_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %aten_view_copy_default_90), kwargs = {})\n",
      "      %aten_mul_tensor_71 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_43, %aten_view_copy_default_85), kwargs = {})\n",
      "      %aten_mul_tensor_73 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_43, %aten_view_copy_default_86), kwargs = {})\n",
      "      %aten_mul_tensor_72 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_44, %aten_view_copy_default_86), kwargs = {})\n",
      "      %aten_mul_tensor_74 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_44, %aten_view_copy_default_85), kwargs = {})\n",
      "      %aten_mul_tensor_75 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_45, %aten_view_copy_default_85), kwargs = {})\n",
      "      %aten_mul_tensor_77 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_45, %aten_view_copy_default_86), kwargs = {})\n",
      "      %aten_mul_tensor_76 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_46, %aten_view_copy_default_86), kwargs = {})\n",
      "      %aten_mul_tensor_78 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_46, %aten_view_copy_default_85), kwargs = {})\n",
      "      %aten_slice_scatter_default_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_4_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_9, 1, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_sub_tensor_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_71, %aten_mul_tensor_72), kwargs = {})\n",
      "      %aten_add_tensor_29 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_73, %aten_mul_tensor_74), kwargs = {})\n",
      "      %aten_sub_tensor_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_75, %aten_mul_tensor_76), kwargs = {})\n",
      "      %aten_add_tensor_30 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_77, %aten_mul_tensor_78), kwargs = {})\n",
      "      %aten_slice_scatter_default_19 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_4_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_18, 0, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_32 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_8, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_33 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_29, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_34 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_9, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_35 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_30, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_39 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_19, 2), kwargs = {})\n",
      "      %aten_cat_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_32, %aten_unsqueeze_copy_default_33], -1), kwargs = {})\n",
      "      %aten_cat_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_34, %aten_unsqueeze_copy_default_35], -1), kwargs = {})\n",
      "      %aten_expand_copy_default_25 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_39, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_87 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_8, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_88 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_9, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_clone_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_25,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_permute_copy_default_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_87, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_permute_copy_default_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_88, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_92 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_9, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_26 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_20, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_89 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_21, [12, 1, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_29 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_view_copy_default_92, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_93 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_26, [12, 1, 64]), kwargs = {})\n",
      "      %aten_index_put_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index_put.default](args = (%b_layers_4_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %aten_view_copy_default_89), kwargs = {})\n",
      "      %aten_view_copy_default_97 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_29, [12, 128, 64]), kwargs = {})\n",
      "      %aten_slice_scatter_default_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_4_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_8, 1, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_slice_scatter_default_17 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_4_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_16, 0, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_38 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_17, 2), kwargs = {})\n",
      "      %aten_expand_copy_default_24 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_38, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_clone_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_24,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_view_copy_default_91 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_8, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_91, [0, 1, 3, 2]), kwargs = {})\n",
      "      %aten_expand_copy_default_27 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_23, [1, 12, 64, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_94 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_27, [12, 64, 128]), kwargs = {})\n",
      "      %aten_bmm_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_93, %aten_view_copy_default_94), kwargs = {})\n",
      "      %aten_view_copy_default_95 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_8, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_mul_tensor_79 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_view_copy_default_95, %_lifted_tensor_constant221), kwargs = {})\n",
      "      %aten_add_tensor_31 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_79, %aten__to_copy_default_4), kwargs = {})\n",
      "      %aten__softmax_default_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._softmax.default](args = (%aten_add_tensor_31, -1, False), kwargs = {})\n",
      "      %aten_expand_copy_default_28 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten__softmax_default_4, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_96 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_28, [12, 1, 128]), kwargs = {})\n",
      "      %aten_bmm_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_96, %aten_view_copy_default_97), kwargs = {})\n",
      "      %aten_view_copy_default_98 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_9, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_24 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_98, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_99 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_24, [1, 1, 768]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_47 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_view_copy_default_99, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_31 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_47, %b_layers_4_attention_wo_weight, %b_layers_4_attention_wo_scales), kwargs = {})\n",
      "      %aten_add_tensor_32 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_27, %aten__weight_int8pack_mm_default_31), kwargs = {})\n",
      "      %aten_mul_tensor_80 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_32, %aten_add_tensor_32), kwargs = {})\n",
      "      %aten_mean_dim_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_80, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_33 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_9, %_lifted_tensor_constant222), kwargs = {})\n",
      "      %aten_rsqrt_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_33,), kwargs = {})\n",
      "      %aten_mul_tensor_81 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_32, %aten_rsqrt_default_9), kwargs = {})\n",
      "      %aten_mul_tensor_82 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_81, %p_layers_4_ffn_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_48 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_82, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_49 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_82, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_32 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_48, %b_layers_4_feed_forward_w1_weight, %b_layers_4_feed_forward_w1_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_33 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_49, %b_layers_4_feed_forward_w3_weight, %b_layers_4_feed_forward_w3_scales), kwargs = {})\n",
      "      %aten_sigmoid_default_4 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sigmoid.default](args = (%aten__weight_int8pack_mm_default_32,), kwargs = {})\n",
      "      %aten_mul_tensor_83 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten__weight_int8pack_mm_default_32, %aten_sigmoid_default_4), kwargs = {})\n",
      "      %aten_mul_tensor_84 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_83, %aten__weight_int8pack_mm_default_33), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_34 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_mul_tensor_84, %b_layers_4_feed_forward_w2_weight, %b_layers_4_feed_forward_w2_scales), kwargs = {})\n",
      "      %aten_add_tensor_34 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_32, %aten__weight_int8pack_mm_default_34), kwargs = {})\n",
      "      %aten_mul_tensor_85 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_34, %aten_add_tensor_34), kwargs = {})\n",
      "      %aten_mean_dim_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_85, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_35 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_10, %_lifted_tensor_constant223), kwargs = {})\n",
      "      %aten_rsqrt_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_35,), kwargs = {})\n",
      "      %aten_mul_tensor_86 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_34, %aten_rsqrt_default_10), kwargs = {})\n",
      "      %aten_mul_tensor_87 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_86, %p_layers_5_attention_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_50 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_87, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_51 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_87, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_52 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_87, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_35 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_50, %b_layers_5_attention_wq_weight, %b_layers_5_attention_wq_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_36 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_51, %b_layers_5_attention_wk_weight, %b_layers_5_attention_wk_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_37 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_52, %b_layers_5_attention_wv_weight, %b_layers_5_attention_wv_scales), kwargs = {})\n",
      "      %aten_view_copy_default_100 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_35, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_101 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_36, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_102 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_37, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_103 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_100, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_104 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_101, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_permute_copy_default_27 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_102, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_103, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_103, 4, 1, 2), kwargs = {})\n",
      "      %aten_slice_copy_tensor_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_104, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_104, 4, 1, 2), kwargs = {})\n",
      "      %aten_view_copy_default_110 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_27, [12, 1, 64]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_53 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_20, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_54 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_21, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_55 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_22, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_56 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_23, [4]), kwargs = {})\n",
      "      %aten_index_put_default_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index_put.default](args = (%b_layers_5_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %aten_view_copy_default_110), kwargs = {})\n",
      "      %aten_mul_tensor_88 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_53, %aten_view_copy_default_105), kwargs = {})\n",
      "      %aten_mul_tensor_90 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_53, %aten_view_copy_default_106), kwargs = {})\n",
      "      %aten_mul_tensor_89 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_54, %aten_view_copy_default_106), kwargs = {})\n",
      "      %aten_mul_tensor_91 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_54, %aten_view_copy_default_105), kwargs = {})\n",
      "      %aten_mul_tensor_92 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_55, %aten_view_copy_default_105), kwargs = {})\n",
      "      %aten_mul_tensor_94 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_55, %aten_view_copy_default_106), kwargs = {})\n",
      "      %aten_mul_tensor_93 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_56, %aten_view_copy_default_106), kwargs = {})\n",
      "      %aten_mul_tensor_95 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_56, %aten_view_copy_default_105), kwargs = {})\n",
      "      %aten_slice_scatter_default_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_5_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_11, 1, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_sub_tensor_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_88, %aten_mul_tensor_89), kwargs = {})\n",
      "      %aten_add_tensor_36 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_90, %aten_mul_tensor_91), kwargs = {})\n",
      "      %aten_sub_tensor_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_92, %aten_mul_tensor_93), kwargs = {})\n",
      "      %aten_add_tensor_37 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_94, %aten_mul_tensor_95), kwargs = {})\n",
      "      %aten_slice_scatter_default_23 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_5_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_22, 0, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_40 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_10, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_41 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_36, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_42 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_11, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_43 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_37, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_47 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_23, 2), kwargs = {})\n",
      "      %aten_cat_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_40, %aten_unsqueeze_copy_default_41], -1), kwargs = {})\n",
      "      %aten_cat_default_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_42, %aten_unsqueeze_copy_default_43], -1), kwargs = {})\n",
      "      %aten_expand_copy_default_31 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_47, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_107 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_10, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_108 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_11, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_clone_default_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_31,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_permute_copy_default_25 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_107, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_permute_copy_default_26 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_108, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_112 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_11, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_32 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_25, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_109 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_26, [12, 1, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_35 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_view_copy_default_112, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_113 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_32, [12, 1, 64]), kwargs = {})\n",
      "      %aten_index_put_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index_put.default](args = (%b_layers_5_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %aten_view_copy_default_109), kwargs = {})\n",
      "      %aten_view_copy_default_117 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_35, [12, 128, 64]), kwargs = {})\n",
      "      %aten_slice_scatter_default_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_5_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_10, 1, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_slice_scatter_default_21 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_5_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_20, 0, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_46 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_21, 2), kwargs = {})\n",
      "      %aten_expand_copy_default_30 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_46, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_clone_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_30,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_view_copy_default_111 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_10, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_28 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_111, [0, 1, 3, 2]), kwargs = {})\n",
      "      %aten_expand_copy_default_33 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_28, [1, 12, 64, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_114 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_33, [12, 64, 128]), kwargs = {})\n",
      "      %aten_bmm_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_113, %aten_view_copy_default_114), kwargs = {})\n",
      "      %aten_view_copy_default_115 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_10, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_mul_tensor_96 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_view_copy_default_115, %_lifted_tensor_constant224), kwargs = {})\n",
      "      %aten_add_tensor_38 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_96, %aten__to_copy_default_5), kwargs = {})\n",
      "      %aten__softmax_default_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._softmax.default](args = (%aten_add_tensor_38, -1, False), kwargs = {})\n",
      "      %aten_expand_copy_default_34 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten__softmax_default_5, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_116 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_34, [12, 1, 128]), kwargs = {})\n",
      "      %aten_bmm_default_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_116, %aten_view_copy_default_117), kwargs = {})\n",
      "      %aten_view_copy_default_118 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_11, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_29 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_118, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_119 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_29, [1, 1, 768]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_57 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_view_copy_default_119, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_38 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_57, %b_layers_5_attention_wo_weight, %b_layers_5_attention_wo_scales), kwargs = {})\n",
      "      %aten_add_tensor_39 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_34, %aten__weight_int8pack_mm_default_38), kwargs = {})\n",
      "      %aten_mul_tensor_97 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_39, %aten_add_tensor_39), kwargs = {})\n",
      "      %aten_mean_dim_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_97, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_40 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_11, %_lifted_tensor_constant225), kwargs = {})\n",
      "      %aten_rsqrt_default_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_40,), kwargs = {})\n",
      "      %aten_mul_tensor_98 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_39, %aten_rsqrt_default_11), kwargs = {})\n",
      "      %aten_mul_tensor_99 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_98, %p_layers_5_ffn_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_58 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_99, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_59 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_99, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_39 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_58, %b_layers_5_feed_forward_w1_weight, %b_layers_5_feed_forward_w1_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_40 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_59, %b_layers_5_feed_forward_w3_weight, %b_layers_5_feed_forward_w3_scales), kwargs = {})\n",
      "      %aten_sigmoid_default_5 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sigmoid.default](args = (%aten__weight_int8pack_mm_default_39,), kwargs = {})\n",
      "      %aten_mul_tensor_100 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten__weight_int8pack_mm_default_39, %aten_sigmoid_default_5), kwargs = {})\n",
      "      %aten_mul_tensor_101 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_100, %aten__weight_int8pack_mm_default_40), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_41 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_mul_tensor_101, %b_layers_5_feed_forward_w2_weight, %b_layers_5_feed_forward_w2_scales), kwargs = {})\n",
      "      %aten_add_tensor_41 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_39, %aten__weight_int8pack_mm_default_41), kwargs = {})\n",
      "      %aten_mul_tensor_102 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_41, %aten_add_tensor_41), kwargs = {})\n",
      "      %aten_mean_dim_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_102, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_42 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_12, %_lifted_tensor_constant226), kwargs = {})\n",
      "      %aten_rsqrt_default_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_42,), kwargs = {})\n",
      "      %aten_mul_tensor_103 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_41, %aten_rsqrt_default_12), kwargs = {})\n",
      "      %aten_mul_tensor_104 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_103, %p_layers_6_attention_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_60 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_104, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_61 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_104, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_62 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_104, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_42 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_60, %b_layers_6_attention_wq_weight, %b_layers_6_attention_wq_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_43 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_61, %b_layers_6_attention_wk_weight, %b_layers_6_attention_wk_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_44 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_62, %b_layers_6_attention_wv_weight, %b_layers_6_attention_wv_scales), kwargs = {})\n",
      "      %aten_view_copy_default_120 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_42, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_121 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_43, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_122 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_44, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_123 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_120, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_124 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_121, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_permute_copy_default_32 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_122, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_24 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_123, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_25 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_123, 4, 1, 2), kwargs = {})\n",
      "      %aten_slice_copy_tensor_26 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_124, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_27 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_124, 4, 1, 2), kwargs = {})\n",
      "      %aten_view_copy_default_130 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_32, [12, 1, 64]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_63 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_24, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_64 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_25, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_65 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_26, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_66 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_27, [4]), kwargs = {})\n",
      "      %aten_index_put_default_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index_put.default](args = (%b_layers_6_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %aten_view_copy_default_130), kwargs = {})\n",
      "      %aten_mul_tensor_105 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_63, %aten_view_copy_default_125), kwargs = {})\n",
      "      %aten_mul_tensor_107 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_63, %aten_view_copy_default_126), kwargs = {})\n",
      "      %aten_mul_tensor_106 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_64, %aten_view_copy_default_126), kwargs = {})\n",
      "      %aten_mul_tensor_108 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_64, %aten_view_copy_default_125), kwargs = {})\n",
      "      %aten_mul_tensor_109 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_65, %aten_view_copy_default_125), kwargs = {})\n",
      "      %aten_mul_tensor_111 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_65, %aten_view_copy_default_126), kwargs = {})\n",
      "      %aten_mul_tensor_110 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_66, %aten_view_copy_default_126), kwargs = {})\n",
      "      %aten_mul_tensor_112 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_66, %aten_view_copy_default_125), kwargs = {})\n",
      "      %aten_slice_scatter_default_26 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_6_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_13, 1, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_sub_tensor_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_105, %aten_mul_tensor_106), kwargs = {})\n",
      "      %aten_add_tensor_43 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_107, %aten_mul_tensor_108), kwargs = {})\n",
      "      %aten_sub_tensor_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_109, %aten_mul_tensor_110), kwargs = {})\n",
      "      %aten_add_tensor_44 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_111, %aten_mul_tensor_112), kwargs = {})\n",
      "      %aten_slice_scatter_default_27 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_6_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_26, 0, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_48 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_12, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_49 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_43, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_50 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_13, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_51 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_44, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_55 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_27, 2), kwargs = {})\n",
      "      %aten_cat_default_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_48, %aten_unsqueeze_copy_default_49], -1), kwargs = {})\n",
      "      %aten_cat_default_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_50, %aten_unsqueeze_copy_default_51], -1), kwargs = {})\n",
      "      %aten_expand_copy_default_37 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_55, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_127 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_12, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_128 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_13, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_clone_default_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_37,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_permute_copy_default_30 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_127, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_permute_copy_default_31 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_128, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_132 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_13, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_38 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_30, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_129 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_31, [12, 1, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_41 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_view_copy_default_132, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_133 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_38, [12, 1, 64]), kwargs = {})\n",
      "      %aten_index_put_default_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index_put.default](args = (%b_layers_6_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %aten_view_copy_default_129), kwargs = {})\n",
      "      %aten_view_copy_default_137 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_41, [12, 128, 64]), kwargs = {})\n",
      "      %aten_slice_scatter_default_24 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_6_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_12, 1, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_slice_scatter_default_25 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_6_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_24, 0, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_54 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_25, 2), kwargs = {})\n",
      "      %aten_expand_copy_default_36 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_54, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_clone_default_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_36,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_view_copy_default_131 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_12, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_33 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_131, [0, 1, 3, 2]), kwargs = {})\n",
      "      %aten_expand_copy_default_39 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_33, [1, 12, 64, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_134 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_39, [12, 64, 128]), kwargs = {})\n",
      "      %aten_bmm_default_12 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_133, %aten_view_copy_default_134), kwargs = {})\n",
      "      %aten_view_copy_default_135 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_12, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_mul_tensor_113 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_view_copy_default_135, %_lifted_tensor_constant227), kwargs = {})\n",
      "      %aten_add_tensor_45 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_113, %aten__to_copy_default_6), kwargs = {})\n",
      "      %aten__softmax_default_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._softmax.default](args = (%aten_add_tensor_45, -1, False), kwargs = {})\n",
      "      %aten_expand_copy_default_40 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten__softmax_default_6, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_136 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_40, [12, 1, 128]), kwargs = {})\n",
      "      %aten_bmm_default_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_136, %aten_view_copy_default_137), kwargs = {})\n",
      "      %aten_view_copy_default_138 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_13, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_34 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_138, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_139 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_34, [1, 1, 768]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_67 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_view_copy_default_139, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_45 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_67, %b_layers_6_attention_wo_weight, %b_layers_6_attention_wo_scales), kwargs = {})\n",
      "      %aten_add_tensor_46 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_41, %aten__weight_int8pack_mm_default_45), kwargs = {})\n",
      "      %aten_mul_tensor_114 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_46, %aten_add_tensor_46), kwargs = {})\n",
      "      %aten_mean_dim_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_114, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_47 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_13, %_lifted_tensor_constant228), kwargs = {})\n",
      "      %aten_rsqrt_default_13 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_47,), kwargs = {})\n",
      "      %aten_mul_tensor_115 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_46, %aten_rsqrt_default_13), kwargs = {})\n",
      "      %aten_mul_tensor_116 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_115, %p_layers_6_ffn_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_68 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_116, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_69 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_116, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_46 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_68, %b_layers_6_feed_forward_w1_weight, %b_layers_6_feed_forward_w1_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_47 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_69, %b_layers_6_feed_forward_w3_weight, %b_layers_6_feed_forward_w3_scales), kwargs = {})\n",
      "      %aten_sigmoid_default_6 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sigmoid.default](args = (%aten__weight_int8pack_mm_default_46,), kwargs = {})\n",
      "      %aten_mul_tensor_117 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten__weight_int8pack_mm_default_46, %aten_sigmoid_default_6), kwargs = {})\n",
      "      %aten_mul_tensor_118 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_117, %aten__weight_int8pack_mm_default_47), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_48 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_mul_tensor_118, %b_layers_6_feed_forward_w2_weight, %b_layers_6_feed_forward_w2_scales), kwargs = {})\n",
      "      %aten_add_tensor_48 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_46, %aten__weight_int8pack_mm_default_48), kwargs = {})\n",
      "      %aten_mul_tensor_119 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_48, %aten_add_tensor_48), kwargs = {})\n",
      "      %aten_mean_dim_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_119, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_49 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_14, %_lifted_tensor_constant229), kwargs = {})\n",
      "      %aten_rsqrt_default_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_49,), kwargs = {})\n",
      "      %aten_mul_tensor_120 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_48, %aten_rsqrt_default_14), kwargs = {})\n",
      "      %aten_mul_tensor_121 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_120, %p_layers_7_attention_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_70 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_121, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_71 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_121, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_72 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_121, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_49 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_70, %b_layers_7_attention_wq_weight, %b_layers_7_attention_wq_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_50 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_71, %b_layers_7_attention_wk_weight, %b_layers_7_attention_wk_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_51 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_72, %b_layers_7_attention_wv_weight, %b_layers_7_attention_wv_scales), kwargs = {})\n",
      "      %aten_view_copy_default_140 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_49, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_141 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_50, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_142 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_51, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_143 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_140, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_144 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_141, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_permute_copy_default_37 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_142, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_28 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_143, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_29 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_143, 4, 1, 2), kwargs = {})\n",
      "      %aten_slice_copy_tensor_30 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_144, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_31 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_144, 4, 1, 2), kwargs = {})\n",
      "      %aten_view_copy_default_150 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_37, [12, 1, 64]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_73 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_28, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_74 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_29, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_75 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_30, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_76 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_31, [4]), kwargs = {})\n",
      "      %aten_index_put_default_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index_put.default](args = (%b_layers_7_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %aten_view_copy_default_150), kwargs = {})\n",
      "      %aten_mul_tensor_122 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_73, %aten_view_copy_default_145), kwargs = {})\n",
      "      %aten_mul_tensor_124 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_73, %aten_view_copy_default_146), kwargs = {})\n",
      "      %aten_mul_tensor_123 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_74, %aten_view_copy_default_146), kwargs = {})\n",
      "      %aten_mul_tensor_125 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_74, %aten_view_copy_default_145), kwargs = {})\n",
      "      %aten_mul_tensor_126 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_75, %aten_view_copy_default_145), kwargs = {})\n",
      "      %aten_mul_tensor_128 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_75, %aten_view_copy_default_146), kwargs = {})\n",
      "      %aten_mul_tensor_127 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_76, %aten_view_copy_default_146), kwargs = {})\n",
      "      %aten_mul_tensor_129 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_76, %aten_view_copy_default_145), kwargs = {})\n",
      "      %aten_slice_scatter_default_30 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_7_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_15, 1, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_sub_tensor_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_122, %aten_mul_tensor_123), kwargs = {})\n",
      "      %aten_add_tensor_50 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_124, %aten_mul_tensor_125), kwargs = {})\n",
      "      %aten_sub_tensor_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_126, %aten_mul_tensor_127), kwargs = {})\n",
      "      %aten_add_tensor_51 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_128, %aten_mul_tensor_129), kwargs = {})\n",
      "      %aten_slice_scatter_default_31 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_7_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_30, 0, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_56 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_14, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_57 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_50, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_58 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_15, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_59 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_51, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_63 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_31, 2), kwargs = {})\n",
      "      %aten_cat_default_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_56, %aten_unsqueeze_copy_default_57], -1), kwargs = {})\n",
      "      %aten_cat_default_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_58, %aten_unsqueeze_copy_default_59], -1), kwargs = {})\n",
      "      %aten_expand_copy_default_43 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_63, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_147 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_14, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_148 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_15, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_clone_default_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_43,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_permute_copy_default_35 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_147, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_permute_copy_default_36 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_148, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_152 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_15, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_44 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_35, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_149 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_36, [12, 1, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_47 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_view_copy_default_152, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_153 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_44, [12, 1, 64]), kwargs = {})\n",
      "      %aten_index_put_default_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index_put.default](args = (%b_layers_7_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %aten_view_copy_default_149), kwargs = {})\n",
      "      %aten_view_copy_default_157 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_47, [12, 128, 64]), kwargs = {})\n",
      "      %aten_slice_scatter_default_28 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_7_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_14, 1, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_slice_scatter_default_29 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_7_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_28, 0, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_62 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_29, 2), kwargs = {})\n",
      "      %aten_expand_copy_default_42 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_62, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_clone_default_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_42,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_view_copy_default_151 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_14, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_38 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_151, [0, 1, 3, 2]), kwargs = {})\n",
      "      %aten_expand_copy_default_45 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_38, [1, 12, 64, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_154 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_45, [12, 64, 128]), kwargs = {})\n",
      "      %aten_bmm_default_14 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_153, %aten_view_copy_default_154), kwargs = {})\n",
      "      %aten_view_copy_default_155 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_14, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_mul_tensor_130 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_view_copy_default_155, %_lifted_tensor_constant230), kwargs = {})\n",
      "      %aten_add_tensor_52 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_130, %aten__to_copy_default_7), kwargs = {})\n",
      "      %aten__softmax_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._softmax.default](args = (%aten_add_tensor_52, -1, False), kwargs = {})\n",
      "      %aten_expand_copy_default_46 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten__softmax_default_7, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_156 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_46, [12, 1, 128]), kwargs = {})\n",
      "      %aten_bmm_default_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_156, %aten_view_copy_default_157), kwargs = {})\n",
      "      %aten_view_copy_default_158 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_15, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_39 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_158, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_159 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_39, [1, 1, 768]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_77 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_view_copy_default_159, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_52 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_77, %b_layers_7_attention_wo_weight, %b_layers_7_attention_wo_scales), kwargs = {})\n",
      "      %aten_add_tensor_53 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_48, %aten__weight_int8pack_mm_default_52), kwargs = {})\n",
      "      %aten_mul_tensor_131 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_53, %aten_add_tensor_53), kwargs = {})\n",
      "      %aten_mean_dim_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_131, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_54 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_15, %_lifted_tensor_constant231), kwargs = {})\n",
      "      %aten_rsqrt_default_15 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_54,), kwargs = {})\n",
      "      %aten_mul_tensor_132 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_53, %aten_rsqrt_default_15), kwargs = {})\n",
      "      %aten_mul_tensor_133 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_132, %p_layers_7_ffn_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_78 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_133, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_79 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_133, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_53 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_78, %b_layers_7_feed_forward_w1_weight, %b_layers_7_feed_forward_w1_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_54 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_79, %b_layers_7_feed_forward_w3_weight, %b_layers_7_feed_forward_w3_scales), kwargs = {})\n",
      "      %aten_sigmoid_default_7 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sigmoid.default](args = (%aten__weight_int8pack_mm_default_53,), kwargs = {})\n",
      "      %aten_mul_tensor_134 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten__weight_int8pack_mm_default_53, %aten_sigmoid_default_7), kwargs = {})\n",
      "      %aten_mul_tensor_135 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_134, %aten__weight_int8pack_mm_default_54), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_55 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_mul_tensor_135, %b_layers_7_feed_forward_w2_weight, %b_layers_7_feed_forward_w2_scales), kwargs = {})\n",
      "      %aten_add_tensor_55 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_53, %aten__weight_int8pack_mm_default_55), kwargs = {})\n",
      "      %aten_mul_tensor_136 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_55, %aten_add_tensor_55), kwargs = {})\n",
      "      %aten_mean_dim_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_136, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_56 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_16, %_lifted_tensor_constant232), kwargs = {})\n",
      "      %aten_rsqrt_default_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_56,), kwargs = {})\n",
      "      %aten_mul_tensor_137 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_55, %aten_rsqrt_default_16), kwargs = {})\n",
      "      %aten_mul_tensor_138 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_137, %p_layers_8_attention_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_80 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_138, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_81 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_138, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_82 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_138, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_56 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_80, %b_layers_8_attention_wq_weight, %b_layers_8_attention_wq_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_57 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_81, %b_layers_8_attention_wk_weight, %b_layers_8_attention_wk_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_58 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_82, %b_layers_8_attention_wv_weight, %b_layers_8_attention_wv_scales), kwargs = {})\n",
      "      %aten_view_copy_default_160 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_56, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_161 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_57, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_162 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_58, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_163 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_160, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_164 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_161, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_permute_copy_default_42 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_162, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_32 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_163, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_33 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_163, 4, 1, 2), kwargs = {})\n",
      "      %aten_slice_copy_tensor_34 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_164, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_35 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_164, 4, 1, 2), kwargs = {})\n",
      "      %aten_view_copy_default_170 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_42, [12, 1, 64]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_83 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_32, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_84 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_33, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_85 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_34, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_86 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_35, [4]), kwargs = {})\n",
      "      %aten_index_put_default_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index_put.default](args = (%b_layers_8_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %aten_view_copy_default_170), kwargs = {})\n",
      "      %aten_mul_tensor_139 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_83, %aten_view_copy_default_165), kwargs = {})\n",
      "      %aten_mul_tensor_141 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_83, %aten_view_copy_default_166), kwargs = {})\n",
      "      %aten_mul_tensor_140 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_84, %aten_view_copy_default_166), kwargs = {})\n",
      "      %aten_mul_tensor_142 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_84, %aten_view_copy_default_165), kwargs = {})\n",
      "      %aten_mul_tensor_143 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_85, %aten_view_copy_default_165), kwargs = {})\n",
      "      %aten_mul_tensor_145 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_85, %aten_view_copy_default_166), kwargs = {})\n",
      "      %aten_mul_tensor_144 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_86, %aten_view_copy_default_166), kwargs = {})\n",
      "      %aten_mul_tensor_146 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_86, %aten_view_copy_default_165), kwargs = {})\n",
      "      %aten_slice_scatter_default_34 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_8_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_17, 1, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_sub_tensor_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_139, %aten_mul_tensor_140), kwargs = {})\n",
      "      %aten_add_tensor_57 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_141, %aten_mul_tensor_142), kwargs = {})\n",
      "      %aten_sub_tensor_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_143, %aten_mul_tensor_144), kwargs = {})\n",
      "      %aten_add_tensor_58 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_145, %aten_mul_tensor_146), kwargs = {})\n",
      "      %aten_slice_scatter_default_35 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_8_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_34, 0, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_64 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_16, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_65 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_57, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_66 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_17, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_67 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_58, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_71 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_35, 2), kwargs = {})\n",
      "      %aten_cat_default_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_64, %aten_unsqueeze_copy_default_65], -1), kwargs = {})\n",
      "      %aten_cat_default_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_66, %aten_unsqueeze_copy_default_67], -1), kwargs = {})\n",
      "      %aten_expand_copy_default_49 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_71, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_167 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_16, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_168 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_17, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_clone_default_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_49,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_permute_copy_default_40 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_167, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_permute_copy_default_41 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_168, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_172 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_17, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_50 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_40, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_169 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_41, [12, 1, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_53 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_view_copy_default_172, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_173 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_50, [12, 1, 64]), kwargs = {})\n",
      "      %aten_index_put_default_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index_put.default](args = (%b_layers_8_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %aten_view_copy_default_169), kwargs = {})\n",
      "      %aten_view_copy_default_177 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_53, [12, 128, 64]), kwargs = {})\n",
      "      %aten_slice_scatter_default_32 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_8_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_16, 1, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_slice_scatter_default_33 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_8_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_32, 0, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_70 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_33, 2), kwargs = {})\n",
      "      %aten_expand_copy_default_48 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_70, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_clone_default_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_48,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_view_copy_default_171 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_16, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_43 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_171, [0, 1, 3, 2]), kwargs = {})\n",
      "      %aten_expand_copy_default_51 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_43, [1, 12, 64, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_174 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_51, [12, 64, 128]), kwargs = {})\n",
      "      %aten_bmm_default_16 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_173, %aten_view_copy_default_174), kwargs = {})\n",
      "      %aten_view_copy_default_175 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_16, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_mul_tensor_147 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_view_copy_default_175, %_lifted_tensor_constant233), kwargs = {})\n",
      "      %aten_add_tensor_59 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_147, %aten__to_copy_default_8), kwargs = {})\n",
      "      %aten__softmax_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._softmax.default](args = (%aten_add_tensor_59, -1, False), kwargs = {})\n",
      "      %aten_expand_copy_default_52 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten__softmax_default_8, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_176 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_52, [12, 1, 128]), kwargs = {})\n",
      "      %aten_bmm_default_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_176, %aten_view_copy_default_177), kwargs = {})\n",
      "      %aten_view_copy_default_178 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_17, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_44 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_178, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_179 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_44, [1, 1, 768]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_87 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_view_copy_default_179, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_59 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_87, %b_layers_8_attention_wo_weight, %b_layers_8_attention_wo_scales), kwargs = {})\n",
      "      %aten_add_tensor_60 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_55, %aten__weight_int8pack_mm_default_59), kwargs = {})\n",
      "      %aten_mul_tensor_148 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_60, %aten_add_tensor_60), kwargs = {})\n",
      "      %aten_mean_dim_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_148, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_61 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_17, %_lifted_tensor_constant234), kwargs = {})\n",
      "      %aten_rsqrt_default_17 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_61,), kwargs = {})\n",
      "      %aten_mul_tensor_149 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_60, %aten_rsqrt_default_17), kwargs = {})\n",
      "      %aten_mul_tensor_150 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_149, %p_layers_8_ffn_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_88 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_150, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_89 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_150, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_60 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_88, %b_layers_8_feed_forward_w1_weight, %b_layers_8_feed_forward_w1_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_61 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_89, %b_layers_8_feed_forward_w3_weight, %b_layers_8_feed_forward_w3_scales), kwargs = {})\n",
      "      %aten_sigmoid_default_8 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sigmoid.default](args = (%aten__weight_int8pack_mm_default_60,), kwargs = {})\n",
      "      %aten_mul_tensor_151 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten__weight_int8pack_mm_default_60, %aten_sigmoid_default_8), kwargs = {})\n",
      "      %aten_mul_tensor_152 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_151, %aten__weight_int8pack_mm_default_61), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_62 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_mul_tensor_152, %b_layers_8_feed_forward_w2_weight, %b_layers_8_feed_forward_w2_scales), kwargs = {})\n",
      "      %aten_add_tensor_62 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_60, %aten__weight_int8pack_mm_default_62), kwargs = {})\n",
      "      %aten_mul_tensor_153 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_62, %aten_add_tensor_62), kwargs = {})\n",
      "      %aten_mean_dim_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_153, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_63 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_18, %_lifted_tensor_constant235), kwargs = {})\n",
      "      %aten_rsqrt_default_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_63,), kwargs = {})\n",
      "      %aten_mul_tensor_154 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_62, %aten_rsqrt_default_18), kwargs = {})\n",
      "      %aten_mul_tensor_155 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_154, %p_layers_9_attention_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_90 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_155, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_91 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_155, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_92 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_155, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_63 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_90, %b_layers_9_attention_wq_weight, %b_layers_9_attention_wq_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_64 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_91, %b_layers_9_attention_wk_weight, %b_layers_9_attention_wk_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_65 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_92, %b_layers_9_attention_wv_weight, %b_layers_9_attention_wv_scales), kwargs = {})\n",
      "      %aten_view_copy_default_180 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_63, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_181 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_64, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_182 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_65, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_183 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_180, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_184 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_181, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_permute_copy_default_47 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_182, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_36 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_183, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_37 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_183, 4, 1, 2), kwargs = {})\n",
      "      %aten_slice_copy_tensor_38 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_184, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_39 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_184, 4, 1, 2), kwargs = {})\n",
      "      %aten_view_copy_default_190 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_47, [12, 1, 64]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_93 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_36, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_94 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_37, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_95 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_38, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_96 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_39, [4]), kwargs = {})\n",
      "      %aten_index_put_default_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index_put.default](args = (%b_layers_9_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %aten_view_copy_default_190), kwargs = {})\n",
      "      %aten_mul_tensor_156 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_93, %aten_view_copy_default_185), kwargs = {})\n",
      "      %aten_mul_tensor_158 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_93, %aten_view_copy_default_186), kwargs = {})\n",
      "      %aten_mul_tensor_157 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_94, %aten_view_copy_default_186), kwargs = {})\n",
      "      %aten_mul_tensor_159 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_94, %aten_view_copy_default_185), kwargs = {})\n",
      "      %aten_mul_tensor_160 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_95, %aten_view_copy_default_185), kwargs = {})\n",
      "      %aten_mul_tensor_162 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_95, %aten_view_copy_default_186), kwargs = {})\n",
      "      %aten_mul_tensor_161 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_96, %aten_view_copy_default_186), kwargs = {})\n",
      "      %aten_mul_tensor_163 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_96, %aten_view_copy_default_185), kwargs = {})\n",
      "      %aten_slice_scatter_default_38 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_9_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_19, 1, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_sub_tensor_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_156, %aten_mul_tensor_157), kwargs = {})\n",
      "      %aten_add_tensor_64 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_158, %aten_mul_tensor_159), kwargs = {})\n",
      "      %aten_sub_tensor_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_160, %aten_mul_tensor_161), kwargs = {})\n",
      "      %aten_add_tensor_65 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_162, %aten_mul_tensor_163), kwargs = {})\n",
      "      %aten_slice_scatter_default_39 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_9_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_38, 0, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_72 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_18, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_73 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_64, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_74 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_19, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_75 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_65, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_79 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_39, 2), kwargs = {})\n",
      "      %aten_cat_default_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_72, %aten_unsqueeze_copy_default_73], -1), kwargs = {})\n",
      "      %aten_cat_default_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_74, %aten_unsqueeze_copy_default_75], -1), kwargs = {})\n",
      "      %aten_expand_copy_default_55 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_79, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_187 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_18, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_188 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_19, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_clone_default_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_55,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_permute_copy_default_45 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_187, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_permute_copy_default_46 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_188, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_192 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_19, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_56 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_45, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_189 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_46, [12, 1, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_59 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_view_copy_default_192, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_193 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_56, [12, 1, 64]), kwargs = {})\n",
      "      %aten_index_put_default_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index_put.default](args = (%b_layers_9_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %aten_view_copy_default_189), kwargs = {})\n",
      "      %aten_view_copy_default_197 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_59, [12, 128, 64]), kwargs = {})\n",
      "      %aten_slice_scatter_default_36 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_9_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_18, 1, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_slice_scatter_default_37 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_9_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_36, 0, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_78 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_37, 2), kwargs = {})\n",
      "      %aten_expand_copy_default_54 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_78, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_clone_default_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_54,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_view_copy_default_191 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_18, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_48 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_191, [0, 1, 3, 2]), kwargs = {})\n",
      "      %aten_expand_copy_default_57 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_48, [1, 12, 64, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_194 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_57, [12, 64, 128]), kwargs = {})\n",
      "      %aten_bmm_default_18 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_193, %aten_view_copy_default_194), kwargs = {})\n",
      "      %aten_view_copy_default_195 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_18, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_mul_tensor_164 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_view_copy_default_195, %_lifted_tensor_constant236), kwargs = {})\n",
      "      %aten_add_tensor_66 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_164, %aten__to_copy_default_9), kwargs = {})\n",
      "      %aten__softmax_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._softmax.default](args = (%aten_add_tensor_66, -1, False), kwargs = {})\n",
      "      %aten_expand_copy_default_58 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten__softmax_default_9, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_196 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_58, [12, 1, 128]), kwargs = {})\n",
      "      %aten_bmm_default_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_196, %aten_view_copy_default_197), kwargs = {})\n",
      "      %aten_view_copy_default_198 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_19, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_49 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_198, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_199 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_49, [1, 1, 768]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_97 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_view_copy_default_199, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_66 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_97, %b_layers_9_attention_wo_weight, %b_layers_9_attention_wo_scales), kwargs = {})\n",
      "      %aten_add_tensor_67 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_62, %aten__weight_int8pack_mm_default_66), kwargs = {})\n",
      "      %aten_mul_tensor_165 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_67, %aten_add_tensor_67), kwargs = {})\n",
      "      %aten_mean_dim_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_165, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_68 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_19, %_lifted_tensor_constant237), kwargs = {})\n",
      "      %aten_rsqrt_default_19 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_68,), kwargs = {})\n",
      "      %aten_mul_tensor_166 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_67, %aten_rsqrt_default_19), kwargs = {})\n",
      "      %aten_mul_tensor_167 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_166, %p_layers_9_ffn_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_98 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_167, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_99 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_167, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_67 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_98, %b_layers_9_feed_forward_w1_weight, %b_layers_9_feed_forward_w1_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_68 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_99, %b_layers_9_feed_forward_w3_weight, %b_layers_9_feed_forward_w3_scales), kwargs = {})\n",
      "      %aten_sigmoid_default_9 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sigmoid.default](args = (%aten__weight_int8pack_mm_default_67,), kwargs = {})\n",
      "      %aten_mul_tensor_168 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten__weight_int8pack_mm_default_67, %aten_sigmoid_default_9), kwargs = {})\n",
      "      %aten_mul_tensor_169 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_168, %aten__weight_int8pack_mm_default_68), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_69 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_mul_tensor_169, %b_layers_9_feed_forward_w2_weight, %b_layers_9_feed_forward_w2_scales), kwargs = {})\n",
      "      %aten_add_tensor_69 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_67, %aten__weight_int8pack_mm_default_69), kwargs = {})\n",
      "      %aten_mul_tensor_170 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_69, %aten_add_tensor_69), kwargs = {})\n",
      "      %aten_mean_dim_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_170, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_70 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_20, %_lifted_tensor_constant238), kwargs = {})\n",
      "      %aten_rsqrt_default_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_70,), kwargs = {})\n",
      "      %aten_mul_tensor_171 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_69, %aten_rsqrt_default_20), kwargs = {})\n",
      "      %aten_mul_tensor_172 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_171, %p_layers_10_attention_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_100 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_172, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_101 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_172, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_102 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_172, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_70 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_100, %b_layers_10_attention_wq_weight, %b_layers_10_attention_wq_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_71 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_101, %b_layers_10_attention_wk_weight, %b_layers_10_attention_wk_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_72 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_102, %b_layers_10_attention_wv_weight, %b_layers_10_attention_wv_scales), kwargs = {})\n",
      "      %aten_view_copy_default_200 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_70, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_201 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_71, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_202 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_72, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_203 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_200, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_204 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_201, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_permute_copy_default_52 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_202, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_40 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_203, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_41 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_203, 4, 1, 2), kwargs = {})\n",
      "      %aten_slice_copy_tensor_42 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_204, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_43 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_204, 4, 1, 2), kwargs = {})\n",
      "      %aten_view_copy_default_210 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_52, [12, 1, 64]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_103 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_40, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_104 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_41, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_105 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_42, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_106 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_43, [4]), kwargs = {})\n",
      "      %aten_index_put_default_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index_put.default](args = (%b_layers_10_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %aten_view_copy_default_210), kwargs = {})\n",
      "      %aten_mul_tensor_173 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_103, %aten_view_copy_default_205), kwargs = {})\n",
      "      %aten_mul_tensor_175 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_103, %aten_view_copy_default_206), kwargs = {})\n",
      "      %aten_mul_tensor_174 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_104, %aten_view_copy_default_206), kwargs = {})\n",
      "      %aten_mul_tensor_176 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_104, %aten_view_copy_default_205), kwargs = {})\n",
      "      %aten_mul_tensor_177 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_105, %aten_view_copy_default_205), kwargs = {})\n",
      "      %aten_mul_tensor_179 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_105, %aten_view_copy_default_206), kwargs = {})\n",
      "      %aten_mul_tensor_178 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_106, %aten_view_copy_default_206), kwargs = {})\n",
      "      %aten_mul_tensor_180 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_106, %aten_view_copy_default_205), kwargs = {})\n",
      "      %aten_slice_scatter_default_42 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_10_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_21, 1, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_sub_tensor_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_173, %aten_mul_tensor_174), kwargs = {})\n",
      "      %aten_add_tensor_71 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_175, %aten_mul_tensor_176), kwargs = {})\n",
      "      %aten_sub_tensor_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_177, %aten_mul_tensor_178), kwargs = {})\n",
      "      %aten_add_tensor_72 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_179, %aten_mul_tensor_180), kwargs = {})\n",
      "      %aten_slice_scatter_default_43 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_10_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_42, 0, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_80 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_20, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_81 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_71, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_82 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_21, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_83 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_72, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_87 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_43, 2), kwargs = {})\n",
      "      %aten_cat_default_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_80, %aten_unsqueeze_copy_default_81], -1), kwargs = {})\n",
      "      %aten_cat_default_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_82, %aten_unsqueeze_copy_default_83], -1), kwargs = {})\n",
      "      %aten_expand_copy_default_61 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_87, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_207 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_20, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_208 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_21, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_clone_default_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_61,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_permute_copy_default_50 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_207, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_permute_copy_default_51 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_208, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_212 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_21, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_62 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_50, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_209 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_51, [12, 1, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_65 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_view_copy_default_212, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_213 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_62, [12, 1, 64]), kwargs = {})\n",
      "      %aten_index_put_default_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index_put.default](args = (%b_layers_10_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %aten_view_copy_default_209), kwargs = {})\n",
      "      %aten_view_copy_default_217 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_65, [12, 128, 64]), kwargs = {})\n",
      "      %aten_slice_scatter_default_40 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_10_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_20, 1, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_slice_scatter_default_41 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_10_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_40, 0, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_86 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_41, 2), kwargs = {})\n",
      "      %aten_expand_copy_default_60 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_86, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_clone_default_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_60,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_view_copy_default_211 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_20, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_53 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_211, [0, 1, 3, 2]), kwargs = {})\n",
      "      %aten_expand_copy_default_63 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_53, [1, 12, 64, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_214 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_63, [12, 64, 128]), kwargs = {})\n",
      "      %aten_bmm_default_20 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_213, %aten_view_copy_default_214), kwargs = {})\n",
      "      %aten_view_copy_default_215 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_20, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_mul_tensor_181 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_view_copy_default_215, %_lifted_tensor_constant239), kwargs = {})\n",
      "      %aten_add_tensor_73 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_181, %aten__to_copy_default_10), kwargs = {})\n",
      "      %aten__softmax_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._softmax.default](args = (%aten_add_tensor_73, -1, False), kwargs = {})\n",
      "      %aten_expand_copy_default_64 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten__softmax_default_10, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_216 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_64, [12, 1, 128]), kwargs = {})\n",
      "      %aten_bmm_default_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_216, %aten_view_copy_default_217), kwargs = {})\n",
      "      %aten_view_copy_default_218 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_21, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_54 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_218, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_219 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_54, [1, 1, 768]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_107 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_view_copy_default_219, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_73 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_107, %b_layers_10_attention_wo_weight, %b_layers_10_attention_wo_scales), kwargs = {})\n",
      "      %aten_add_tensor_74 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_69, %aten__weight_int8pack_mm_default_73), kwargs = {})\n",
      "      %aten_mul_tensor_182 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_74, %aten_add_tensor_74), kwargs = {})\n",
      "      %aten_mean_dim_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_182, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_75 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_21, %_lifted_tensor_constant240), kwargs = {})\n",
      "      %aten_rsqrt_default_21 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_75,), kwargs = {})\n",
      "      %aten_mul_tensor_183 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_74, %aten_rsqrt_default_21), kwargs = {})\n",
      "      %aten_mul_tensor_184 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_183, %p_layers_10_ffn_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_108 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_184, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_109 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_184, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_74 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_108, %b_layers_10_feed_forward_w1_weight, %b_layers_10_feed_forward_w1_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_75 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_109, %b_layers_10_feed_forward_w3_weight, %b_layers_10_feed_forward_w3_scales), kwargs = {})\n",
      "      %aten_sigmoid_default_10 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sigmoid.default](args = (%aten__weight_int8pack_mm_default_74,), kwargs = {})\n",
      "      %aten_mul_tensor_185 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten__weight_int8pack_mm_default_74, %aten_sigmoid_default_10), kwargs = {})\n",
      "      %aten_mul_tensor_186 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_185, %aten__weight_int8pack_mm_default_75), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_76 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_mul_tensor_186, %b_layers_10_feed_forward_w2_weight, %b_layers_10_feed_forward_w2_scales), kwargs = {})\n",
      "      %aten_add_tensor_76 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_74, %aten__weight_int8pack_mm_default_76), kwargs = {})\n",
      "      %aten_mul_tensor_187 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_76, %aten_add_tensor_76), kwargs = {})\n",
      "      %aten_mean_dim_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_187, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_77 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_22, %_lifted_tensor_constant241), kwargs = {})\n",
      "      %aten_rsqrt_default_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_77,), kwargs = {})\n",
      "      %aten_mul_tensor_188 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_76, %aten_rsqrt_default_22), kwargs = {})\n",
      "      %aten_mul_tensor_189 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_188, %p_layers_11_attention_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_110 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_189, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_111 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_189, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_112 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_189, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_77 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_110, %b_layers_11_attention_wq_weight, %b_layers_11_attention_wq_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_78 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_111, %b_layers_11_attention_wk_weight, %b_layers_11_attention_wk_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_79 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_112, %b_layers_11_attention_wv_weight, %b_layers_11_attention_wv_scales), kwargs = {})\n",
      "      %aten_view_copy_default_220 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_77, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_221 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_78, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_222 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten__weight_int8pack_mm_default_79, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_223 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_220, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_view_copy_default_224 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_view_copy_default_221, [1, 1, 12, -1, 2]), kwargs = {})\n",
      "      %aten_permute_copy_default_57 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_222, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_slice_copy_tensor_44 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_223, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_45 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_223, 4, 1, 2), kwargs = {})\n",
      "      %aten_slice_copy_tensor_46 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_224, 4, 0, 1), kwargs = {})\n",
      "      %aten_slice_copy_tensor_47 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_copy.Tensor](args = (%aten_view_copy_default_224, 4, 1, 2), kwargs = {})\n",
      "      %aten_view_copy_default_230 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_57, [12, 1, 64]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_113 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_44, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_114 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_45, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_115 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_46, [4]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_116 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_slice_copy_tensor_47, [4]), kwargs = {})\n",
      "      %aten_index_put_default_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index_put.default](args = (%b_layers_11_attention_sdpa_kv_cache_v_cache, [None, None, %input_pos], %aten_view_copy_default_230), kwargs = {})\n",
      "      %aten_mul_tensor_190 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_113, %aten_view_copy_default_225), kwargs = {})\n",
      "      %aten_mul_tensor_192 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_113, %aten_view_copy_default_226), kwargs = {})\n",
      "      %aten_mul_tensor_191 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_114, %aten_view_copy_default_226), kwargs = {})\n",
      "      %aten_mul_tensor_193 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_114, %aten_view_copy_default_225), kwargs = {})\n",
      "      %aten_mul_tensor_194 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_115, %aten_view_copy_default_225), kwargs = {})\n",
      "      %aten_mul_tensor_196 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_115, %aten_view_copy_default_226), kwargs = {})\n",
      "      %aten_mul_tensor_195 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_116, %aten_view_copy_default_226), kwargs = {})\n",
      "      %aten_mul_tensor_197 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_squeeze_copy_dims_116, %aten_view_copy_default_225), kwargs = {})\n",
      "      %aten_slice_scatter_default_46 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_11_attention_sdpa_kv_cache_v_cache, %aten_index_put_default_23, 1, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_sub_tensor_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_190, %aten_mul_tensor_191), kwargs = {})\n",
      "      %aten_add_tensor_78 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_192, %aten_mul_tensor_193), kwargs = {})\n",
      "      %aten_sub_tensor_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sub.Tensor](args = (%aten_mul_tensor_194, %aten_mul_tensor_195), kwargs = {})\n",
      "      %aten_add_tensor_79 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_196, %aten_mul_tensor_197), kwargs = {})\n",
      "      %aten_slice_scatter_default_47 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_11_attention_sdpa_kv_cache_v_cache, %aten_slice_scatter_default_46, 0, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_88 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_22, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_89 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_78, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_90 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_sub_tensor_23, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_91 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_add_tensor_79, 4), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_95 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_47, 2), kwargs = {})\n",
      "      %aten_cat_default_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_88, %aten_unsqueeze_copy_default_89], -1), kwargs = {})\n",
      "      %aten_cat_default_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.cat.default](args = ([%aten_unsqueeze_copy_default_90, %aten_unsqueeze_copy_default_91], -1), kwargs = {})\n",
      "      %aten_expand_copy_default_67 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_95, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_227 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_22, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_228 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_cat_default_23, [1, 1, 12, 64]), kwargs = {})\n",
      "      %aten_clone_default_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_67,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_permute_copy_default_55 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_227, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_permute_copy_default_56 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_228, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_232 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_23, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_68 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_55, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_229 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_56, [12, 1, 64]), kwargs = {})\n",
      "      %aten_expand_copy_default_71 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_view_copy_default_232, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_view_copy_default_233 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_68, [12, 1, 64]), kwargs = {})\n",
      "      %aten_index_put_default_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.index_put.default](args = (%b_layers_11_attention_sdpa_kv_cache_k_cache, [None, None, %input_pos], %aten_view_copy_default_229), kwargs = {})\n",
      "      %aten_view_copy_default_237 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_71, [12, 128, 64]), kwargs = {})\n",
      "      %aten_slice_scatter_default_44 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_11_attention_sdpa_kv_cache_k_cache, %aten_index_put_default_22, 1, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_slice_scatter_default_45 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.slice_scatter.default](args = (%b_layers_11_attention_sdpa_kv_cache_k_cache, %aten_slice_scatter_default_44, 0, 0, 9223372036854775807), kwargs = {})\n",
      "      %aten_unsqueeze_copy_default_94 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.unsqueeze_copy.default](args = (%aten_slice_scatter_default_45, 2), kwargs = {})\n",
      "      %aten_expand_copy_default_66 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_unsqueeze_copy_default_94, [1, 12, 1, 128, 64]), kwargs = {})\n",
      "      %aten_clone_default_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.clone.default](args = (%aten_expand_copy_default_66,), kwargs = {memory_format: torch.contiguous_format})\n",
      "      %aten_view_copy_default_231 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_clone_default_22, [1, 12, 128, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_58 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_231, [0, 1, 3, 2]), kwargs = {})\n",
      "      %aten_expand_copy_default_69 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten_permute_copy_default_58, [1, 12, 64, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_234 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_69, [12, 64, 128]), kwargs = {})\n",
      "      %aten_bmm_default_22 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_233, %aten_view_copy_default_234), kwargs = {})\n",
      "      %aten_view_copy_default_235 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_22, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_mul_tensor_198 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_view_copy_default_235, %_lifted_tensor_constant242), kwargs = {})\n",
      "      %aten_add_tensor_80 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mul_tensor_198, %aten__to_copy_default_11), kwargs = {})\n",
      "      %aten__softmax_default_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._softmax.default](args = (%aten_add_tensor_80, -1, False), kwargs = {})\n",
      "      %aten_expand_copy_default_70 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.expand_copy.default](args = (%aten__softmax_default_11, [1, 12, 1, 128]), kwargs = {})\n",
      "      %aten_view_copy_default_236 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_expand_copy_default_70, [12, 1, 128]), kwargs = {})\n",
      "      %aten_bmm_default_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.bmm.default](args = (%aten_view_copy_default_236, %aten_view_copy_default_237), kwargs = {})\n",
      "      %aten_view_copy_default_238 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_bmm_default_23, [1, 12, 1, 64]), kwargs = {})\n",
      "      %aten_permute_copy_default_59 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.permute_copy.default](args = (%aten_view_copy_default_238, [0, 2, 1, 3]), kwargs = {})\n",
      "      %aten_view_copy_default_239 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.view_copy.default](args = (%aten_permute_copy_default_59, [1, 1, 768]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_117 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_view_copy_default_239, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_80 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_117, %b_layers_11_attention_wo_weight, %b_layers_11_attention_wo_scales), kwargs = {})\n",
      "      %aten_add_tensor_81 : [num_users=3] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_76, %aten__weight_int8pack_mm_default_80), kwargs = {})\n",
      "      %aten_mul_tensor_199 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_81, %aten_add_tensor_81), kwargs = {})\n",
      "      %aten_mean_dim_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_199, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_82 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_23, %_lifted_tensor_constant243), kwargs = {})\n",
      "      %aten_rsqrt_default_23 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_82,), kwargs = {})\n",
      "      %aten_mul_tensor_200 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_81, %aten_rsqrt_default_23), kwargs = {})\n",
      "      %aten_mul_tensor_201 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_200, %p_layers_11_ffn_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_118 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_201, [0]), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_119 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_201, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_81 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_118, %b_layers_11_feed_forward_w1_weight, %b_layers_11_feed_forward_w1_scales), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_82 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_119, %b_layers_11_feed_forward_w3_weight, %b_layers_11_feed_forward_w3_scales), kwargs = {})\n",
      "      %aten_sigmoid_default_11 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.sigmoid.default](args = (%aten__weight_int8pack_mm_default_81,), kwargs = {})\n",
      "      %aten_mul_tensor_202 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten__weight_int8pack_mm_default_81, %aten_sigmoid_default_11), kwargs = {})\n",
      "      %aten_mul_tensor_203 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_202, %aten__weight_int8pack_mm_default_82), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_83 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_mul_tensor_203, %b_layers_11_feed_forward_w2_weight, %b_layers_11_feed_forward_w2_scales), kwargs = {})\n",
      "      %aten_add_tensor_83 : [num_users=2] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_add_tensor_81, %aten__weight_int8pack_mm_default_83), kwargs = {})\n",
      "      %aten_mul_tensor_204 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_83, %aten_add_tensor_83), kwargs = {})\n",
      "      %aten_mean_dim_24 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mean.dim](args = (%aten_mul_tensor_204, [-1], True), kwargs = {})\n",
      "      %aten_add_tensor_84 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.add.Tensor](args = (%aten_mean_dim_24, %_lifted_tensor_constant244), kwargs = {})\n",
      "      %aten_rsqrt_default_24 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.rsqrt.default](args = (%aten_add_tensor_84,), kwargs = {})\n",
      "      %aten_mul_tensor_205 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_add_tensor_83, %aten_rsqrt_default_24), kwargs = {})\n",
      "      %aten_mul_tensor_206 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.mul.Tensor](args = (%aten_mul_tensor_205, %p_norm_weight), kwargs = {})\n",
      "      %aten_squeeze_copy_dims_120 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten.squeeze_copy.dims](args = (%aten_mul_tensor_206, [0]), kwargs = {})\n",
      "      %aten__weight_int8pack_mm_default_84 : [num_users=1] = call_function[target=executorch.exir.dialects.edge._ops.aten._weight_int8pack_mm.default](args = (%aten_squeeze_copy_dims_120, %b_output_weight, %b_output_scales), kwargs = {})\n",
      "      return (aten_slice_scatter_default_3, aten_slice_scatter_default_1, aten_slice_scatter_default_7, aten_slice_scatter_default_5, aten_slice_scatter_default_11, aten_slice_scatter_default_9, aten_slice_scatter_default_15, aten_slice_scatter_default_13, aten_slice_scatter_default_19, aten_slice_scatter_default_17, aten_slice_scatter_default_23, aten_slice_scatter_default_21, aten_slice_scatter_default_27, aten_slice_scatter_default_25, aten_slice_scatter_default_31, aten_slice_scatter_default_29, aten_slice_scatter_default_35, aten_slice_scatter_default_33, aten_slice_scatter_default_39, aten_slice_scatter_default_37, aten_slice_scatter_default_43, aten_slice_scatter_default_41, aten_slice_scatter_default_47, aten_slice_scatter_default_45, aten__weight_int8pack_mm_default_84)\n",
      "  %executorch_call_delegate : [num_users=25] = call_function[target=torch.ops.higher_order.executorch_call_delegate](args = (%lowered_module_0, %b_layers_0_attention_sdpa_kv_cache_v_cache, %b_layers_0_attention_sdpa_kv_cache_k_cache, %b_layers_1_attention_sdpa_kv_cache_v_cache, %b_layers_1_attention_sdpa_kv_cache_k_cache, %b_layers_2_attention_sdpa_kv_cache_v_cache, %b_layers_2_attention_sdpa_kv_cache_k_cache, %b_layers_3_attention_sdpa_kv_cache_v_cache, %b_layers_3_attention_sdpa_kv_cache_k_cache, %b_layers_4_attention_sdpa_kv_cache_v_cache, %b_layers_4_attention_sdpa_kv_cache_k_cache, %b_layers_5_attention_sdpa_kv_cache_v_cache, %b_layers_5_attention_sdpa_kv_cache_k_cache, %b_layers_6_attention_sdpa_kv_cache_v_cache, %b_layers_6_attention_sdpa_kv_cache_k_cache, %b_layers_7_attention_sdpa_kv_cache_v_cache, %b_layers_7_attention_sdpa_kv_cache_k_cache, %b_layers_8_attention_sdpa_kv_cache_v_cache, %b_layers_8_attention_sdpa_kv_cache_k_cache, %b_layers_9_attention_sdpa_kv_cache_v_cache, %b_layers_9_attention_sdpa_kv_cache_k_cache, %b_layers_10_attention_sdpa_kv_cache_v_cache, %b_layers_10_attention_sdpa_kv_cache_k_cache, %b_layers_11_attention_sdpa_kv_cache_v_cache, %b_layers_11_attention_sdpa_kv_cache_k_cache, %tokens, %input_pos), kwargs = {})\n",
      "  %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 0), kwargs = {})\n",
      "  %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 1), kwargs = {})\n",
      "  %getitem_2 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 2), kwargs = {})\n",
      "  %getitem_3 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 3), kwargs = {})\n",
      "  %getitem_4 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 4), kwargs = {})\n",
      "  %getitem_5 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 5), kwargs = {})\n",
      "  %getitem_6 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 6), kwargs = {})\n",
      "  %getitem_7 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 7), kwargs = {})\n",
      "  %getitem_8 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 8), kwargs = {})\n",
      "  %getitem_9 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 9), kwargs = {})\n",
      "  %getitem_10 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 10), kwargs = {})\n",
      "  %getitem_11 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 11), kwargs = {})\n",
      "  %getitem_12 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 12), kwargs = {})\n",
      "  %getitem_13 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 13), kwargs = {})\n",
      "  %getitem_14 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 14), kwargs = {})\n",
      "  %getitem_15 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 15), kwargs = {})\n",
      "  %getitem_16 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 16), kwargs = {})\n",
      "  %getitem_17 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 17), kwargs = {})\n",
      "  %getitem_18 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 18), kwargs = {})\n",
      "  %getitem_19 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 19), kwargs = {})\n",
      "  %getitem_20 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 20), kwargs = {})\n",
      "  %getitem_21 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 21), kwargs = {})\n",
      "  %getitem_22 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 22), kwargs = {})\n",
      "  %getitem_23 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 23), kwargs = {})\n",
      "  %getitem_24 : [num_users=1] = call_function[target=operator.getitem](args = (%executorch_call_delegate, 24), kwargs = {})\n",
      "  %copy_ : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_0_attention_sdpa_kv_cache_k_cache, %getitem_1), kwargs = {})\n",
      "  %copy__1 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_0_attention_sdpa_kv_cache_v_cache, %getitem), kwargs = {})\n",
      "  %copy__2 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_1_attention_sdpa_kv_cache_k_cache, %getitem_3), kwargs = {})\n",
      "  %copy__3 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_1_attention_sdpa_kv_cache_v_cache, %getitem_2), kwargs = {})\n",
      "  %copy__4 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_2_attention_sdpa_kv_cache_k_cache, %getitem_5), kwargs = {})\n",
      "  %copy__5 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_2_attention_sdpa_kv_cache_v_cache, %getitem_4), kwargs = {})\n",
      "  %copy__6 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_3_attention_sdpa_kv_cache_k_cache, %getitem_7), kwargs = {})\n",
      "  %copy__7 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_3_attention_sdpa_kv_cache_v_cache, %getitem_6), kwargs = {})\n",
      "  %copy__8 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_4_attention_sdpa_kv_cache_k_cache, %getitem_9), kwargs = {})\n",
      "  %copy__9 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_4_attention_sdpa_kv_cache_v_cache, %getitem_8), kwargs = {})\n",
      "  %copy__10 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_5_attention_sdpa_kv_cache_k_cache, %getitem_11), kwargs = {})\n",
      "  %copy__11 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_5_attention_sdpa_kv_cache_v_cache, %getitem_10), kwargs = {})\n",
      "  %copy__12 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_6_attention_sdpa_kv_cache_k_cache, %getitem_13), kwargs = {})\n",
      "  %copy__13 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_6_attention_sdpa_kv_cache_v_cache, %getitem_12), kwargs = {})\n",
      "  %copy__14 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_7_attention_sdpa_kv_cache_k_cache, %getitem_15), kwargs = {})\n",
      "  %copy__15 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_7_attention_sdpa_kv_cache_v_cache, %getitem_14), kwargs = {})\n",
      "  %copy__16 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_8_attention_sdpa_kv_cache_k_cache, %getitem_17), kwargs = {})\n",
      "  %copy__17 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_8_attention_sdpa_kv_cache_v_cache, %getitem_16), kwargs = {})\n",
      "  %copy__18 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_9_attention_sdpa_kv_cache_k_cache, %getitem_19), kwargs = {})\n",
      "  %copy__19 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_9_attention_sdpa_kv_cache_v_cache, %getitem_18), kwargs = {})\n",
      "  %copy__20 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_10_attention_sdpa_kv_cache_k_cache, %getitem_21), kwargs = {})\n",
      "  %copy__21 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_10_attention_sdpa_kv_cache_v_cache, %getitem_20), kwargs = {})\n",
      "  %copy__22 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_11_attention_sdpa_kv_cache_k_cache, %getitem_23), kwargs = {})\n",
      "  %copy__23 : [num_users=0] = call_function[target=torch.ops.aten.copy_.default](args = (%b_layers_11_attention_sdpa_kv_cache_v_cache, %getitem_22), kwargs = {})\n",
      "  return (getitem_24,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from executorch.exir.backend.utils import print_delegated_graph\n",
    "\n",
    "print_delegated_graph(builder.export_program.exported_program(\"forward\").graph_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2024-05-08 18:05:27,276 utils.py:113] Saved exported program to stories110M_int8_cpu.pte\n"
     ]
    }
   ],
   "source": [
    "builder.save_to_pte(\"stories110M_int8_cpu.pte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2024-05-08 14:39:40,251 utils.py:112] Saved exported program to stories110M_int8.pte\n"
     ]
    }
   ],
   "source": [
    "builder.save_to_pte(\"stories110M_int8.pte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2024-05-08 17:58:18,813 utils.py:113] Saved exported program to stories110M_int8_mps.pte\n"
     ]
    }
   ],
   "source": [
    "builder.save_to_pte(\"stories110M_int8_mps.pte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from executorch.extension.pybindings.portable_lib import _load_for_executorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[program.cpp:130] InternalConsistency verification requested but not available"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "m = _load_for_executorch(\"stories110M_int8.pte\")\n",
    "res = m.forward((torch.tensor([[1]], dtype=torch.long), torch.tensor(0, dtype=torch.long)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(res)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "files = [\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmpp7jovcm9/schema.json\",\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmpn0uo5apz/schema.json\",\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmp0i_0v_b0/schema.json\",\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmpgjvbi4s1/schema.json\",\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmpt79bbpbt/schema.json\",\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmp6ychs24g/schema.json\",\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmpqawc68v7/schema.json\",\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmpt6sq63zo/schema.json\",\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmp9d080mdv/schema.json\",\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmp6jpstr7y/schema.json\",\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmpzutwk8fg/schema.json\",\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmpp1cerjiu/schema.json\",\n",
    "    \"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmpz4iu5_hx/schema.json\",\n",
    "]\n",
    "nodes = []\n",
    "for j in files:\n",
    "    with open(j) as f:\n",
    "        data = json.load(f)\n",
    "        for i, node in enumerate(data[\"mps_nodes\"]):\n",
    "            if node[\"mpsnode_union_type\"] == \"MPSIndexTensor\":\n",
    "                print(i)\n",
    "                nodes.append(node)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['version', 'mps_nodes', 'mps_values', 'input_ids', 'output_ids', 'constant_ids', 'graph_type'])\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mpsnode_union': {'input1_id': 32, 'output_id': 34, 'indices_id': [-1, -1, 3]}, 'mpsnode_union_type': 'MPSIndexTensor', 'min_max': None}\n"
     ]
    }
   ],
   "source": [
    "print(nodes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[-1, -1, 3]\n",
      "1\n",
      "[-1, -1, 5]\n",
      "2\n",
      "[-1, -1, 5]\n",
      "3\n",
      "[-1, -1, 5]\n",
      "4\n",
      "[-1, -1, 5]\n",
      "5\n",
      "[-1, -1, 5]\n",
      "6\n",
      "[-1, -1, 5]\n",
      "7\n",
      "[-1, -1, 5]\n",
      "8\n",
      "[-1, -1, 5]\n",
      "9\n",
      "[-1, -1, 5]\n",
      "10\n",
      "[-1, -1, 5]\n",
      "11\n",
      "[-1, -1, 5]\n",
      "12\n",
      "[1]\n",
      "13\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "for i, n in enumerate(nodes):\n",
    "    print(i)\n",
    "    print(n[\"mpsnode_union\"][\"indices_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 12, 13, 15, 16, 21, 32, 46]\n"
     ]
    }
   ],
   "source": [
    "print(data[\"output_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "for n in custom_nodes:\n",
    "    values.extend([data[\"mps_values\"][i] for i in n[\"mpsnode_union\"].values() if data[\"mps_values\"][i][\"datatype\"] == 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datatype': 3,\n",
       " 'num_dims': 1,\n",
       " 'dims': [768],\n",
       " 'constant_buffer_size': 1536,\n",
       " 'constant_buffer': {'storage': [20,\n",
       "   59,\n",
       "   34,\n",
       "   59,\n",
       "   21,\n",
       "   59,\n",
       "   43,\n",
       "   59,\n",
       "   161,\n",
       "   58,\n",
       "   232,\n",
       "   58,\n",
       "   165,\n",
       "   58,\n",
       "   0,\n",
       "   59,\n",
       "   205,\n",
       "   58,\n",
       "   10,\n",
       "   59,\n",
       "   186,\n",
       "   58,\n",
       "   195,\n",
       "   58,\n",
       "   215,\n",
       "   58,\n",
       "   199,\n",
       "   58,\n",
       "   152,\n",
       "   58,\n",
       "   177,\n",
       "   58,\n",
       "   226,\n",
       "   58,\n",
       "   239,\n",
       "   58,\n",
       "   162,\n",
       "   58,\n",
       "   164,\n",
       "   58,\n",
       "   137,\n",
       "   58,\n",
       "   217,\n",
       "   58,\n",
       "   4,\n",
       "   59,\n",
       "   245,\n",
       "   58,\n",
       "   153,\n",
       "   58,\n",
       "   229,\n",
       "   58,\n",
       "   148,\n",
       "   58,\n",
       "   198,\n",
       "   58,\n",
       "   15,\n",
       "   59,\n",
       "   143,\n",
       "   58,\n",
       "   148,\n",
       "   58,\n",
       "   221,\n",
       "   58,\n",
       "   56,\n",
       "   58,\n",
       "   86,\n",
       "   59,\n",
       "   30,\n",
       "   59,\n",
       "   93,\n",
       "   58,\n",
       "   72,\n",
       "   58,\n",
       "   2,\n",
       "   59,\n",
       "   90,\n",
       "   59,\n",
       "   76,\n",
       "   58,\n",
       "   20,\n",
       "   58,\n",
       "   4,\n",
       "   60,\n",
       "   149,\n",
       "   58,\n",
       "   150,\n",
       "   59,\n",
       "   255,\n",
       "   58,\n",
       "   186,\n",
       "   58,\n",
       "   185,\n",
       "   58,\n",
       "   185,\n",
       "   58,\n",
       "   54,\n",
       "   59,\n",
       "   158,\n",
       "   58,\n",
       "   131,\n",
       "   58,\n",
       "   53,\n",
       "   59,\n",
       "   132,\n",
       "   58,\n",
       "   31,\n",
       "   59,\n",
       "   225,\n",
       "   58,\n",
       "   206,\n",
       "   58,\n",
       "   241,\n",
       "   58,\n",
       "   197,\n",
       "   58,\n",
       "   221,\n",
       "   58,\n",
       "   228,\n",
       "   58,\n",
       "   219,\n",
       "   58,\n",
       "   236,\n",
       "   58,\n",
       "   199,\n",
       "   58,\n",
       "   177,\n",
       "   58,\n",
       "   210,\n",
       "   58,\n",
       "   244,\n",
       "   58,\n",
       "   153,\n",
       "   58,\n",
       "   160,\n",
       "   58,\n",
       "   219,\n",
       "   58,\n",
       "   160,\n",
       "   58,\n",
       "   185,\n",
       "   58,\n",
       "   178,\n",
       "   58,\n",
       "   203,\n",
       "   58,\n",
       "   191,\n",
       "   58,\n",
       "   146,\n",
       "   58,\n",
       "   201,\n",
       "   58,\n",
       "   163,\n",
       "   58,\n",
       "   184,\n",
       "   58,\n",
       "   199,\n",
       "   58,\n",
       "   187,\n",
       "   58,\n",
       "   198,\n",
       "   58,\n",
       "   152,\n",
       "   58,\n",
       "   182,\n",
       "   58,\n",
       "   152,\n",
       "   58,\n",
       "   142,\n",
       "   58,\n",
       "   160,\n",
       "   58,\n",
       "   174,\n",
       "   58,\n",
       "   188,\n",
       "   58,\n",
       "   164,\n",
       "   58,\n",
       "   172,\n",
       "   58,\n",
       "   181,\n",
       "   58,\n",
       "   162,\n",
       "   58,\n",
       "   137,\n",
       "   58,\n",
       "   202,\n",
       "   58,\n",
       "   143,\n",
       "   58,\n",
       "   213,\n",
       "   58,\n",
       "   154,\n",
       "   58,\n",
       "   169,\n",
       "   58,\n",
       "   174,\n",
       "   58,\n",
       "   211,\n",
       "   58,\n",
       "   150,\n",
       "   58,\n",
       "   225,\n",
       "   58,\n",
       "   18,\n",
       "   59,\n",
       "   130,\n",
       "   58,\n",
       "   253,\n",
       "   58,\n",
       "   136,\n",
       "   58,\n",
       "   0,\n",
       "   59,\n",
       "   6,\n",
       "   59,\n",
       "   153,\n",
       "   58,\n",
       "   51,\n",
       "   59,\n",
       "   218,\n",
       "   58,\n",
       "   137,\n",
       "   58,\n",
       "   134,\n",
       "   58,\n",
       "   183,\n",
       "   58,\n",
       "   226,\n",
       "   58,\n",
       "   253,\n",
       "   58,\n",
       "   4,\n",
       "   59,\n",
       "   251,\n",
       "   58,\n",
       "   172,\n",
       "   58,\n",
       "   213,\n",
       "   58,\n",
       "   243,\n",
       "   58,\n",
       "   217,\n",
       "   58,\n",
       "   221,\n",
       "   58,\n",
       "   220,\n",
       "   58,\n",
       "   16,\n",
       "   59,\n",
       "   213,\n",
       "   58,\n",
       "   224,\n",
       "   58,\n",
       "   199,\n",
       "   58,\n",
       "   248,\n",
       "   58,\n",
       "   186,\n",
       "   58,\n",
       "   222,\n",
       "   58,\n",
       "   178,\n",
       "   58,\n",
       "   206,\n",
       "   58,\n",
       "   240,\n",
       "   58,\n",
       "   240,\n",
       "   58,\n",
       "   217,\n",
       "   58,\n",
       "   223,\n",
       "   58,\n",
       "   199,\n",
       "   58,\n",
       "   210,\n",
       "   58,\n",
       "   11,\n",
       "   59,\n",
       "   189,\n",
       "   58,\n",
       "   218,\n",
       "   58,\n",
       "   213,\n",
       "   58,\n",
       "   224,\n",
       "   58,\n",
       "   224,\n",
       "   58,\n",
       "   216,\n",
       "   58,\n",
       "   222,\n",
       "   58,\n",
       "   231,\n",
       "   58,\n",
       "   210,\n",
       "   58,\n",
       "   192,\n",
       "   58,\n",
       "   159,\n",
       "   58,\n",
       "   212,\n",
       "   58,\n",
       "   210,\n",
       "   58,\n",
       "   186,\n",
       "   58,\n",
       "   177,\n",
       "   58,\n",
       "   216,\n",
       "   58,\n",
       "   181,\n",
       "   58,\n",
       "   242,\n",
       "   58,\n",
       "   200,\n",
       "   58,\n",
       "   187,\n",
       "   58,\n",
       "   182,\n",
       "   58,\n",
       "   210,\n",
       "   58,\n",
       "   182,\n",
       "   58,\n",
       "   187,\n",
       "   58,\n",
       "   208,\n",
       "   58,\n",
       "   217,\n",
       "   58,\n",
       "   189,\n",
       "   58,\n",
       "   242,\n",
       "   58,\n",
       "   4,\n",
       "   59,\n",
       "   7,\n",
       "   59,\n",
       "   13,\n",
       "   59,\n",
       "   168,\n",
       "   58,\n",
       "   15,\n",
       "   59,\n",
       "   215,\n",
       "   58,\n",
       "   204,\n",
       "   58,\n",
       "   1,\n",
       "   59,\n",
       "   244,\n",
       "   58,\n",
       "   175,\n",
       "   58,\n",
       "   216,\n",
       "   58,\n",
       "   208,\n",
       "   58,\n",
       "   212,\n",
       "   58,\n",
       "   218,\n",
       "   58,\n",
       "   13,\n",
       "   59,\n",
       "   192,\n",
       "   58,\n",
       "   1,\n",
       "   59,\n",
       "   206,\n",
       "   58,\n",
       "   11,\n",
       "   59,\n",
       "   229,\n",
       "   58,\n",
       "   247,\n",
       "   58,\n",
       "   196,\n",
       "   58,\n",
       "   245,\n",
       "   58,\n",
       "   13,\n",
       "   59,\n",
       "   60,\n",
       "   59,\n",
       "   208,\n",
       "   58,\n",
       "   242,\n",
       "   58,\n",
       "   216,\n",
       "   58,\n",
       "   212,\n",
       "   58,\n",
       "   216,\n",
       "   58,\n",
       "   173,\n",
       "   58,\n",
       "   178,\n",
       "   58,\n",
       "   207,\n",
       "   58,\n",
       "   237,\n",
       "   58,\n",
       "   236,\n",
       "   58,\n",
       "   178,\n",
       "   58,\n",
       "   236,\n",
       "   58,\n",
       "   196,\n",
       "   58,\n",
       "   197,\n",
       "   58,\n",
       "   199,\n",
       "   58,\n",
       "   0,\n",
       "   59,\n",
       "   199,\n",
       "   58,\n",
       "   234,\n",
       "   58,\n",
       "   246,\n",
       "   58,\n",
       "   9,\n",
       "   59,\n",
       "   191,\n",
       "   58,\n",
       "   181,\n",
       "   58,\n",
       "   202,\n",
       "   58,\n",
       "   28,\n",
       "   59,\n",
       "   195,\n",
       "   58,\n",
       "   218,\n",
       "   58,\n",
       "   233,\n",
       "   58,\n",
       "   16,\n",
       "   59,\n",
       "   180,\n",
       "   58,\n",
       "   152,\n",
       "   58,\n",
       "   226,\n",
       "   58,\n",
       "   145,\n",
       "   58,\n",
       "   216,\n",
       "   58,\n",
       "   116,\n",
       "   58,\n",
       "   226,\n",
       "   58,\n",
       "   224,\n",
       "   58,\n",
       "   123,\n",
       "   58,\n",
       "   73,\n",
       "   59,\n",
       "   52,\n",
       "   58,\n",
       "   31,\n",
       "   58,\n",
       "   206,\n",
       "   59,\n",
       "   54,\n",
       "   58,\n",
       "   184,\n",
       "   59,\n",
       "   167,\n",
       "   58,\n",
       "   90,\n",
       "   59,\n",
       "   219,\n",
       "   58,\n",
       "   249,\n",
       "   58,\n",
       "   17,\n",
       "   59,\n",
       "   197,\n",
       "   58,\n",
       "   204,\n",
       "   58,\n",
       "   210,\n",
       "   58,\n",
       "   11,\n",
       "   59,\n",
       "   223,\n",
       "   58,\n",
       "   248,\n",
       "   58,\n",
       "   15,\n",
       "   59,\n",
       "   6,\n",
       "   59,\n",
       "   244,\n",
       "   58,\n",
       "   190,\n",
       "   58,\n",
       "   229,\n",
       "   58,\n",
       "   10,\n",
       "   59,\n",
       "   232,\n",
       "   58,\n",
       "   14,\n",
       "   59,\n",
       "   1,\n",
       "   59,\n",
       "   68,\n",
       "   59,\n",
       "   38,\n",
       "   59,\n",
       "   48,\n",
       "   59,\n",
       "   17,\n",
       "   59,\n",
       "   16,\n",
       "   59,\n",
       "   12,\n",
       "   59,\n",
       "   244,\n",
       "   58,\n",
       "   246,\n",
       "   58,\n",
       "   195,\n",
       "   58,\n",
       "   9,\n",
       "   59,\n",
       "   205,\n",
       "   58,\n",
       "   35,\n",
       "   59,\n",
       "   216,\n",
       "   58,\n",
       "   30,\n",
       "   59,\n",
       "   198,\n",
       "   58,\n",
       "   13,\n",
       "   59,\n",
       "   162,\n",
       "   58,\n",
       "   231,\n",
       "   58,\n",
       "   158,\n",
       "   58,\n",
       "   10,\n",
       "   59,\n",
       "   239,\n",
       "   58,\n",
       "   166,\n",
       "   58,\n",
       "   201,\n",
       "   58,\n",
       "   178,\n",
       "   58,\n",
       "   122,\n",
       "   58,\n",
       "   3,\n",
       "   59,\n",
       "   116,\n",
       "   58,\n",
       "   13,\n",
       "   59,\n",
       "   81,\n",
       "   59,\n",
       "   89,\n",
       "   58,\n",
       "   102,\n",
       "   58,\n",
       "   228,\n",
       "   58,\n",
       "   90,\n",
       "   59,\n",
       "   76,\n",
       "   58,\n",
       "   56,\n",
       "   58,\n",
       "   33,\n",
       "   59,\n",
       "   221,\n",
       "   58,\n",
       "   95,\n",
       "   58,\n",
       "   117,\n",
       "   59,\n",
       "   12,\n",
       "   58,\n",
       "   26,\n",
       "   60,\n",
       "   180,\n",
       "   57,\n",
       "   227,\n",
       "   58,\n",
       "   237,\n",
       "   58,\n",
       "   20,\n",
       "   60,\n",
       "   115,\n",
       "   58,\n",
       "   216,\n",
       "   58,\n",
       "   230,\n",
       "   58,\n",
       "   247,\n",
       "   58,\n",
       "   151,\n",
       "   58,\n",
       "   20,\n",
       "   59,\n",
       "   247,\n",
       "   58,\n",
       "   12,\n",
       "   59,\n",
       "   4,\n",
       "   59,\n",
       "   213,\n",
       "   58,\n",
       "   248,\n",
       "   58,\n",
       "   0,\n",
       "   59,\n",
       "   45,\n",
       "   59,\n",
       "   7,\n",
       "   59,\n",
       "   227,\n",
       "   58,\n",
       "   177,\n",
       "   58,\n",
       "   24,\n",
       "   59,\n",
       "   232,\n",
       "   58,\n",
       "   247,\n",
       "   58,\n",
       "   214,\n",
       "   58,\n",
       "   233,\n",
       "   58,\n",
       "   0,\n",
       "   59,\n",
       "   173,\n",
       "   58,\n",
       "   222,\n",
       "   58,\n",
       "   6,\n",
       "   59,\n",
       "   182,\n",
       "   58,\n",
       "   220,\n",
       "   58,\n",
       "   14,\n",
       "   59,\n",
       "   212,\n",
       "   58,\n",
       "   227,\n",
       "   58,\n",
       "   21,\n",
       "   59,\n",
       "   150,\n",
       "   58,\n",
       "   224,\n",
       "   58,\n",
       "   243,\n",
       "   58,\n",
       "   210,\n",
       "   58,\n",
       "   211,\n",
       "   58,\n",
       "   7,\n",
       "   59,\n",
       "   186,\n",
       "   58,\n",
       "   187,\n",
       "   58,\n",
       "   162,\n",
       "   58,\n",
       "   214,\n",
       "   58,\n",
       "   3,\n",
       "   59,\n",
       "   19,\n",
       "   59,\n",
       "   4,\n",
       "   59,\n",
       "   224,\n",
       "   58,\n",
       "   188,\n",
       "   58,\n",
       "   200,\n",
       "   58,\n",
       "   225,\n",
       "   58,\n",
       "   242,\n",
       "   58,\n",
       "   199,\n",
       "   58,\n",
       "   238,\n",
       "   58,\n",
       "   251,\n",
       "   58,\n",
       "   224,\n",
       "   58,\n",
       "   194,\n",
       "   58,\n",
       "   181,\n",
       "   58,\n",
       "   204,\n",
       "   58,\n",
       "   213,\n",
       "   58,\n",
       "   158,\n",
       "   58,\n",
       "   255,\n",
       "   58,\n",
       "   33,\n",
       "   59,\n",
       "   133,\n",
       "   58,\n",
       "   255,\n",
       "   58,\n",
       "   0,\n",
       "   59,\n",
       "   187,\n",
       "   58,\n",
       "   36,\n",
       "   59,\n",
       "   190,\n",
       "   58,\n",
       "   169,\n",
       "   58,\n",
       "   195,\n",
       "   58,\n",
       "   250,\n",
       "   58,\n",
       "   182,\n",
       "   58,\n",
       "   205,\n",
       "   58,\n",
       "   35,\n",
       "   59,\n",
       "   217,\n",
       "   58,\n",
       "   200,\n",
       "   58,\n",
       "   1,\n",
       "   59,\n",
       "   211,\n",
       "   58,\n",
       "   36,\n",
       "   59,\n",
       "   47,\n",
       "   59,\n",
       "   29,\n",
       "   59,\n",
       "   23,\n",
       "   59,\n",
       "   224,\n",
       "   58,\n",
       "   82,\n",
       "   59,\n",
       "   228,\n",
       "   58,\n",
       "   92,\n",
       "   59,\n",
       "   88,\n",
       "   59,\n",
       "   12,\n",
       "   59,\n",
       "   116,\n",
       "   59,\n",
       "   1,\n",
       "   59,\n",
       "   70,\n",
       "   59,\n",
       "   70,\n",
       "   59,\n",
       "   250,\n",
       "   58,\n",
       "   45,\n",
       "   59,\n",
       "   23,\n",
       "   59,\n",
       "   15,\n",
       "   59,\n",
       "   231,\n",
       "   58,\n",
       "   240,\n",
       "   58,\n",
       "   35,\n",
       "   59,\n",
       "   249,\n",
       "   58,\n",
       "   22,\n",
       "   59,\n",
       "   35,\n",
       "   59,\n",
       "   6,\n",
       "   59,\n",
       "   180,\n",
       "   58,\n",
       "   12,\n",
       "   59,\n",
       "   182,\n",
       "   58,\n",
       "   157,\n",
       "   58,\n",
       "   28,\n",
       "   59,\n",
       "   171,\n",
       "   58,\n",
       "   241,\n",
       "   58,\n",
       "   234,\n",
       "   58,\n",
       "   219,\n",
       "   58,\n",
       "   155,\n",
       "   58,\n",
       "   147,\n",
       "   58,\n",
       "   239,\n",
       "   58,\n",
       "   18,\n",
       "   59,\n",
       "   225,\n",
       "   58,\n",
       "   152,\n",
       "   58,\n",
       "   218,\n",
       "   58,\n",
       "   7,\n",
       "   59,\n",
       "   129,\n",
       "   58,\n",
       "   248,\n",
       "   58,\n",
       "   163,\n",
       "   58,\n",
       "   147,\n",
       "   58,\n",
       "   135,\n",
       "   58,\n",
       "   247,\n",
       "   59,\n",
       "   68,\n",
       "   58,\n",
       "   108,\n",
       "   58,\n",
       "   200,\n",
       "   59,\n",
       "   150,\n",
       "   58,\n",
       "   79,\n",
       "   59,\n",
       "   86,\n",
       "   59,\n",
       "   193,\n",
       "   58,\n",
       "   52,\n",
       "   59,\n",
       "   163,\n",
       "   58,\n",
       "   31,\n",
       "   59,\n",
       "   188,\n",
       "   58,\n",
       "   223,\n",
       "   58,\n",
       "   222,\n",
       "   58,\n",
       "   169,\n",
       "   58,\n",
       "   239,\n",
       "   58,\n",
       "   198,\n",
       "   58,\n",
       "   174,\n",
       "   58,\n",
       "   218,\n",
       "   58,\n",
       "   8,\n",
       "   59,\n",
       "   0,\n",
       "   59,\n",
       "   150,\n",
       "   58,\n",
       "   233,\n",
       "   58,\n",
       "   244,\n",
       "   58,\n",
       "   43,\n",
       "   59,\n",
       "   1,\n",
       "   59,\n",
       "   243,\n",
       "   58,\n",
       "   68,\n",
       "   59,\n",
       "   29,\n",
       "   59,\n",
       "   46,\n",
       "   59,\n",
       "   184,\n",
       "   58,\n",
       "   54,\n",
       "   59,\n",
       "   244,\n",
       "   58,\n",
       "   12,\n",
       "   59,\n",
       "   4,\n",
       "   59,\n",
       "   8,\n",
       "   59,\n",
       "   194,\n",
       "   58,\n",
       "   7,\n",
       "   59,\n",
       "   7,\n",
       "   59,\n",
       "   223,\n",
       "   58,\n",
       "   11,\n",
       "   59,\n",
       "   25,\n",
       "   59,\n",
       "   197,\n",
       "   58,\n",
       "   1,\n",
       "   59,\n",
       "   13,\n",
       "   59,\n",
       "   183,\n",
       "   58,\n",
       "   222,\n",
       "   58,\n",
       "   1,\n",
       "   59,\n",
       "   29,\n",
       "   59,\n",
       "   24,\n",
       "   59,\n",
       "   30,\n",
       "   59,\n",
       "   18,\n",
       "   59,\n",
       "   173,\n",
       "   58,\n",
       "   39,\n",
       "   59,\n",
       "   16,\n",
       "   59,\n",
       "   208,\n",
       "   58,\n",
       "   249,\n",
       "   58,\n",
       "   8,\n",
       "   59,\n",
       "   245,\n",
       "   58,\n",
       "   171,\n",
       "   58,\n",
       "   180,\n",
       "   58,\n",
       "   71,\n",
       "   59,\n",
       "   129,\n",
       "   59,\n",
       "   199,\n",
       "   58,\n",
       "   55,\n",
       "   59,\n",
       "   130,\n",
       "   58,\n",
       "   184,\n",
       "   59,\n",
       "   112,\n",
       "   58,\n",
       "   158,\n",
       "   58,\n",
       "   148,\n",
       "   59,\n",
       "   179,\n",
       "   58,\n",
       "   127,\n",
       "   59,\n",
       "   215,\n",
       "   58,\n",
       "   65,\n",
       "   59,\n",
       "   185,\n",
       "   58,\n",
       "   43,\n",
       "   59,\n",
       "   ...]}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"mps_values\"][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class WeightOnlyInt8QuantHandler(QuantHandler):\n",
      "    def __init__(\n",
      "        self,\n",
      "        mod,\n",
      "        device=\"cpu\",\n",
      "        *,\n",
      "        node_type: str = \"*\",\n",
      "        bitwidth: Optional[int] = None,\n",
      "        group_size: Optional[int] = None,\n",
      "    ):\n",
      "        self.mod = mod\n",
      "        self.group_size = group_size\n",
      "        self.node_type = node_type\n",
      "        if bitwidth is None:\n",
      "            self.bitwidth = 8\n",
      "        else:\n",
      "            self.bitwidth = bitwidth\n",
      "\n",
      "    @torch.no_grad()\n",
      "    def create_quantized_state_dict(self) -> Dict:\n",
      "        cur_state_dict = self.mod.state_dict()\n",
      "\n",
      "        if self.bitwidth == 4:\n",
      "            range_min = -8\n",
      "            range_max = 7\n",
      "        elif self.bitwidth == 8:\n",
      "            range_min = -128\n",
      "            range_max = 127\n",
      "        else:\n",
      "            raise ValueError(f\"Unsupported bitwidth {self.bitwidth}\")\n",
      "\n",
      "        for fqn, mod in self.mod.named_modules():\n",
      "            # print(f\"maybe? quantize {fqn}...{type(mod)}\")\n",
      "            if isinstance(mod, torch.nn.Linear) or isinstance(mod, fsLinear):\n",
      "                # print(f\"candidate {fqn}, nodetype {self.node_type}\")\n",
      "                if (\n",
      "                    (self.node_type == \"*\")\n",
      "                    or (self.node_type == \"output\" and fqn in [\"output\", \"final_proj\"])\n",
      "                    or (\n",
      "                        self.node_type == \"!output\"\n",
      "                        and fqn not in [\"output\", \"final_proj\"]\n",
      "                    )\n",
      "                ):\n",
      "                    print(\n",
      "                        f\"quantize {self.node_type} {fqn, mod} with group_size {self.group_size}, bitwidth {self.bitwidth}\"\n",
      "                    )\n",
      "\n",
      "                    # print(f\"initial weight shape {mod.weight.shape}\")\n",
      "                    input_weight = mod.weight.float()\n",
      "\n",
      "                    # print(f\"expanded weight shape {input_weight.shape}\")\n",
      "                    weight, scales, _ = dynamically_quantize_per_channel(\n",
      "                        input_weight,\n",
      "                        range_min,\n",
      "                        range_max,\n",
      "                        torch.int8,\n",
      "                        self.group_size,\n",
      "                        scales_dtype=input_weight.dtype,\n",
      "                    )\n",
      "\n",
      "                    cur_state_dict[f\"{fqn}.weight\"] = weight\n",
      "                    # squeeze makes group_size=rowsize unidimensional\n",
      "                    cur_state_dict[f\"{fqn}.scales\"] = scales.squeeze(dim=-1)\n",
      "\n",
      "        return cur_state_dict\n",
      "\n",
      "    def convert_for_runtime(self) -> nn.Module:\n",
      "        replace_linear_weight_only_int8_per_channel(self.mod, self.node_type)\n",
      "        return self.mod\n",
      "\n",
      "    def quantized_model(self) -> nn.Module:\n",
      "        model_updated_state_dict = self.create_quantized_state_dict()\n",
      "        self.convert_for_runtime()\n",
      "        self.mod.load_state_dict(model_updated_state_dict)\n",
      "        return self.mod\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(WeightOnlyInt8QuantHandler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flatbuffers\n",
    "from mpsgraph.MPSGraph import MPSGraph\n",
    "from mpsgraph.MPSIndexTensor import MPSIndexTensor\n",
    "with open(\"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmpudja56ka/schema.bin\", 'rb') as f:\n",
    "    g = MPSGraph.GetRootAsMPSGraph(f.read(), 0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "nodes = []\n",
    "with open(\"/var/folders/21/pcyct_g904x1pf8l_b2pvpy00000gn/T/tmpudja56ka/schema.json\") as f:\n",
    "    data = json.load(f)\n",
    "    nodes = [node for node in data[\"mps_nodes\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MPSCast\n",
      "1 MPSCast\n",
      "2 MPSCast\n",
      "3 MPSCast\n",
      "4 MPSCast\n",
      "5 MPSCast\n",
      "6 MPSSqueeze\n",
      "7 MPSUnsqueeze\n",
      "8 MPSUnsqueeze\n",
      "9 MPSUnsqueeze\n",
      "10 MPSExpand\n",
      "11 MPSExpand\n",
      "12 MPSPermute\n",
      "13 MPSUnsqueeze\n",
      "14 MPSPermute\n",
      "15 MPSPermute\n",
      "16 MPSPermute\n",
      "17 MPSPermute\n",
      "18 MPSPermute\n",
      "19 MPSMatMul\n",
      "20 MPSIndexTensor\n",
      "21 MPSView\n",
      "22 MPSView\n",
      "23 MPSMul\n",
      "24 MPSPermute\n",
      "25 MPSExpand\n",
      "26 MPSView\n",
      "27 MPSExpand\n",
      "28 MPSView\n",
      "29 MPSView\n",
      "30 MPSView\n",
      "31 MPSSlice\n",
      "32 MPSSlice\n",
      "33 MPSSqueeze\n",
      "34 MPSSqueeze\n",
      "35 MPSMul\n",
      "36 MPSMul\n",
      "37 MPSMul\n",
      "38 MPSMul\n",
      "39 MPSSub\n",
      "40 MPSAdd\n",
      "41 MPSUnsqueeze\n",
      "42 MPSUnsqueeze\n",
      "43 MPSCat\n",
      "44 MPSView\n",
      "45 MPSPermute\n",
      "46 MPSExpand\n",
      "47 MPSView\n",
      "48 MPSMatMul\n",
      "49 MPSView\n",
      "50 MPSMul\n",
      "51 MPSAdd\n",
      "52 MPSSoftmax\n",
      "53 MPSExpand\n",
      "54 MPSView\n",
      "55 MPSMatMul\n",
      "56 MPSView\n",
      "57 MPSPermute\n",
      "58 MPSView\n",
      "59 MPSSqueeze\n",
      "60 MPSMatMul\n",
      "61 MPSMul\n",
      "62 MPSAdd\n",
      "63 MPSMul\n",
      "64 MPSMean\n",
      "65 MPSAdd\n",
      "66 MPSRsqrt\n",
      "67 MPSMul\n",
      "68 MPSMul\n",
      "69 MPSSqueeze\n",
      "70 MPSSqueeze\n",
      "71 MPSMatMul\n",
      "72 MPSMatMul\n",
      "73 MPSMul\n",
      "74 MPSMul\n",
      "75 MPSSigmoid\n",
      "76 MPSMul\n",
      "77 MPSMul\n",
      "78 MPSMatMul\n",
      "79 MPSMul\n",
      "80 MPSAdd\n",
      "81 MPSMul\n",
      "82 MPSMean\n",
      "83 MPSAdd\n",
      "84 MPSRsqrt\n",
      "85 MPSMul\n",
      "86 MPSMul\n",
      "87 MPSSqueeze\n",
      "88 MPSMatMul\n",
      "89 MPSMul\n",
      "90 MPSCast\n"
     ]
    }
   ],
   "source": [
    "for i, node in enumerate(nodes):\n",
    "    print(i, node[\"mpsnode_union_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 75\n",
      "1 75\n",
      "2 75\n",
      "3 75\n",
      "4 75\n",
      "5 75\n",
      "6 69\n",
      "7 70\n",
      "8 70\n",
      "9 70\n",
      "10 67\n",
      "11 67\n",
      "12 65\n",
      "13 70\n",
      "14 65\n",
      "15 65\n",
      "16 65\n",
      "17 65\n",
      "18 65\n",
      "19 53\n",
      "20 62\n",
      "21 66\n",
      "22 66\n",
      "23 9\n",
      "24 65\n",
      "25 67\n",
      "26 66\n",
      "27 67\n",
      "28 66\n",
      "29 66\n",
      "30 66\n",
      "31 72\n",
      "32 72\n",
      "33 69\n",
      "34 69\n",
      "35 9\n",
      "36 9\n",
      "37 9\n",
      "38 9\n",
      "39 8\n",
      "40 7\n",
      "41 70\n",
      "42 70\n",
      "43 68\n",
      "44 66\n",
      "45 65\n",
      "46 67\n",
      "47 66\n",
      "48 53\n",
      "49 66\n",
      "50 9\n",
      "51 7\n",
      "52 5\n",
      "53 67\n",
      "54 66\n",
      "55 53\n",
      "56 66\n",
      "57 65\n",
      "58 66\n",
      "59 69\n",
      "60 53\n",
      "61 9\n",
      "62 7\n",
      "63 9\n",
      "64 64\n",
      "65 7\n",
      "66 32\n",
      "67 9\n",
      "68 9\n",
      "69 69\n",
      "70 69\n",
      "71 53\n",
      "72 53\n",
      "73 9\n",
      "74 9\n",
      "75 33\n",
      "76 9\n",
      "77 9\n",
      "78 53\n",
      "79 9\n",
      "80 7\n",
      "81 9\n",
      "82 64\n",
      "83 7\n",
      "84 32\n",
      "85 9\n",
      "86 9\n",
      "87 69\n",
      "88 53\n",
      "89 9\n",
      "90 75\n"
     ]
    }
   ],
   "source": [
    "for i in range(g.MpsNodesLength()):\n",
    "    print(i, g.MpsNodes(i).MpsnodeUnionType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -1, 3]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[20][\"mpsnode_union\"][\"indices_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_tensor = g.MpsNodes(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "print(index_tensor.MpsnodeUnionType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpsgraph.MPSIndexTensor import MPSIndexTensor\n",
    "\n",
    "t = MPSIndexTensor.GetRootAs(g._tab.Bytes, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad number -31589593 for type uint32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m t\u001b[39m.\u001b[39;49mIndicesIdAsNumpy()\n",
      "File \u001b[0;32m~/CLionProjects/executorch/mpsgraph/MPSIndexTensor.py:48\u001b[0m, in \u001b[0;36mMPSIndexTensor.IndicesIdAsNumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mIndicesIdAsNumpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 48\u001b[0m     o \u001b[39m=\u001b[39m flatbuffers\u001b[39m.\u001b[39mnumber_types\u001b[39m.\u001b[39mUOffsetTFlags\u001b[39m.\u001b[39mpy_type(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tab\u001b[39m.\u001b[39;49mOffset(\u001b[39m6\u001b[39;49m))\n\u001b[1;32m     49\u001b[0m     \u001b[39mif\u001b[39;00m o \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     50\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tab\u001b[39m.\u001b[39mGetVectorAsNumpy(flatbuffers\u001b[39m.\u001b[39mnumber_types\u001b[39m.\u001b[39mInt32Flags, o)\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/flatbuffers/table.py:38\u001b[0m, in \u001b[0;36mTable.Offset\u001b[0;34m(self, vtableOffset)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Offset provides access into the Table's vtable.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \n\u001b[1;32m     35\u001b[0m \u001b[39mDeprecated fields are ignored by checking the vtable's length.\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m vtable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mPos \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mGet(N\u001b[39m.\u001b[39mSOffsetTFlags, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mPos)\n\u001b[0;32m---> 38\u001b[0m vtableEnd \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mGet(N\u001b[39m.\u001b[39;49mVOffsetTFlags, vtable)\n\u001b[1;32m     39\u001b[0m \u001b[39mif\u001b[39;00m vtableOffset \u001b[39m<\u001b[39m vtableEnd:\n\u001b[1;32m     40\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mGet(N\u001b[39m.\u001b[39mVOffsetTFlags, vtable \u001b[39m+\u001b[39m vtableOffset)\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/flatbuffers/table.py:92\u001b[0m, in \u001b[0;36mTable.Get\u001b[0;34m(self, flags, off)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mGet\u001b[39m(\u001b[39mself\u001b[39m, flags, off):\n\u001b[1;32m     88\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[39m    Get retrieves a value of the type specified by `flags`  at the\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[39m    given offset.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     N\u001b[39m.\u001b[39;49menforce_number(off, N\u001b[39m.\u001b[39;49mUOffsetTFlags)\n\u001b[1;32m     93\u001b[0m     \u001b[39mreturn\u001b[39;00m flags\u001b[39m.\u001b[39mpy_type(encode\u001b[39m.\u001b[39mGet(flags\u001b[39m.\u001b[39mpacker_type, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mBytes, off))\n",
      "File \u001b[0;32m~/miniconda3/envs/executorch/lib/python3.11/site-packages/flatbuffers/number_types.py:150\u001b[0m, in \u001b[0;36menforce_number\u001b[0;34m(n, flags)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m flags\u001b[39m.\u001b[39mmin_val \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m n \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m flags\u001b[39m.\u001b[39mmax_val:\n\u001b[0;32m--> 150\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbad number \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mstr\u001b[39m(n), flags\u001b[39m.\u001b[39mname))\n",
      "\u001b[0;31mTypeError\u001b[0m: bad number -31589593 for type uint32"
     ]
    }
   ],
   "source": [
    "t.IndicesIdAsNumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "executorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
