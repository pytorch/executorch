# automatically generated by the FlatBuffers compiler, do not modify

# namespace: executorch_flatbuffer

from executorch.exir._serialize.generated import executorch_flatbuffer
import flatbuffers
from flatbuffers.compat import import_numpy
from typing import Any
from executorch.exir._serialize.generated.executorch_flatbuffer.AllocationDetails import AllocationDetails
from executorch.exir._serialize.generated.executorch_flatbuffer.ExtraTensorInfo import ExtraTensorInfo
from typing import Optional
np = import_numpy()

class Tensor(object):
    __slots__ = ['_tab']

    @classmethod
    def GetRootAs(cls, buf, offset: int = 0):
        n = flatbuffers.encode.Get(flatbuffers.packer.uoffset, buf, offset)
        x = Tensor()
        x.Init(buf, n + offset)
        return x

    @classmethod
    def GetRootAsTensor(cls, buf, offset=0):
        """This method is deprecated. Please switch to GetRootAs."""
        return cls.GetRootAs(buf, offset)
    @classmethod
    def TensorBufferHasIdentifier(cls, buf, offset, size_prefixed=False):
        return flatbuffers.util.BufferHasIdentifier(buf, offset, b"\x45\x54\x31\x32", size_prefixed=size_prefixed)

    # Tensor
    def Init(self, buf: bytes, pos: int):
        self._tab = flatbuffers.table.Table(buf, pos)

    # Tensor
    def ScalarType(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))
        if o != 0:
            return self._tab.Get(flatbuffers.number_types.Int8Flags, o + self._tab.Pos)
        return 0

    # Tensor
    def StorageOffset(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))
        if o != 0:
            return self._tab.Get(flatbuffers.number_types.Int32Flags, o + self._tab.Pos)
        return 0

    # Tensor
    def Sizes(self, j: int):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(8))
        if o != 0:
            a = self._tab.Vector(o)
            return self._tab.Get(flatbuffers.number_types.Int32Flags, a + flatbuffers.number_types.UOffsetTFlags.py_type(j * 4))
        return 0

    # Tensor
    def SizesAsNumpy(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(8))
        if o != 0:
            return self._tab.GetVectorAsNumpy(flatbuffers.number_types.Int32Flags, o)
        return 0

    # Tensor
    def SizesLength(self) -> int:
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(8))
        if o != 0:
            return self._tab.VectorLen(o)
        return 0

    # Tensor
    def SizesIsNone(self) -> bool:
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(8))
        return o == 0

    # Tensor
    def DimOrder(self, j: int):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(10))
        if o != 0:
            a = self._tab.Vector(o)
            return self._tab.Get(flatbuffers.number_types.Uint8Flags, a + flatbuffers.number_types.UOffsetTFlags.py_type(j * 1))
        return 0

    # Tensor
    def DimOrderAsNumpy(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(10))
        if o != 0:
            return self._tab.GetVectorAsNumpy(flatbuffers.number_types.Uint8Flags, o)
        return 0

    # Tensor
    def DimOrderLength(self) -> int:
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(10))
        if o != 0:
            return self._tab.VectorLen(o)
        return 0

    # Tensor
    def DimOrderIsNone(self) -> bool:
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(10))
        return o == 0

    # Tensor
    def RequiresGrad(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(12))
        if o != 0:
            return bool(self._tab.Get(flatbuffers.number_types.BoolFlags, o + self._tab.Pos))
        return False

    # Tensor
    def DataBufferIdx(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(14))
        if o != 0:
            return self._tab.Get(flatbuffers.number_types.Uint32Flags, o + self._tab.Pos)
        return 0

    # Tensor
    def AllocationInfo(self) -> Optional[AllocationDetails]:
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(16))
        if o != 0:
            x = self._tab.Indirect(o + self._tab.Pos)
            obj = AllocationDetails()
            obj.Init(self._tab.Bytes, x)
            return obj
        return None

    # Tensor
    def Layout(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(18))
        if o != 0:
            return self._tab.Get(flatbuffers.number_types.Int8Flags, o + self._tab.Pos)
        return 0

    # Tensor
    def ShapeDynamism(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(20))
        if o != 0:
            return self._tab.Get(flatbuffers.number_types.Int8Flags, o + self._tab.Pos)
        return 0

    # Tensor
    def ExtraTensorInfo(self) -> Optional[ExtraTensorInfo]:
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(22))
        if o != 0:
            x = self._tab.Indirect(o + self._tab.Pos)
            obj = ExtraTensorInfo()
            obj.Init(self._tab.Bytes, x)
            return obj
        return None

def TensorStart(builder: flatbuffers.Builder):
    builder.StartObject(10)

def Start(builder: flatbuffers.Builder):
    TensorStart(builder)

def TensorAddScalarType(builder: flatbuffers.Builder, scalarType: int):
    builder.PrependInt8Slot(0, scalarType, 0)

def AddScalarType(builder: flatbuffers.Builder, scalarType: int):
    TensorAddScalarType(builder, scalarType)

def TensorAddStorageOffset(builder: flatbuffers.Builder, storageOffset: int):
    builder.PrependInt32Slot(1, storageOffset, 0)

def AddStorageOffset(builder: flatbuffers.Builder, storageOffset: int):
    TensorAddStorageOffset(builder, storageOffset)

def TensorAddSizes(builder: flatbuffers.Builder, sizes: int):
    builder.PrependUOffsetTRelativeSlot(2, flatbuffers.number_types.UOffsetTFlags.py_type(sizes), 0)

def AddSizes(builder: flatbuffers.Builder, sizes: int):
    TensorAddSizes(builder, sizes)

def TensorStartSizesVector(builder, numElems: int) -> int:
    return builder.StartVector(4, numElems, 4)

def StartSizesVector(builder, numElems: int) -> int:
    return TensorStartSizesVector(builder, numElems)

def TensorAddDimOrder(builder: flatbuffers.Builder, dimOrder: int):
    builder.PrependUOffsetTRelativeSlot(3, flatbuffers.number_types.UOffsetTFlags.py_type(dimOrder), 0)

def AddDimOrder(builder: flatbuffers.Builder, dimOrder: int):
    TensorAddDimOrder(builder, dimOrder)

def TensorStartDimOrderVector(builder, numElems: int) -> int:
    return builder.StartVector(1, numElems, 1)

def StartDimOrderVector(builder, numElems: int) -> int:
    return TensorStartDimOrderVector(builder, numElems)

def TensorAddRequiresGrad(builder: flatbuffers.Builder, requiresGrad: bool):
    builder.PrependBoolSlot(4, requiresGrad, 0)

def AddRequiresGrad(builder: flatbuffers.Builder, requiresGrad: bool):
    TensorAddRequiresGrad(builder, requiresGrad)

def TensorAddDataBufferIdx(builder: flatbuffers.Builder, dataBufferIdx: int):
    builder.PrependUint32Slot(5, dataBufferIdx, 0)

def AddDataBufferIdx(builder: flatbuffers.Builder, dataBufferIdx: int):
    TensorAddDataBufferIdx(builder, dataBufferIdx)

def TensorAddAllocationInfo(builder: flatbuffers.Builder, allocationInfo: int):
    builder.PrependUOffsetTRelativeSlot(6, flatbuffers.number_types.UOffsetTFlags.py_type(allocationInfo), 0)

def AddAllocationInfo(builder: flatbuffers.Builder, allocationInfo: int):
    TensorAddAllocationInfo(builder, allocationInfo)

def TensorAddLayout(builder: flatbuffers.Builder, layout: int):
    builder.PrependInt8Slot(7, layout, 0)

def AddLayout(builder: flatbuffers.Builder, layout: int):
    TensorAddLayout(builder, layout)

def TensorAddShapeDynamism(builder: flatbuffers.Builder, shapeDynamism: int):
    builder.PrependInt8Slot(8, shapeDynamism, 0)

def AddShapeDynamism(builder: flatbuffers.Builder, shapeDynamism: int):
    TensorAddShapeDynamism(builder, shapeDynamism)

def TensorAddExtraTensorInfo(builder: flatbuffers.Builder, extraTensorInfo: int):
    builder.PrependUOffsetTRelativeSlot(9, flatbuffers.number_types.UOffsetTFlags.py_type(extraTensorInfo), 0)

def AddExtraTensorInfo(builder: flatbuffers.Builder, extraTensorInfo: int):
    TensorAddExtraTensorInfo(builder, extraTensorInfo)

def TensorEnd(builder: flatbuffers.Builder) -> int:
    return builder.EndObject()

def End(builder: flatbuffers.Builder) -> int:
    return TensorEnd(builder)

from executorch.exir._serialize.generated.executorch_flatbuffer import AllocationDetails
from executorch.exir._serialize.generated.executorch_flatbuffer import ExtraTensorInfo
try:
    from typing import List, Optional
except:
    pass

class TensorT(object):

    # TensorT
    def __init__(self):
        self.scalarType = 0  # type: int
        self.storageOffset = 0  # type: int
        self.sizes = None  # type: List[int]
        self.dimOrder = None  # type: List[int]
        self.requiresGrad = False  # type: bool
        self.dataBufferIdx = 0  # type: int
        self.allocationInfo = None  # type: Optional[executorch_flatbuffer.AllocationDetails.AllocationDetailsT]
        self.layout = 0  # type: int
        self.shapeDynamism = 0  # type: int
        self.extraTensorInfo = None  # type: Optional[executorch_flatbuffer.ExtraTensorInfo.ExtraTensorInfoT]

    @classmethod
    def InitFromBuf(cls, buf, pos):
        tensor = Tensor()
        tensor.Init(buf, pos)
        return cls.InitFromObj(tensor)

    @classmethod
    def InitFromPackedBuf(cls, buf, pos=0):
        n = flatbuffers.encode.Get(flatbuffers.packer.uoffset, buf, pos)
        return cls.InitFromBuf(buf, pos+n)

    @classmethod
    def InitFromObj(cls, tensor):
        x = TensorT()
        x._UnPack(tensor)
        return x

    def __eq__(self, other):
        return type(self) == type(other) and \
            self.scalarType == other.scalarType and \
            self.storageOffset == other.storageOffset and \
            self.sizes == other.sizes and \
            self.dimOrder == other.dimOrder and \
            self.requiresGrad == other.requiresGrad and \
            self.dataBufferIdx == other.dataBufferIdx and \
            self.allocationInfo == other.allocationInfo and \
            self.layout == other.layout and \
            self.shapeDynamism == other.shapeDynamism and \
            self.extraTensorInfo == other.extraTensorInfo

    # TensorT
    def _UnPack(self, tensor):
        if tensor is None:
            return
        self.scalarType = tensor.ScalarType()
        self.storageOffset = tensor.StorageOffset()
        if not tensor.SizesIsNone():
            if np is None:
                self.sizes = []
                for i in range(tensor.SizesLength()):
                    self.sizes.append(tensor.Sizes(i))
            else:
                self.sizes = tensor.SizesAsNumpy()
        if not tensor.DimOrderIsNone():
            if np is None:
                self.dimOrder = []
                for i in range(tensor.DimOrderLength()):
                    self.dimOrder.append(tensor.DimOrder(i))
            else:
                self.dimOrder = tensor.DimOrderAsNumpy()
        self.requiresGrad = tensor.RequiresGrad()
        self.dataBufferIdx = tensor.DataBufferIdx()
        if tensor.AllocationInfo() is not None:
            self.allocationInfo = executorch_flatbuffer.AllocationDetails.AllocationDetailsT.InitFromObj(tensor.AllocationInfo())
        self.layout = tensor.Layout()
        self.shapeDynamism = tensor.ShapeDynamism()
        if tensor.ExtraTensorInfo() is not None:
            self.extraTensorInfo = executorch_flatbuffer.ExtraTensorInfo.ExtraTensorInfoT.InitFromObj(tensor.ExtraTensorInfo())

    # TensorT
    def Pack(self, builder):
        if self.sizes is not None:
            if np is not None and type(self.sizes) is np.ndarray:
                sizes = builder.CreateNumpyVector(self.sizes)
            else:
                TensorStartSizesVector(builder, len(self.sizes))
                for i in reversed(range(len(self.sizes))):
                    builder.PrependInt32(self.sizes[i])
                sizes = builder.EndVector()
        if self.dimOrder is not None:
            if np is not None and type(self.dimOrder) is np.ndarray:
                dimOrder = builder.CreateNumpyVector(self.dimOrder)
            else:
                TensorStartDimOrderVector(builder, len(self.dimOrder))
                for i in reversed(range(len(self.dimOrder))):
                    builder.PrependUint8(self.dimOrder[i])
                dimOrder = builder.EndVector()
        if self.allocationInfo is not None:
            allocationInfo = self.allocationInfo.Pack(builder)
        if self.extraTensorInfo is not None:
            extraTensorInfo = self.extraTensorInfo.Pack(builder)
        TensorStart(builder)
        TensorAddScalarType(builder, self.scalarType)
        TensorAddStorageOffset(builder, self.storageOffset)
        if self.sizes is not None:
            TensorAddSizes(builder, sizes)
        if self.dimOrder is not None:
            TensorAddDimOrder(builder, dimOrder)
        TensorAddRequiresGrad(builder, self.requiresGrad)
        TensorAddDataBufferIdx(builder, self.dataBufferIdx)
        if self.allocationInfo is not None:
            TensorAddAllocationInfo(builder, allocationInfo)
        TensorAddLayout(builder, self.layout)
        TensorAddShapeDynamism(builder, self.shapeDynamism)
        if self.extraTensorInfo is not None:
            TensorAddExtraTensorInfo(builder, extraTensorInfo)
        tensor = TensorEnd(builder)
        return tensor
