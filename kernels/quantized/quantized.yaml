- func: quantized_decomposed::add.out(Tensor a, float a_scale, int a_zero_point, int a_quant_min, int a_quant_max, Tensor b, float b_scale, int b_zero_point, int b_quant_min, int b_quant_max, float out_scale, int out_zero_point, int out_quant_min, int out_quant_max, *, Tensor(a!) out) -> Tensor(a!)
  variants: function
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::quantized_add_out

- func: quantized_decomposed::choose_qparams.Tensor_out(Tensor input, int quant_min, int quant_max, float eps, ScalarType dtype, *, Tensor(a!) scale_out, Tensor(b!) zero_point_out) -> (Tensor(a!), Tensor(b!))
  variants: function
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::choose_qparams_tensor_out

- func: quantized_decomposed::dequantize_per_tensor.out(Tensor input, float scale, int zero_point, int quant_min, int quant_max, ScalarType dtype, *, Tensor(a!) out) -> Tensor(a!)
  variants: function
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::dequantize_per_tensor_out

- func: quantized_decomposed::dequantize_per_tensor.Tensor_out(Tensor input, Tensor scale, Tensor zero_point, int quant_min, int quant_max, ScalarType dtype, *, Tensor(a!) out) -> Tensor(a!)
  variants: function
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::dequantize_per_tensor_tensor_args_out

- func: quantized_decomposed::quantize_per_channel.out(Tensor input, Tensor scales, Tensor zero_points, int axis, int quant_min, int quant_max, ScalarType dtype, *, Tensor(a!) out) -> Tensor(a!)
  variants: function
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::quantize_per_channel_out

- func: dequantize_per_channel.out(Tensor input, Tensor scales, Tensor zero_points, int axis, int quant_min, int quant_max, ScalarType dtype, *, Tensor(a!) out) -> Tensor(a!)
  variants: function
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::dequantize_per_channel_out

- func: quantized_decomposed::embedding_byte.out(Tensor weight, Tensor weight_scales, Tensor weight_zero_points, int weight_quant_min, int weight_quant_max, Tensor indices, *, Tensor(a!) out) -> Tensor(a!)
  variants: function
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::quantized_embedding_byte_out

- func: quantized_decomposed::quantize_per_tensor.out(Tensor input, float scale, int zero_point, int quant_min, int quant_max, ScalarType dtype, *, Tensor(a!) out) -> Tensor(a!)
  variants: function
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::quantize_per_tensor_out

- func: quantized_decomposed::quantize_per_tensor.Tensor_out(Tensor input, Tensor scale, Tensor zero_point, int quant_min, int quant_max, ScalarType dtype, *, Tensor(a!) out) -> Tensor(a!)
  variants: function
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::quantize_per_tensor_tensor_args_out
