# Copyright (c) Meta Platforms, Inc. and affiliates.
#
# This yaml file contains operators that have optimized kernels available.
# Note that this is a copy of optimized.yaml that does not include gelu and
# log_softmax, due to the OSS build not currently including sleef.
# TODO (T183193812)

- op: add.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::opt_add_out

- op: add.Scalar_out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::opt_add_scalar_out

- op: bmm.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::opt_bmm_out

- op: div.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::opt_div_out

- op: div.Scalar_out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::opt_div_scalar_out

- op: exp.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::opt_exp_out

- op: sigmoid.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::opt_sigmoid_out

- op: gelu.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::opt_gelu_out

- op: le.Scalar_out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::opt_le_scalar_out

- op: le.Tensor_out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::opt_le_tensor_out

- op: linear.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::opt_linear_out

- op: mul.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::opt_mul_out

- op: mul.Scalar_out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::opt_mul_scalar_out

- op: native_layer_norm.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::opt_native_layer_norm_out

- op: neg.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::opt_neg_out

- op: sub.out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::opt_sub_out

- op: sub.Scalar_out
  kernels:
    - arg_meta: null
      kernel_name: torch::executor::opt_sub_scalar_out
