[INFO 2025-11-13 23:19:32,847 utils.py:246] 
+-------------------------------------------------------+---------------+-----------------+
| Final Operators                                       |   Final Graph |   To_edge Graph |
+=======================================================+===============+=================+
| cadence::quantized_conv2d_nchw.per_tensor             |            20 |              20 |
| cadence::dequantize_per_tensor                        |            18 |               0 |
| cadence::quantized_relu.per_tensor                    |            17 |              17 |
| cadence::quantize_per_tensor                          |            11 |               0 |
| aten::add.Tensor                                      |             8 |               8 |
| aten::max_pool2d_with_indices                         |             1 |               1 |
| aten::mean.dim                                        |             1 |               1 |
| aten::view_copy                                       |             1 |               1 |
| cadence::quantized_linear.per_tensor                  |             1 |               1 |
+-------------------------------------------------------+---------------+-----------------+
[INFO 2025-11-13 23:19:32,847 utils.py:262] +-------------------------------------------------------+---------------+-----------------+
| Deleted Operators                                     |   Final Graph |   To_edge Graph |
+=======================================================+===============+=================+
| quantized_decomposed::quantize_per_tensor             |             0 |              11 |
| quantized_decomposed::dequantize_per_tensor           |             0 |              18 |
+-------------------------------------------------------+---------------+-----------------+
[INFO 2025-11-13 23:19:33,417 memory_planning.py:322] 
+----------------+----------------+-----------------------+-----------------------------+
|   Memory Space | Base Address   |   Memory Size (Bytes) |   Peak Memory Usage (Bytes) |
+================+================+=======================+=============================+
|              1 |                |           68719476736 |                      458752 |
+----------------+----------------+-----------------------+-----------------------------+
[INFO 2025-11-13 23:19:33,420 memory_planning.py:355] 
+-------------------------------------+--------------+---------+
| Peak memory usage across all spaces | 458752 bytes | Node 52 |
+-------------------------------------+--------------+---------+
[INFO 2025-11-13 23:19:33,597 compiler.py:478] Generated ETRecord at /tmp/tmpa650fq6b/etrecord.bin
[INFO 2025-11-13 23:19:33,597 export_example.py:76] Final exported graph:

opcode         name                                         target                                        args                                                                                                                                                                                kwargs
-------------  -------------------------------------------  --------------------------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  ------------------------------------
placeholder    b__frozen_param0                             b__frozen_param0                              ()                                                                                                                                                                                  {}
placeholder    b__frozen_param1                             b__frozen_param1                              ()                                                                                                                                                                                  {}
placeholder    b__frozen_param2                             b__frozen_param2                              ()                                                                                                                                                                                  {}
placeholder    b__frozen_param3                             b__frozen_param3                              ()                                                                                                                                                                                  {}
placeholder    b__frozen_param4                             b__frozen_param4                              ()                                                                                                                                                                                  {}
placeholder    b__frozen_param5                             b__frozen_param5                              ()                                                                                                                                                                                  {}
placeholder    b__frozen_param6                             b__frozen_param6                              ()                                                                                                                                                                                  {}
placeholder    b__frozen_param7                             b__frozen_param7                              ()                                                                                                                                                                                  {}
placeholder    b__frozen_param8                             b__frozen_param8                              ()                                                                                                                                                                                  {}
placeholder    b__frozen_param9                             b__frozen_param9                              ()                                                                                                                                                                                  {}
placeholder    b__frozen_param10                            b__frozen_param10                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param11                            b__frozen_param11                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param12                            b__frozen_param12                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param13                            b__frozen_param13                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param14                            b__frozen_param14                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param15                            b__frozen_param15                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param16                            b__frozen_param16                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param17                            b__frozen_param17                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param18                            b__frozen_param18                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param19                            b__frozen_param19                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param20                            b__frozen_param20                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param21                            b__frozen_param21                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param22                            b__frozen_param22                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param23                            b__frozen_param23                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param24                            b__frozen_param24                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param25                            b__frozen_param25                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param26                            b__frozen_param26                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param27                            b__frozen_param27                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param28                            b__frozen_param28                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param29                            b__frozen_param29                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param30                            b__frozen_param30                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param31                            b__frozen_param31                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param32                            b__frozen_param32                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param33                            b__frozen_param33                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param34                            b__frozen_param34                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param35                            b__frozen_param35                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param36                            b__frozen_param36                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param37                            b__frozen_param37                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param38                            b__frozen_param38                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param39                            b__frozen_param39                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param40                            b__frozen_param40                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param41                            b__frozen_param41                             ()                                                                                                                                                                                  {}
placeholder    x                                            x                                             ()                                                                                                                                                                                  {}
call_function  alloc                                        <function alloc at 0x7f43e45639c0>            (((1, 3, 64, 64), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantize_per_tensor_default          cadence.quantize_per_tensor.out               (x, 0.030682159587740898, 10, -128, 127, torch.int8)                                                                                                                                {'out': alloc}
call_function  alloc_1                                      <function alloc at 0x7f43e45639c0>            (((1, 64, 32, 32), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_conv2d_nchw_per_tensor     cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantize_per_tensor_default, b__frozen_param0, b__frozen_param22, [2, 2], [3, 3], [1, 1], 1, 10, 0, 9.47839133942749e-05, 0.027794336900115013, -8, 1874770688, -8)        {'out': alloc_1}
call_function  alloc_2                                      <function alloc at 0x7f43e45639c0>            (((1, 64, 32, 32), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_relu_per_tensor            cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor, -8, -128, 2024523776, 1)                                                                                                                 {'out': alloc_2}
call_function  alloc_3                                      <function alloc at 0x7f43e45639c0>            (((1, 64, 32, 32), torch.float32),)                                                                                                                                                 {}
call_function  cadence_dequantize_per_tensor_default        cadence.dequantize_per_tensor.out             (cadence_quantized_relu_per_tensor, 0.014741215854883194, -128, -128, 127, torch.int8)                                                                                              {'out': alloc_3}
call_function  alloc_4                                      <function alloc at 0x7f43e45639c0>            (((1, 64, 16, 16), torch.float32),)                                                                                                                                                 {}
call_function  alloc_5                                      <function alloc at 0x7f43e45639c0>            (((1, 64, 16, 16), torch.int64),)                                                                                                                                                   {}
call_function  aten_max_pool2d_with_indices_default         aten.max_pool2d_with_indices.out              (cadence_dequantize_per_tensor_default, [3, 3], [2, 2], [1, 1], [1, 1], False)                                                                                                      {'out': alloc_4, 'indices': alloc_5}
call_function  getitem                                      <built-in function getitem>                   (aten_max_pool2d_with_indices_default, 0)                                                                                                                                           {}
call_function  alloc_6                                      <function alloc at 0x7f43e45639c0>            (((1, 64, 16, 16), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantize_per_tensor_default_1        cadence.quantize_per_tensor.out               (getitem, 0.015278616920113564, -128, -128, 127, torch.int8)                                                                                                                        {'out': alloc_6}
call_function  alloc_7                                      <function alloc at 0x7f43e45639c0>            (((1, 64, 16, 16), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_1   cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantize_per_tensor_default_1, b__frozen_param1, b__frozen_param23, [1, 1], [1, 1], [1, 1], 1, -128, 0, 4.4877691380913916e-05, 0.017864873632788658, 51, 1381021312, -8)  {'out': alloc_7}
call_function  alloc_8                                      <function alloc at 0x7f43e45639c0>            (((1, 64, 16, 16), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_relu_per_tensor_1          cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_1, 51, -128, 1844780544, 2)                                                                                                               {'out': alloc_8}
call_function  alloc_9                                      <function alloc at 0x7f43e45639c0>            (((1, 64, 16, 16), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_2   cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_1, b__frozen_param2, b__frozen_param24, [1, 1], [1, 1], [1, 1], 1, -128, 0, 3.143011955552069e-05, 0.0169333815574646, -27, 2040808064, -9)      {'out': alloc_9}
call_function  alloc_10                                     <function alloc at 0x7f43e45639c0>            (((1, 64, 16, 16), torch.float32),)                                                                                                                                                 {}
call_function  cadence_dequantize_per_tensor_default_1      cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_2, 0.0169333815574646, -27, -128, 127, torch.int8)                                                                                        {'out': alloc_10}
call_function  alloc_11                                     <function alloc at 0x7f43e45639c0>            (((1, 64, 16, 16), torch.float32),)                                                                                                                                                 {}
call_function  aten_add_tensor                              aten.add.out                                  (cadence_dequantize_per_tensor_default_1, getitem)                                                                                                                                  {'alpha': 1, 'out': alloc_11}
call_function  alloc_12                                     <function alloc at 0x7f43e45639c0>            (((1, 64, 16, 16), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantize_per_tensor_default_2        cadence.quantize_per_tensor.out               (aten_add_tensor, 0.02243735082447529, -52, -128, 127, torch.int8)                                                                                                                  {'out': alloc_12}
call_function  alloc_13                                     <function alloc at 0x7f43e45639c0>            (((1, 64, 16, 16), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_relu_per_tensor_2          cadence.quantized_relu.per_tensor_out         (cadence_quantize_per_tensor_default_2, -52, -128, 1527975936, 1)                                                                                                                   {'out': alloc_13}
call_function  alloc_14                                     <function alloc at 0x7f43e45639c0>            (((1, 64, 16, 16), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_3   cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_2, b__frozen_param3, b__frozen_param25, [1, 1], [1, 1], [1, 1], 1, -128, 0, 3.462076445740533e-05, 0.017995325848460197, 7, 2115323392, -9)      {'out': alloc_14}
call_function  alloc_15                                     <function alloc at 0x7f43e45639c0>            (((1, 64, 16, 16), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_relu_per_tensor_3          cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_3, 7, -128, 1141007488, 2)                                                                                                                {'out': alloc_15}
call_function  alloc_16                                     <function alloc at 0x7f43e45639c0>            (((1, 64, 16, 16), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_4   cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_3, b__frozen_param4, b__frozen_param26, [1, 1], [1, 1], [1, 1], 1, -128, 0, 6.955681256498938e-05, 0.025420034304261208, 39, 1504296192, -8)     {'out': alloc_16}
call_function  alloc_17                                     <function alloc at 0x7f43e45639c0>            (((1, 64, 16, 16), torch.float32),)                                                                                                                                                 {}
call_function  cadence_dequantize_per_tensor_default_2      cadence.dequantize_per_tensor.out             (cadence_quantized_relu_per_tensor_2, 0.015767212957143784, -128, -128, 127, torch.int8)                                                                                            {'out': alloc_17}
call_function  alloc_18                                     <function alloc at 0x7f43e45639c0>            (((1, 64, 16, 16), torch.float32),)                                                                                                                                                 {}
call_function  cadence_dequantize_per_tensor_default_3      cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_4, 0.025420034304261208, 39, -128, 127, torch.int8)                                                                                       {'out': alloc_18}
call_function  alloc_19                                     <function alloc at 0x7f43e45639c0>            (((1, 64, 16, 16), torch.float32),)                                                                                                                                                 {}
call_function  aten_add_tensor_1                            aten.add.out                                  (cadence_dequantize_per_tensor_default_3, cadence_dequantize_per_tensor_default_2)                                                                                                  {'alpha': 1, 'out': alloc_19}
call_function  alloc_20                                     <function alloc at 0x7f43e45639c0>            (((1, 64, 16, 16), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantize_per_tensor_default_3        cadence.quantize_per_tensor.out               (aten_add_tensor_1, 0.034086115658283234, -11, -128, 127, torch.int8)                                                                                                               {'out': alloc_20}
call_function  alloc_21                                     <function alloc at 0x7f43e45639c0>            (((1, 64, 16, 16), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_relu_per_tensor_4          cadence.quantized_relu.per_tensor_out         (cadence_quantize_per_tensor_default_3, -11, -128, 1873321472, 1)                                                                                                                   {'out': alloc_21}
call_function  alloc_22                                     <function alloc at 0x7f43e45639c0>            (((1, 128, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_5   cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_4, b__frozen_param7, b__frozen_param29, [2, 2], [0, 0], [1, 1], 1, -128, 0, 0.00010607630476632598, 0.019417885690927505, 7, 1501607040, -7)     {'out': alloc_22}
call_function  alloc_23                                     <function alloc at 0x7f43e45639c0>            (((1, 128, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_6   cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_4, b__frozen_param5, b__frozen_param27, [2, 2], [1, 1], [1, 1], 1, -128, 0, 3.2592207512852946e-05, 0.016330568119883537, 9, 1097191168, -8)     {'out': alloc_23}
call_function  alloc_24                                     <function alloc at 0x7f43e45639c0>            (((1, 128, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_5          cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_6, 9, -128, 1157860608, 2)                                                                                                                {'out': alloc_24}
call_function  alloc_25                                     <function alloc at 0x7f43e45639c0>            (((1, 128, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_7   cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_5, b__frozen_param6, b__frozen_param28, [1, 1], [1, 1], [1, 1], 1, -128, 0, 4.3006430122884956e-05, 0.01731596514582634, -16, 1365389440, -8)    {'out': alloc_25}
call_function  alloc_26                                     <function alloc at 0x7f43e45639c0>            (((1, 128, 8, 8), torch.float32),)                                                                                                                                                  {}
call_function  cadence_dequantize_per_tensor_default_4      cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_5, 0.019417885690927505, 7, -128, 127, torch.int8)                                                                                        {'out': alloc_26}
call_function  alloc_27                                     <function alloc at 0x7f43e45639c0>            (((1, 128, 8, 8), torch.float32),)                                                                                                                                                  {}
call_function  cadence_dequantize_per_tensor_default_5      cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_7, 0.01731596514582634, -16, -128, 127, torch.int8)                                                                                       {'out': alloc_27}
call_function  alloc_28                                     <function alloc at 0x7f43e45639c0>            (((1, 128, 8, 8), torch.float32),)                                                                                                                                                  {}
call_function  aten_add_tensor_2                            aten.add.out                                  (cadence_dequantize_per_tensor_default_5, cadence_dequantize_per_tensor_default_4)                                                                                                  {'alpha': 1, 'out': alloc_28}
call_function  alloc_29                                     <function alloc at 0x7f43e45639c0>            (((1, 128, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantize_per_tensor_default_4        cadence.quantize_per_tensor.out               (aten_add_tensor_2, 0.023569190874695778, 11, -128, 127, torch.int8)                                                                                                                {'out': alloc_29}
call_function  alloc_30                                     <function alloc at 0x7f43e45639c0>            (((1, 128, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_6          cadence.quantized_relu.per_tensor_out         (cadence_quantize_per_tensor_default_4, 11, -128, 1180013568, 2)                                                                                                                    {'out': alloc_30}
call_function  alloc_31                                     <function alloc at 0x7f43e45639c0>            (((1, 128, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_8   cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_6, b__frozen_param8, b__frozen_param30, [1, 1], [1, 1], [1, 1], 1, -128, 0, 2.6160643338617303e-05, 0.014842085540294647, 17, 1937997952, -9)    {'out': alloc_31}
call_function  alloc_32                                     <function alloc at 0x7f43e45639c0>            (((1, 128, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_7          cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_8, 17, -128, 1245177088, 2)                                                                                                               {'out': alloc_32}
call_function  alloc_33                                     <function alloc at 0x7f43e45639c0>            (((1, 128, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_9   cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_7, b__frozen_param9, b__frozen_param31, [1, 1], [1, 1], [1, 1], 1, -128, 0, 4.402120402473286e-05, 0.013536881655454636, 18, 1787776000, -8)     {'out': alloc_33}
call_function  alloc_34                                     <function alloc at 0x7f43e45639c0>            (((1, 128, 8, 8), torch.float32),)                                                                                                                                                  {}
call_function  cadence_dequantize_per_tensor_default_6      cadence.dequantize_per_tensor.out             (cadence_quantized_relu_per_tensor_6, 0.010723276995122433, -128, -128, 127, torch.int8)                                                                                            {'out': alloc_34}
call_function  alloc_35                                     <function alloc at 0x7f43e45639c0>            (((1, 128, 8, 8), torch.float32),)                                                                                                                                                  {}
call_function  cadence_dequantize_per_tensor_default_7      cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_9, 0.013536881655454636, 18, -128, 127, torch.int8)                                                                                       {'out': alloc_35}
call_function  alloc_36                                     <function alloc at 0x7f43e45639c0>            (((1, 128, 8, 8), torch.float32),)                                                                                                                                                  {}
call_function  aten_add_tensor_3                            aten.add.out                                  (cadence_dequantize_per_tensor_default_7, cadence_dequantize_per_tensor_default_6)                                                                                                  {'alpha': 1, 'out': alloc_36}
call_function  alloc_37                                     <function alloc at 0x7f43e45639c0>            (((1, 128, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantize_per_tensor_default_5        cadence.quantize_per_tensor.out               (aten_add_tensor_3, 0.021968744695186615, -41, -128, 127, torch.int8)                                                                                                               {'out': alloc_37}
call_function  alloc_38                                     <function alloc at 0x7f43e45639c0>            (((1, 128, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_8          cadence.quantized_relu.per_tensor_out         (cadence_quantize_per_tensor_default_5, -41, -128, 1625394048, 1)                                                                                                                   {'out': alloc_38}
call_function  alloc_39                                     <function alloc at 0x7f43e45639c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_10  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_8, b__frozen_param12, b__frozen_param34, [2, 2], [0, 0], [1, 1], 1, -128, 0, 4.645879946447778e-05, 0.0054017617367208, 30, 1182067840, -6)      {'out': alloc_39}
call_function  alloc_40                                     <function alloc at 0x7f43e45639c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_11  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_8, b__frozen_param10, b__frozen_param32, [2, 2], [1, 1], [1, 1], 1, -128, 0, 2.6830442369491446e-05, 0.011026516556739807, 22, 1337701888, -8)   {'out': alloc_40}
call_function  alloc_41                                     <function alloc at 0x7f43e45639c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_9          cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_11, 22, -128, 1307655552, 2)                                                                                                              {'out': alloc_41}
call_function  alloc_42                                     <function alloc at 0x7f43e45639c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_12  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_9, b__frozen_param11, b__frozen_param33, [1, 1], [1, 1], [1, 1], 1, -128, 0, 2.0022649288700678e-05, 0.014650599099695683, -9, 1502678144, -9)   {'out': alloc_42}
call_function  alloc_43                                     <function alloc at 0x7f43e45639c0>            (((1, 256, 4, 4), torch.float32),)                                                                                                                                                  {}
call_function  cadence_dequantize_per_tensor_default_8      cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_10, 0.0054017617367208, 30, -128, 127, torch.int8)                                                                                        {'out': alloc_43}
call_function  alloc_44                                     <function alloc at 0x7f43e45639c0>            (((1, 256, 4, 4), torch.float32),)                                                                                                                                                  {}
call_function  cadence_dequantize_per_tensor_default_9      cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_12, 0.014650599099695683, -9, -128, 127, torch.int8)                                                                                      {'out': alloc_44}
call_function  alloc_45                                     <function alloc at 0x7f43e45639c0>            (((1, 256, 4, 4), torch.float32),)                                                                                                                                                  {}
call_function  aten_add_tensor_4                            aten.add.out                                  (cadence_dequantize_per_tensor_default_9, cadence_dequantize_per_tensor_default_8)                                                                                                  {'alpha': 1, 'out': alloc_45}
call_function  alloc_46                                     <function alloc at 0x7f43e45639c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantize_per_tensor_default_6        cadence.quantize_per_tensor.out               (aten_add_tensor_4, 0.016459360718727112, 29, -128, 127, torch.int8)                                                                                                                {'out': alloc_46}
call_function  alloc_47                                     <function alloc at 0x7f43e45639c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_10         cadence.quantized_relu.per_tensor_out         (cadence_quantize_per_tensor_default_6, 29, -128, 1393055360, 2)                                                                                                                    {'out': alloc_47}
call_function  alloc_48                                     <function alloc at 0x7f43e45639c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_13  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_10, b__frozen_param13, b__frozen_param35, [1, 1], [1, 1], [1, 1], 1, -128, 0, 1.3551405218673387e-05, 0.009140515699982643, 34, 1630097024, -9)  {'out': alloc_48}
call_function  alloc_49                                     <function alloc at 0x7f43e45639c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_11         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_13, 34, -128, 1463404032, 2)                                                                                                              {'out': alloc_49}
call_function  alloc_50                                     <function alloc at 0x7f43e45639c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_14  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_11, b__frozen_param14, b__frozen_param36, [1, 1], [1, 1], [1, 1], 1, -128, 0, 2.5514792184823734e-05, 0.012442205101251602, 48, 1127364864, -8)  {'out': alloc_50}
call_function  alloc_51                                     <function alloc at 0x7f43e45639c0>            (((1, 256, 4, 4), torch.float32),)                                                                                                                                                  {}
call_function  cadence_dequantize_per_tensor_default_10     cadence.dequantize_per_tensor.out             (cadence_quantized_relu_per_tensor_10, 0.006343288347125053, -128, -128, 127, torch.int8)                                                                                           {'out': alloc_51}
call_function  alloc_52                                     <function alloc at 0x7f43e45639c0>            (((1, 256, 4, 4), torch.float32),)                                                                                                                                                  {}
call_function  cadence_dequantize_per_tensor_default_11     cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_14, 0.012442205101251602, 48, -128, 127, torch.int8)                                                                                      {'out': alloc_52}
call_function  alloc_53                                     <function alloc at 0x7f43e45639c0>            (((1, 256, 4, 4), torch.float32),)                                                                                                                                                  {}
call_function  aten_add_tensor_5                            aten.add.out                                  (cadence_dequantize_per_tensor_default_11, cadence_dequantize_per_tensor_default_10)                                                                                                {'alpha': 1, 'out': alloc_53}
call_function  alloc_54                                     <function alloc at 0x7f43e45639c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantize_per_tensor_default_7        cadence.quantize_per_tensor.out               (aten_add_tensor_5, 0.013750055804848671, 31, -128, 127, torch.int8)                                                                                                                {'out': alloc_54}
call_function  alloc_55                                     <function alloc at 0x7f43e45639c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_12         cadence.quantized_relu.per_tensor_out         (cadence_quantize_per_tensor_default_7, 31, -128, 1422485760, 2)                                                                                                                    {'out': alloc_55}
call_function  alloc_56                                     <function alloc at 0x7f43e45639c0>            (((1, 512, 2, 2), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_15  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_12, b__frozen_param17, b__frozen_param39, [2, 2], [0, 0], [1, 1], 1, -128, 0, 4.062910932648139e-05, 0.010303915478289127, 8, 1083864192, -7)    {'out': alloc_56}
call_function  alloc_57                                     <function alloc at 0x7f43e45639c0>            (((1, 512, 2, 2), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_16  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_12, b__frozen_param15, b__frozen_param37, [2, 2], [1, 1], [1, 1], 1, -128, 0, 1.2276665403840835e-05, 0.005493179429322481, 17, 1228645120, -8)  {'out': alloc_57}
call_function  alloc_58                                     <function alloc at 0x7f43e45639c0>            (((1, 512, 2, 2), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_13         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_16, 17, -128, 1226715520, 2)                                                                                                              {'out': alloc_58}
call_function  alloc_59                                     <function alloc at 0x7f43e45639c0>            (((1, 512, 2, 2), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_17  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_13, b__frozen_param16, b__frozen_param38, [1, 1], [1, 1], [1, 1], 1, -128, 0, 2.156652188727709e-05, 0.012095586396753788, -28, 1960437504, -9)  {'out': alloc_59}
call_function  alloc_60                                     <function alloc at 0x7f43e45639c0>            (((1, 512, 2, 2), torch.float32),)                                                                                                                                                  {}
call_function  cadence_dequantize_per_tensor_default_12     cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_15, 0.010303915478289127, 8, -128, 127, torch.int8)                                                                                       {'out': alloc_60}
call_function  alloc_61                                     <function alloc at 0x7f43e45639c0>            (((1, 512, 2, 2), torch.float32),)                                                                                                                                                  {}
call_function  cadence_dequantize_per_tensor_default_13     cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_17, 0.012095586396753788, -28, -128, 127, torch.int8)                                                                                     {'out': alloc_61}
call_function  alloc_62                                     <function alloc at 0x7f43e45639c0>            (((1, 512, 2, 2), torch.float32),)                                                                                                                                                  {}
call_function  aten_add_tensor_6                            aten.add.out                                  (cadence_dequantize_per_tensor_default_13, cadence_dequantize_per_tensor_default_12)                                                                                                {'alpha': 1, 'out': alloc_62}
call_function  alloc_63                                     <function alloc at 0x7f43e45639c0>            (((1, 512, 2, 2), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantize_per_tensor_default_8        cadence.quantize_per_tensor.out               (aten_add_tensor_6, 0.01564018428325653, -8, -128, 127, torch.int8)                                                                                                                 {'out': alloc_63}
call_function  alloc_64                                     <function alloc at 0x7f43e45639c0>            (((1, 512, 2, 2), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_14         cadence.quantized_relu.per_tensor_out         (cadence_quantize_per_tensor_default_8, -8, -128, 2023225088, 1)                                                                                                                    {'out': alloc_64}
call_function  alloc_65                                     <function alloc at 0x7f43e45639c0>            (((1, 512, 2, 2), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_18  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_14, b__frozen_param18, b__frozen_param40, [1, 1], [1, 1], [1, 1], 1, -128, 0, 1.909168194477208e-05, 0.0077148196287453175, 19, 1360467712, -8)  {'out': alloc_65}
call_function  alloc_66                                     <function alloc at 0x7f43e45639c0>            (((1, 512, 2, 2), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_15         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_18, 19, -128, 1271572608, 2)                                                                                                              {'out': alloc_66}
call_function  alloc_67                                     <function alloc at 0x7f43e45639c0>            (((1, 512, 2, 2), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_19  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_15, b__frozen_param19, b__frozen_param41, [1, 1], [1, 1], [1, 1], 1, -128, 0, 9.320426968452596e-05, 0.04142403230071068, -40, 1236953216, -8)   {'out': alloc_67}
call_function  alloc_68                                     <function alloc at 0x7f43e45639c0>            (((1, 512, 2, 2), torch.float32),)                                                                                                                                                  {}
call_function  cadence_dequantize_per_tensor_default_14     cadence.dequantize_per_tensor.out             (cadence_quantized_relu_per_tensor_14, 0.00830037146806717, -128, -128, 127, torch.int8)                                                                                            {'out': alloc_68}
call_function  alloc_69                                     <function alloc at 0x7f43e45639c0>            (((1, 512, 2, 2), torch.float32),)                                                                                                                                                  {}
call_function  cadence_dequantize_per_tensor_default_15     cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_19, 0.04142403230071068, -40, -128, 127, torch.int8)                                                                                      {'out': alloc_69}
call_function  alloc_70                                     <function alloc at 0x7f43e45639c0>            (((1, 512, 2, 2), torch.float32),)                                                                                                                                                  {}
call_function  aten_add_tensor_7                            aten.add.out                                  (cadence_dequantize_per_tensor_default_15, cadence_dequantize_per_tensor_default_14)                                                                                                {'alpha': 1, 'out': alloc_70}
call_function  alloc_71                                     <function alloc at 0x7f43e45639c0>            (((1, 512, 2, 2), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantize_per_tensor_default_9        cadence.quantize_per_tensor.out               (aten_add_tensor_7, 0.045566532760858536, -48, -128, 127, torch.int8)                                                                                                               {'out': alloc_71}
call_function  alloc_72                                     <function alloc at 0x7f43e45639c0>            (((1, 512, 2, 2), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_16         cadence.quantized_relu.per_tensor_out         (cadence_quantize_per_tensor_default_9, -48, -128, 1560259840, 1)                                                                                                                   {'out': alloc_72}
call_function  alloc_73                                     <function alloc at 0x7f43e45639c0>            (((1, 512, 2, 2), torch.float32),)                                                                                                                                                  {}
call_function  cadence_dequantize_per_tensor_default_16     cadence.dequantize_per_tensor.out             (cadence_quantized_relu_per_tensor_16, 0.03135804086923599, -128, -128, 127, torch.int8)                                                                                            {'out': alloc_73}
call_function  alloc_74                                     <function alloc at 0x7f43e45639c0>            (((1, 512, 1, 1), torch.float32),)                                                                                                                                                  {}
call_function  aten_mean_dim                                aten.mean.out                                 (cadence_dequantize_per_tensor_default_16, [-1, -2], True)                                                                                                                          {'dtype': None, 'out': alloc_74}
call_function  alloc_75                                     <function alloc at 0x7f43e45639c0>            (((1, 512, 1, 1), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantize_per_tensor_default_10       cadence.quantize_per_tensor.out               (aten_mean_dim, 0.030390599742531776, -128, -128, 127, torch.int8)                                                                                                                  {'out': alloc_75}
call_function  aten_view_copy_default                       <function view at 0x7f43e4563b00>             (cadence_quantize_per_tensor_default_10, [1, 512])                                                                                                                                  {}
call_function  alloc_76                                     <function alloc at 0x7f43e45639c0>            (((1, 1000), torch.int8),)                                                                                                                                                          {}
call_function  cadence_quantized_linear_per_tensor          cadence.quantized_linear.per_tensor_out       (aten_view_copy_default, b__frozen_param20, b__frozen_param21, -128, -57, 1796753536, -9, -38, None)                                                                                {'out': alloc_76}
call_function  alloc_77                                     <function alloc at 0x7f43e45639c0>            (((1, 1000), torch.float32),)                                                                                                                                                       {}
call_function  cadence_dequantize_per_tensor_default_17     cadence.dequantize_per_tensor.out             (cadence_quantized_linear_per_tensor, 0.07242691516876221, -38, -128, 127, torch.int8)                                                                                              {'out': alloc_77}
output         output_1                                     output                                        ((cadence_dequantize_per_tensor_default_17,),)                                                                                                                                      {}[INFO 2025-11-13 23:19:41,922 utils.py:287] Saved exported program to /tmp/tmpa650fq6b/CadenceDemoModel.pte
[INFO 2025-11-13 23:19:41,927 utils.py:304] Saved exported program to /tmp/tmpa650fq6b/CadenceDemoModel.bpte
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/kvariar/ExecuTorch/stable/executorch/examples/cadence/models/resnet18.py", line 30, in <module>
    export_and_run_model(model, example_inputs)
  File "/home/kvariar/ExecuTorch/stable/executorch/.venv/lib/python3.11/site-packages/executorch/backends/cadence/aot/export_example.py", line 110, in export_and_run_model
    runtime.run_and_compare(
  File "/home/kvariar/ExecuTorch/stable/executorch/.venv/lib/python3.11/site-packages/executorch/backends/cadence/runtime/runtime.py", line 140, in run_and_compare
    outputs = run(executorch_prog, inputs, ref_outputs, working_dir)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kvariar/ExecuTorch/stable/executorch/.venv/lib/python3.11/site-packages/executorch/backends/cadence/runtime/runtime.py", line 61, in run
    program = executorch_prog.executorch_program
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'executorch_program'

