[INFO 2025-12-08 02:01:41,484 utils.py:246] 
+-------------------------------------------------------+---------------+-----------------+
| Final Operators                                       |   Final Graph |   To_edge Graph |
+=======================================================+===============+=================+
| cadence::quantized_conv2d_nchw.per_tensor             |            53 |              53 |
| cadence::quantized_relu.per_tensor                    |            49 |              49 |
| cadence::dequantize_per_tensor                        |            35 |               0 |
| cadence::quantize_per_tensor                          |            19 |               0 |
| aten::add.Tensor                                      |            16 |              16 |
| aten::max_pool2d_with_indices                         |             1 |               1 |
| aten::mean.dim                                        |             1 |               1 |
| aten::view_copy                                       |             1 |               1 |
| cadence::quantized_linear.per_tensor                  |             1 |               1 |
+-------------------------------------------------------+---------------+-----------------+
[INFO 2025-12-08 02:01:41,485 utils.py:262] +-------------------------------------------------------+---------------+-----------------+
| Deleted Operators                                     |   Final Graph |   To_edge Graph |
+=======================================================+===============+=================+
| quantized_decomposed::quantize_per_tensor             |             0 |              19 |
| quantized_decomposed::dequantize_per_tensor           |             0 |              35 |
+-------------------------------------------------------+---------------+-----------------+
[INFO 2025-12-08 02:01:42,848 memory_planning.py:322] 
+----------------+----------------+-----------------------+-----------------------------+
|   Memory Space | Base Address   |   Memory Size (Bytes) |   Peak Memory Usage (Bytes) |
+================+================+=======================+=============================+
|              1 |                |           68719476736 |                      786432 |
+----------------+----------------+-----------------------+-----------------------------+
[INFO 2025-12-08 02:01:42,859 memory_planning.py:355] 
+-------------------------------------+--------------+----------+
| Peak memory usage across all spaces | 786432 bytes | Node 139 |
+-------------------------------------+--------------+----------+
[INFO 2025-12-08 02:01:43,254 compiler.py:478] Generated ETRecord at /tmp/tmpcait_n8z/etrecord.bin
[INFO 2025-12-08 02:01:43,254 export_example.py:76] Final exported graph:

opcode         name                                         target                                        args                                                                                                                                                                                kwargs
-------------  -------------------------------------------  --------------------------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  ------------------------------------
placeholder    b__frozen_param0                             b__frozen_param0                              ()                                                                                                                                                                                  {}
placeholder    b__frozen_param1                             b__frozen_param1                              ()                                                                                                                                                                                  {}
placeholder    b__frozen_param2                             b__frozen_param2                              ()                                                                                                                                                                                  {}
placeholder    b__frozen_param3                             b__frozen_param3                              ()                                                                                                                                                                                  {}
placeholder    b__frozen_param4                             b__frozen_param4                              ()                                                                                                                                                                                  {}
placeholder    b__frozen_param5                             b__frozen_param5                              ()                                                                                                                                                                                  {}
placeholder    b__frozen_param6                             b__frozen_param6                              ()                                                                                                                                                                                  {}
placeholder    b__frozen_param7                             b__frozen_param7                              ()                                                                                                                                                                                  {}
placeholder    b__frozen_param8                             b__frozen_param8                              ()                                                                                                                                                                                  {}
placeholder    b__frozen_param9                             b__frozen_param9                              ()                                                                                                                                                                                  {}
placeholder    b__frozen_param10                            b__frozen_param10                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param11                            b__frozen_param11                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param12                            b__frozen_param12                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param13                            b__frozen_param13                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param14                            b__frozen_param14                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param15                            b__frozen_param15                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param16                            b__frozen_param16                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param17                            b__frozen_param17                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param18                            b__frozen_param18                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param19                            b__frozen_param19                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param20                            b__frozen_param20                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param21                            b__frozen_param21                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param22                            b__frozen_param22                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param23                            b__frozen_param23                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param24                            b__frozen_param24                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param25                            b__frozen_param25                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param26                            b__frozen_param26                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param27                            b__frozen_param27                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param28                            b__frozen_param28                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param29                            b__frozen_param29                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param30                            b__frozen_param30                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param31                            b__frozen_param31                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param32                            b__frozen_param32                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param33                            b__frozen_param33                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param34                            b__frozen_param34                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param35                            b__frozen_param35                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param36                            b__frozen_param36                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param37                            b__frozen_param37                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param38                            b__frozen_param38                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param39                            b__frozen_param39                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param40                            b__frozen_param40                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param41                            b__frozen_param41                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param42                            b__frozen_param42                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param43                            b__frozen_param43                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param44                            b__frozen_param44                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param45                            b__frozen_param45                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param46                            b__frozen_param46                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param47                            b__frozen_param47                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param48                            b__frozen_param48                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param49                            b__frozen_param49                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param50                            b__frozen_param50                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param51                            b__frozen_param51                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param52                            b__frozen_param52                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param53                            b__frozen_param53                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param54                            b__frozen_param54                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param55                            b__frozen_param55                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param56                            b__frozen_param56                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param57                            b__frozen_param57                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param58                            b__frozen_param58                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param59                            b__frozen_param59                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param60                            b__frozen_param60                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param61                            b__frozen_param61                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param62                            b__frozen_param62                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param63                            b__frozen_param63                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param64                            b__frozen_param64                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param65                            b__frozen_param65                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param66                            b__frozen_param66                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param67                            b__frozen_param67                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param68                            b__frozen_param68                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param69                            b__frozen_param69                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param70                            b__frozen_param70                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param71                            b__frozen_param71                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param72                            b__frozen_param72                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param73                            b__frozen_param73                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param74                            b__frozen_param74                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param75                            b__frozen_param75                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param76                            b__frozen_param76                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param77                            b__frozen_param77                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param78                            b__frozen_param78                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param79                            b__frozen_param79                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param80                            b__frozen_param80                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param81                            b__frozen_param81                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param82                            b__frozen_param82                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param83                            b__frozen_param83                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param84                            b__frozen_param84                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param85                            b__frozen_param85                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param86                            b__frozen_param86                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param87                            b__frozen_param87                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param88                            b__frozen_param88                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param89                            b__frozen_param89                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param90                            b__frozen_param90                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param91                            b__frozen_param91                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param92                            b__frozen_param92                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param93                            b__frozen_param93                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param94                            b__frozen_param94                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param95                            b__frozen_param95                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param96                            b__frozen_param96                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param97                            b__frozen_param97                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param98                            b__frozen_param98                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param99                            b__frozen_param99                             ()                                                                                                                                                                                  {}
placeholder    b__frozen_param100                           b__frozen_param100                            ()                                                                                                                                                                                  {}
placeholder    b__frozen_param101                           b__frozen_param101                            ()                                                                                                                                                                                  {}
placeholder    b__frozen_param102                           b__frozen_param102                            ()                                                                                                                                                                                  {}
placeholder    b__frozen_param103                           b__frozen_param103                            ()                                                                                                                                                                                  {}
placeholder    b__frozen_param104                           b__frozen_param104                            ()                                                                                                                                                                                  {}
placeholder    b__frozen_param105                           b__frozen_param105                            ()                                                                                                                                                                                  {}
placeholder    b__frozen_param106                           b__frozen_param106                            ()                                                                                                                                                                                  {}
placeholder    b__frozen_param107                           b__frozen_param107                            ()                                                                                                                                                                                  {}
placeholder    x                                            x                                             ()                                                                                                                                                                                  {}
call_function  alloc                                        <function alloc at 0x7fc963e9b9c0>            (((1, 3, 64, 64), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantize_per_tensor_default          cadence.quantize_per_tensor.out               (x, 0.027526574209332466, 0, -128, 127, torch.int8)                                                                                                                                 {'out': alloc}
call_function  alloc_1                                      <function alloc at 0x7fc963e9b9c0>            (((1, 64, 32, 32), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_conv2d_nchw_per_tensor     cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantize_per_tensor_default, b__frozen_param0, b__frozen_param55, [2, 2], [3, 3], [1, 1], 1, 0, 0, 0.0009489500005174858, 0.25873926281929016, -5, 2016279936, -8)         {'out': alloc_1}
call_function  alloc_2                                      <function alloc at 0x7fc963e9b9c0>            (((1, 64, 32, 32), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_relu_per_tensor            cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor, -5, -128, 2068455168, 1)                                                                                                                 {'out': alloc_2}
call_function  alloc_3                                      <function alloc at 0x7fc963e9b9c0>            (((1, 64, 32, 32), torch.float32),)                                                                                                                                                 {}
call_function  cadence_dequantize_per_tensor_default        cadence.dequantize_per_tensor.out             (cadence_quantized_relu_per_tensor, 0.13431239128112793, -128, -128, 127, torch.int8)                                                                                               {'out': alloc_3}
call_function  alloc_4                                      <function alloc at 0x7fc963e9b9c0>            (((1, 64, 16, 16), torch.float32),)                                                                                                                                                 {}
call_function  alloc_5                                      <function alloc at 0x7fc963e9b9c0>            (((1, 64, 16, 16), torch.int64),)                                                                                                                                                   {}
call_function  aten_max_pool2d_with_indices_default         aten.max_pool2d_with_indices.out              (cadence_dequantize_per_tensor_default, [3, 3], [2, 2], [1, 1], [1, 1], False)                                                                                                      {'out': alloc_4, 'indices': alloc_5}
call_function  getitem                                      <built-in function getitem>                   (aten_max_pool2d_with_indices_default, 0)                                                                                                                                           {}
call_function  alloc_6                                      <function alloc at 0x7fc963e9b9c0>            (((1, 64, 16, 16), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantize_per_tensor_default_1        cadence.quantize_per_tensor.out               (getitem, 0.1509815901517868, -128, -128, 127, torch.int8)                                                                                                                          {'out': alloc_6}
call_function  alloc_7                                      <function alloc at 0x7fc963e9b9c0>            (((1, 256, 16, 16), torch.int8),)                                                                                                                                                   {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_1   cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantize_per_tensor_default_1, b__frozen_param4, b__frozen_param59, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.002400006726930748, 0.23186378180980682, 39, 1422621568, -6)     {'out': alloc_7}
call_function  alloc_8                                      <function alloc at 0x7fc963e9b9c0>            (((1, 64, 16, 16), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_2   cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantize_per_tensor_default_1, b__frozen_param1, b__frozen_param56, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0010892521278148826, 0.18792521953582764, 50, 1593247232, -7)    {'out': alloc_8}
call_function  alloc_9                                      <function alloc at 0x7fc963e9b9c0>            (((1, 64, 16, 16), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_relu_per_tensor_1          cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_2, 50, -128, 1783666560, 2)                                                                                                               {'out': alloc_9}
call_function  alloc_10                                     <function alloc at 0x7fc963e9b9c0>            (((1, 64, 16, 16), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_3   cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_1, b__frozen_param2, b__frozen_param57, [1, 1], [1, 1], [1, 1], 1, -128, 0, 0.0003066766800699783, 0.12756337225437164, 9, 1321674752, -8)       {'out': alloc_10}
call_function  alloc_11                                     <function alloc at 0x7fc963e9b9c0>            (((1, 64, 16, 16), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_relu_per_tensor_2          cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_3, 9, -128, 1146593280, 2)                                                                                                                {'out': alloc_11}
call_function  alloc_12                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 16, 16), torch.int8),)                                                                                                                                                   {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_4   cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_2, b__frozen_param3, b__frozen_param58, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0013468903298303955, 0.09397086501121521, -40, 1969921152, -6)     {'out': alloc_12}
call_function  alloc_13                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 16, 16), torch.float32),)                                                                                                                                                {}
call_function  cadence_dequantize_per_tensor_default_1      cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_1, 0.23186378180980682, 39, -128, 127, torch.int8)                                                                                        {'out': alloc_13}
call_function  alloc_14                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 16, 16), torch.float32),)                                                                                                                                                {}
call_function  cadence_dequantize_per_tensor_default_2      cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_4, 0.09397086501121521, -40, -128, 127, torch.int8)                                                                                       {'out': alloc_14}
call_function  alloc_15                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 16, 16), torch.float32),)                                                                                                                                                {}
call_function  aten_add_tensor                              aten.add.out                                  (cadence_dequantize_per_tensor_default_2, cadence_dequantize_per_tensor_default_1)                                                                                                  {'alpha': 1, 'out': alloc_15}
call_function  alloc_16                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 16, 16), torch.int8),)                                                                                                                                                   {}
call_function  cadence_quantize_per_tensor_default_2        cadence.quantize_per_tensor.out               (aten_add_tensor, 0.22009551525115967, 36, -128, 127, torch.int8)                                                                                                                   {'out': alloc_16}
call_function  alloc_17                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 16, 16), torch.int8),)                                                                                                                                                   {}
call_function  cadence_quantized_relu_per_tensor_3          cadence.quantized_relu.per_tensor_out         (cadence_quantize_per_tensor_default_2, 36, -128, 1508807424, 2)                                                                                                                    {'out': alloc_17}
call_function  alloc_18                                     <function alloc at 0x7fc963e9b9c0>            (((1, 64, 16, 16), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_5   cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_3, b__frozen_param5, b__frozen_param60, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0032146851245308805, 0.20702983438968658, 46, 2134102912, -6)      {'out': alloc_18}
call_function  alloc_19                                     <function alloc at 0x7fc963e9b9c0>            (((1, 64, 16, 16), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_relu_per_tensor_4          cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_5, 46, -128, 1661744896, 2)                                                                                                               {'out': alloc_19}
call_function  alloc_20                                     <function alloc at 0x7fc963e9b9c0>            (((1, 64, 16, 16), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_6   cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_4, b__frozen_param6, b__frozen_param61, [1, 1], [1, 1], [1, 1], 1, -128, 0, 0.0005006674662015181, 0.15972614288330078, 32, 1723229824, -8)      {'out': alloc_20}
call_function  alloc_21                                     <function alloc at 0x7fc963e9b9c0>            (((1, 64, 16, 16), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_relu_per_tensor_5          cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_6, 32, -128, 1437998848, 2)                                                                                                               {'out': alloc_21}
call_function  alloc_22                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 16, 16), torch.int8),)                                                                                                                                                   {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_7   cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_5, b__frozen_param7, b__frozen_param62, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0013307422344569914, 0.1512899547815323, 57, 1208909184, -6)       {'out': alloc_22}
call_function  alloc_23                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 16, 16), torch.float32),)                                                                                                                                                {}
call_function  cadence_dequantize_per_tensor_default_3      cadence.dequantize_per_tensor.out             (cadence_quantized_relu_per_tensor_3, 0.07831541448831558, -128, -128, 127, torch.int8)                                                                                             {'out': alloc_23}
call_function  alloc_24                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 16, 16), torch.float32),)                                                                                                                                                {}
call_function  cadence_dequantize_per_tensor_default_4      cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_7, 0.1512899547815323, 57, -128, 127, torch.int8)                                                                                         {'out': alloc_24}
call_function  alloc_25                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 16, 16), torch.float32),)                                                                                                                                                {}
call_function  aten_add_tensor_1                            aten.add.out                                  (cadence_dequantize_per_tensor_default_4, cadence_dequantize_per_tensor_default_3)                                                                                                  {'alpha': 1, 'out': alloc_25}
call_function  alloc_26                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 16, 16), torch.int8),)                                                                                                                                                   {}
call_function  cadence_quantize_per_tensor_default_3        cadence.quantize_per_tensor.out               (aten_add_tensor_1, 0.19764165580272675, 12, -128, 127, torch.int8)                                                                                                                 {'out': alloc_26}
call_function  alloc_27                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 16, 16), torch.int8),)                                                                                                                                                   {}
call_function  cadence_quantized_relu_per_tensor_6          cadence.quantized_relu.per_tensor_out         (cadence_quantize_per_tensor_default_3, 12, -128, 1185771776, 2)                                                                                                                    {'out': alloc_27}
call_function  alloc_28                                     <function alloc at 0x7fc963e9b9c0>            (((1, 64, 16, 16), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_8   cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_6, b__frozen_param8, b__frozen_param63, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0012656971297384245, 0.1278509497642517, 65, 1360616320, -6)       {'out': alloc_28}
call_function  alloc_29                                     <function alloc at 0x7fc963e9b9c0>            (((1, 64, 16, 16), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_relu_per_tensor_7          cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_8, 65, -128, 1141318912, 3)                                                                                                               {'out': alloc_29}
call_function  alloc_30                                     <function alloc at 0x7fc963e9b9c0>            (((1, 64, 16, 16), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_9   cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_7, b__frozen_param9, b__frozen_param64, [1, 1], [1, 1], [1, 1], 1, -128, 0, 0.00027466554494935506, 0.10610199719667435, 47, 1423149312, -8)     {'out': alloc_30}
call_function  alloc_31                                     <function alloc at 0x7fc963e9b9c0>            (((1, 64, 16, 16), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_relu_per_tensor_8          cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_9, 47, -128, 1578303360, 2)                                                                                                               {'out': alloc_31}
call_function  alloc_32                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 16, 16), torch.int8),)                                                                                                                                                   {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_10  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_8, b__frozen_param10, b__frozen_param65, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.001488827597780712, 0.11697299033403397, 44, 1749317504, -6)      {'out': alloc_32}
call_function  alloc_33                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 16, 16), torch.float32),)                                                                                                                                                {}
call_function  cadence_dequantize_per_tensor_default_5      cadence.dequantize_per_tensor.out             (cadence_quantized_relu_per_tensor_6, 0.08948438614606857, -128, -128, 127, torch.int8)                                                                                             {'out': alloc_33}
call_function  alloc_34                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 16, 16), torch.float32),)                                                                                                                                                {}
call_function  cadence_dequantize_per_tensor_default_6      cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_10, 0.11697299033403397, 44, -128, 127, torch.int8)                                                                                       {'out': alloc_34}
call_function  alloc_35                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 16, 16), torch.float32),)                                                                                                                                                {}
call_function  aten_add_tensor_2                            aten.add.out                                  (cadence_dequantize_per_tensor_default_6, cadence_dequantize_per_tensor_default_5)                                                                                                  {'alpha': 1, 'out': alloc_35}
call_function  alloc_36                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 16, 16), torch.int8),)                                                                                                                                                   {}
call_function  cadence_quantize_per_tensor_default_4        cadence.quantize_per_tensor.out               (aten_add_tensor_2, 0.1647031158208847, -6, -128, 127, torch.int8)                                                                                                                  {'out': alloc_36}
call_function  alloc_37                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 16, 16), torch.int8),)                                                                                                                                                   {}
call_function  cadence_quantized_relu_per_tensor_9          cadence.quantized_relu.per_tensor_out         (cadence_quantize_per_tensor_default_4, -6, -128, 2057173248, 1)                                                                                                                    {'out': alloc_37}
call_function  alloc_38                                     <function alloc at 0x7fc963e9b9c0>            (((1, 512, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_11  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_9, b__frozen_param14, b__frozen_param69, [2, 2], [0, 0], [1, 1], 1, -128, 0, 0.0011119275737415252, 0.12166623026132584, -12, 1256077056, -6)    {'out': alloc_38}
call_function  alloc_39                                     <function alloc at 0x7fc963e9b9c0>            (((1, 128, 16, 16), torch.int8),)                                                                                                                                                   {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_12  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_9, b__frozen_param11, b__frozen_param66, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0007153706855314579, 0.15722018480300903, 37, 1250727424, -7)     {'out': alloc_39}
call_function  alloc_40                                     <function alloc at 0x7fc963e9b9c0>            (((1, 128, 16, 16), torch.int8),)                                                                                                                                                   {}
call_function  cadence_quantized_relu_per_tensor_10         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_12, 37, -128, 1455846784, 2)                                                                                                              {'out': alloc_40}
call_function  alloc_41                                     <function alloc at 0x7fc963e9b9c0>            (((1, 128, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_13  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_10, b__frozen_param12, b__frozen_param67, [2, 2], [1, 1], [1, 1], 1, -128, 0, 0.00011696219265617657, 0.09061974287033081, -45, 1419131008, -9)  {'out': alloc_41}
call_function  alloc_42                                     <function alloc at 0x7fc963e9b9c0>            (((1, 128, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_11         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_13, -45, -128, 1591124224, 1)                                                                                                             {'out': alloc_42}
call_function  alloc_43                                     <function alloc at 0x7fc963e9b9c0>            (((1, 512, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_14  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_11, b__frozen_param13, b__frozen_param68, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0007843095838061011, 0.0976618230342865, 37, 1103754624, -6)     {'out': alloc_43}
call_function  alloc_44                                     <function alloc at 0x7fc963e9b9c0>            (((1, 512, 8, 8), torch.float32),)                                                                                                                                                  {}
call_function  cadence_dequantize_per_tensor_default_7      cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_11, 0.12166623026132584, -12, -128, 127, torch.int8)                                                                                      {'out': alloc_44}
call_function  alloc_45                                     <function alloc at 0x7fc963e9b9c0>            (((1, 512, 8, 8), torch.float32),)                                                                                                                                                  {}
call_function  cadence_dequantize_per_tensor_default_8      cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_14, 0.0976618230342865, 37, -128, 127, torch.int8)                                                                                        {'out': alloc_45}
call_function  alloc_46                                     <function alloc at 0x7fc963e9b9c0>            (((1, 512, 8, 8), torch.float32),)                                                                                                                                                  {}
call_function  aten_add_tensor_3                            aten.add.out                                  (cadence_dequantize_per_tensor_default_8, cadence_dequantize_per_tensor_default_7)                                                                                                  {'alpha': 1, 'out': alloc_46}
call_function  alloc_47                                     <function alloc at 0x7fc963e9b9c0>            (((1, 512, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantize_per_tensor_default_5        cadence.quantize_per_tensor.out               (aten_add_tensor_3, 0.1640065461397171, 16, -128, 127, torch.int8)                                                                                                                  {'out': alloc_47}
call_function  alloc_48                                     <function alloc at 0x7fc963e9b9c0>            (((1, 512, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_12         cadence.quantized_relu.per_tensor_out         (cadence_quantize_per_tensor_default_5, 16, -128, 1236379008, 2)                                                                                                                    {'out': alloc_48}
call_function  alloc_49                                     <function alloc at 0x7fc963e9b9c0>            (((1, 128, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_15  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_12, b__frozen_param15, b__frozen_param70, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0003730750475941409, 0.1335737109184265, 72, 1535483136, -8)     {'out': alloc_49}
call_function  alloc_50                                     <function alloc at 0x7fc963e9b9c0>            (((1, 128, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_13         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_15, 72, -128, 1257963904, 3)                                                                                                              {'out': alloc_50}
call_function  alloc_51                                     <function alloc at 0x7fc963e9b9c0>            (((1, 128, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_16  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_13, b__frozen_param16, b__frozen_param71, [1, 1], [1, 1], [1, 1], 1, -128, 0, 0.0001422832828028367, 0.09931497275829315, 58, 1575211904, -9)    {'out': alloc_51}
call_function  alloc_52                                     <function alloc at 0x7fc963e9b9c0>            (((1, 128, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_14         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_16, 58, -128, 2018146944, 2)                                                                                                              {'out': alloc_52}
call_function  alloc_53                                     <function alloc at 0x7fc963e9b9c0>            (((1, 512, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_17  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_14, b__frozen_param17, b__frozen_param72, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0005435250986268562, 0.08495178818702698, 49, 1758680320, -7)    {'out': alloc_53}
call_function  alloc_54                                     <function alloc at 0x7fc963e9b9c0>            (((1, 512, 8, 8), torch.float32),)                                                                                                                                                  {}
call_function  cadence_dequantize_per_tensor_default_9      cadence.dequantize_per_tensor.out             (cadence_quantized_relu_per_tensor_12, 0.07121630758047104, -128, -128, 127, torch.int8)                                                                                            {'out': alloc_54}
call_function  alloc_55                                     <function alloc at 0x7fc963e9b9c0>            (((1, 512, 8, 8), torch.float32),)                                                                                                                                                  {}
call_function  cadence_dequantize_per_tensor_default_10     cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_17, 0.08495178818702698, 49, -128, 127, torch.int8)                                                                                       {'out': alloc_55}
call_function  alloc_56                                     <function alloc at 0x7fc963e9b9c0>            (((1, 512, 8, 8), torch.float32),)                                                                                                                                                  {}
call_function  aten_add_tensor_4                            aten.add.out                                  (cadence_dequantize_per_tensor_default_10, cadence_dequantize_per_tensor_default_9)                                                                                                 {'alpha': 1, 'out': alloc_56}
call_function  alloc_57                                     <function alloc at 0x7fc963e9b9c0>            (((1, 512, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantize_per_tensor_default_6        cadence.quantize_per_tensor.out               (aten_add_tensor_4, 0.11627285927534103, -9, -128, 127, torch.int8)                                                                                                                 {'out': alloc_57}
call_function  alloc_58                                     <function alloc at 0x7fc963e9b9c0>            (((1, 512, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_15         cadence.quantized_relu.per_tensor_out         (cadence_quantize_per_tensor_default_6, -9, -128, 2037361792, 1)                                                                                                                    {'out': alloc_58}
call_function  alloc_59                                     <function alloc at 0x7fc963e9b9c0>            (((1, 128, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_18  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_15, b__frozen_param18, b__frozen_param73, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.00034514808943855724, 0.07766450196504593, 49, 1221582336, -7)   {'out': alloc_59}
call_function  alloc_60                                     <function alloc at 0x7fc963e9b9c0>            (((1, 128, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_16         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_18, 49, -128, 1755115264, 2)                                                                                                              {'out': alloc_60}
call_function  alloc_61                                     <function alloc at 0x7fc963e9b9c0>            (((1, 128, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_19  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_16, b__frozen_param19, b__frozen_param74, [1, 1], [1, 1], [1, 1], 1, -128, 0, 0.0002053148613739321, 0.06131798401474953, 7, 1840781952, -8)     {'out': alloc_61}
call_function  alloc_62                                     <function alloc at 0x7fc963e9b9c0>            (((1, 128, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_17         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_19, 7, -128, 1150715648, 2)                                                                                                               {'out': alloc_62}
call_function  alloc_63                                     <function alloc at 0x7fc963e9b9c0>            (((1, 512, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_20  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_17, b__frozen_param20, b__frozen_param75, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0006961368692252855, 0.06163328140974045, 8, 1552348288, -6)     {'out': alloc_63}
call_function  alloc_64                                     <function alloc at 0x7fc963e9b9c0>            (((1, 512, 8, 8), torch.float32),)                                                                                                                                                  {}
call_function  cadence_dequantize_per_tensor_default_11     cadence.dequantize_per_tensor.out             (cadence_quantized_relu_per_tensor_15, 0.061278775334358215, -128, -128, 127, torch.int8)                                                                                           {'out': alloc_64}
call_function  alloc_65                                     <function alloc at 0x7fc963e9b9c0>            (((1, 512, 8, 8), torch.float32),)                                                                                                                                                  {}
call_function  cadence_dequantize_per_tensor_default_12     cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_20, 0.06163328140974045, 8, -128, 127, torch.int8)                                                                                        {'out': alloc_65}
call_function  alloc_66                                     <function alloc at 0x7fc963e9b9c0>            (((1, 512, 8, 8), torch.float32),)                                                                                                                                                  {}
call_function  aten_add_tensor_5                            aten.add.out                                  (cadence_dequantize_per_tensor_default_12, cadence_dequantize_per_tensor_default_11)                                                                                                {'alpha': 1, 'out': alloc_66}
call_function  alloc_67                                     <function alloc at 0x7fc963e9b9c0>            (((1, 512, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantize_per_tensor_default_7        cadence.quantize_per_tensor.out               (aten_add_tensor_5, 0.0953293964266777, -40, -128, 127, torch.int8)                                                                                                                 {'out': alloc_67}
call_function  alloc_68                                     <function alloc at 0x7fc963e9b9c0>            (((1, 512, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_18         cadence.quantized_relu.per_tensor_out         (cadence_quantize_per_tensor_default_7, -40, -128, 1642816768, 1)                                                                                                                   {'out': alloc_68}
call_function  alloc_69                                     <function alloc at 0x7fc963e9b9c0>            (((1, 128, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_21  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_18, b__frozen_param21, b__frozen_param76, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0002135927724067066, 0.06309914588928223, 58, 1860942336, -8)    {'out': alloc_69}
call_function  alloc_70                                     <function alloc at 0x7fc963e9b9c0>            (((1, 128, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_19         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_21, 58, -128, 1898190208, 2)                                                                                                              {'out': alloc_70}
call_function  alloc_71                                     <function alloc at 0x7fc963e9b9c0>            (((1, 128, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_22  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_19, b__frozen_param22, b__frozen_param77, [1, 1], [1, 1], [1, 1], 1, -128, 0, 9.407592536365191e-05, 0.06030377745628357, 8, 1715275136, -9)     {'out': alloc_71}
call_function  alloc_72                                     <function alloc at 0x7fc963e9b9c0>            (((1, 128, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_20         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_22, 8, -128, 1159169408, 2)                                                                                                               {'out': alloc_72}
call_function  alloc_73                                     <function alloc at 0x7fc963e9b9c0>            (((1, 512, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_23  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_20, b__frozen_param23, b__frozen_param78, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.000412486582965204, 0.05269680544734001, 29, 1075809536, -6)     {'out': alloc_73}
call_function  alloc_74                                     <function alloc at 0x7fc963e9b9c0>            (((1, 512, 8, 8), torch.float32),)                                                                                                                                                  {}
call_function  cadence_dequantize_per_tensor_default_13     cadence.dequantize_per_tensor.out             (cadence_quantized_relu_per_tensor_18, 0.06230710819363594, -128, -128, 127, torch.int8)                                                                                            {'out': alloc_74}
call_function  alloc_75                                     <function alloc at 0x7fc963e9b9c0>            (((1, 512, 8, 8), torch.float32),)                                                                                                                                                  {}
call_function  cadence_dequantize_per_tensor_default_14     cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_23, 0.05269680544734001, 29, -128, 127, torch.int8)                                                                                       {'out': alloc_75}
call_function  alloc_76                                     <function alloc at 0x7fc963e9b9c0>            (((1, 512, 8, 8), torch.float32),)                                                                                                                                                  {}
call_function  aten_add_tensor_6                            aten.add.out                                  (cadence_dequantize_per_tensor_default_14, cadence_dequantize_per_tensor_default_13)                                                                                                {'alpha': 1, 'out': alloc_76}
call_function  alloc_77                                     <function alloc at 0x7fc963e9b9c0>            (((1, 512, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantize_per_tensor_default_8        cadence.quantize_per_tensor.out               (aten_add_tensor_6, 0.09178024530410767, -38, -128, 127, torch.int8)                                                                                                                {'out': alloc_77}
call_function  alloc_78                                     <function alloc at 0x7fc963e9b9c0>            (((1, 512, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_21         cadence.quantized_relu.per_tensor_out         (cadence_quantize_per_tensor_default_8, -38, -128, 1629495808, 1)                                                                                                                   {'out': alloc_78}
call_function  alloc_79                                     <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_24  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_21, b__frozen_param27, b__frozen_param82, [2, 2], [0, 0], [1, 1], 1, -128, 0, 0.0005981601126077429, 0.056490492075681686, 6, 1455298048, -6)    {'out': alloc_79}
call_function  alloc_80                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_25  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_21, b__frozen_param24, b__frozen_param79, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0004484975790593551, 0.08195355534553528, 33, 1504291968, -7)    {'out': alloc_80}
call_function  alloc_81                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 8, 8), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_22         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_25, 33, -128, 1459227136, 2)                                                                                                              {'out': alloc_81}
call_function  alloc_82                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_26  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_22, b__frozen_param25, b__frozen_param80, [2, 2], [1, 1], [1, 1], 1, -128, 0, 0.000107272752543415, 0.03986844792962074, -32, 1479210368, -8)    {'out': alloc_82}
call_function  alloc_83                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_23         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_26, -32, -128, 1716654592, 1)                                                                                                             {'out': alloc_83}
call_function  alloc_84                                     <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_27  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_23, b__frozen_param26, b__frozen_param81, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0002915891987818886, 0.07138154655694962, 13, 1122859264, -7)    {'out': alloc_84}
call_function  alloc_85                                     <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.float32),)                                                                                                                                                 {}
call_function  cadence_dequantize_per_tensor_default_15     cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_24, 0.056490492075681686, 6, -128, 127, torch.int8)                                                                                       {'out': alloc_85}
call_function  alloc_86                                     <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.float32),)                                                                                                                                                 {}
call_function  cadence_dequantize_per_tensor_default_16     cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_27, 0.07138154655694962, 13, -128, 127, torch.int8)                                                                                       {'out': alloc_86}
call_function  alloc_87                                     <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.float32),)                                                                                                                                                 {}
call_function  aten_add_tensor_7                            aten.add.out                                  (cadence_dequantize_per_tensor_default_16, cadence_dequantize_per_tensor_default_15)                                                                                                {'alpha': 1, 'out': alloc_87}
call_function  alloc_88                                     <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantize_per_tensor_default_9        cadence.quantize_per_tensor.out               (aten_add_tensor_7, 0.08320571482181549, 1, -128, 127, torch.int8)                                                                                                                  {'out': alloc_88}
call_function  alloc_89                                     <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_relu_per_tensor_24         cadence.quantized_relu.per_tensor_out         (cadence_quantize_per_tensor_default_9, 1, -128, 1084555008, 2)                                                                                                                     {'out': alloc_89}
call_function  alloc_90                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_28  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_24, b__frozen_param28, b__frozen_param83, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0002448842180352469, 0.05043509975075722, 5, 1334651136, -7)     {'out': alloc_90}
call_function  alloc_91                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_25         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_28, 5, -128, 1118181120, 2)                                                                                                               {'out': alloc_91}
call_function  alloc_92                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_29  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_25, b__frozen_param29, b__frozen_param84, [1, 1], [1, 1], [1, 1], 1, -128, 0, 0.00025775318016276784, 0.061358362436294556, 47, 1154702464, -7)  {'out': alloc_92}
call_function  alloc_93                                     <function alloc at 0x7fc963e9b9c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_26         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_29, 47, -128, 1702861440, 2)                                                                                                              {'out': alloc_93}
call_function  alloc_94                                     <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_30  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_26, b__frozen_param30, b__frozen_param85, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0003917143526523739, 0.06192275136709213, 24, 1738837760, -7)    {'out': alloc_94}
call_function  alloc_95                                     <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.float32),)                                                                                                                                                 {}
call_function  cadence_dequantize_per_tensor_default_17     cadence.dequantize_per_tensor.out             (cadence_quantized_relu_per_tensor_24, 0.0411880686879158, -128, -128, 127, torch.int8)                                                                                             {'out': alloc_95}
call_function  alloc_96                                     <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.float32),)                                                                                                                                                 {}
call_function  cadence_dequantize_per_tensor_default_18     cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_30, 0.06192275136709213, 24, -128, 127, torch.int8)                                                                                       {'out': alloc_96}
call_function  alloc_97                                     <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.float32),)                                                                                                                                                 {}
call_function  aten_add_tensor_8                            aten.add.out                                  (cadence_dequantize_per_tensor_default_18, cadence_dequantize_per_tensor_default_17)                                                                                                {'alpha': 1, 'out': alloc_97}
call_function  alloc_98                                     <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantize_per_tensor_default_10       cadence.quantize_per_tensor.out               (aten_add_tensor_8, 0.0684950053691864, -27, -128, 127, torch.int8)                                                                                                                 {'out': alloc_98}
call_function  alloc_99                                     <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_relu_per_tensor_27         cadence.quantized_relu.per_tensor_out         (cadence_quantize_per_tensor_default_10, -27, -128, 1771551104, 1)                                                                                                                  {'out': alloc_99}
call_function  alloc_100                                    <function alloc at 0x7fc963e9b9c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_31  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_27, b__frozen_param31, b__frozen_param86, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.00018478976397623935, 0.045249853283166885, 27, 1122536704, -7)  {'out': alloc_100}
call_function  alloc_101                                    <function alloc at 0x7fc963e9b9c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_28         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_31, 27, -128, 1366144640, 2)                                                                                                              {'out': alloc_101}
call_function  alloc_102                                    <function alloc at 0x7fc963e9b9c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_32  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_28, b__frozen_param32, b__frozen_param87, [1, 1], [1, 1], [1, 1], 1, -128, 0, 0.00015758091575716025, 0.07725805789232254, 5, 1121320192, -8)    {'out': alloc_102}
call_function  alloc_103                                    <function alloc at 0x7fc963e9b9c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_29         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_32, 5, -128, 1119091072, 2)                                                                                                               {'out': alloc_103}
call_function  alloc_104                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_33  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_29, b__frozen_param33, b__frozen_param88, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0009230363453247153, 0.08244925737380981, 1, 1538657280, -6)     {'out': alloc_104}
call_function  alloc_105                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.float32),)                                                                                                                                                 {}
call_function  cadence_dequantize_per_tensor_default_19     cadence.dequantize_per_tensor.out             (cadence_quantized_relu_per_tensor_27, 0.04151500388979912, -128, -128, 127, torch.int8)                                                                                            {'out': alloc_105}
call_function  alloc_106                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.float32),)                                                                                                                                                 {}
call_function  cadence_dequantize_per_tensor_default_20     cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_33, 0.08244925737380981, 1, -128, 127, torch.int8)                                                                                        {'out': alloc_106}
call_function  alloc_107                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.float32),)                                                                                                                                                 {}
call_function  aten_add_tensor_9                            aten.add.out                                  (cadence_dequantize_per_tensor_default_20, cadence_dequantize_per_tensor_default_19)                                                                                                {'alpha': 1, 'out': alloc_107}
call_function  alloc_108                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantize_per_tensor_default_11       cadence.quantize_per_tensor.out               (aten_add_tensor_9, 0.10565080493688583, -31, -128, 127, torch.int8)                                                                                                                {'out': alloc_108}
call_function  alloc_109                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_relu_per_tensor_30         cadence.quantized_relu.per_tensor_out         (cadence_quantize_per_tensor_default_11, -31, -128, 1731114624, 1)                                                                                                                  {'out': alloc_109}
call_function  alloc_110                                    <function alloc at 0x7fc963e9b9c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_34  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_30, b__frozen_param34, b__frozen_param89, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0002599480320192235, 0.1301003098487854, -63, 1098444288, -8)    {'out': alloc_110}
call_function  alloc_111                                    <function alloc at 0x7fc963e9b9c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_31         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_34, -63, -128, 1444147840, 1)                                                                                                             {'out': alloc_111}
call_function  alloc_112                                    <function alloc at 0x7fc963e9b9c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_35  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_31, b__frozen_param35, b__frozen_param90, [1, 1], [1, 1], [1, 1], 1, -128, 0, 0.0008711321311019385, 0.13753221929073334, -77, 1741082752, -7)   {'out': alloc_112}
call_function  alloc_113                                    <function alloc at 0x7fc963e9b9c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_32         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_35, -77, -128, 1340947456, 1)                                                                                                             {'out': alloc_113}
call_function  alloc_114                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_36  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_32, b__frozen_param36, b__frozen_param91, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0020927174457803926, 0.32821574807167053, 1, 1752633088, -7)     {'out': alloc_114}
call_function  alloc_115                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.float32),)                                                                                                                                                 {}
call_function  cadence_dequantize_per_tensor_default_21     cadence.dequantize_per_tensor.out             (cadence_quantized_relu_per_tensor_30, 0.06553100794553757, -128, -128, 127, torch.int8)                                                                                            {'out': alloc_115}
call_function  alloc_116                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.float32),)                                                                                                                                                 {}
call_function  cadence_dequantize_per_tensor_default_22     cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_36, 0.32821574807167053, 1, -128, 127, torch.int8)                                                                                        {'out': alloc_116}
call_function  alloc_117                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.float32),)                                                                                                                                                 {}
call_function  aten_add_tensor_10                           aten.add.out                                  (cadence_dequantize_per_tensor_default_22, cadence_dequantize_per_tensor_default_21)                                                                                                {'alpha': 1, 'out': alloc_117}
call_function  alloc_118                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantize_per_tensor_default_12       cadence.quantize_per_tensor.out               (aten_add_tensor_10, 0.32821574807167053, 1, -128, 127, torch.int8)                                                                                                                 {'out': alloc_118}
call_function  alloc_119                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_relu_per_tensor_33         cadence.quantized_relu.per_tensor_out         (cadence_quantize_per_tensor_default_12, 1, -128, 1088461952, 2)                                                                                                                    {'out': alloc_119}
call_function  alloc_120                                    <function alloc at 0x7fc963e9b9c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_37  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_33, b__frozen_param37, b__frozen_param92, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0008116611186395062, 0.2033010721206665, -73, 1097425152, -7)    {'out': alloc_120}
call_function  alloc_121                                    <function alloc at 0x7fc963e9b9c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_34         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_37, -73, -128, 1366221056, 1)                                                                                                             {'out': alloc_121}
call_function  alloc_122                                    <function alloc at 0x7fc963e9b9c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_38  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_34, b__frozen_param38, b__frozen_param93, [1, 1], [1, 1], [1, 1], 1, -128, 0, 0.0008763294262362636, 0.20487716794013977, 35, 1175746432, -7)    {'out': alloc_122}
call_function  alloc_123                                    <function alloc at 0x7fc963e9b9c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_35         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_38, 35, -128, 1480005760, 2)                                                                                                              {'out': alloc_123}
call_function  alloc_124                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_39  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_35, b__frozen_param39, b__frozen_param94, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0013648221068387478, 0.22529654204845428, 27, 1665180672, -7)    {'out': alloc_124}
call_function  alloc_125                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.float32),)                                                                                                                                                 {}
call_function  cadence_dequantize_per_tensor_default_23     cadence.dequantize_per_tensor.out             (cadence_quantized_relu_per_tensor_33, 0.1618885099887848, -128, -128, 127, torch.int8)                                                                                             {'out': alloc_125}
call_function  alloc_126                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.float32),)                                                                                                                                                 {}
call_function  cadence_dequantize_per_tensor_default_24     cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_39, 0.22529654204845428, 27, -128, 127, torch.int8)                                                                                       {'out': alloc_126}
call_function  alloc_127                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.float32),)                                                                                                                                                 {}
call_function  aten_add_tensor_11                           aten.add.out                                  (cadence_dequantize_per_tensor_default_24, cadence_dequantize_per_tensor_default_23)                                                                                                {'alpha': 1, 'out': alloc_127}
call_function  alloc_128                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantize_per_tensor_default_13       cadence.quantize_per_tensor.out               (aten_add_tensor_11, 0.25621622800827026, 9, -128, 127, torch.int8)                                                                                                                 {'out': alloc_128}
call_function  alloc_129                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_relu_per_tensor_36         cadence.quantized_relu.per_tensor_out         (cadence_quantize_per_tensor_default_13, 9, -128, 1155905280, 2)                                                                                                                    {'out': alloc_129}
call_function  alloc_130                                    <function alloc at 0x7fc963e9b9c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_40  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_36, b__frozen_param40, b__frozen_param95, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0004232842196463596, 0.11695156246423721, -8, 1989737984, -8)    {'out': alloc_130}
call_function  alloc_131                                    <function alloc at 0x7fc963e9b9c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_37         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_40, -8, -128, 2021345024, 1)                                                                                                              {'out': alloc_131}
call_function  alloc_132                                    <function alloc at 0x7fc963e9b9c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_41  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_37, b__frozen_param41, b__frozen_param96, [1, 1], [1, 1], [1, 1], 1, -128, 0, 0.00030903609939696153, 0.10458056628704071, -4, 1624531200, -8)   {'out': alloc_132}
call_function  alloc_133                                    <function alloc at 0x7fc963e9b9c0>            (((1, 256, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_38         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_41, -4, -128, 2089329280, 1)                                                                                                              {'out': alloc_133}
call_function  alloc_134                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_42  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_38, b__frozen_param42, b__frozen_param97, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0006002259903122031, 0.09967485815286636, 71, 1655270656, -7)    {'out': alloc_134}
call_function  alloc_135                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.float32),)                                                                                                                                                 {}
call_function  cadence_dequantize_per_tensor_default_25     cadence.dequantize_per_tensor.out             (cadence_quantized_relu_per_tensor_36, 0.11900199949741364, -128, -128, 127, torch.int8)                                                                                            {'out': alloc_135}
call_function  alloc_136                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.float32),)                                                                                                                                                 {}
call_function  cadence_dequantize_per_tensor_default_26     cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_42, 0.09967485815286636, 71, -128, 127, torch.int8)                                                                                       {'out': alloc_136}
call_function  alloc_137                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.float32),)                                                                                                                                                 {}
call_function  aten_add_tensor_12                           aten.add.out                                  (cadence_dequantize_per_tensor_default_26, cadence_dequantize_per_tensor_default_25)                                                                                                {'alpha': 1, 'out': alloc_137}
call_function  alloc_138                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantize_per_tensor_default_14       cadence.quantize_per_tensor.out               (aten_add_tensor_12, 0.18141138553619385, -31, -128, 127, torch.int8)                                                                                                               {'out': alloc_138}
call_function  alloc_139                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1024, 4, 4), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_relu_per_tensor_39         cadence.quantized_relu.per_tensor_out         (cadence_quantize_per_tensor_default_14, -31, -128, 1732870784, 1)                                                                                                                  {'out': alloc_139}
call_function  alloc_140                                    <function alloc at 0x7fc963e9b9c0>            (((1, 2048, 2, 2), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_43  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_39, b__frozen_param46, b__frozen_param101, [2, 2], [0, 0], [1, 1], 1, -128, 0, 0.0017036434359395947, 0.3600798547267914, -41, 1300528000, -7)   {'out': alloc_140}
call_function  alloc_141                                    <function alloc at 0x7fc963e9b9c0>            (((1, 512, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_44  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_39, b__frozen_param43, b__frozen_param98, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0005951313671410316, 0.08365777879953384, 14, 1955448320, -7)    {'out': alloc_141}
call_function  alloc_142                                    <function alloc at 0x7fc963e9b9c0>            (((1, 512, 4, 4), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_40         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_44, 14, -128, 1208204288, 2)                                                                                                              {'out': alloc_142}
call_function  alloc_143                                    <function alloc at 0x7fc963e9b9c0>            (((1, 512, 2, 2), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_45  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_40, b__frozen_param44, b__frozen_param99, [2, 2], [1, 1], [1, 1], 1, -128, 0, 0.00010140423864624451, 0.06247749552130699, -39, 1784564864, -9)  {'out': alloc_143}
call_function  alloc_144                                    <function alloc at 0x7fc963e9b9c0>            (((1, 512, 2, 2), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_41         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_45, -39, -128, 1648567552, 1)                                                                                                             {'out': alloc_144}
call_function  alloc_145                                    <function alloc at 0x7fc963e9b9c0>            (((1, 2048, 2, 2), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_46  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_41, b__frozen_param45, b__frozen_param100, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0005052883621042038, 0.1352553516626358, 6, 2053783552, -8)     {'out': alloc_145}
call_function  alloc_146                                    <function alloc at 0x7fc963e9b9c0>            (((1, 2048, 2, 2), torch.float32),)                                                                                                                                                 {}
call_function  cadence_dequantize_per_tensor_default_27     cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_43, 0.3600798547267914, -41, -128, 127, torch.int8)                                                                                       {'out': alloc_146}
call_function  alloc_147                                    <function alloc at 0x7fc963e9b9c0>            (((1, 2048, 2, 2), torch.float32),)                                                                                                                                                 {}
call_function  cadence_dequantize_per_tensor_default_28     cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_46, 0.1352553516626358, 6, -128, 127, torch.int8)                                                                                         {'out': alloc_147}
call_function  alloc_148                                    <function alloc at 0x7fc963e9b9c0>            (((1, 2048, 2, 2), torch.float32),)                                                                                                                                                 {}
call_function  aten_add_tensor_13                           aten.add.out                                  (cadence_dequantize_per_tensor_default_28, cadence_dequantize_per_tensor_default_27)                                                                                                {'alpha': 1, 'out': alloc_148}
call_function  alloc_149                                    <function alloc at 0x7fc963e9b9c0>            (((1, 2048, 2, 2), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantize_per_tensor_default_15       cadence.quantize_per_tensor.out               (aten_add_tensor_13, 0.3892597556114197, -47, -128, 127, torch.int8)                                                                                                                {'out': alloc_149}
call_function  alloc_150                                    <function alloc at 0x7fc963e9b9c0>            (((1, 2048, 2, 2), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_relu_per_tensor_42         cadence.quantized_relu.per_tensor_out         (cadence_quantize_per_tensor_default_15, -47, -128, 1577705344, 1)                                                                                                                  {'out': alloc_150}
call_function  alloc_151                                    <function alloc at 0x7fc963e9b9c0>            (((1, 512, 2, 2), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_47  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_42, b__frozen_param47, b__frozen_param102, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0008708861660832595, 0.1644454002380371, 1, 1455725568, -7)     {'out': alloc_151}
call_function  alloc_152                                    <function alloc at 0x7fc963e9b9c0>            (((1, 512, 2, 2), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_43         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_47, 1, -128, 1089402240, 2)                                                                                                               {'out': alloc_152}
call_function  alloc_153                                    <function alloc at 0x7fc963e9b9c0>            (((1, 512, 2, 2), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_48  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_43, b__frozen_param48, b__frozen_param103, [1, 1], [1, 1], [1, 1], 1, -128, 0, 0.00036731751547357944, 0.1346309781074524, 41, 1499914368, -8)   {'out': alloc_153}
call_function  alloc_154                                    <function alloc at 0x7fc963e9b9c0>            (((1, 512, 2, 2), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_44         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_48, 41, -128, 1596106368, 2)                                                                                                              {'out': alloc_154}
call_function  alloc_155                                    <function alloc at 0x7fc963e9b9c0>            (((1, 2048, 2, 2), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_49  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_44, b__frozen_param49, b__frozen_param104, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0009656981009766585, 0.22836171090602875, -8, 1162406272, -7)   {'out': alloc_155}
call_function  alloc_156                                    <function alloc at 0x7fc963e9b9c0>            (((1, 2048, 2, 2), torch.float32),)                                                                                                                                                 {}
call_function  cadence_dequantize_per_tensor_default_29     cadence.dequantize_per_tensor.out             (cadence_quantized_relu_per_tensor_42, 0.2649192214012146, -128, -128, 127, torch.int8)                                                                                             {'out': alloc_156}
call_function  alloc_157                                    <function alloc at 0x7fc963e9b9c0>            (((1, 2048, 2, 2), torch.float32),)                                                                                                                                                 {}
call_function  cadence_dequantize_per_tensor_default_30     cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_49, 0.22836171090602875, -8, -128, 127, torch.int8)                                                                                       {'out': alloc_157}
call_function  alloc_158                                    <function alloc at 0x7fc963e9b9c0>            (((1, 2048, 2, 2), torch.float32),)                                                                                                                                                 {}
call_function  aten_add_tensor_14                           aten.add.out                                  (cadence_dequantize_per_tensor_default_30, cadence_dequantize_per_tensor_default_29)                                                                                                {'alpha': 1, 'out': alloc_158}
call_function  alloc_159                                    <function alloc at 0x7fc963e9b9c0>            (((1, 2048, 2, 2), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantize_per_tensor_default_16       cadence.quantize_per_tensor.out               (aten_add_tensor_14, 0.32402440905570984, -51, -128, 127, torch.int8)                                                                                                               {'out': alloc_159}
call_function  alloc_160                                    <function alloc at 0x7fc963e9b9c0>            (((1, 2048, 2, 2), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_relu_per_tensor_45         cadence.quantized_relu.per_tensor_out         (cadence_quantize_per_tensor_default_16, -51, -128, 1534751872, 1)                                                                                                                  {'out': alloc_160}
call_function  alloc_161                                    <function alloc at 0x7fc963e9b9c0>            (((1, 512, 2, 2), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_50  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_45, b__frozen_param50, b__frozen_param105, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0008967246213265334, 0.19660654664039612, 25, 1253721216, -7)   {'out': alloc_161}
call_function  alloc_162                                    <function alloc at 0x7fc963e9b9c0>            (((1, 512, 2, 2), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_46         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_50, 25, -128, 1341230848, 2)                                                                                                              {'out': alloc_162}
call_function  alloc_163                                    <function alloc at 0x7fc963e9b9c0>            (((1, 512, 2, 2), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_51  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_46, b__frozen_param51, b__frozen_param106, [1, 1], [1, 1], [1, 1], 1, -128, 0, 0.0008294675022259834, 0.14566606283187866, 56, 1565239552, -7)   {'out': alloc_163}
call_function  alloc_164                                    <function alloc at 0x7fc963e9b9c0>            (((1, 512, 2, 2), torch.int8),)                                                                                                                                                     {}
call_function  cadence_quantized_relu_per_tensor_47         cadence.quantized_relu.per_tensor_out         (cadence_quantized_conv2d_nchw_per_tensor_51, 56, -128, 1915064192, 2)                                                                                                              {'out': alloc_164}
call_function  alloc_165                                    <function alloc at 0x7fc963e9b9c0>            (((1, 2048, 2, 2), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_conv2d_nchw_per_tensor_52  cadence.quantized_conv2d_nchw.per_tensor_out  (cadence_quantized_relu_per_tensor_47, b__frozen_param52, b__frozen_param107, [1, 1], [0, 0], [1, 1], 1, -128, 0, 0.0016441260669558533, 0.2070486843585968, 74, 1091371136, -6)    {'out': alloc_165}
call_function  alloc_166                                    <function alloc at 0x7fc963e9b9c0>            (((1, 2048, 2, 2), torch.float32),)                                                                                                                                                 {}
call_function  cadence_dequantize_per_tensor_default_31     cadence.dequantize_per_tensor.out             (cadence_quantized_relu_per_tensor_45, 0.22669368982315063, -128, -128, 127, torch.int8)                                                                                            {'out': alloc_166}
call_function  alloc_167                                    <function alloc at 0x7fc963e9b9c0>            (((1, 2048, 2, 2), torch.float32),)                                                                                                                                                 {}
call_function  cadence_dequantize_per_tensor_default_32     cadence.dequantize_per_tensor.out             (cadence_quantized_conv2d_nchw_per_tensor_52, 0.2070486843585968, 74, -128, 127, torch.int8)                                                                                        {'out': alloc_167}
call_function  alloc_168                                    <function alloc at 0x7fc963e9b9c0>            (((1, 2048, 2, 2), torch.float32),)                                                                                                                                                 {}
call_function  aten_add_tensor_15                           aten.add.out                                  (cadence_dequantize_per_tensor_default_32, cadence_dequantize_per_tensor_default_31)                                                                                                {'alpha': 1, 'out': alloc_168}
call_function  alloc_169                                    <function alloc at 0x7fc963e9b9c0>            (((1, 2048, 2, 2), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantize_per_tensor_default_17       cadence.quantize_per_tensor.out               (aten_add_tensor_15, 0.2198672741651535, -16, -128, 127, torch.int8)                                                                                                                {'out': alloc_169}
call_function  alloc_170                                    <function alloc at 0x7fc963e9b9c0>            (((1, 2048, 2, 2), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantized_relu_per_tensor_48         cadence.quantized_relu.per_tensor_out         (cadence_quantize_per_tensor_default_17, -16, -128, 1911307776, 1)                                                                                                                  {'out': alloc_170}
call_function  alloc_171                                    <function alloc at 0x7fc963e9b9c0>            (((1, 2048, 2, 2), torch.float32),)                                                                                                                                                 {}
call_function  cadence_dequantize_per_tensor_default_33     cadence.dequantize_per_tensor.out             (cadence_quantized_relu_per_tensor_48, 0.12351787835359573, -128, -128, 127, torch.int8)                                                                                            {'out': alloc_171}
call_function  alloc_172                                    <function alloc at 0x7fc963e9b9c0>            (((1, 2048, 1, 1), torch.float32),)                                                                                                                                                 {}
call_function  aten_mean_dim                                aten.mean.out                                 (cadence_dequantize_per_tensor_default_33, [-1, -2], True)                                                                                                                          {'dtype': None, 'out': alloc_172}
call_function  alloc_173                                    <function alloc at 0x7fc963e9b9c0>            (((1, 2048, 1, 1), torch.int8),)                                                                                                                                                    {}
call_function  cadence_quantize_per_tensor_default_18       cadence.quantize_per_tensor.out               (aten_mean_dim, 0.04673806205391884, -128, -128, 127, torch.int8)                                                                                                                   {'out': alloc_173}
call_function  aten_view_copy_default                       <function view at 0x7fc963e9bb00>             (cadence_quantize_per_tensor_default_18, [1, 2048])                                                                                                                                 {}
call_function  alloc_174                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1000), torch.int8),)                                                                                                                                                          {}
call_function  cadence_quantized_linear_per_tensor          cadence.quantized_linear.per_tensor_out       (aten_view_copy_default, b__frozen_param53, b__frozen_param54, -128, -64, 1414715776, -7, -83, None)                                                                                {'out': alloc_174}
call_function  alloc_175                                    <function alloc at 0x7fc963e9b9c0>            (((1, 1000), torch.float32),)                                                                                                                                                       {}
call_function  cadence_dequantize_per_tensor_default_34     cadence.dequantize_per_tensor.out             (cadence_quantized_linear_per_tensor, 0.06094535440206528, -83, -128, 127, torch.int8)                                                                                              {'out': alloc_175}
output         output_1                                     output                                        ((cadence_dequantize_per_tensor_default_34,),)                                                                                                                                      {}[INFO 2025-12-08 02:02:02,651 utils.py:287] Saved exported program to /tmp/tmpcait_n8z/CadenceDemoModel.pte
[INFO 2025-12-08 02:02:02,663 utils.py:304] Saved exported program to /tmp/tmpcait_n8z/CadenceDemoModel.bpte
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/kvariar/ExecuTorch/stable/executorch/examples/cadence/models/resnet50.py", line 30, in <module>
    export_and_run_model(model, example_inputs)
  File "/home/kvariar/ExecuTorch/stable/executorch/.venv/lib/python3.11/site-packages/executorch/backends/cadence/aot/export_example.py", line 110, in export_and_run_model
    runtime.run_and_compare(
  File "/home/kvariar/ExecuTorch/stable/executorch/.venv/lib/python3.11/site-packages/executorch/backends/cadence/runtime/runtime.py", line 140, in run_and_compare
    outputs = run(executorch_prog, inputs, ref_outputs, working_dir)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kvariar/ExecuTorch/stable/executorch/.venv/lib/python3.11/site-packages/executorch/backends/cadence/runtime/runtime.py", line 61, in run
    program = executorch_prog.executorch_program
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'executorch_program'

