(home)=
# Welcome to the ExecuTorch Documentation

**ExecuTorch** is PyTorch's solution for efficient AI inference on edge devices â€” from mobile phones to embedded systems.

## Key Value Propositions

- **Portability:** Run on diverse platforms, from high-end mobile to constrained microcontrollers
- **Performance:** Lightweight runtime with full hardware acceleration (CPU, GPU, NPU, DSP)
- **Productivity:** Use familiar PyTorch tools from authoring to deployment

---

## ðŸŽ¯ Wins & Success Stories

::::{grid} 1
:class-container: success-showcase
:::{grid-item-card}
:class-header: bg-primary text-white
:class-body: text-center
[View All Success Stories â†’](success-stories)
:::
::::

---

## Quick Navigation

::::{grid} 2

:::{grid-item-card} **Get Started**
:link: quick-start-section
:link-type: doc

New to ExecuTorch? Start here for installation and your first model deployment.
:::

:::{grid-item-card} **Deploy on Edge Platforms**
:link: edge-platforms-section
:link-type: doc

Deploy on Android, iOS, Laptops / Desktops and embedded platforms with optimized backends.
:::

:::{grid-item-card} **Work with LLMs**
:link: llm/working-with-llms
:link-type: doc

Export, optimize, and deploy Large Language Models on edge devices.
:::

:::{grid-item-card} ðŸ”§ **Developer Tools**
:link: tools-section
:link-type: doc

Profile, debug, and inspect your models with comprehensive tooling.
:::

::::

---

## Explore Documentation

::::{grid} 1
:::{grid-item-card} **Intro**
:link: intro-section
:link-type: doc

**Overview, architecture, and core concepts** â€” Understand how ExecuTorch works and its benefits
:::
::::

::::{grid} 1
:::{grid-item-card} **Quick Start**
:link: quick-start-section
:link-type: doc

**Get started with ExecuTorch** â€” Install, export your first model, and run inference
:::
::::

::::{grid} 1
:::{grid-item-card} **Edge**
:link: edge-platforms-section
:link-type: doc

**Android, iOS, Desktop, Embedded** â€” Platform-specific deployment guides and examples
:::
::::

::::{grid} 1
:::{grid-item-card} **Backends**
:link: backends-section
:link-type: doc

**CPU, GPU, NPU/Accelerator backends** â€” Hardware acceleration and backend selection
:::
::::

::::{grid} 1
:::{grid-item-card} **LLMs**
:link: llm/working-with-llms
:link-type: doc

**LLM export, optimization, and deployment** â€” Complete LLM workflow for edge devices
:::
::::

::::{grid} 1
:::{grid-item-card} **Advanced**
:link: advanced-topics-section
:link-type: doc

**Quantization, memory planning, custom passes** â€” Deep customization and optimization
:::
::::

::::{grid} 1
:::{grid-item-card} **Tools**
:link: tools-section
:link-type: doc

**Developer tools, profiling, debugging** â€” Comprehensive development and debugging suite
:::
::::

::::{grid} 1
:::{grid-item-card} **API**
:link: api-section
:link-type: doc

**API Reference Usages & Examples** â€” Detailed Python, C++, and Java API references
:::
::::

::::{grid} 1
:::{grid-item-card} **ðŸ’¬ Support**
:link: support-section
:link-type: doc

**FAQ, troubleshooting, contributing** â€” Get help and contribute to the project
:::
::::

---

## What's Supported

::::{grid} 3

:::{grid-item}
**Model Types**

- Large Language Models (LLMs)
- Computer Vision (CV)
- Speech Recognition (ASR)
- Text-to-Speech (TTS)
- More ...
:::

:::{grid-item}
**Platforms**

- Android & iOS
- Linux, macOS, Windows
- Embedded & MCUs
- Go **â†’ {doc}`edge-platforms-section`**
:::

:::{grid-item}
**Rich Acceleration**

- CPU
- GPU
- NPU
- DSP
- Go **â†’ {doc}`backends-section`**
:::

::::

```{toctree}
:hidden:
:maxdepth: 1

intro-section
quick-start-section
edge-platforms-section
backends-section
llm/working-with-llms
advanced-topics-section
tools-section
api-section
support-section
