
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, user-scalable=yes">
    <title>ExecuTorch - On-Device AI Inference Powered by PyTorch</title>
    <meta name="description" content="ExecuTorch is PyTorch's unified solution for deploying AI models on-device—from smartphones to microcontrollers. Deploy LLMs, vision, speech, and multimodal models with the same PyTorch APIs.">
    <link rel="icon" type="image/svg+xml" href="https://raw.githubusercontent.com/dbort/executorch-logos/main/img/executorch-chip-logo.svg">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="ExecuTorch - On-Device AI Inference Powered by PyTorch">
    <meta property="og:description" content="PyTorch's unified solution for on-device AI. Deploy LLMs, vision, and speech models from smartphones to microcontrollers with 50KB runtime and 12+ hardware backends.">
    <meta property="og:image" content="https://raw.githubusercontent.com/dbort/executorch-logos/main/img/executorch-chip-logo.svg">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="ExecuTorch - On-Device AI Inference Powered by PyTorch">
    <meta name="twitter:description" content="PyTorch's unified solution for on-device AI. Deploy LLMs, vision, and speech models from smartphones to microcontrollers.">

    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <!-- Navigation -->
    <nav>
        <div class="container">
            <div class="nav-content">
            <div class="logo">
                <img src="https://raw.githubusercontent.com/dbort/executorch-logos/main/img/executorch-chip-logo.svg" alt="ExecuTorch Logo" height="40">
                <span style="color:#e0f2fe;">ExecuTorch</span>
            </div>
            <ul class="nav-links" id="navLinks">
                <li><a href="#why-ondevice">Why On-Device</a></li>
                <li><a href="#challenges">Challenges</a></li>
                <li><a href="#features">Solution</a></li>
                <li><a href="#performance">Backends</a></li>
                <li><a href="#partners">Partners</a></li>
                <li><a href="https://github.com/pytorch/executorch" target="_blank">GitHub</a></li>
            </ul>
            <form class="nav-search" action="https://docs.pytorch.org/executorch/1.0/search.html" method="get">
                <input type="text" placeholder="Search docs…" name="q" style="padding: 0.5rem 1rem; border-radius: 6px; border: 1px solid #e2e8f0;">
            </form>
            <button class="nav-toggle" onclick="toggleNav()" aria-label="Toggle navigation">☰</button>
            </div>
        </div>
    </nav>

    <!-- Hero -->
    <section class="title_banner">
        <div class="title_banner-container">
            <div class="logo-text-container">
                <img src="https://raw.githubusercontent.com/dbort/executorch-logos/main/img/executorch-chip-logo.svg" alt="ExecuTorch" class="title_banner-logo">
                <span class="banner_highlight">Execu<span class="highlight">Torch</span></span>
            </div>
        </div>
    </section>
    <section class="hero">
        <div class="container">
            <p class="hero-subtitle">Deploy PyTorch models directly to edge devices. Text, vision, and audio AI with privacy-preserving, real-time inference — no cloud required.</p>
            <div class="stats">
                <a href="#performance" style="text-decoration: none;">
                    <div class="stat-card stat-card-clickable">
                        <div class="stat-number">12+</div>
                        <div class="stat-label">hardware backends supported</div>
                    </div>
                </a>
                <a href="https://engineering.fb.com/2025/07/28/android/executorch-on-device-ml-meta-family-of-apps/" target="_blank" rel="noopener noreferrer" style="text-decoration: none;">
                    <div class="stat-card stat-card-clickable">
                        <div class="stat-number">Billions</div>
                        <div class="stat-label">users in production at Meta</div>
                    </div>
                </a>
                <div class="stat-card">
                    <div class="stat-number">50KB</div>
                    <div class="stat-label">base runtime footprint</div>
                </div>
            </div>

            <div>
                <a href="https://docs.pytorch.org/executorch/main/getting-started.html" class="btn btn-primary">Get Started</a>
                <a href="https://github.com/pytorch/executorch" class="btn btn-secondary">View on GitHub</a>
            </div>
        </div>
    </section>

    <!-- Why On-Device -->

    <!-- Why On-Device Cards -->
    <section id="why-ondevice">
        <div class="container">
        <h2 class="section-title">Why On-Device AI <span class="highlight">Matters</span></h2>
        <div class="grid-2x2">
            <div class="card">
                <div class="card-icon">
                    <!-- Privacy SVG -->
                    <svg width="32" height="32" viewBox="0 0 32 32" fill="none">
                    <circle cx="16" cy="16" r="16" fill="#de3412"/>
                    <path d="M16 10a4 4 0 0 1 4 4v2h-8v-2a4 4 0 0 1 4-4zm-6 6v6a6 6 0 0 0 12 0v-6" stroke="#fff" stroke-width="2"/>
                    </svg>
                </div>
            <h3 class="card-title">Enhanced Privacy</h3>
            <p class="card-text">Data never leaves the device. Process personal content, conversations, and media locally without cloud exposure.</p>
            </div>
            <div class="card">
                <div class="card-icon">
                    <!-- Lightning SVG -->
                    <svg width="32" height="32" viewBox="0 0 32 32" fill="none">
                    <circle cx="16" cy="16" r="16" fill="#de3412"/>
                    <polygon points="14,8 22,16 16,16 18,24 10,16 16,16" fill="#fff"/>
                    </svg>
                </div>
            <h3 class="card-title">Real-Time Response</h3>
            <p class="card-text">Instant inference with no network round-trips. Perfect for AR/VR experiences, multimodal AI interactions, and responsive conversational agents.</p>
            </div>
            <div class="card">
                <div class="card-icon">
                    <!-- Globe SVG -->
                    <svg width="32" height="32" viewBox="0 0 32 32" fill="none">
                    <circle cx="16" cy="16" r="16" fill="#de3412"/>
                    <ellipse cx="16" cy="16" rx="10" ry="6" stroke="#fff" stroke-width="2"/>
                    <ellipse cx="16" cy="16" rx="6" ry="10" stroke="#fff" stroke-width="2"/>
                    </svg>
                </div>
            <h3 class="card-title">Offline & Low-Bandwidth Ready</h3>
            <p class="card-text">Zero network dependency for inference. Works seamlessly in low-bandwidth regions, remote areas, or completely offline.</p>
            </div>
            <div class="card">
                <div class="card-icon">
                    <!-- Dollar SVG -->
                    <svg width="32" height="32" viewBox="0 0 32 32" fill="none">
                    <circle cx="16" cy="16" r="16" fill="#de3412"/>
                    <text x="10" y="22" font-size="16" fill="#fff" font-family="Inter, Arial, sans-serif">$</text>
                    </svg>
                </div>
            <h3 class="card-title">Cost Efficient</h3>
            <p class="card-text">No cloud compute bills. No API rate limits. Scale to billions of users without infrastructure costs growing linearly.</p>
            </div>
        </div>
        </div>
    </section>

    <!-- Model Evolution -->
    <section class="alt">
        <div class="container">
            <h2 class="section-title">Models Are Getting <span class="highlight">Smaller & Smarter</span></h2>
            <p class="section-subtitle">The convergence of efficient architectures and edge hardware creates new opportunities</p>

            <div class="features-3">
                <div class="feature-item">
                    <div class="feature-title">Dramatically Smaller</div>
                    <div class="feature-text">Modern LLMs achieve high quality at a fraction of historical sizes</div>
                </div>
                <div class="feature-item">
                    <div class="feature-title">Edge-Ready Performance</div>
                    <div class="feature-text">Real-time inference on consumer smartphones</div>
                </div>
                <div class="feature-item">
                    <div class="feature-title">Quantization Benefits</div>
                    <div class="feature-text">Significant size reduction while preserving accuracy</div>
                </div>
            </div>

            <p style="text-align: center; font-size: 1.1rem; color: var(--text-dark); margin-top: 2rem;">
                <strong>The opportunity is now:</strong> Foundation models have crossed the efficiency threshold.
                Deploy sophisticated AI directly where data lives.
            </p>
        </div>
    </section>

    <!-- Challenges -->
    <section id="challenges">
        <div class="container">
            <h2 class="section-title">Why On-Device AI Was <span class="highlight">Hard</span></h2>

            <div class="grid-2x2">
                <div class="card">
                    <!-- Power Constraints (Battery) -->
                    <div class="card-icon">
                        <svg width="64" height="64" viewBox="0 0 48 48" fill="none">
                        <!-- Battery body -->
                        <rect x="10" y="12" width="28" height="24" rx="6" fill="#fff" stroke="#de3412" stroke-width="3"/>
                        <!-- Battery tip -->
                        <rect x="20" y="8" width="8" height="6" rx="2" fill="#de3412"/>
                        <!-- Low charge indicator -->
                        <rect x="14" y="28" width="8" height="4" rx="2" fill="#de3412"/>
                        <!-- Power bolt -->
                        <polygon points="30,18 26,26 32,26 28,34" fill="#de3412" stroke="#de3412" stroke-width="1"/>
                        <!-- Optional: subtle shadow for depth -->
                        <ellipse cx="24" cy="40" rx="12" ry="3" fill="#de3412" opacity="0.08"/>
                        </svg>
                    </div>

                    <h3 class="card-title">Power Constraints</h3>
                    <p class="card-text">From battery-powered phones to energy-harvesting sensors, edge devices have strict power budgets. Microcontrollers may run on milliwatts, requiring extreme efficiency.</p>
                </div>

                <div class="card">
                    <div class="card-icon">
                        <svg width="64" height="64" viewBox="0 0 64 64" fill="none">
                        <!-- Thermometer bulb -->
                        <circle cx="32" cy="48" r="10" fill="#de3412" stroke="#de3412" stroke-width="2"/>
                        <!-- Thermometer tube -->
                        <rect x="28" y="16" width="8" height="32" rx="4" fill="#fff" stroke="#de3412" stroke-width="2"/>
                        <!-- Mercury column -->
                        <rect x="30.5" y="20" width="3" height="24" rx="1.5" fill="#de3412"/>
                        <!-- Heat waves -->
                        <path d="M44 20c2 2 6 2 8 0" stroke="#de3412" stroke-width="2" fill="none" stroke-linecap="round"/>
                        <path d="M44 14c2 2 6 2 8 0" stroke="#de3412" stroke-width="2" fill="none" stroke-linecap="round" opacity="0.7"/>
                        <!-- Optional: subtle shadow for depth -->
                        <ellipse cx="32" cy="58" rx="14" ry="4" fill="#de3412" opacity="0.08"/>
                        </svg>
                    </div>
                    <h3 class="card-title">Thermal Management</h3>
                    <p class="card-text">Sustained inference generates heat without active cooling. From smartphones to industrial IoT devices, thermal throttling limits continuous AI workloads.</p>
                </div>

                <div class="card">
                    <div class="card-icon">
                        <svg width="64" height="64" viewBox="0 0 64 64" fill="none">
                        <!-- RAM chip body -->
                        <rect x="14" y="22" width="36" height="20" rx="4" fill="#fff" stroke="#de3412" stroke-width="3"/>
                        <!-- RAM chip pins (top) -->
                        <rect x="18" y="18" width="4" height="6" rx="1" fill="#de3412"/>
                        <rect x="26" y="18" width="4" height="6" rx="1" fill="#de3412"/>
                        <rect x="34" y="18" width="4" height="6" rx="1" fill="#de3412"/>
                        <rect x="42" y="18" width="4" height="6" rx="1" fill="#de3412"/>
                        <rect x="50" y="18" width="4" height="6" rx="1" fill="#de3412"/>
                        <!-- RAM chip pins (bottom) -->
                        <rect x="18" y="42" width="4" height="6" rx="1" fill="#de3412"/>
                        <rect x="26" y="42" width="4" height="6" rx="1" fill="#de3412"/>
                        <rect x="34" y="42" width="4" height="6" rx="1" fill="#de3412"/>
                        <rect x="42" y="42" width="4" height="6" rx="1" fill="#de3412"/>
                        <rect x="50" y="42" width="4" height="6" rx="1" fill="#de3412"/>
                        <!-- Memory cells (interior) -->
                        <rect x="22" y="28" width="20" height="8" rx="2" fill="#de3412" opacity="0.15"/>
                        <!-- Optional: subtle shadow for depth -->
                        <ellipse cx="32" cy="54" rx="16" ry="4" fill="#de3412" opacity="0.08"/>
                        </svg>
                    </div>
                    <h3 class="card-title">Memory Limitations</h3>
                    <p class="card-text">Edge devices range from high-end phones to tiny microcontrollers. Beyond capacity, limited memory bandwidth creates bottlenecks when moving tensors between compute units.</p>
                </div>

                <div class="card">
                    <div class="card-icon">
                        <svg width="48" height="48" viewBox="0 0 48 48" fill="none">
                            <rect width="48" height="48" rx="12" fill="#F5F5F5"/>
                            <!-- CPU -->
                            <rect x="6" y="6" width="12" height="12" rx="3" fill="#de3412" stroke="#de3412" stroke-width="2"/>
                            <!-- GPU -->
                            <rect x="30" y="6" width="12" height="12" rx="2" fill="#fff" stroke="#de3412" stroke-width="2"/>
                            <circle cx="12" cy="36" r="6" fill="#de3412" stroke="#de3412" stroke-width="2"/>
                            <!-- NPU/FPGA (hexagon) -->
                            <polygon points="36,30 42,33 42,39 36,42 30,39 30,33" fill="#fff" stroke="#de3412" stroke-width="2"/>
                            <!-- Interconnecting lines -->
                            <line x1="18" y1="12" x2="30" y2="12" stroke="#de3412" stroke-width="2"/>
                            <line x1="12" y1="18" x2="12" y2="30" stroke="#de3412" stroke-width="2"/>
                            <line x1="18" y1="36" x2="30" y2="36" stroke="#de3412" stroke-width="2"/>
                            <line x1="36" y1="18" x2="36" y2="30" stroke="#de3412" stroke-width="2"/>
                        </svg>
                    </div>
                    <h3 class="card-title">Hardware Heterogeneity</h3>
                    <p class="card-text">From microcontrollers to smartphone NPUs to embedded GPUs. Each architecture demands unique optimizations, making broad deployment across diverse form factors extremely challenging.</p>
                </div>
            </div>
        </div>
    </section>

    <!-- PyTorch Problem -->
    <section class="alt">
        <div class="container">
            <h2 class="section-title">PyTorch Powers <span class="highlight">>90%</span> of AI Research</h2>
            <p class="section-subtitle">But deploying PyTorch models to edge devices meant losing everything that made PyTorch great</p>

            <div class="problem-solution">
                <div class="problem-card good">
                    <h3 style="color: var(--primary); margin-bottom: 1rem;">Research & Training</h3>
                    <p style="color: var(--text-gray);">PyTorch's intuitive APIs and eager execution power breakthrough research</p>
                </div>

                <div class="arrow">→</div>

                <div class="problem-card bad">
                    <h3 style="color: #dc2626; margin-bottom: 1rem;">The Conversion Nightmare</h3>
                    <p style="color: #7f1d1d;">Multiple intermediate formats, custom runtimes, C++ rewrites</p>
                </div>
            </div>

            <div class="card" style="margin: 3rem 0;">
                <h3 style="font-size: 1.5rem; margin-bottom: 1.5rem; text-align: center;">The Hidden Costs of Conversion (Status Quo)</h3>
                <div class="issues">
                    <div>
                        <div class="issue-item">
                            <span class="issue-icon">❌</span>
                            <strong class="issue-title">Lost Semantics</strong>
                        </div>
                        <p class="issue-text">PyTorch operations don't map 1:1 to other formats</p>
                    </div>
                    <div>
                        <div class="issue-item">
                            <span class="issue-icon">❌</span>
                            <strong class="issue-title">Debugging Nightmare</strong>
                        </div>
                        <p class="issue-text">Can't trace errors back to original PyTorch code</p>
                    </div>
                    <div>
                        <div class="issue-item">
                            <span class="issue-icon">❌</span>
                            <strong class="issue-title">Vendor-Specific Formats</strong>
                        </div>
                        <p class="issue-text">Locked into proprietary formats with limited operator support</p>
                    </div>
                    <div>
                        <div class="issue-item">
                            <span class="issue-icon">❌</span>
                            <strong class="issue-title">Language Barriers</strong>
                        </div>
                        <p class="issue-text">Teams spend months rewriting Python models in C++ for production</p>
                    </div>
                </div>
            </div>

        </div>
    </section>

    <!-- Features -->
    <section id="features">
        <div class="container">
            <h2 class="section-title">ExecuTorch<br><span class="highlight" style="font-size: 0.8em;">PyTorch's On-Device AI Framework</span></h2>

            <div class="grid">
                <div class="card">
                    <div class="card-icon">
                       <svg width="48" height="48" viewBox="0 0 48 48" fill="none">
                            <rect width="48" height="48" rx="12" fill="#F5F5F5"/>
                            <!-- Left data table -->
                            <rect x="8" y="16" width="10" height="16" rx="2" fill="#FF6F00"/>
                            <line x1="10" y1="20" x2="16" y2="20" stroke="#fff" stroke-width="1.5"/>
                            <line x1="10" y1="24" x2="16" y2="24" stroke="#fff" stroke-width="1.5"/>
                            <line x1="10" y1="28" x2="16" y2="28" stroke="#fff" stroke-width="1.5"/>
                            <!-- Right data table -->
                            <rect x="30" y="16" width="10" height="16" rx="2" fill="#FF6F00"/>
                            <line x1="32" y1="20" x2="38" y2="20" stroke="#fff" stroke-width="1.5"/>
                            <line x1="32" y1="24" x2="38" y2="24" stroke="#fff" stroke-width="1.5"/>
                            <line x1="32" y1="28" x2="38" y2="28" stroke="#fff" stroke-width="1.5"/>
                            <!-- Arrow -->
                            <line x1="18" y1="24" x2="30" y2="24" stroke="#FF6F00" stroke-width="2" stroke-linecap="round"/>
                            <!-- Checkmark above arrow -->
                            <path d="M20 32 L24 36 L32 22" stroke="#388e3c" stroke-width="2.5" fill="none" stroke-linecap="round"/>
                        </svg>
                    </div>
                    <h3 class="card-title">No Conversions</h3>
                    <p class="card-text">Direct export from PyTorch to edge. Core ATen operators preserved. No intermediate formats, no vendor lock-in.</p>
                </div>

                <div class="card">
                    <div class="card-icon">
                        <svg width="48" height="48" viewBox="0 0 48 48" fill="none">
                            <rect width="48" height="48" rx="12" fill="#F5F5F5"/>
                            <rect x="12" y="12" width="24" height="24" rx="6" fill="#de3412"/>
                            <rect x="20" y="20" width="8" height="8" rx="2" fill="#fff"/>
                            <path d="M24 18 L22 26 L26 26 L24 34" stroke="#de3412" stroke-width="2" fill="none"/>
                            <path d="M8 24 H12" stroke="#888" stroke-width="2" stroke-linecap="round"/>
                            <path d="M36 24 H40" stroke="#888" stroke-width="2" stroke-linecap="round"/>
                            <path d="M24 8 V12" stroke="#888" stroke-width="2" stroke-linecap="round"/>
                            <path d="M24 36 V40" stroke="#888" stroke-width="2" stroke-linecap="round"/>
                        </svg>
                    </div>
                    <h3 class="card-title">Ahead-of-Time Compilation</h3>
                    <p class="card-text">Optimize models offline for target device capabilities. Hardware-specific performance tuning before deployment.</p>
                </div>

                <div class="card">
                    <div class="card-icon">
                        <svg width="48" height="48" viewBox="0 0 48 48" fill="none">
                            <rect width="48" height="48" rx="12" fill="#F5F5F5"/>
                            <rect x="10" y="10" width="14" height="14" rx="3" fill="#de3412"/>
                            <rect x="24" y="24" width="14" height="14" rx="3" fill="#de3412" fill-opacity="0.7"/>
                            <rect x="17" y="17" width="14" height="14" rx="3" fill="#de3412" fill-opacity="0.4"/>
                            <rect x="10" y="10" width="14" height="14" rx="3" stroke="#de3412" stroke-width="2"/>
                            <rect x="24" y="24" width="14" height="14" rx="3" stroke="#de3412" stroke-width="2"/>
                            <rect x="17" y="17" width="14" height="14" rx="3" stroke="#de3412" stroke-width="2"/>
                        </svg>
                    </div>
                    <h3 class="card-title">Modular by Design</h3>
                    <p class="card-text">Pick and choose optimization steps. Composable at both compile-time and runtime for maximum flexibility.</p>
                </div>

                <div class="card">
                    <div class="card-icon">
                        <svg width="48" height="48" viewBox="0 0 48 48" fill="none">
                            <rect width="48" height="48" rx="12" fill="#F5F5F5"/>
                            <rect x="14" y="14" width="20" height="20" rx="4" fill="#de3412"/>
                            <!-- Connection nodes -->
                            <circle cx="24" cy="6" r="2" fill="#de3412"/>
                            <circle cx="24" cy="42" r="2" fill="#de3412"/>
                            <circle cx="6" cy="24" r="2" fill="#de3412"/>
                            <circle cx="42" cy="24" r="2" fill="#de3412"/>
                            <circle cx="10" cy="10" r="2" fill="#de3412" fill-opacity="0.7"/>
                            <circle cx="38" cy="10" r="2" fill="#de3412" fill-opacity="0.7"/>
                            <circle cx="10" cy="38" r="2" fill="#de3412" fill-opacity="0.7"/>
                            <circle cx="38" cy="38" r="2" fill="#de3412" fill-opacity="0.7"/>
                            <!-- Chip outline -->
                            <rect x="14" y="14" width="20" height="20" rx="4" stroke="#de3412" stroke-width="2"/>
                        </svg>
                    </div>
                    <h3 class="card-title">Hardware Ecosystem</h3>
                    <p class="card-text">Fully open source with hardware partner contributions. Built on PyTorch's standardized IR and operator set.</p>
                </div>

                <div class="card">
                    <div class="card-icon">
                        <svg width="48" height="48" viewBox="0 0 48 48" fill="none">
                            <rect width="48" height="48" rx="12" fill="#F5F5F5"/>
                            <!-- Microchip -->
                            <rect x="14" y="14" width="20" height="20" rx="4" fill="#de3412" stroke="#de3412" stroke-width="2"/>
                            <!-- Feather (lightweight/embedded) -->
                            <path d="M20 30 Q28 18 28 30 Q26 28 24 30 Q22 32 20 30 Z" fill="#fff" fill-opacity="0.9" stroke="#de3412" stroke-width="1.5"/>
                        </svg>
                    </div>
                    <h3 class="card-title">Embedded-Friendly Runtime</h3>
                    <p class="card-text">Portable C++ runtime runs on microcontrollers to smartphones.</p>
                </div>

                <div class="card">
                    <div class="card-icon">
                        <svg width="48" height="48" viewBox="0 0 48 48" fill="none">
                            <!-- Background -->
                            <rect width="48" height="48" rx="12" fill="#F5F5F5"/>
                            <!-- Official PyTorch Flame (stylized, based on www.pytorch.org) -->
                            <path d="M24 10 C28 18, 20 22, 24 34 C28 28, 36 20, 24 10 Z" fill="#FF6F00"/>
                            <circle cx="24" cy="24" r="4" fill="#fff" stroke="#FF6F00" stroke-width="1.5"/>
                            <!-- Ecosystem: Orbiting nodes -->
                            <circle cx="38" cy="24" r="3" fill="#de3412" fill-opacity="0.7"/>
                            <circle cx="24" cy="38" r="3" fill="#de3412" fill-opacity="0.7"/>
                            <circle cx="10" cy="24" r="3" fill="#de3412" fill-opacity="0.7"/>
                            <circle cx="24" cy="10" r="3" fill="#de3412" fill-opacity="0.7"/>
                            <!-- Dashed orbit ring -->
                            <circle cx="24" cy="24" r="14" stroke="#de3412" stroke-width="1.2" fill="none" stroke-dasharray="4 3"/>
                        </svg>
                    </div>
                    <h3 class="card-title">PyTorch Ecosystem</h3>
                    <p class="card-text">Native integration with PyTorch ecosystem, including torchao for quantization. Stay in familiar tools throughout.</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Code Example -->
    <section class="alt">
        <div class="code-section-container">
            <h2 class="section-title" style="font-size: 2.5rem; margin-bottom: 0.5rem;">Simple as <span class="highlight">1-2-3</span></h2>
            <p class="section-subtitle" style="margin-bottom: 2rem;">Export, optimize, and run PyTorch models on edge devices</p>

            <div style="background: #1e293b; border-radius: 12px; padding: 1.5rem; margin-top: 1.5rem;">
                <div style="display: flex; flex-direction: column; gap: 1.5rem;">
                    <!-- Step 1: Export -->
                    <div>
                        <h3 style="color: #06d6a0; font-size: 1.2rem; margin-bottom: 1rem; font-weight: 600;">
                            1. Export Your PyTorch Model
                        </h3>
                        <pre style="background: #0f172a; border-radius: 8px; padding: 1.5rem; overflow-x: auto; margin: 0;"><code style="color: #e2e8f0; font-family: 'Courier New', monospace; font-size: 0.9rem;"><span style="color: #c084fc;">import</span> torch

<span style="color: #64748b;"># Your existing PyTorch model</span>
model = MyModel().eval()
example_inputs = (torch.randn(<span style="color: #06d6a0;">1</span>, <span style="color: #06d6a0;">3</span>, <span style="color: #06d6a0;">224</span>, <span style="color: #06d6a0;">224</span>),)

<span style="color: #64748b;"># Export to create semantically equivalent graph</span>
exported_program = torch.export.export(model, example_inputs)</code></pre>
                    </div>

                    <!-- Step 2: Optimize -->
                    <div>
                        <h3 style="color: #06d6a0; font-size: 1.2rem; margin-bottom: 1rem; font-weight: 600;">
                            2. Optimize for Target Hardware
                        </h3>
                        <p style="color: #94a3b8; margin-bottom: 1rem; text-align: center; font-size: 0.95rem;">
                            Switch between backends with a single line change
                        </p>

                        <div class="backend-switcher">
                            <div class="code-instruction">Choose your target hardware to see the corresponding code:</div>
                            <div class="backend-cards">
                                <div class="backend-card active" onclick="switchBackend('cpu', event)">
                                    <div class="backend-card-title">CPU Optimization</div>
                                    <div class="backend-card-desc">XNNPACK with Arm Kleidi</div>
                                </div>
                                <div class="backend-card" onclick="switchBackend('apple', event)">
                                    <div class="backend-card-title">Apple Devices</div>
                                    <div class="backend-card-desc">Core ML partitioner</div>
                                </div>
                                <div class="backend-card" onclick="switchBackend('qualcomm', event)">
                                    <div class="backend-card-title">Qualcomm® AI Engine</div>
                                    <div class="backend-card-desc">Qualcomm® Hexagon™ NPU</div>
                                </div>
                                <a href="https://docs.pytorch.org/executorch/main/backends-overview.html" target="_blank" rel="noopener noreferrer" style="text-decoration: none;">
                                    <div class="backend-card more-backends">
                                        <div class="backend-card-title">+ 9 More</div>
                                        <div class="backend-card-desc">Vulkan, MediaTek, Samsung...</div>
                                    </div>
                                </a>
                            </div>

                            <div id="cpu" class="backend-content active">
                                <div style="background: #0f172a; border-radius: 8px; padding: 1.5rem; border: 1px solid #334155;">
                                    <pre style="background: transparent; border: none; padding: 0; margin: 0; font-size: 0.85rem;"><code style="color: #e2e8f0; font-family: 'Courier New', monospace;"><span style="color: #c084fc;">from</span> executorch.exir <span style="color: #c084fc;">import</span> to_edge_transform_and_lower
<span style="color: #c084fc;">from</span> executorch.backends.xnnpack.partition.xnnpack_partitioner <span style="color: #c084fc;">import</span> XnnpackPartitioner

program = to_edge_transform_and_lower(
    exported_program,
    partitioner=[XnnpackPartitioner()]
).to_executorch()

<span style="color: #64748b;"># Save to .pte file</span>
<span style="color: #c084fc;">with</span> <span style="color: #38bdf8;">open</span>(<span style="color: #fbbf24;">"model.pte"</span>, <span style="color: #fbbf24;">"wb"</span>) <span style="color: #c084fc;">as</span> f:
    f.write(program.buffer)</code></pre>
                                </div>
                            </div>

                            <div id="apple" class="backend-content">
                                <div style="background: #0f172a; border-radius: 8px; padding: 1.5rem; border: 1px solid #334155;">
                                    <pre style="background: transparent; border: none; padding: 0; margin: 0; font-size: 0.85rem;"><code style="color: #e2e8f0; font-family: 'Courier New', monospace;"><span style="color: #c084fc;">from</span> executorch.exir <span style="color: #c084fc;">import</span> to_edge_transform_and_lower
<span style="color: #c084fc;">from</span> executorch.backends.apple.coreml.partition.coreml_partitioner <span style="color: #c084fc;">import</span> CoreMLPartitioner

program = to_edge_transform_and_lower(
    exported_program,
    partitioner=[CoreMLPartitioner()]
).to_executorch()

<span style="color: #64748b;"># Save to .pte file</span>
<span style="color: #c084fc;">with</span> <span style="color: #38bdf8;">open</span>(<span style="color: #fbbf24;">"model.pte"</span>, <span style="color: #fbbf24;">"wb"</span>) <span style="color: #c084fc;">as</span> f:
    f.write(program.buffer)</code></pre>
                                </div>
                            </div>

                            <div id="qualcomm" class="backend-content">
                                <div style="background: #0f172a; border-radius: 8px; padding: 1.5rem; border: 1px solid #334155;">
                                    <pre style="background: transparent; border: none; padding: 0; margin: 0; font-size: 0.85rem;"><code style="color: #e2e8f0; font-family: 'Courier New', monospace;"><span style="color: #c084fc;">from</span> executorch.exir <span style="color: #c084fc;">import</span> to_edge_transform_and_lower
<span style="color: #c084fc;">from</span> executorch.backends.qualcomm.partition.qnn_partitioner <span style="color: #c084fc;">import</span> QnnPartitioner

program = to_edge_transform_and_lower(
    exported_program,
    partitioner=[QnnPartitioner()]
).to_executorch()

<span style="color: #64748b;"># Save to .pte file</span>
<span style="color: #c084fc;">with</span> <span style="color: #38bdf8;">open</span>(<span style="color: #fbbf24;">"model.pte"</span>, <span style="color: #fbbf24;">"wb"</span>) <span style="color: #c084fc;">as</span> f:
    f.write(program.buffer)</code></pre>
                                </div>
                            </div>
                        </div>
                    </div>

                    <!-- Step 3: Run -->
                    <div>
                        <h3 style="color: #06d6a0; font-size: 1.2rem; margin-bottom: 1rem; font-weight: 600;">
                            3. Run on Any Platform
                        </h3>
                        <div class="platform-switcher">
                            <div class="code-instruction">Choose your platform to see the native API:</div>
                            <div class="platform-cards">
                                <div class="platform-card active" onclick="switchPlatform('cpp', event)">
                                    <div class="platform-card-title">C++</div>
                                </div>
                                <div class="platform-card" onclick="switchPlatform('swift', event)">
                                    <div class="platform-card-title">Swift</div>
                                </div>
                                <div class="platform-card" onclick="switchPlatform('kotlin', event)">
                                    <div class="platform-card-title">Kotlin</div>
                                </div>
                                <div class="platform-card" onclick="switchPlatform('objc', event)">
                                    <div class="platform-card-title">Objective-C</div>
                                </div>
                                <div class="platform-card" onclick="switchPlatform('wasm', event)">
                                    <div class="platform-card-title">WebAssembly</div>
                                </div>
                            </div>

                            <div id="cpp" class="platform-content active">
                                <div style="background: #0f172a; border-radius: 8px; padding: 1.5rem; border: 1px solid #334155;">
                                    <pre style="background: transparent; border: none; padding: 0; margin: 0; font-size: 0.85rem;"><code style="color: #e2e8f0; font-family: 'Courier New', monospace;"><span style="color: #c084fc;">#include</span> <span style="color: #fbbf24;">&lt;executorch/extension/module/module.h&gt;</span>
<span style="color: #c084fc;">#include</span> <span style="color: #fbbf24;">&lt;executorch/extension/tensor/tensor.h&gt;</span>

Module module(<span style="color: #fbbf24;">"model.pte"</span>);
<span style="color: #38bdf8;">auto</span> tensor = make_tensor_ptr({<span style="color: #06d6a0;">2</span>, <span style="color: #06d6a0;">2</span>}, {<span style="color: #06d6a0;">1.0f</span>, <span style="color: #06d6a0;">2.0f</span>, <span style="color: #06d6a0;">3.0f</span>, <span style="color: #06d6a0;">4.0f</span>});
<span style="color: #38bdf8;">auto</span> outputs = module.forward(tensor);</code></pre>
                                </div>
                            </div>

                            <div id="swift" class="platform-content">
                                <div style="background: #0f172a; border-radius: 8px; padding: 1.5rem; border: 1px solid #334155;">
                                    <pre style="background: transparent; border: none; padding: 0; margin: 0; font-size: 0.85rem;"><code style="color: #e2e8f0; font-family: 'Courier New', monospace;"><span style="color: #c084fc;">import</span> ExecuTorch

<span style="color: #c084fc;">let</span> module = Module(filePath: <span style="color: #fbbf24;">"model.pte"</span>)
<span style="color: #c084fc;">let</span> input = Tensor&lt;Float&gt;([<span style="color: #06d6a0;">1.0</span>, <span style="color: #06d6a0;">2.0</span>, <span style="color: #06d6a0;">3.0</span>, <span style="color: #06d6a0;">4.0</span>], shape: [<span style="color: #06d6a0;">2</span>, <span style="color: #06d6a0;">2</span>])
<span style="color: #c084fc;">let</span> outputs = <span style="color: #38bdf8;">try</span> module.forward(input)</code></pre>
                                </div>
                            </div>

                            <div id="kotlin" class="platform-content">
                                <div style="background: #0f172a; border-radius: 8px; padding: 1.5rem; border: 1px solid #334155;">
                                    <pre style="background: transparent; border: none; padding: 0; margin: 0; font-size: 0.85rem;"><code style="color: #e2e8f0; font-family: 'Courier New', monospace;"><span style="color: #c084fc;">val</span> module = Module.load(<span style="color: #fbbf24;">"model.pte"</span>)
<span style="color: #c084fc;">val</span> inputTensor = Tensor.fromBlob(floatArrayOf(<span style="color: #06d6a0;">1.0f</span>, <span style="color: #06d6a0;">2.0f</span>, <span style="color: #06d6a0;">3.0f</span>, <span style="color: #06d6a0;">4.0f</span>), longArrayOf(<span style="color: #06d6a0;">2</span>, <span style="color: #06d6a0;">2</span>))
<span style="color: #c084fc;">val</span> outputs = module.forward(EValue.from(inputTensor))</code></pre>
                                </div>
                            </div>

                            <div id="objc" class="platform-content">
                                <div style="background: #0f172a; border-radius: 8px; padding: 1.5rem; border: 1px solid #334155;">
                                    <pre style="background: transparent; border: none; padding: 0; margin: 0; font-size: 0.85rem;"><code style="color: #e2e8f0; font-family: 'Courier New', monospace;"><span style="color: #c084fc;">#import</span> <span style="color: #fbbf24;">&lt;ExecuTorch/ExecuTorch.h&gt;</span>

NSString *modelPath = [[NSBundle mainBundle] pathForResource:<span style="color: #fbbf24;">@"model"</span> ofType:<span style="color: #fbbf24;">@"pte"</span>];
ExecuTorchModule *module = [[ExecuTorchModule alloc] initWithFilePath:modelPath];

<span style="color: #38bdf8;">float</span> data[] = {<span style="color: #06d6a0;">1.0f</span>, <span style="color: #06d6a0;">2.0f</span>, <span style="color: #06d6a0;">3.0f</span>, <span style="color: #06d6a0;">4.0f</span>};
ExecuTorchTensor *input = [[ExecuTorchTensor alloc] initWithBytes:data
                                                            shape:<span style="color: #fbbf24;">@[@2, @2]</span>
                                                         dataType:ExecuTorchDataTypeFloat];
NSArray&lt;ExecuTorchValue *&gt; *outputs = [module forwardWithTensor:input error:<span style="color: #38bdf8;">nil</span>];</code></pre>
                                </div>
                            </div>

                            <div id="wasm" class="platform-content">
                                <div style="background: #0f172a; border-radius: 8px; padding: 1.5rem; border: 1px solid #334155;">
                                    <pre style="background: transparent; border: none; padding: 0; margin: 0; font-size: 0.85rem;"><code style="color: #e2e8f0; font-family: 'Courier New', monospace;"><span style="color: #64748b;">// Load model from file or buffer</span>
<span style="color: #c084fc;">const</span> module = et.Module.load(<span style="color: #fbbf24;">"model.pte"</span>);
<span style="color: #64748b;">// Create input tensor from array</span>
<span style="color: #c084fc;">const</span> input = et.Tensor.fromArray([<span style="color: #06d6a0;">2</span>, <span style="color: #06d6a0;">2</span>], [<span style="color: #06d6a0;">1.0</span>, <span style="color: #06d6a0;">2.0</span>, <span style="color: #06d6a0;">3.0</span>, <span style="color: #06d6a0;">4.0</span>]);
<span style="color: #64748b;">// Run inference</span>
<span style="color: #c084fc;">const</span> outputs = module.forward([input]);</code></pre>
                                </div>
                            </div>
                        </div>
                        <p style="color: #94a3b8; text-align: center; margin-top: 1rem; font-size: 0.9rem;">
                            Available on Android, iOS, Linux, Windows, macOS, and embedded microcontrollers (e.g., DSP and Cortex-M processors)
                        </p>
                    </div>
                </div>

                <div style="text-align: center; margin-top: 2rem;">
                    <p style="color: #94a3b8; font-size: 0.9rem; margin-bottom: 1rem; font-style: italic;">
                        Need advanced features? ExecuTorch supports memory planning, quantization, profiling, and custom compiler passes.
                    </p>
                    <a href="https://docs.pytorch.org/executorch/main/getting-started.html"
                       style="display: inline-block; padding: 0.75rem 1.5rem; background: #059669; color: #ffffff;
                              border-radius: 8px; text-decoration: none; font-weight: 600;
                              transition: all 0.3s; box-shadow: 0 2px 8px rgba(5, 150, 105, 0.3);"
                       onmouseover="this.style.background='#047857'; this.style.boxShadow='0 4px 16px rgba(5, 150, 105, 0.4)'"
                       onmouseout="this.style.background='#059669'; this.style.boxShadow='0 2px 8px rgba(5, 150, 105, 0.3)'">
                        Try the Full Tutorial →
                    </a>
                </div>
            </div>
        </div>
    </section>

    <!-- Multimodal API -->
    <section>
        <div class="code-section-container">
            <h2 class="section-title" style="font-size: 2.5rem; margin-bottom: 0.5rem;">High-Level <span class="highlight">Multimodal APIs</span></h2>
            <p class="section-subtitle" style="margin-bottom: 2rem;">Run complex multimodal LLMs with simplified C++ interfaces</p>

            <div style="background: #1e293b; border-radius: 12px; padding: 1.5rem; margin-top: 1.5rem;">
                <div style="display: grid; grid-template-columns: 1fr; gap: 1.5rem;">
                    <div>
                        <h3 style="color: #06d6a0; font-size: 1.2rem; margin-bottom: 1rem; font-weight: 600;">
                            Multimodal Runner - Text + Vision + Audio in One API
                        </h3>
                        <p style="color: #94a3b8; margin-bottom: 1rem; text-align: center; font-size: 0.95rem;">
                            Choose your platform to see the multimodal API supporting text, images, and audio:
                        </p>

                        <div class="platform-switcher-multimodal">
                            <div class="code-instruction">Unified API across mobile platforms:</div>
                            <div class="platform-cards">
                                <div class="platform-card active" onclick="switchMultimodalPlatform('cpp', event)">
                                    <div class="platform-card-title">C++</div>
                                    <div class="platform-card-desc">Cross-platform</div>
                                </div>
                                <div class="platform-card" onclick="switchMultimodalPlatform('swift', event)">
                                    <div class="platform-card-title">Swift</div>
                                    <div class="platform-card-desc">iOS native</div>
                                </div>
                                <div class="platform-card" onclick="switchMultimodalPlatform('kotlin', event)">
                                    <div class="platform-card-title">Kotlin</div>
                                    <div class="platform-card-desc">Android native</div>
                                </div>
                            </div>

                            <div id="cpp-multimodal" class="multimodal-content active">
                                <div style="background: #0f172a; border-radius: 8px; padding: 1.5rem; border: 1px solid #334155;">
                                    <pre style="background: transparent; border: none; padding: 0; margin: 0; font-size: 0.85rem;"><code style="color: #e2e8f0; font-family: 'Courier New', monospace;"><span style="color: #c084fc;">#include</span> <span style="color: #fbbf24;">&lt;executorch/extension/llm/runner/multimodal_runner.h&gt;</span>

<span style="color: #64748b;">// Create multimodal runner (LLaVA, Voxtral, etc.)</span>
<span style="color: #c084fc;">auto</span> tokenizer = load_tokenizer(<span style="color: #fbbf24;">"tokenizer.model"</span>);
<span style="color: #c084fc;">auto</span> runner = create_multimodal_runner(
    <span style="color: #fbbf24;">"llava.pte"</span>, std::move(tokenizer)
);

<span style="color: #64748b;">// Build multimodal inputs (text + image)</span>
std::vector<MultimodalInput> inputs;
inputs.emplace_back(make_text_input(<span style="color: #fbbf24;">"Describe this image:"</span>));
inputs.emplace_back(make_image_input(std::move(image)));

GenerationConfig config;
config.max_new_tokens = <span style="color: #06d6a0;">100</span>;

<span style="color: #64748b;">// Generate with streaming callback</span>
runner->generate(inputs, config,
    [](std::string token) { std::cout << token; }
);</code></pre>
                                </div>
                            </div>

                            <div id="swift-multimodal" class="multimodal-content">
                                <div style="background: #0f172a; border-radius: 8px; padding: 1.5rem; border: 1px solid #334155;">
                                    <pre style="background: transparent; border: none; padding: 0; margin: 0; font-size: 0.85rem;"><code style="color: #e2e8f0; font-family: 'Courier New', monospace;"><span style="color: #c084fc;">import</span> ExecuTorch
<span style="color: #c084fc;">import</span> AVFoundation

<span style="color: #64748b;">// Initialize multimodal runner with audio support</span>
<span style="color: #c084fc;">let</span> runner = <span style="color: #c084fc;">try</span> MultimodalRunner(
    modelPath: <span style="color: #fbbf24;">"model.pte"</span>,
    visionPath: <span style="color: #fbbf24;">"vision.pte"</span>,
    audioPath: <span style="color: #fbbf24;">"audio.pte"</span>,
    tokenizerPath: tokenizerPath,
    temperature: <span style="color: #06d6a0;">0.7</span>
)

<span style="color: #64748b;">// Process audio and image inputs</span>
<span style="color: #c084fc;">let</span> audioTensor = AudioProcessor.preprocess(audioURL)
<span style="color: #c084fc;">let</span> imageTensor = ImageProcessor.preprocess(uiImage)

<span style="color: #64748b;">// Generate with audio + vision + text</span>
<span style="color: #c084fc;">let</span> result = <span style="color: #c084fc;">try</span> runner.generateMultimodal(
    prompt: <span style="color: #fbbf24;">"Describe what you hear and see"</span>,
    audio: audioTensor,
    image: imageTensor,
    maxTokens: <span style="color: #06d6a0;">512</span>
)

<span style="color: #64748b;">// Stream tokens to UI</span>
result.tokens.forEach { token <span style="color: #c084fc;">in</span>
    <span style="color: #c084fc;">DispatchQueue</span>.main.async {
        responseText += token
    }
}</code></pre>
                                </div>
                            </div>

                            <div id="kotlin-multimodal" class="multimodal-content">
                                <div style="background: #0f172a; border-radius: 8px; padding: 1.5rem; border: 1px solid #334155;">
                                    <pre style="background: transparent; border: none; padding: 0; margin: 0; font-size: 0.85rem;"><code style="color: #e2e8f0; font-family: 'Courier New', monospace;"><span style="color: #c084fc;">import</span> org.pytorch.executorch.MultimodalRunner
<span style="color: #c084fc;">import</span> android.media.MediaRecorder

<span style="color: #64748b;">// Initialize multimodal runner with audio</span>
<span style="color: #c084fc;">val</span> runner = MultimodalRunner.create(
    modelPath = <span style="color: #fbbf24;">"model.pte"</span>,
    visionPath = <span style="color: #fbbf24;">"vision.pte"</span>,
    audioPath = <span style="color: #fbbf24;">"audio.pte"</span>,
    tokenizerPath = tokenizerPath,
    temperature = <span style="color: #06d6a0;">0.7f</span>
)

<span style="color: #64748b;">// Process audio and image inputs</span>
<span style="color: #c084fc;">val</span> audioTensor = AudioProcessor.preprocess(audioFile)
<span style="color: #c084fc;">val</span> imageTensor = ImageProcessor.preprocess(bitmap)

<span style="color: #64748b;">// Generate with audio + vision + text</span>
<span style="color: #c084fc;">val</span> result = runner.generateMultimodal(
    prompt = <span style="color: #fbbf24;">"Describe what you hear and see"</span>,
    audio = audioTensor,
    image = imageTensor,
    maxTokens = <span style="color: #06d6a0;">512</span>
)

<span style="color: #64748b;">// Display streaming response</span>
result.tokens.forEach { token ->
    runOnUiThread {
        responseView.append(token)
    }
}</code></pre>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <div style="text-align: center; margin-top: 1.5rem;">
                    <p style="color: #94a3b8; font-size: 0.9rem; margin-bottom: 1rem; font-style: italic;">
                        High-level APIs abstract away model complexity - just load, prompt, and get results
                    </p>
                    <a href="https://docs.pytorch.org/executorch/main/llm/getting-started.html"
                       style="display: inline-block; padding: 0.75rem 1.5rem; background: #059669; color: #ffffff;
                              border-radius: 8px; text-decoration: none; font-weight: 600;
                              transition: all 0.3s; box-shadow: 0 2px 8px rgba(5, 150, 105, 0.3);"
                       onmouseover="this.style.background='#047857'; this.style.boxShadow='0 4px 16px rgba(5, 150, 105, 0.4)'"
                       onmouseout="this.style.background='#059669'; this.style.boxShadow='0 2px 8px rgba(5, 150, 105, 0.3)'">
                        Explore LLM APIs →
                    </a>
                </div>
            </div>
        </div>
    </section>

    <!-- General Purpose AI -->
    <section>
        <div class="container">
            <h2 class="section-title">Universal <span class="highlight">AI Runtime</span></h2>
            <div style="text-align: center; margin: 2rem 0;">
                <div class="domain-slider">
                    <div class="domain-track">
                        <span>💬 LLMs</span>
                        <span>👁️ Computer Vision</span>
                        <span>🎤 Speech AI</span>
                        <span>🎯 Recommendations</span>
                        <span>🧠 Multimodal</span>
                        <span>⚡ Any PyTorch Model</span>
                        <!-- Duplicate for seamless loop -->
                        <span>💬 LLMs</span>
                        <span>👁️ Computer Vision</span>
                        <span>🎤 Speech AI</span>
                        <span>🎯 Recommendations</span>
                        <span>🧠 Multimodal</span>
                        <span>⚡ Any PyTorch Model</span>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Performance -->
    <section id="performance" class="alt">
        <div class="container">
            <h2 class="section-title">Comprehensive Hardware <span class="highlight">Ecosystem</span></h2>
            <p class="section-subtitle">12+ hardware backends with acceleration contributed by industry partners via open source</p>

            <div class="grid">
                <div class="card">
                    <h3 class="card-title">XNNPACK with Arm Kleidi</h3>
                    <p class="card-text">CPU acceleration across Arm and x86 architectures</p>
                </div>

                <div class="card">
                    <h3 class="card-title">Apple Core ML for Apple silicon</h3>
                    <p class="card-text">Neural Engine and Apple Silicon optimization</p>
                </div>

                <div class="card">
                    <h3 class="card-title">Qualcomm® AI Engine for Qualcomm® Hexagon™ NPU</h3>
                    <p class="card-text">Hardware-accelerated AI inference on Qualcomm platforms</p>
                </div>

                <div class="card">
                    <h3 class="card-title">Arm Ethos-U NPU</h3>
                    <p class="card-text">Microcontroller NPU for ultra-low power</p>
                </div>

                <div class="card">
                    <h3 class="card-title">Vulkan GPU</h3>
                    <p class="card-text">Cross-platform graphics acceleration</p>
                </div>

                <div class="card">
                    <h3 class="card-title">OpenVINO from Intel</h3>
                    <p class="card-text">x86 CPU and integrated GPU optimization</p>
                </div>

                <div class="card">
                    <h3 class="card-title">MediaTek NPU</h3>
                    <p class="card-text">Dimensity chipset acceleration</p>
                </div>

                <div class="card">
                    <h3 class="card-title">Samsung Exynos NPU</h3>
                    <p class="card-text">Integrated NPU optimization</p>
                </div>

                <div class="card">
                    <h3 class="card-title">NXP Semiconductors' eIQ® Neutron NPU</h3>
                    <p class="card-text">Automotive and IoT acceleration</p>
                </div>

                <div class="card">
                    <h3 class="card-title">Apple Metal Performance Shaders (MPS)</h3>
                    <p class="card-text">GPU acceleration on macOS and iOS</p>
                </div>

                <div class="card">
                    <h3 class="card-title">Arm VGF</h3>
                    <p class="card-text">Versatile graphics framework support</p>
                </div>

                <div class="card">
                    <h3 class="card-title">Cadence DSP</h3>
                    <p class="card-text">Digital signal processor optimization</p>
                </div>
            </div>

            <div style="text-align: center; margin-top: 2rem;">
                <a href="https://docs.pytorch.org/executorch/main/backends-overview.html" style="color: var(--primary); text-decoration: none; font-size: 1.1rem; font-weight: 600;">
                    → View detailed backend documentation
                </a>
            </div>
        </div>
    </section>


    <!-- Partners -->
    <section id="partners">
        <div class="container">
            <h2 class="section-title">Success <span class="highlight">Stories</span></h2>
            <p class="section-subtitle">Production deployments and strategic partnerships accelerating edge AI</p>

            <div style="margin-bottom: 3rem;">
                <h3 style="font-size: 1.5rem; margin-bottom: 1.5rem; color: var(--text-dark);">Production Deployments</h3>
                <ul style="color: var(--text-gray); line-height: 2; list-style: none; padding-left: 0;">
                    <li><strong class="highlight"><a href="https://engineering.fb.com/2025/07/28/android/executorch-on-device-ml-meta-family-of-apps/" style="color: var(--primary); text-decoration: none;">Meta Family of Apps</a>:</strong> Production deployment across Instagram, Facebook, and WhatsApp serving billions of users</li>
                    <li><strong class="highlight">Meta Reality Labs:</strong> Powers Quest 3 VR and Ray-Ban Meta Smart Glasses AI experiences</li>
                </ul>
            </div>

            <div style="margin-bottom: 3rem;">
                <h3 style="font-size: 1.5rem; margin-bottom: 1.5rem; color: var(--text-dark);">Ecosystem Integration</h3>
                <ul style="color: var(--text-gray); line-height: 2; list-style: none; padding-left: 0;">
                    <li><strong class="highlight"><a href="https://github.com/huggingface/optimum-executorch" style="color: var(--primary); text-decoration: none;">Hugging Face</a>:</strong> Optimum-ExecuTorch for direct transformer model deployment</li>
                    <li><strong class="highlight">LiquidAI:</strong> Next-generation Liquid Foundation Models optimized for edge deployment</li>
                    <li><strong class="highlight">Software Mansion:</strong> React Native ExecuTorch bringing edge AI to mobile apps</li>
                </ul>
            </div>

            <div style="margin-bottom: 3rem;">
                <h3 style="font-size: 1.5rem; margin-bottom: 1.5rem; color: var(--text-dark);">Examples & Models</h3>
                <ul style="color: var(--text-gray); line-height: 2; list-style: none; padding-left: 0;">
                    <li><strong class="highlight">LLMs:</strong> <a href="https://github.com/pytorch/executorch/blob/main/examples/models/llama/README.md" style="color: var(--primary); text-decoration: none;">Llama 3.2/3.1/3</a>, <a href="https://github.com/pytorch/executorch/blob/main/examples/models/qwen3/README.md" style="color: var(--primary); text-decoration: none;">Qwen 3</a>, <a href="https://github.com/pytorch/executorch/blob/main/examples/models/phi_4_mini/README.md" style="color: var(--primary); text-decoration: none;">Phi-4-mini</a>, <a href="https://github.com/pytorch/executorch/blob/main/examples/models/lfm2/README.md" style="color: var(--primary); text-decoration: none;">LiquidAI LFM2</a></li>
                    <li><strong class="highlight">Multimodal:</strong> <a href="https://github.com/pytorch/executorch/blob/main/examples/models/llava/README.md" style="color: var(--primary); text-decoration: none;">Llava</a> (vision-language), <a href="https://github.com/pytorch/executorch/blob/main/examples/models/voxtral/README.md" style="color: var(--primary); text-decoration: none;">Voxtral</a> (audio-language)</li>
                    <li><strong class="highlight">Vision/Speech:</strong> <a href="https://github.com/meta-pytorch/executorch-examples/tree/main/mv2" style="color: var(--primary); text-decoration: none;">MobileNetV2</a>, <a href="https://github.com/meta-pytorch/executorch-examples/tree/main/dl3" style="color: var(--primary); text-decoration: none;">DeepLabV3</a>, <a href="https://github.com/meta-pytorch/executorch-examples/tree/main/whisper/android/WhisperApp" style="color: var(--primary); text-decoration: none;">Whisper</a></li>
                </ul>
            </div>

            <div style="text-align: center; margin-top: 2rem;">
                <a href="https://docs.pytorch.org/executorch/main/success-stories.html" style="color: var(--primary); text-decoration: none; font-size: 1.1rem; font-weight: 600;">
                    → View all success stories
                </a>
            </div>
        </div>
    </section>

    <!-- CTA -->
    <section class="cta">
        <div class="container">
            <h2 class="cta-title">Ready to Deploy AI at the Edge?</h2>
            <p class="cta-text">Join thousands of developers using ExecuTorch in production</p>
            <a href="https://docs.pytorch.org/executorch/main/getting-started.html" class="btn">Get Started Today</a>
        </div>
    </section>

    <!-- Footer -->
    <footer>
        <div class="container">
            <p>ExecuTorch is part of the PyTorch ecosystem • Open source under BSD license</p>
            <p style="margin-top: 1rem;">
                <a href="https://github.com/pytorch/executorch" style="color: var(--text-gray); margin: 0 1rem; text-decoration: none;">GitHub</a>
                <a href="https://docs.pytorch.org/executorch/main/index.html" style="color: var(--text-gray); margin: 0 1rem; text-decoration: none;">Documentation</a>
                <a href="https://pytorch.org/blog" style="color: var(--text-gray); margin: 0 1rem; text-decoration: none;">Blog</a>
            </p>
        </div>
    </footer>

    <script>
        // Navbar scroll effect
        window.addEventListener('scroll', function() {
            const navbar = document.querySelector('nav');
            if (window.scrollY > 50) {
                navbar.style.background = 'rgba(48,48,48,0.97)';
                navbar.style.boxShadow = '0 2px 20px rgba(0,0,0,0.1)';
            } else {
                navbar.style.background = 'rgba(48,48,48,0.97)';
                navbar.style.boxShadow = 'none';
            }
        });

        // Smooth scrolling
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({
                        behavior: 'smooth',
                        block: 'start'
                    });
                }
            });
        });

        // Backend switcher
        function switchBackend(backend, event) {
            // Hide all backend content
            document.querySelectorAll('.backend-content').forEach(content => {
                content.classList.remove('active');
            });

            // Remove active class from all cards
            document.querySelectorAll('.backend-card').forEach(card => {
                card.classList.remove('active');
            });

            // Show selected backend content
            document.getElementById(backend).classList.add('active');

            // Add active class to clicked card
            event.currentTarget.classList.add('active');
        }

        // Platform switcher
        function switchPlatform(platform, event) {
            // Hide all platform content
            document.querySelectorAll('.platform-content').forEach(content => {
                content.classList.remove('active');
            });

            // Remove active class from all cards
            document.querySelectorAll('.platform-card').forEach(card => {
                card.classList.remove('active');
            });

            // Show selected platform content
            document.getElementById(platform).classList.add('active');

            // Add active class to clicked card
            event.currentTarget.classList.add('active');
        }

        // Multimodal platform switcher
        function switchMultimodalPlatform(platform, event) {
            // Hide all multimodal platform content
            document.querySelectorAll('.multimodal-content').forEach(content => {
                content.classList.remove('active');
            });

            // Remove active class from all multimodal platform cards
            document.querySelectorAll('.platform-switcher-multimodal .platform-card').forEach(card => {
                card.classList.remove('active');
            });

            // Show selected platform content
            document.getElementById(platform + '-multimodal').classList.add('active');

            // Add active class to clicked card
            event.currentTarget.classList.add('active');
        }

        // Hamburger menu toggle
        function toggleNav() {
            var navLinks = document.getElementById('navLinks');
            navLinks.classList.toggle('open');
        }

        // Highlight active nav link on click and close menu on mobile
        document.querySelectorAll('.nav-links a').forEach(function(link) {
            link.addEventListener('click', function() {
                document.querySelectorAll('.nav-links a').forEach(function(l) {
                    l.classList.remove('active');
                });
                this.classList.add('active');

                // Close mobile menu when clicking a link
                var navLinks = document.getElementById('navLinks');
                if (navLinks.classList.contains('open')) {
                    navLinks.classList.remove('open');
                }
            });
        });
    </script>
</body>
</html>
