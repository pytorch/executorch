# Any targets that should be shared between fbcode and xplat must be defined in
# targets.bzl. This file can contain fbcode-only targets.

load("@fbsource//xplat/executorch/build:runtime_wrapper.bzl", "runtime")
load(":targets.bzl", "define_common_targets")

oncall("executorch")

define_common_targets()

runtime.python_library(
    name = "llama_transformer",
    srcs = [
        "llama_transformer.py",
        "rope.py",
    ],
    _is_external_target = True,
    base_module = "executorch.examples.models.llama2",
    visibility = [
        "//executorch/...",
        "@EXECUTORCH_CLIENTS",
    ],
    deps = [
        "//caffe2:torch",
    ],
)

runtime.python_library(
    name = "llama2_model",
    srcs = [
        "__init__.py",
        "fairseq2.py",
        "model.py",
    ],
    _is_external_target = True,
    base_module = "executorch.examples.models.llama2",
    resources = {
        "//executorch/examples/models/llama2/params:params": "params",
    },
    visibility = [
        "//bento/...",
        "//bento_kernels/...",
        "//executorch/...",
    ],
    deps = [
        "//caffe2:torch",
        "//executorch/examples/models:model_base",
        "//executorch/examples/models/llama2:llama_transformer",
    ],
)

runtime.python_binary(
    name = "export_llama",
    main_function = "executorch.examples.models.llama2.export_llama.main",
    # visibility = ["//executorch/examples/..."],
    preload_deps = [
        "//executorch/extension/llm/custom_ops:custom_ops_aot_lib",
        "//executorch/kernels/quantized:aot_lib",
    ],
    deps = [
        ":export_library",
        "//caffe2:torch",
        "//executorch/extension/pybindings:aten_lib",
    ],
)

runtime.python_library(
    name = "export_library",
    srcs = [
        "export_llama.py",
        "export_llama_lib.py",
        "model.py",
        "source_transformation/apply_spin_quant_r1_r2.py",
        "source_transformation/quantize.py",
        "source_transformation/rms_norm.py",
        "source_transformation/rope.py",
        "source_transformation/sdpa.py",
        "source_transformation/spin_quant.py",
    ],
    _is_external_target = True,
    base_module = "executorch.examples.models.llama2",
    visibility = [
        "//bento/...",
        "//bento_kernels/...",
        "//executorch/examples/...",
        "@EXECUTORCH_CLIENTS",
    ],
    deps = [
        "//ai_codesign/gen_ai/fast_hadamard_transform:fast_hadamard_transform",
        "//caffe2:torch",
        "//executorch/examples/models:model_base",
        "//executorch/examples/models:models",
        "//executorch/extension/llm/custom_ops:custom_ops_aot_py",
        "//executorch/extension/llm/export:export_lib",
        # one definition has to be included in the user of the libarary
        # depending on what library the client wants to use
        # "//executorch/extension/pybindings:aten_lib",
        # "//executorch/extension/pybindings:portable_lib",
        # "//executorch/extension/pybindings:portable_lib_plus_custom",
        "//executorch/devtools/etrecord:etrecord",
        "//executorch/util:memory_profiler",
        "//executorch/util:python_profiler",
        "fbsource//third-party/pypi/coremltools:coremltools",
        "fbsource//third-party/pypi/sentencepiece:sentencepiece",
    ],
)
