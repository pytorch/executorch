# CLI Tool for Compile / Deploy Pre-Built QNN Artifacts

An easy-to-use tool for generating / executing .pte program from pre-built model libraries / context binaries from Qualcomm AI Engine Direct.

## Description

This tool aims for users who want to leverage ExecuTorch runtime framework with their existent artifacts generated by QNN. It's possible for them to produce .pte program in few steps:

* Model libraries(.so) came from `qnn-model-lib-generator`, further steps would be required to generate context binaries. More details will be shown in following [examples](#example_anchor).

* Context binaries(.bin) came from `qnn-context-binary-generator`:
  - To produce .pte program:
    ```bash
    $ python export.py compile
    ```
  - To perform inference with generated .pte program:
    ```bash
    $ python export.py execute
    ```

For users interested in well-known applcations, [Qualcomm AI HUB](https://aihub.qualcomm.com/) is a great approach which provides tons of optimized SOTA models ready for deploying. All of them could be downloaded in model library or context binary format.

<a name="example_anchor"></a>
## E2E Example to Get Started

### Dependencies

* Register for Qualcomm AI HUB.
* Download the corresponding QNN SDK via [QPM](https://qpm.qualcomm.com/#/main/tools/details/qualcomm_ai_engine_direct) which your favorite model is compiled with.

### Target Example

* [QuickSRNetLarge-Quantized](https://aihub.qualcomm.com/models/quicksrnetlarge_quantized?searchTerm=quantized)
* [Install](https://huggingface.co/qualcomm/QuickSRNetLarge-Quantized#installation) package as instructed.
* Create workspace and export pre-built model library:
  ```bash
  mkdir $MY_WS && cd $MY_WS
  python -m qai_hub_models.models.quicksrnetlarge_quantized.export --target-runtime qnn
  ```
* Target chipset is `SM8650`

### Compiling Program

* Serialize model library into context binary:
  ```bash
  adb shell "mkdir $DEVICE_WS"
  adb push build/quicksrnetlarge_quantized/quicksrnetlarge_quantized.so $DEVICE_WS
  adb push $QNN_SDK_ROOT/bin/aarch64-android/qnn-context-binary-generator $DEVICE_WS
  adb push $QNN_SDK_ROOT/lib/aarch64-android/libQnnHtp.so $DEVICE_WS
  adb push $QNN_SDK_ROOT/lib/aarch64-android/libQnnHtpV75Stub.so $DEVICE_WS
  adb push $QNN_SDK_ROOT/lib/aarch64-android/libQnnHtpPrepare.so $DEVICE_WS
  adb push $QNN_SDK_ROOT/lib/hexagon-v75/unsigned/libQnnHtpV75Skel.so $DEVICE_WS
  adb shell "cd $DEVICE_WS && export LD_LIBRARY_PATH=. && ./qnn-context-binary-generator --model quicksrnetlarge_quantized.so --backend libQnnHtp.so --binary_file qsrl"
  adb pull $DEVICE_WS/output/qsrl.bin .
  ```
* Compile .pte program
  ```bash
  PYTHONPATH=$EXECUTORCH_ROOT/.. python $EXECUTORCH_ROOT/examples/qualcomm/aihub/utils/export.py compile -c qsrl.bin -m SM8650
  ```
* Artifacts for checking IO information
  - `$MY_WS/output_pte/qsrl/qsrl.json`
  - `$MY_WS/output_pte/qsrl/qsrl.svg`

### Executing Program

* Prepare test image
  ```bash
  cd $MY_WS
  wget https://user-images.githubusercontent.com/12981474/40157448-eff91f06-5953-11e8-9a37-f6b5693fa03f.png -O baboon.png
  ```
  Execute following python script to generate input data:
  ```python
  import torch
  import torchvision.transforms as transforms
  from PIL import Image
  img = Image.open('baboon.png').resize((128, 128))
  transform = transforms.Compose([transforms.PILToTensor()])
  # convert (C, H, W) to (N, H, W, C)
  img = transform(img).permute(1, 2, 0).unsqueeze(0)
  torch.save(img, 'baboon.pt')
  ```
* Execute .pte program
  ```bash
  PYTHONPATH=$EXECUTORCH_ROOT/.. python $EXECUTORCH_ROOT/examples/qualcomm/aihub/utils/export.py execute -p output_pte/qsrl -i baboon.pt -s $DEVICE_SERIAL
  ```
* Post-process generated data
  ```bash
  cd output_data
  ```
  Execute following python script to generate output image:
  ```python
  import io
  import torch
  import torchvision.transforms as transforms
  # output info. could be read from output_pte/qsrl/qsrl.json | qsrl.svg
  with open('output__142.pt', 'rb') as f:
      buffer = io.BytesIO(f.read())
  img = torch.load(buffer, weights_only=False)
  transform = transforms.Compose([transforms.ToPILImage()])
  img_pil = transform(img.squeeze(0))
  img_pil.save('baboon_upscaled.png')
  ```
  You could check the upscaled result now!

## Help

Please check help messages for more information:
```bash
python export.py -h
python export.py compile -h
python export.py execute -h
```
