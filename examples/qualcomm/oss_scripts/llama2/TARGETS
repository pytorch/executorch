load("@fbcode_macros//build_defs:python_library.bzl", "python_library")
load("@fbsource//xplat/executorch/backends/qualcomm/qnn_version.bzl", "get_qnn_library_verision")
load("@fbcode_macros//build_defs:python_binary.bzl", "python_binary")
load("@fbsource//xplat/executorch/build:runtime_wrapper.bzl", "runtime")

oncall("executorch")


python_library(
    name = "static_llama",
    srcs = [
        "model/static_llama.py",
    ],
    deps = [
        "//caffe2:torch",
    ],
)

python_binary(
    name = "llama",
    srcs = ["llama.py"],
    main_function = "executorch.examples.qualcomm.oss_scripts.llama2.llama.main",
    deps = [
        ":static_llama",
        "//caffe2:torch",
        "//executorch/extension/pybindings:aten_lib",
        "//executorch/backends/qualcomm/partition:partition",
        "//executorch/backends/qualcomm/quantizer:quantizer",
        "//executorch/devtools:lib",
        "//executorch/examples/models:models",
        "//executorch/examples/qualcomm:utils",
        "//executorch/extension/export_util:export_util",
        "//executorch/extension/llm/export:export_lib",
    ],
)

runtime.command_alias(
    name = "llama_qnn",
    env = {
        "LD_LIBRARY_PATH": "$(location fbsource//third-party/qualcomm/qnn/qnn-{0}:qnn_offline_compile_libs)".format(get_qnn_library_verision()),
    },
    exe = ":llama",
)
